{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export TRANSFORMERS_CACHE=/scratch/eecs692w23_class_root/eecs692w23_class/anrao/cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! source image2paraenv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHUDrbbycP-Y",
    "outputId": "e5037ceb-2fc6-4fe3-e2a7-667804541847",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl\n",
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html\n",
      "Collecting git+https://github.com/facebookresearch/segment-anything.git (from -r requirements.txt (line 12))\n",
      "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-lfo4_3oj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-lfo4_3oj\n",
      "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 567662b0fd33ca4b022d94d3b8de896628cd32dd\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n",
      "  Using cached en_core_web_sm-3.0.0-py3-none-any.whl\n",
      "Collecting torch==1.9.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp39-cp39-linux_x86_64.whl (2041.4 MB)\n",
      "Collecting torchvision==0.10.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp39-cp39-linux_x86_64.whl (23.1 MB)\n",
      "Collecting torchaudio==0.9.0\n",
      "  Using cached torchaudio-0.9.0-cp39-cp39-manylinux1_x86_64.whl (1.9 MB)\n",
      "Collecting detectron2==0.6\n",
      "  Using cached https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/detectron2-0.6%2Bcu111-cp39-cp39-linux_x86_64.whl (6.8 MB)\n",
      "Requirement already satisfied: transformers in /home/anrao/.local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (4.29.0.dev0)\n",
      "Collecting timm==0.4.12\n",
      "  Using cached timm-0.4.12-py3-none-any.whl (376 kB)\n",
      "Collecting openai\n",
      "  Using cached openai-0.27.4-py3-none-any.whl (70 kB)\n",
      "Collecting diffusers[torch]\n",
      "  Using cached diffusers-0.15.1-py3-none-any.whl (851 kB)\n",
      "Collecting setuptools==59.5.0\n",
      "  Using cached setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "Collecting openmim\n",
      "  Using cached openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n",
      "Collecting mmcv\n",
      "  Using cached mmcv-2.0.0.tar.gz (473 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting spacy\n",
      "  Using cached spacy-3.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "Collecting lvis\n",
      "  Using cached lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /home/anrao/.local/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (1.8.0)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.26.117-py3-none-any.whl (135 kB)\n",
      "Requirement already satisfied: jsonschema in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from -r requirements.txt (line 20)) (3.2.0)\n",
      "Requirement already satisfied: entrypoints in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (0.3)\n",
      "Requirement already satisfied: nltk in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (3.6.5)\n",
      "Requirement already satisfied: typing-extensions in /home/anrao/.local/lib/python3.9/site-packages (from torch==1.9.0+cu111->-r requirements.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/anrao/.local/lib/python3.9/site-packages (from torchvision==0.10.0+cu111->-r requirements.txt (line 3)) (1.24.2)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/anrao/.local/lib/python3.9/site-packages (from torchvision==0.10.0+cu111->-r requirements.txt (line 3)) (9.1.0)\n",
      "Requirement already satisfied: future in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from detectron2==0.6->-r requirements.txt (line 6)) (0.18.2)\n",
      "Collecting hydra-core>=1.1\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /home/anrao/.local/lib/python3.9/site-packages (from detectron2==0.6->-r requirements.txt (line 6)) (0.1.8)\n",
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /home/anrao/.local/lib/python3.9/site-packages (from detectron2==0.6->-r requirements.txt (line 6)) (4.64.0)\n",
      "Collecting black==21.4b2\n",
      "  Using cached black-21.4b2-py3-none-any.whl (130 kB)\n",
      "Requirement already satisfied: matplotlib in /home/anrao/.local/lib/python3.9/site-packages (from detectron2==0.6->-r requirements.txt (line 6)) (3.5.1)\n",
      "Collecting termcolor>=1.1\n",
      "  Using cached termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting pycocotools>=2.0.2\n",
      "  Using cached pycocotools-2.0.6-cp39-cp39-linux_x86_64.whl\n",
      "Collecting pydot\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting iopath<0.1.10,>=0.1.7\n",
      "  Using cached iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Collecting fvcore<0.1.6,>=0.1.5\n",
      "  Using cached fvcore-0.1.5.post20221221-py3-none-any.whl\n",
      "Collecting omegaconf>=2.1\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: cloudpickle in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from detectron2==0.6->-r requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: toml>=0.10.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from black==21.4b2->detectron2==0.6->-r requirements.txt (line 6)) (0.10.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from black==21.4b2->detectron2==0.6->-r requirements.txt (line 6)) (0.4.3)\n",
      "Collecting pathspec<1,>=0.8.1\n",
      "  Using cached pathspec-0.11.1-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: click>=7.1.2 in /home/anrao/.local/lib/python3.9/site-packages (from black==21.4b2->detectron2==0.6->-r requirements.txt (line 6)) (8.1.2)\n",
      "Requirement already satisfied: regex>=2020.1.8 in /home/anrao/.local/lib/python3.9/site-packages (from black==21.4b2->detectron2==0.6->-r requirements.txt (line 6)) (2022.3.15)\n",
      "Requirement already satisfied: appdirs in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from black==21.4b2->detectron2==0.6->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 7)) (21.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/anrao/.local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/anrao/.local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 7)) (0.13.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/anrao/.local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 7)) (6.0)\n",
      "Requirement already satisfied: requests in /home/anrao/.local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 7)) (2.27.1)\n",
      "Requirement already satisfied: filelock in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 7)) (3.3.1)\n",
      "Requirement already satisfied: aiohttp in /home/anrao/.local/lib/python3.9/site-packages (from openai->-r requirements.txt (line 9)) (3.8.1)\n",
      "Requirement already satisfied: importlib-metadata in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from diffusers[torch]->-r requirements.txt (line 10)) (4.8.1)\n",
      "Collecting accelerate>=0.11.0\n",
      "  Using cached accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
      "Requirement already satisfied: pandas in /home/anrao/.local/lib/python3.9/site-packages (from openmim->-r requirements.txt (line 13)) (1.4.2)\n",
      "Collecting rich\n",
      "  Using cached rich-13.3.4-py3-none-any.whl (238 kB)\n",
      "Collecting model-index\n",
      "  Using cached model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pip>=19.3 in /home/anrao/.local/lib/python3.9/site-packages (from openmim->-r requirements.txt (line 13)) (22.2.2)\n",
      "Requirement already satisfied: colorama in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from openmim->-r requirements.txt (line 13)) (0.4.4)\n",
      "Requirement already satisfied: addict in /home/anrao/.local/lib/python3.9/site-packages (from mmcv->-r requirements.txt (line 14)) (2.4.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mmengine>=0.2.0\n",
      "  Using cached mmengine-0.7.2-py3-none-any.whl (366 kB)\n",
      "Requirement already satisfied: yapf in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from mmcv->-r requirements.txt (line 14)) (0.31.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/anrao/.local/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 15)) (2.0.7)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.10.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: jinja2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 15)) (3.1.2)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/anrao/.local/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 15)) (0.10.1)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Using cached thinc-8.1.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.0.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.0.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "  Using cached spacy-3.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "  Using cached spacy-3.0.6-cp39-cp39-manylinux2014_x86_64.whl (12.6 MB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.7.4-cp39-cp39-manylinux2014_x86_64.whl (10.3 MB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.0.5-cp39-cp39-manylinux2014_x86_64.whl (12.6 MB)\n",
      "  Using cached spacy-3.0.4-cp39-cp39-manylinux2014_x86_64.whl (12.6 MB)\n",
      "  Using cached spacy-3.0.3-cp39-cp39-manylinux2014_x86_64.whl (12.5 MB)\n",
      "  Using cached spacy-3.0.2-cp39-cp39-manylinux2014_x86_64.whl (12.5 MB)\n",
      "  Using cached spacy-3.0.1-cp39-cp39-manylinux2014_x86_64.whl (12.5 MB)\n",
      "  Using cached spacy-3.0.0-cp39-cp39-manylinux2014_x86_64.whl (12.5 MB)\n",
      "INFO: pip is looking at multiple versions of en-core-web-sm to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of spacy to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached spacy-3.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Using cached thinc-8.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (825 kB)\n",
      "  Using cached thinc-8.1.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (823 kB)\n",
      "  Using cached thinc-8.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (815 kB)\n",
      "INFO: pip is looking at multiple versions of en-core-web-sm to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached thinc-8.1.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (813 kB)\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached thinc-8.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (813 kB)\n",
      "  Using cached thinc-8.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (813 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (813 kB)\n",
      "Collecting blis<0.10.0,>=0.7.8\n",
      "  Using cached blis-0.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (831 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached spacy-3.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "  Using cached spacy-3.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "  Using cached spacy-3.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "INFO: pip is looking at multiple versions of spacy to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached spacy-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "Collecting thinc<8.1.0,>=8.0.14\n",
      "  Using cached thinc-8.0.17-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (668 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from lvis->-r requirements.txt (line 17)) (1.16.0)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /home/anrao/.local/lib/python3.9/site-packages (from lvis->-r requirements.txt (line 17)) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /home/anrao/.local/lib/python3.9/site-packages (from lvis->-r requirements.txt (line 17)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /home/anrao/.local/lib/python3.9/site-packages (from lvis->-r requirements.txt (line 17)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from lvis->-r requirements.txt (line 17)) (3.0.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /home/anrao/.local/lib/python3.9/site-packages (from lvis->-r requirements.txt (line 17)) (4.7.0.72)\n",
      "Requirement already satisfied: Cython>=0.29.12 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from lvis->-r requirements.txt (line 17)) (0.29.24)\n",
      "Collecting botocore<1.30.0,>=1.29.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached botocore-1.29.117-py3-none-any.whl (10.7 MB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jsonschema->-r requirements.txt (line 20)) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jsonschema->-r requirements.txt (line 20)) (21.2.0)\n",
      "Requirement already satisfied: joblib in /home/anrao/.local/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 22)) (1.1.0)\n",
      "Requirement already satisfied: psutil in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from accelerate>=0.11.0->diffusers[torch]->-r requirements.txt (line 10)) (5.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/anrao/.local/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.117->boto3->-r requirements.txt (line 19)) (1.26.9)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/anrao/.local/lib/python3.9/site-packages (from hydra-core>=1.1->detectron2==0.6->-r requirements.txt (line 6)) (4.9.3)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/anrao/.local/lib/python3.9/site-packages (from matplotlib->detectron2==0.6->-r requirements.txt (line 6)) (4.32.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/anrao/.local/lib/python3.9/site-packages (from requests->transformers->-r requirements.txt (line 7)) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anrao/.local/lib/python3.9/site-packages (from requests->transformers->-r requirements.txt (line 7)) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anrao/.local/lib/python3.9/site-packages (from requests->transformers->-r requirements.txt (line 7)) (3.3)\n",
      "Collecting click>=7.1.2\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/anrao/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/anrao/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 9)) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/anrao/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/anrao/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 9)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/anrao/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 9)) (1.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from importlib-metadata->diffusers[torch]->-r requirements.txt (line 10)) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jinja2->spacy->-r requirements.txt (line 15)) (2.1.1)\n",
      "Collecting ordered-set\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Collecting markdown\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/anrao/.local/lib/python3.9/site-packages (from pandas->openmim->-r requirements.txt (line 13)) (2022.1)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/anrao/.local/lib/python3.9/site-packages (from tensorboard->detectron2==0.6->-r requirements.txt (line 6)) (1.8.1)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Using cached grpcio-1.54.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorboard->detectron2==0.6->-r requirements.txt (line 6)) (2.0.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorboard->detectron2==0.6->-r requirements.txt (line 6)) (0.37.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting protobuf>=3.19.6\n",
      "  Using cached protobuf-4.22.3-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: mmcv\n",
      "  Building wheel for mmcv (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mmcv: filename=mmcv-2.0.0-py2.py3-none-any.whl size=719333 sha256=96587ac3236911bea15c47c33d51b6064409129d8353265d2284594be6af1c13\n",
      "  Stored in directory: /home/anrao/.cache/pip/wheels/1b/64/bd/12c67416b3f5113fe4e4be4eb04ec78d1110c8b4d7bc56e7ce\n",
      "Successfully built mmcv\n",
      "Installing collected packages: torch, termcolor, tensorboard-data-server, tabulate, spacy-legacy, smart-open, setuptools, pygments, pydot, pydantic, pyasn1, protobuf, portalocker, pathspec, ordered-set, omegaconf, oauthlib, murmurhash, mdurl, jmespath, grpcio, click, catalogue, cachetools, blis, absl-py, typer, torchvision, torchaudio, srsly, rsa, requests-oauthlib, pyasn1-modules, preshed, markdown-it-py, markdown, iopath, hydra-core, botocore, black, accelerate, timm, thinc, s3transfer, rich, pycocotools, pathy, openai, model-index, lvis, google-auth, fvcore, diffusers, spacy, openmim, mmengine, google-auth-oauthlib, boto3, tensorboard, mmcv, en_core_web_sm, detectron2\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.2\n",
      "    Uninstalling click-8.1.2:\n",
      "      Successfully uninstalled click-8.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.1 requires ruamel-yaml, which is not installed.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 accelerate-0.18.0 black-21.4b2 blis-0.7.9 boto3-1.26.117 botocore-1.29.117 cachetools-5.3.0 catalogue-2.0.8 click-7.1.2 detectron2-0.6+cu111 diffusers-0.15.1 en_core_web_sm-3.0.0 fvcore-0.1.5.post20221221 google-auth-2.17.3 google-auth-oauthlib-1.0.0 grpcio-1.54.0 hydra-core-1.3.2 iopath-0.1.9 jmespath-1.0.1 lvis-0.5.3 markdown-3.4.3 markdown-it-py-2.2.0 mdurl-0.1.2 mmcv-2.0.0 mmengine-0.7.2 model-index-0.1.11 murmurhash-1.0.9 oauthlib-3.2.2 omegaconf-2.3.0 openai-0.27.4 openmim-0.3.7 ordered-set-4.1.0 pathspec-0.11.1 pathy-0.10.1 portalocker-2.7.0 preshed-3.0.8 protobuf-4.22.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycocotools-2.0.6 pydantic-1.8.2 pydot-1.4.2 pygments-2.15.1 requests-oauthlib-1.3.1 rich-13.3.4 rsa-4.9 s3transfer-0.6.0 setuptools-59.5.0 smart-open-6.3.0 spacy-3.0.9 spacy-legacy-3.0.12 srsly-2.4.6 tabulate-0.9.0 tensorboard-2.12.2 tensorboard-data-server-0.7.0 termcolor-2.2.0 thinc-8.0.17 timm-0.4.12 torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111 typer-0.3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05esHYgQck3b",
    "outputId": "b9026c75-ebbf-4086-a773-2d0ff4ff43ab"
   },
   "source": [
    "!mkdir pretrained_models; cd pretrained_models; wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth; wget https://datarelease.blob.core.windows.net/grit/models/grit_b_densecap_objectdet.pth; cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0nwT_3fhkROs",
    "outputId": "1e6eef29-0760-4da8-a297-ed22b72740a5"
   },
   "source": [
    "! cd pretrained_models; wget -c https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth; cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pF4vbRwUtjc_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQBRc9fYtqhn",
    "outputId": "27bd3067-d57a-4ed1-8b46-bdba9b32835b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;34m----Welcome to the Image2Paragraph toolbox...-----\u001b[0m\n",
      "\u001b[1;33m--------------Initializing models...--------------\u001b[0m\n",
      "\u001b[1;31m------This is time-consuming, please wait...------\u001b[0m\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:14<00:00,  7.20s/it]\n",
      "initalize edit anything model\n",
      "\u001b[1;32m----------Model initialization finished!----------\u001b[0m\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210325_121618 111\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210325_124510 33\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210325_125317 34\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210325_125749 20\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210325_170350 80\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210325_173840 69\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210325_175421 17\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210325_175902 37\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210401_172132 28\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210401_172843 23\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210401_173413 9\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210401_173658 8\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210405_152436 43\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210405_153510 17\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210405_153941 39\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210405_154441 38\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210407_170235 33\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210407_171115 30\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210407_171817 40\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210407_173104 23\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210407_173846 18\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210408_161512 46\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210408_162734 13\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210408_163106 32\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210408_164019 90\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210408_165949 36\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_100623 85\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_102828 30\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_103607 17\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_104028 13\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_104406 16\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_130105 0\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_130938 32\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_131720 45\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_132732 53\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210409_133913 0\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_142313 76\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_144034 25\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_144657 26\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_145310 45\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_150329 0\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_170855 70\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_172801 21\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_173317 18\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_173743 25\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210423_174339 32\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210429_143419 109\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210429_150209 65\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210429_151811 67\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210429_153316 45\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210429_154347 41\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210430_163839 21\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210430_164427 28\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210430_165255 21\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "/home/anrao/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1341: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with two wooden blocks and a white floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "/home/anrao/.local/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/home/anrao/.local/lib/python3.9/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=linear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/home/anrao/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is made: [35, 108, 353, 211]; a small brown basket: [166, 100, 198, 118]; a small black box: [81, 98, 163, 122]; a bed in the room: [41, 24, 351, 175]; the bed is made: [51, 48, 224, 155]; white wall in the background: [0, 1, 125, 128]; the wall is white: [123, 1, 365, 118]; the basket is brown: [161, 95, 203, 123]; the snow is white: [202, 128, 320, 198]; a black square object: [363, 104, 383, 128]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 116, 383, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[123, 1, 260, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 123, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[82, 102, 80, 19]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a door in the middle: [0, 0, 383, 129]; a white snowy area with a black background: [0, 116, 383, 96]; a black and white image of a building with a clock: [123, 1, 260, 121]; a gray shaped piece of paper: [0, 0, 123, 129]; a black block of stone on a black background: [82, 102, 80, 19]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with two wooden blocks and a white floor; Dense Caption: the bed is made: [35, 108, 353, 211]; a small brown basket: [166, 100, 198, 118]; a small black box: [81, 98, 163, 122]; a bed in the room: [41, 24, 351, 175]; the bed is made: [51, 48, 224, 155]; white wall in the background: [0, 1, 125, 128]; the wall is white: [123, 1, 365, 118]; the basket is brown: [161, 95, 203, 123]; the snow is white: [202, 128, 320, 198]; a black square object: [363, 104, 383, 128]; ; Region Captions: a gray wall with a door in the middle: [0, 0, 383, 129]; a white snowy area with a black background: [0, 116, 383, 96]; a black and white image of a building with a clock: [123, 1, 260, 121]; a gray shaped piece of paper: [0, 0, 123, 129]; a black block of stone on a black background: [82, 102, 80, 19]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden floor and a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is made: [33, 75, 352, 210]; a brown wicker basket: [139, 65, 173, 84]; the bed is made: [36, 10, 349, 144]; the basket is made of wood: [33, 63, 136, 91]; a black square object with white dots: [316, 65, 382, 102]; the wall is white: [79, 1, 364, 82]; the basket is brown: [134, 60, 178, 89]; the bed is made: [24, 37, 235, 164]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 82, 383, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 87, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 137, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[35, 68, 100, 21]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy area with a black background: [0, 82, 383, 130]; a gray wall with a black background: [0, 0, 383, 93]; a grey paper with the word'save' on it: [0, 0, 87, 93]; a grey square with a white letter on it: [0, 0, 137, 94]; a black and white image of a black and white tile: [35, 68, 100, 21]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden floor and a wooden box; Dense Caption: the bed is made: [33, 75, 352, 210]; a brown wicker basket: [139, 65, 173, 84]; the bed is made: [36, 10, 349, 144]; the basket is made of wood: [33, 63, 136, 91]; a black square object with white dots: [316, 65, 382, 102]; the wall is white: [79, 1, 364, 82]; the basket is brown: [134, 60, 178, 89]; the bed is made: [24, 37, 235, 164]; ; Region Captions: a white snowy area with a black background: [0, 82, 383, 130]; a gray wall with a black background: [0, 0, 383, 93]; a grey paper with the word'save' on it: [0, 0, 87, 93]; a grey square with a white letter on it: [0, 0, 137, 94]; a black and white image of a black and white tile: [35, 68, 100, 21]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden box and a white floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the basket is brown: [102, 55, 162, 87]; the bed is made: [34, 76, 348, 210]; the pillow is brown: [0, 50, 105, 111]; the wall is white: [35, 0, 350, 91]; white pillow on bed: [0, 0, 36, 59]; a brown box on the bed: [27, 8, 221, 121]; a bed in the room: [25, 16, 271, 193]; the pillow is black and white: [5, 0, 110, 115]; the basket is brown: [96, 47, 173, 99]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 80, 383, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 58, 103, 50]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 33, 58]\n",
      "process_ann took 0.00 seconds\n",
      "[104, 59, 55, 26]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a white floor with a black background: [0, 80, 383, 132]; a black and white image of a black and white image: [2, 0, 381, 90]; a black block of bricks on a black background: [0, 58, 103, 50]; a black and white image of a triangle: [0, 0, 33, 58]; a stack of wooden blocks on a black background: [104, 59, 55, 26]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden box and a white floor; Dense Caption: the basket is brown: [102, 55, 162, 87]; the bed is made: [34, 76, 348, 210]; the pillow is brown: [0, 50, 105, 111]; the wall is white: [35, 0, 350, 91]; white pillow on bed: [0, 0, 36, 59]; a brown box on the bed: [27, 8, 221, 121]; a bed in the room: [25, 16, 271, 193]; the pillow is black and white: [5, 0, 110, 115]; the basket is brown: [96, 47, 173, 99]; ; Region Captions: a white floor with a black background: [0, 80, 383, 132]; a black and white image of a black and white image: [2, 0, 381, 90]; a black block of bricks on a black background: [0, 58, 103, 50]; a black and white image of a triangle: [0, 0, 33, 58]; a stack of wooden blocks on a black background: [104, 59, 55, 26]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden table and a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden trunk: [163, 84, 269, 164]; the blanket is checkered: [0, 74, 169, 173]; bed in the bedroom: [31, 75, 343, 211]; a bed with a box on it: [14, 10, 279, 194]; white wall behind bed: [0, 1, 113, 86]; the suitcase is brown: [115, 68, 301, 193]; the wall is white: [84, 1, 348, 154]; the sheet is white in color: [66, 152, 168, 208]; a pen is on the bed: [24, 78, 94, 98]; the bed is made: [4, 77, 135, 139]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[104, 1, 279, 175]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 117, 383, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 79, 261, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 79, 168, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 112, 85]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a 3d model of a wall with a black background: [104, 1, 279, 175]; a mountain with a white png: [0, 117, 383, 95]; a block of ice with a blue light: [0, 79, 261, 90]; a black and white block with a blue window: [0, 79, 168, 90]; a grey square with a black background: [0, 0, 112, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden table and a wooden box; Dense Caption: a brown wooden trunk: [163, 84, 269, 164]; the blanket is checkered: [0, 74, 169, 173]; bed in the bedroom: [31, 75, 343, 211]; a bed with a box on it: [14, 10, 279, 194]; white wall behind bed: [0, 1, 113, 86]; the suitcase is brown: [115, 68, 301, 193]; the wall is white: [84, 1, 348, 154]; the sheet is white in color: [66, 152, 168, 208]; a pen is on the bed: [24, 78, 94, 98]; the bed is made: [4, 77, 135, 139]; ; Region Captions: a 3d model of a wall with a black background: [104, 1, 279, 175]; a mountain with a white png: [0, 117, 383, 95]; a block of ice with a blue light: [0, 79, 261, 90]; a black and white block with a blue window: [0, 79, 168, 90]; a grey square with a black background: [0, 0, 112, 85]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden box and a wooden table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden trunk: [114, 94, 246, 197]; the checkered bedspread: [0, 85, 127, 188]; a bedroom: [0, 2, 381, 207]; white tablecloth on the table: [0, 137, 382, 211]; white cylinder on wall: [0, 0, 58, 96]; the bed has a wooden headboard: [20, 73, 253, 208]; a black object on the bed: [0, 89, 56, 112]; a bed with a white and black blanket: [0, 2, 133, 197]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[38, 0, 345, 196]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 104, 383, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 138, 383, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[118, 102, 122, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 126, 94]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.50 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a black background: [38, 0, 345, 196]; a black and white image of a mountain: [0, 104, 383, 108]; a silver triangle with a black background: [0, 138, 383, 75]; a wooden block on a black background: [118, 102, 122, 92]; a black and white pixelated block: [0, 90, 126, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden box and a wooden table; Dense Caption: a large wooden trunk: [114, 94, 246, 197]; the checkered bedspread: [0, 85, 127, 188]; a bedroom: [0, 2, 381, 207]; white tablecloth on the table: [0, 137, 382, 211]; white cylinder on wall: [0, 0, 58, 96]; the bed has a wooden headboard: [20, 73, 253, 208]; a black object on the bed: [0, 89, 56, 112]; a bed with a white and black blanket: [0, 2, 133, 197]; ; Region Captions: a gray wall with a black background: [38, 0, 345, 196]; a black and white image of a mountain: [0, 104, 383, 108]; a silver triangle with a black background: [0, 138, 383, 75]; a wooden block on a black background: [118, 102, 122, 92]; a black and white pixelated block: [0, 90, 126, 94]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden box next to it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden trunk: [137, 84, 274, 201]; the checkered bedspread: [0, 73, 150, 183]; the wall is white: [45, 0, 341, 203]; white table top: [0, 86, 381, 210]; the sheet is white in color: [69, 161, 158, 211]; white wall behind bed: [0, 1, 88, 86]; a white tag on the mattress: [17, 84, 42, 100]; the top of the box is brown: [138, 90, 272, 128]; the bench is made of wood: [188, 103, 245, 150]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 202]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 129, 383, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 129, 245, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 81, 148, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[139, 95, 129, 105]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a 3d model of a room with a black wall: [0, 0, 383, 202]; a silver mountain logo with a black background: [0, 129, 383, 84]; a silver triangle with a black background: [0, 129, 245, 83]; a black and white image of a minecraft block: [0, 81, 148, 99]; a wooden block in minecraft: [139, 95, 129, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden box next to it; Dense Caption: a large wooden trunk: [137, 84, 274, 201]; the checkered bedspread: [0, 73, 150, 183]; the wall is white: [45, 0, 341, 203]; white table top: [0, 86, 381, 210]; the sheet is white in color: [69, 161, 158, 211]; white wall behind bed: [0, 1, 88, 86]; a white tag on the mattress: [17, 84, 42, 100]; the top of the box is brown: [138, 90, 272, 128]; the bench is made of wood: [188, 103, 245, 150]; ; Region Captions: a 3d model of a room with a black wall: [0, 0, 383, 202]; a silver mountain logo with a black background: [0, 129, 383, 84]; a silver triangle with a black background: [0, 129, 245, 83]; a black and white image of a minecraft block: [0, 81, 148, 99]; a wooden block in minecraft: [139, 95, 129, 105]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden box next to it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden trunk: [137, 84, 274, 201]; the checkered bedspread: [0, 73, 150, 183]; the wall is white: [45, 0, 341, 203]; white table top: [0, 86, 381, 210]; the sheet is white in color: [69, 161, 158, 211]; white wall behind bed: [0, 1, 88, 86]; a white tag on the mattress: [17, 84, 42, 100]; the top of the box is brown: [138, 90, 272, 128]; the bench is made of wood: [188, 103, 245, 150]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 202]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 129, 383, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 129, 245, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 81, 148, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[139, 95, 129, 105]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a 3d model of a room with a black wall: [0, 0, 383, 202]; a silver mountain logo with a black background: [0, 129, 383, 84]; a silver triangle with a black background: [0, 129, 245, 83]; a black and white image of a minecraft block: [0, 81, 148, 99]; a wooden block in minecraft: [139, 95, 129, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden box next to it; Dense Caption: a large wooden trunk: [137, 84, 274, 201]; the checkered bedspread: [0, 73, 150, 183]; the wall is white: [45, 0, 341, 203]; white table top: [0, 86, 381, 210]; the sheet is white in color: [69, 161, 158, 211]; white wall behind bed: [0, 1, 88, 86]; a white tag on the mattress: [17, 84, 42, 100]; the top of the box is brown: [138, 90, 272, 128]; the bench is made of wood: [188, 103, 245, 150]; ; Region Captions: a 3d model of a room with a black wall: [0, 0, 383, 202]; a silver mountain logo with a black background: [0, 129, 383, 84]; a silver triangle with a black background: [0, 129, 245, 83]; a black and white image of a minecraft block: [0, 81, 148, 99]; a wooden block in minecraft: [139, 95, 129, 105]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden box in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden box: [83, 49, 229, 153]; a checkered bedspread: [0, 40, 96, 148]; white sheets on the bed: [33, 93, 349, 212]; a bedroom: [0, 3, 379, 206]; the table is brown: [5, 30, 242, 164]; a line of wood: [86, 53, 226, 90]; white sheet on bed: [28, 132, 256, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 145]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 100, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[85, 57, 139, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 45, 95, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 21, 13, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.70 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 1, 383, 145]; a white and black png image of a mountain: [0, 100, 383, 112]; a wooden block on a black background: [85, 57, 139, 92]; a black and white pixelated image of a minecraft table: [0, 45, 95, 97]; the black sailor shoes are on a black background: [0, 21, 13, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden box in a minecraft game; Dense Caption: a large wooden box: [83, 49, 229, 153]; a checkered bedspread: [0, 40, 96, 148]; white sheets on the bed: [33, 93, 349, 212]; a bedroom: [0, 3, 379, 206]; the table is brown: [5, 30, 242, 164]; a line of wood: [86, 53, 226, 90]; white sheet on bed: [28, 132, 256, 211]; ; Region Captions: a black and white image of a wall: [0, 1, 383, 145]; a white and black png image of a mountain: [0, 100, 383, 112]; a wooden block on a black background: [85, 57, 139, 92]; a black and white pixelated image of a minecraft table: [0, 45, 95, 97]; the black sailor shoes are on a black background: [0, 21, 13, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden box in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden box: [83, 49, 229, 153]; a checkered bedspread: [0, 40, 96, 148]; white sheets on the bed: [33, 93, 349, 212]; a bedroom: [0, 3, 379, 206]; the table is brown: [5, 30, 242, 164]; a line of wood: [86, 53, 226, 90]; white sheet on bed: [28, 132, 256, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 145]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 100, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[85, 57, 139, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 45, 95, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 21, 13, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 1, 383, 145]; a white and black png image of a mountain: [0, 100, 383, 112]; a wooden block on a black background: [85, 57, 139, 92]; a black and white pixelated image of a minecraft table: [0, 45, 95, 97]; the black sailor shoes are on a black background: [0, 21, 13, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden box in a minecraft game; Dense Caption: a large wooden box: [83, 49, 229, 153]; a checkered bedspread: [0, 40, 96, 148]; white sheets on the bed: [33, 93, 349, 212]; a bedroom: [0, 3, 379, 206]; the table is brown: [5, 30, 242, 164]; a line of wood: [86, 53, 226, 90]; white sheet on bed: [28, 132, 256, 211]; ; Region Captions: a black and white image of a wall: [0, 1, 383, 145]; a white and black png image of a mountain: [0, 100, 383, 112]; a wooden block on a black background: [85, 57, 139, 92]; a black and white pixelated image of a minecraft table: [0, 45, 95, 97]; the black sailor shoes are on a black background: [0, 21, 13, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green square on the table: [203, 71, 297, 157]; white bed sheets: [1, 48, 381, 211]; the basket is small: [69, 46, 153, 75]; a white wall: [69, 0, 311, 58]; the bag is green: [173, 58, 320, 177]; the basket is on the bed: [46, 11, 185, 112]; a dark colored basket: [266, 41, 335, 61]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 57, 383, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[74, 0, 229, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 83, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[207, 76, 87, 78]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black square in the middle of a snowy field: [0, 57, 383, 155]; a room with a black wall and a white door: [0, 0, 383, 127]; a grey box with a white background: [74, 0, 229, 60]; a grey piece of paper with a black background: [0, 0, 83, 127]; a green block in minecraft: [207, 76, 87, 78]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green square on the table: [203, 71, 297, 157]; white bed sheets: [1, 48, 381, 211]; the basket is small: [69, 46, 153, 75]; a white wall: [69, 0, 311, 58]; the bag is green: [173, 58, 320, 177]; the basket is on the bed: [46, 11, 185, 112]; a dark colored basket: [266, 41, 335, 61]; ; Region Captions: a black square in the middle of a snowy field: [0, 57, 383, 155]; a room with a black wall and a white door: [0, 0, 383, 127]; a grey box with a white background: [74, 0, 229, 60]; a grey piece of paper with a black background: [0, 0, 83, 127]; a green block in minecraft: [207, 76, 87, 78]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green square in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green square with lines: [147, 131, 281, 211]; white table top: [0, 5, 382, 211]; the basket is on the bed: [0, 9, 81, 39]; the bed is white: [32, 17, 317, 151]; the pillows are black: [28, 2, 293, 68]; the basket is made of wood: [217, 6, 283, 30]; a small hole in the snow: [152, 41, 177, 56]; a hole in the snow: [145, 35, 184, 63]; the snow is white and clear: [94, 56, 341, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 23, 383, 189]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 58]\n",
      "process_ann took 0.00 seconds\n",
      "[155, 138, 122, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[261, 0, 122, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 13, 80, 24]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white floor with a hole in it: [0, 23, 383, 189]; a 3d image of a room with a door: [0, 0, 383, 58]; a green square with the word li: [155, 138, 122, 75]; a grey teddy bear is sitting on a black background: [261, 0, 122, 57]; a black block of ice with a black ice cube: [0, 13, 80, 24]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green square in a minecraft game; Dense Caption: green square with lines: [147, 131, 281, 211]; white table top: [0, 5, 382, 211]; the basket is on the bed: [0, 9, 81, 39]; the bed is white: [32, 17, 317, 151]; the pillows are black: [28, 2, 293, 68]; the basket is made of wood: [217, 6, 283, 30]; a small hole in the snow: [152, 41, 177, 56]; a hole in the snow: [145, 35, 184, 63]; the snow is white and clear: [94, 56, 341, 211]; ; Region Captions: a white floor with a hole in it: [0, 23, 383, 189]; a 3d image of a room with a door: [0, 0, 383, 58]; a green square with the word li: [155, 138, 122, 75]; a grey teddy bear is sitting on a black background: [261, 0, 122, 57]; a black block of ice with a black ice cube: [0, 13, 80, 24]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden box and a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [210, 67, 280, 125]; square shaped wicker basket: [115, 47, 221, 105]; a bed in a room: [28, 38, 347, 211]; the boxes are made of wood: [174, 39, 321, 175]; the clock is made of wicker: [92, 24, 233, 123]; the bed is white: [27, 112, 280, 211]; a design on the top of the ottoman: [138, 52, 187, 71]; two brown baskets on white table: [114, 44, 283, 129]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 78, 383, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 181]\n",
      "process_ann took 0.00 seconds\n",
      "[185, 0, 198, 181]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 184, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 380, 88]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy mountain with a white ridge: [0, 78, 383, 134]; a 3d rendering of a room with a black wall: [0, 0, 383, 181]; a gray wall with a black arrow on it: [185, 0, 198, 181]; a grey shaped object with a black background: [0, 0, 184, 88]; a grey png file with a black background: [0, 0, 380, 88]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden box and a wooden box; Dense Caption: a brown wooden box: [210, 67, 280, 125]; square shaped wicker basket: [115, 47, 221, 105]; a bed in a room: [28, 38, 347, 211]; the boxes are made of wood: [174, 39, 321, 175]; the clock is made of wicker: [92, 24, 233, 123]; the bed is white: [27, 112, 280, 211]; a design on the top of the ottoman: [138, 52, 187, 71]; two brown baskets on white table: [114, 44, 283, 129]; ; Region Captions: a white snowy mountain with a white ridge: [0, 78, 383, 134]; a 3d rendering of a room with a black wall: [0, 0, 383, 181]; a gray wall with a black arrow on it: [185, 0, 198, 181]; a grey shaped object with a black background: [0, 0, 184, 88]; a grey png file with a black background: [0, 0, 380, 88]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden box and a wooden floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [199, 64, 268, 122]; square woven brown basket: [100, 45, 210, 105]; a bed in a room: [30, 33, 346, 210]; the bed is made of wood: [166, 27, 332, 182]; the clock is made of wicker: [84, 27, 219, 127]; the bed is white: [26, 114, 276, 211]; a design on the top of the ottoman: [125, 49, 179, 69]; two brown boxes on white table: [76, 26, 302, 148]; a white wall: [0, 1, 173, 90]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 77, 383, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 179]\n",
      "process_ann took 0.00 seconds\n",
      "[173, 0, 210, 179]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 365, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 172, 88]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a white snowflake with a black background: [0, 77, 383, 135]; a room with a black floor and a black wall: [0, 0, 383, 179]; a black and white image of a wall: [173, 0, 210, 179]; a white and gray paper with a black background: [0, 0, 365, 88]; a gray shaped object with a black background: [0, 0, 172, 88]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden box and a wooden floor; Dense Caption: a brown wooden box: [199, 64, 268, 122]; square woven brown basket: [100, 45, 210, 105]; a bed in a room: [30, 33, 346, 210]; the bed is made of wood: [166, 27, 332, 182]; the clock is made of wicker: [84, 27, 219, 127]; the bed is white: [26, 114, 276, 211]; a design on the top of the ottoman: [125, 49, 179, 69]; two brown boxes on white table: [76, 26, 302, 148]; a white wall: [0, 1, 173, 90]; ; Region Captions: a white snowflake with a black background: [0, 77, 383, 135]; a room with a black floor and a black wall: [0, 0, 383, 179]; a black and white image of a wall: [173, 0, 210, 179]; a white and gray paper with a black background: [0, 0, 365, 88]; a gray shaped object with a black background: [0, 0, 172, 88]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green lego with yellow lines: [46, 112, 221, 212]; the wooden box on the bed: [225, 74, 291, 119]; square shaped wicker basket: [150, 69, 235, 101]; a white table: [38, 67, 351, 212]; a bed in the room: [61, 24, 316, 156]; the boxes are made of wood: [120, 52, 305, 128]; the wall is white: [0, 1, 211, 90]; the mat is green in color: [103, 134, 206, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[208, 0, 175, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 208, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[48, 118, 167, 94]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a room with a black wall and a black floor: [0, 0, 383, 149]; a black and white image of a small square: [0, 90, 383, 122]; a gray wall with a black slanted edge: [208, 0, 175, 149]; a gray piece of paper with a black background: [0, 0, 208, 94]; a green block in minecraft: [48, 118, 167, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft room; Dense Caption: green lego with yellow lines: [46, 112, 221, 212]; the wooden box on the bed: [225, 74, 291, 119]; square shaped wicker basket: [150, 69, 235, 101]; a white table: [38, 67, 351, 212]; a bed in the room: [61, 24, 316, 156]; the boxes are made of wood: [120, 52, 305, 128]; the wall is white: [0, 1, 211, 90]; the mat is green in color: [103, 134, 206, 209]; ; Region Captions: a room with a black wall and a black floor: [0, 0, 383, 149]; a black and white image of a small square: [0, 90, 383, 122]; a gray wall with a black slanted edge: [208, 0, 175, 149]; a gray piece of paper with a black background: [0, 0, 208, 94]; a green block in minecraft: [48, 118, 167, 94]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green square on blanket: [96, 98, 249, 211]; the brown wooden box: [265, 60, 346, 107]; white table top: [0, 64, 382, 211]; the basket is made of plastic: [183, 50, 278, 86]; the boxes are brown: [128, 24, 344, 141]; a bed in a room: [41, 6, 344, 185]; two brown wooden boxes: [177, 44, 351, 111]; the box is brown: [243, 39, 362, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 72, 383, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 250, 72]\n",
      "process_ann took 0.00 seconds\n",
      "[99, 102, 146, 111]\n",
      "process_ann took 0.00 seconds\n",
      "[246, 0, 137, 125]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small square: [0, 72, 383, 140]; a black and white image of a room with a black wall: [0, 0, 383, 125]; a gray piece of paper with a black background: [0, 0, 250, 72]; a green block on a black background: [99, 102, 146, 111]; a gray png of a gun with a black handle: [246, 0, 137, 125]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft room; Dense Caption: green square on blanket: [96, 98, 249, 211]; the brown wooden box: [265, 60, 346, 107]; white table top: [0, 64, 382, 211]; the basket is made of plastic: [183, 50, 278, 86]; the boxes are brown: [128, 24, 344, 141]; a bed in a room: [41, 6, 344, 185]; two brown wooden boxes: [177, 44, 351, 111]; the box is brown: [243, 39, 362, 127]; ; Region Captions: a black and white image of a small square: [0, 72, 383, 140]; a black and white image of a room with a black wall: [0, 0, 383, 125]; a gray piece of paper with a black background: [0, 0, 250, 72]; a green block on a black background: [99, 102, 146, 111]; a gray png of a gun with a black handle: [246, 0, 137, 125]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green square on blanket: [69, 112, 235, 211]; the brown wooden box: [241, 75, 313, 121]; square shaped wicker basket: [164, 67, 254, 103]; a white table: [46, 60, 349, 212]; a bed in the room: [73, 16, 335, 160]; white wall in a bedroom: [1, 1, 228, 89]; the boxes are brown: [148, 53, 323, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 225, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[225, 0, 158, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[71, 118, 159, 95]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a room with a black wall and a white floor: [0, 0, 383, 146]; a black and white image of a small black and white cat: [0, 90, 383, 122]; a gray square with a black background: [0, 0, 225, 92]; a gray png of a gun with a black background: [225, 0, 158, 146]; a green square block on a black background: [71, 118, 159, 95]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft room; Dense Caption: green square on blanket: [69, 112, 235, 211]; the brown wooden box: [241, 75, 313, 121]; square shaped wicker basket: [164, 67, 254, 103]; a white table: [46, 60, 349, 212]; a bed in the room: [73, 16, 335, 160]; white wall in a bedroom: [1, 1, 228, 89]; the boxes are brown: [148, 53, 323, 127]; ; Region Captions: a room with a black wall and a white floor: [0, 0, 383, 146]; a black and white image of a small black and white cat: [0, 90, 383, 122]; a gray square with a black background: [0, 0, 225, 92]; a gray png of a gun with a black background: [225, 0, 158, 146]; a green square block on a black background: [71, 118, 159, 95]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green square on blanket: [69, 112, 235, 211]; the brown wooden box: [241, 75, 313, 121]; square shaped wicker basket: [164, 67, 254, 103]; a white table: [46, 60, 349, 212]; a bed in the room: [73, 16, 335, 160]; white wall in a bedroom: [1, 1, 228, 89]; the boxes are brown: [148, 53, 323, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 225, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[225, 0, 158, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[71, 118, 159, 95]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a room with a black wall and a white floor: [0, 0, 383, 146]; a black and white image of a small black and white cat: [0, 90, 383, 122]; a gray square with a black background: [0, 0, 225, 92]; a gray png of a gun with a black background: [225, 0, 158, 146]; a green square block on a black background: [71, 118, 159, 95]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft room; Dense Caption: green square on blanket: [69, 112, 235, 211]; the brown wooden box: [241, 75, 313, 121]; square shaped wicker basket: [164, 67, 254, 103]; a white table: [46, 60, 349, 212]; a bed in the room: [73, 16, 335, 160]; white wall in a bedroom: [1, 1, 228, 89]; the boxes are brown: [148, 53, 323, 127]; ; Region Captions: a room with a black wall and a white floor: [0, 0, 383, 146]; a black and white image of a small black and white cat: [0, 90, 383, 122]; a gray square with a black background: [0, 0, 225, 92]; a gray png of a gun with a black background: [225, 0, 158, 146]; a green square block on a black background: [71, 118, 159, 95]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green square on blanket: [69, 112, 235, 211]; the brown wooden box: [241, 75, 313, 121]; square shaped wicker basket: [164, 67, 254, 103]; a white table: [46, 60, 349, 212]; a bed in the room: [73, 16, 335, 160]; white wall in a bedroom: [1, 1, 228, 89]; the boxes are brown: [148, 53, 323, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 225, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[225, 0, 158, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[71, 118, 159, 95]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a room with a black wall and a white floor: [0, 0, 383, 146]; a black and white image of a small black and white cat: [0, 90, 383, 122]; a gray square with a black background: [0, 0, 225, 92]; a gray png of a gun with a black background: [225, 0, 158, 146]; a green square block on a black background: [71, 118, 159, 95]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft room; Dense Caption: green square on blanket: [69, 112, 235, 211]; the brown wooden box: [241, 75, 313, 121]; square shaped wicker basket: [164, 67, 254, 103]; a white table: [46, 60, 349, 212]; a bed in the room: [73, 16, 335, 160]; white wall in a bedroom: [1, 1, 228, 89]; the boxes are brown: [148, 53, 323, 127]; ; Region Captions: a room with a black wall and a white floor: [0, 0, 383, 146]; a black and white image of a small black and white cat: [0, 90, 383, 122]; a gray square with a black background: [0, 0, 225, 92]; a gray png of a gun with a black background: [225, 0, 158, 146]; a green square block on a black background: [71, 118, 159, 95]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "square green plastic object: [132, 71, 283, 210]; white table top: [0, 30, 382, 212]; a brown box: [313, 35, 383, 98]; the basket is black: [220, 22, 339, 64]; the wall is white: [37, 2, 339, 101]; the corner of a black book: [0, 20, 49, 50]; the wall is white: [1, 1, 345, 53]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 42, 383, 170]\n",
      "process_ann took 0.00 seconds\n",
      "[137, 77, 142, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 44]\n",
      "process_ann took 0.00 seconds\n",
      "[224, 27, 115, 35]\n",
      "process_ann took 0.00 seconds\n",
      "[296, 0, 87, 43]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.50 seconds\n",
      "finished...\n",
      "\n",
      "a black square sitting on a white surface: [0, 42, 383, 170]; a green block in minecraft: [137, 77, 142, 134]; a grey shirt with a black background: [0, 0, 383, 44]; a black and white patterned box: [224, 27, 115, 35]; a black and gray striped shirt: [296, 0, 87, 43]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: square green plastic object: [132, 71, 283, 210]; white table top: [0, 30, 382, 212]; a brown box: [313, 35, 383, 98]; the basket is black: [220, 22, 339, 64]; the wall is white: [37, 2, 339, 101]; the corner of a black book: [0, 20, 49, 50]; the wall is white: [1, 1, 345, 53]; ; Region Captions: a black square sitting on a white surface: [0, 42, 383, 170]; a green block in minecraft: [137, 77, 142, 134]; a grey shirt with a black background: [0, 0, 383, 44]; a black and white patterned box: [224, 27, 115, 35]; a black and gray striped shirt: [296, 0, 87, 43]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic diamond on a blanket: [53, 141, 224, 212]; the wooden box on the bed: [229, 100, 296, 147]; small square metal box: [154, 97, 238, 128]; white table top: [41, 98, 349, 212]; a bedroom: [0, 1, 381, 210]; a bed in the room: [81, 29, 330, 185]; a brown wicker basket: [190, 49, 341, 184]; white wall in the background: [1, 1, 211, 116]; two brown baskets on white table: [151, 90, 297, 146]; the boxes are brown: [134, 77, 327, 171]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 174]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 210, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[212, 0, 171, 174]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 117, 383, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 145, 167, 68]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a room with a corner and a black wall: [0, 0, 383, 174]; a gray square with a white background: [0, 0, 210, 120]; a black and white image of a wall: [212, 0, 171, 174]; a black and white image of a stairway: [0, 117, 383, 95]; a green square on a black background: [54, 145, 167, 68]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft room; Dense Caption: green plastic diamond on a blanket: [53, 141, 224, 212]; the wooden box on the bed: [229, 100, 296, 147]; small square metal box: [154, 97, 238, 128]; white table top: [41, 98, 349, 212]; a bedroom: [0, 1, 381, 210]; a bed in the room: [81, 29, 330, 185]; a brown wicker basket: [190, 49, 341, 184]; white wall in the background: [1, 1, 211, 116]; two brown baskets on white table: [151, 90, 297, 146]; the boxes are brown: [134, 77, 327, 171]; ; Region Captions: a room with a corner and a black wall: [0, 0, 383, 174]; a gray square with a white background: [0, 0, 210, 120]; a black and white image of a wall: [212, 0, 171, 174]; a black and white image of a stairway: [0, 117, 383, 95]; a green square on a black background: [54, 145, 167, 68]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "minecraft menu screenshots\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the keyboard is black: [90, 51, 292, 166]; a white and gray sign: [98, 102, 187, 120]; a black informational sign: [194, 123, 284, 143]; a small gray sign with white letters: [98, 79, 188, 99]; a computer keyboard and keyboard: [1, 2, 379, 209]; a small gray sign with white letters: [195, 103, 282, 120]; a small gray sign with white letters: [98, 122, 188, 143]; a white informational sign: [98, 143, 284, 164]; a small gray sign with white letters: [194, 79, 283, 98]; the name of the store: [164, 148, 218, 161]; the words printed on a television: [164, 30, 218, 45]; a small white sign: [98, 58, 284, 77]; a black remote control: [292, 112, 382, 143]; a black remote control: [0, 113, 98, 146]; the name of the company that took the photo: [159, 61, 225, 75]; white and black signs: [104, 61, 276, 120]; words on the screen: [152, 23, 229, 52]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 131, 383, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 44, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 115, 383, 29]\n",
      "process_ann took 0.00 seconds\n",
      "[347, 0, 36, 116]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a black door with a black frame: [0, 0, 383, 128]; a black and white image of a black cat: [0, 131, 383, 81]; a black laptop with a black screen: [0, 0, 44, 118]; two black blocks on a black background: [0, 115, 383, 29]; a black mug with a black background: [347, 0, 36, 116]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: minecraft menu screenshots; Dense Caption: the keyboard is black: [90, 51, 292, 166]; a white and gray sign: [98, 102, 187, 120]; a black informational sign: [194, 123, 284, 143]; a small gray sign with white letters: [98, 79, 188, 99]; a computer keyboard and keyboard: [1, 2, 379, 209]; a small gray sign with white letters: [195, 103, 282, 120]; a small gray sign with white letters: [98, 122, 188, 143]; a white informational sign: [98, 143, 284, 164]; a small gray sign with white letters: [194, 79, 283, 98]; the name of the store: [164, 148, 218, 161]; the words printed on a television: [164, 30, 218, 45]; a small white sign: [98, 58, 284, 77]; a black remote control: [292, 112, 382, 143]; a black remote control: [0, 113, 98, 146]; the name of the company that took the photo: [159, 61, 225, 75]; white and black signs: [104, 61, 276, 120]; words on the screen: [152, 23, 229, 52]; ; Region Captions: a black door with a black frame: [0, 0, 383, 128]; a black and white image of a black cat: [0, 131, 383, 81]; a black laptop with a black screen: [0, 0, 44, 118]; two black blocks on a black background: [0, 115, 383, 29]; a black mug with a black background: [347, 0, 36, 116]; \n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210430_165909 19\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character with a red shirt and green pants\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a stack of different colored boxes: [93, 4, 293, 214]; snow covering the ground: [0, 72, 382, 211]; a toy train that is red and blue: [105, 176, 276, 212]; a red box: [186, 80, 254, 182]; the back of a sign: [136, 4, 236, 99]; the sky is gray: [1, 1, 383, 88]; a red box: [271, 185, 359, 212]; a brick wall in the background: [281, 62, 382, 90]; a black fence in the background: [23, 61, 124, 86]; green and white square: [140, 86, 196, 177]; green and red sign: [138, 5, 247, 183]; a red light on a traffic signal: [181, 193, 201, 212]; sticker on the laptop: [129, 195, 145, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 6, 383, 206]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 78, 383, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 78, 268, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 78, 147, 134]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building in the snow: [0, 6, 383, 206]; a black tower with a white sand floor: [0, 78, 383, 134]; a silhouette of a tall building with a black background: [0, 0, 383, 87]; a white t shirt with a white hat on it: [0, 78, 268, 134]; a white snowy mountain with a white sand: [0, 78, 147, 134]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character with a red shirt and green pants; Dense Caption: a stack of different colored boxes: [93, 4, 293, 214]; snow covering the ground: [0, 72, 382, 211]; a toy train that is red and blue: [105, 176, 276, 212]; a red box: [186, 80, 254, 182]; the back of a sign: [136, 4, 236, 99]; the sky is gray: [1, 1, 383, 88]; a red box: [271, 185, 359, 212]; a brick wall in the background: [281, 62, 382, 90]; a black fence in the background: [23, 61, 124, 86]; green and white square: [140, 86, 196, 177]; green and red sign: [138, 5, 247, 183]; a red light on a traffic signal: [181, 193, 201, 212]; sticker on the laptop: [129, 195, 145, 211]; ; Region Captions: a black and white image of a building in the snow: [0, 6, 383, 206]; a black tower with a white sand floor: [0, 78, 383, 134]; a silhouette of a tall building with a black background: [0, 0, 383, 87]; a white t shirt with a white hat on it: [0, 78, 268, 134]; a white snowy mountain with a white sand: [0, 78, 147, 134]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in front of a bed\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown wooden box on white table: [164, 77, 294, 128]; a black and white checkered bedspread: [0, 74, 145, 210]; white table cloth on table: [9, 108, 378, 211]; a bedroom: [1, 2, 380, 210]; the box is brown: [136, 66, 307, 150]; a yellow square of cloth: [205, 80, 248, 125]; the corner of a colorful box: [348, 43, 383, 210]; the table is white: [161, 141, 287, 209]; shadow of a flag on the ground: [334, 164, 382, 211]; the yellow and red object: [356, 98, 383, 130]; the wall is white: [23, 7, 346, 117]; white sheet on bed: [132, 123, 336, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[34, 111, 349, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 81, 144, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 25, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[336, 171, 47, 42]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a gray png image of a black and white png: [0, 0, 383, 114]; a white png image of a snowy surface: [34, 111, 349, 102]; a minecraft block with a black and white pattern: [0, 81, 144, 132]; a black and gray triangle: [0, 0, 25, 82]; a gray hat with a black handle: [336, 171, 47, 42]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in front of a bed; Dense Caption: brown wooden box on white table: [164, 77, 294, 128]; a black and white checkered bedspread: [0, 74, 145, 210]; white table cloth on table: [9, 108, 378, 211]; a bedroom: [1, 2, 380, 210]; the box is brown: [136, 66, 307, 150]; a yellow square of cloth: [205, 80, 248, 125]; the corner of a colorful box: [348, 43, 383, 210]; the table is white: [161, 141, 287, 209]; shadow of a flag on the ground: [334, 164, 382, 211]; the yellow and red object: [356, 98, 383, 130]; the wall is white: [23, 7, 346, 117]; white sheet on bed: [132, 123, 336, 209]; ; Region Captions: a gray png image of a black and white png: [0, 0, 383, 114]; a white png image of a snowy surface: [34, 111, 349, 102]; a minecraft block with a black and white pattern: [0, 81, 144, 132]; a black and gray triangle: [0, 0, 25, 82]; a gray hat with a black handle: [336, 171, 47, 42]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large building: [145, 143, 381, 211]; a checkered bedspread: [1, 141, 119, 212]; the sky is dark: [35, 4, 349, 184]; a bed in the middle of the room: [60, 75, 347, 209]; this is a bed: [217, 147, 309, 211]; a section of white table: [98, 195, 147, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 196]\n",
      "process_ann took 0.00 seconds\n",
      "[147, 148, 236, 65]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 145, 116, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[149, 149, 159, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[219, 149, 89, 64]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man with a hat: [0, 1, 383, 196]; a stack of wooden blocks: [147, 148, 236, 65]; a black and white block with a black background: [0, 145, 116, 68]; a wooden block with a wooden slat: [149, 149, 159, 64]; a wooden plank on a black background: [219, 149, 89, 64]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a large building: [145, 143, 381, 211]; a checkered bedspread: [1, 141, 119, 212]; the sky is dark: [35, 4, 349, 184]; a bed in the middle of the room: [60, 75, 347, 209]; this is a bed: [217, 147, 309, 211]; a section of white table: [98, 195, 147, 212]; ; Region Captions: a black and white image of a man with a hat: [0, 1, 383, 196]; a stack of wooden blocks: [147, 148, 236, 65]; a black and white block with a black background: [0, 145, 116, 68]; a wooden block with a wooden slat: [149, 149, 159, 64]; a wooden plank on a black background: [219, 149, 89, 64]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white checkered bedspread: [0, 68, 116, 210]; lego person is carrying a book: [231, 19, 358, 190]; shadow of the object: [229, 153, 313, 209]; the floor is white: [0, 82, 381, 210]; the boxes are stacked: [128, 30, 242, 114]; red and white stripes on the side of a sign: [235, 72, 338, 144]; yellow and blue triangles: [253, 21, 358, 89]; blue and red striped box: [240, 136, 305, 192]; a green piece of luggage: [130, 33, 176, 79]; green and brown box: [127, 30, 180, 114]; lego toy on the ground: [119, 15, 360, 199]; white floor of the room: [68, 114, 227, 211]; the brown box on the floor: [136, 68, 242, 113]; a yellow square of wood: [174, 70, 212, 112]; the sky is gray: [0, 1, 379, 106]; a square orange stripe: [236, 75, 270, 145]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 94, 381, 119]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 74, 113, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[256, 25, 100, 64]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a person standing in a room: [0, 1, 383, 211]; a person walking on a white floor: [2, 94, 381, 119]; a silhouette of a city with a dark sky: [0, 0, 383, 102]; a black and white image of a minecraft block: [0, 74, 113, 137]; a head with blue eyes and a blue hair: [256, 25, 100, 64]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a black and white checkered bedspread: [0, 68, 116, 210]; lego person is carrying a book: [231, 19, 358, 190]; shadow of the object: [229, 153, 313, 209]; the floor is white: [0, 82, 381, 210]; the boxes are stacked: [128, 30, 242, 114]; red and white stripes on the side of a sign: [235, 72, 338, 144]; yellow and blue triangles: [253, 21, 358, 89]; blue and red striped box: [240, 136, 305, 192]; a green piece of luggage: [130, 33, 176, 79]; green and brown box: [127, 30, 180, 114]; lego toy on the ground: [119, 15, 360, 199]; white floor of the room: [68, 114, 227, 211]; the brown box on the floor: [136, 68, 242, 113]; a yellow square of wood: [174, 70, 212, 112]; the sky is gray: [0, 1, 379, 106]; a square orange stripe: [236, 75, 270, 145]; ; Region Captions: a 3d image of a person standing in a room: [0, 1, 383, 211]; a person walking on a white floor: [2, 94, 381, 119]; a silhouette of a city with a dark sky: [0, 0, 383, 102]; a black and white image of a minecraft block: [0, 74, 113, 137]; a head with blue eyes and a blue hair: [256, 25, 100, 64]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a square in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and green box: [274, 38, 383, 211]; white bedspread on bed: [34, 79, 347, 213]; the basket is brown: [182, 79, 247, 101]; the wall is white: [0, 1, 228, 98]; green square on the bottom of the vase: [280, 120, 382, 212]; a bed in the room: [18, 13, 274, 194]; a blue laptop screen: [288, 44, 382, 141]; a round object on the bed: [68, 116, 104, 132]; the wall is white: [39, 11, 171, 77]; the snow is white: [45, 138, 168, 205]; a hole in the snow: [63, 111, 109, 138]; a hole in the snow: [39, 102, 117, 156]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 96, 338, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 221, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[284, 46, 99, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[221, 0, 162, 103]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.80 seconds\n",
      "finished...\n",
      "\n",
      "a white piece of paper with a hole in it: [0, 96, 338, 116]; a gray wall with a black door: [0, 0, 383, 103]; a gray square with a black background: [0, 0, 221, 101]; a blue and green block in minecraft: [284, 46, 99, 166]; a gray png of a map of the state of californi: [221, 0, 162, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a square in a minecraft game; Dense Caption: a blue and green box: [274, 38, 383, 211]; white bedspread on bed: [34, 79, 347, 213]; the basket is brown: [182, 79, 247, 101]; the wall is white: [0, 1, 228, 98]; green square on the bottom of the vase: [280, 120, 382, 212]; a bed in the room: [18, 13, 274, 194]; a blue laptop screen: [288, 44, 382, 141]; a round object on the bed: [68, 116, 104, 132]; the wall is white: [39, 11, 171, 77]; the snow is white: [45, 138, 168, 205]; a hole in the snow: [63, 111, 109, 138]; a hole in the snow: [39, 102, 117, 156]; ; Region Captions: a white piece of paper with a hole in it: [0, 96, 338, 116]; a gray wall with a black door: [0, 0, 383, 103]; a gray square with a black background: [0, 0, 221, 101]; a blue and green block in minecraft: [284, 46, 99, 166]; a gray png of a map of the state of californi: [221, 0, 162, 103]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing next to a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the brown object in the middle of the snow: [223, 89, 301, 155]; lego person is walking: [106, 50, 160, 138]; white tablecloth on the table: [4, 76, 381, 211]; a brown cardboard box: [0, 137, 39, 212]; the red part of the cake: [109, 74, 156, 108]; the wall is white: [129, 0, 359, 84]; the brown object in the middle of the snow: [199, 76, 320, 168]; blue post it note: [123, 105, 148, 131]; a cake with a bear: [98, 26, 360, 188]; a black box on the side of the bed: [299, 66, 382, 91]; a lego toy on the snow: [72, 40, 199, 185]; a small square building: [147, 71, 190, 93]; yellow top of the lego a cake: [116, 53, 148, 81]; shadow of the object: [115, 119, 158, 140]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 167]\n",
      "process_ann took 0.00 seconds\n",
      "[24, 84, 359, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 133, 167]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 0, 217, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 94, 69, 57]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a room with a black wall and a door: [0, 0, 383, 167]; a black and white image of a person standing on a snowy ground: [24, 84, 359, 128]; a gray map with the words nevada: [0, 0, 133, 167]; a gray box with a white background: [131, 0, 217, 83]; a block of wood in minecraft: [228, 94, 69, 57]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing next to a block; Dense Caption: the brown object in the middle of the snow: [223, 89, 301, 155]; lego person is walking: [106, 50, 160, 138]; white tablecloth on the table: [4, 76, 381, 211]; a brown cardboard box: [0, 137, 39, 212]; the red part of the cake: [109, 74, 156, 108]; the wall is white: [129, 0, 359, 84]; the brown object in the middle of the snow: [199, 76, 320, 168]; blue post it note: [123, 105, 148, 131]; a cake with a bear: [98, 26, 360, 188]; a black box on the side of the bed: [299, 66, 382, 91]; a lego toy on the snow: [72, 40, 199, 185]; a small square building: [147, 71, 190, 93]; yellow top of the lego a cake: [116, 53, 148, 81]; shadow of the object: [115, 119, 158, 140]; ; Region Captions: a room with a black wall and a door: [0, 0, 383, 167]; a black and white image of a person standing on a snowy ground: [24, 84, 359, 128]; a gray map with the words nevada: [0, 0, 133, 167]; a gray box with a white background: [131, 0, 217, 83]; a block of wood in minecraft: [228, 94, 69, 57]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing next to a block of wood\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [20, 82, 283, 211]; lime green square with white speckles: [0, 1, 120, 145]; a very big bed: [1, 1, 377, 210]; red and yellow design on the umbrella: [337, 80, 383, 183]; a brown and white box: [101, 91, 210, 205]; the sky is grey: [108, 1, 365, 144]; the white table: [115, 94, 380, 212]; the sky is white: [180, 15, 310, 78]; the corner of the table: [185, 86, 283, 185]; the sky is overcast: [134, 4, 369, 80]; blue stripe on the umbrella: [358, 179, 383, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[77, 0, 306, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 117, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 117, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[116, 116, 256, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[38, 95, 168, 115]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a gray shaped table with a black background: [77, 0, 306, 127]; a green block in minecraft: [0, 0, 117, 210]; a green block in minecraft: [0, 0, 117, 143]; a silver wing with a white background: [116, 116, 256, 97]; a wooden block in minecraft: [38, 95, 168, 115]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing next to a block of wood; Dense Caption: the box is brown: [20, 82, 283, 211]; lime green square with white speckles: [0, 1, 120, 145]; a very big bed: [1, 1, 377, 210]; red and yellow design on the umbrella: [337, 80, 383, 183]; a brown and white box: [101, 91, 210, 205]; the sky is grey: [108, 1, 365, 144]; the white table: [115, 94, 380, 212]; the sky is white: [180, 15, 310, 78]; the corner of the table: [185, 86, 283, 185]; the sky is overcast: [134, 4, 369, 80]; blue stripe on the umbrella: [358, 179, 383, 212]; ; Region Captions: a gray shaped table with a black background: [77, 0, 306, 127]; a green block in minecraft: [0, 0, 117, 210]; a green block in minecraft: [0, 0, 117, 143]; a silver wing with a white background: [116, 116, 256, 97]; a wooden block in minecraft: [38, 95, 168, 115]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a block of wood and a green plant\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [19, 81, 283, 212]; lime green square with white speckles: [0, 1, 120, 146]; a green and brown box: [1, 1, 372, 210]; a brown and white section of a bed: [101, 91, 210, 204]; white table next to a brown box: [111, 106, 382, 212]; the wall is textured: [107, 0, 367, 148]; the corner of the books: [185, 86, 283, 185]; white and green keys on a keyboard: [107, 90, 206, 132]; the top of the box: [185, 85, 282, 124]; the counter is white: [282, 120, 380, 210]; the sky is overcast: [133, 4, 374, 83]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[77, 0, 306, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 117, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 116, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[117, 112, 266, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[104, 95, 171, 113]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a gray shaped object with a black background: [77, 0, 306, 127]; a green block in minecraft: [0, 0, 117, 210]; a green block in minecraft: [0, 0, 116, 143]; a white png of a cliff with a black background: [117, 112, 266, 101]; a wooden block in minecraft: [104, 95, 171, 113]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a block of wood and a green plant; Dense Caption: the box is brown: [19, 81, 283, 212]; lime green square with white speckles: [0, 1, 120, 146]; a green and brown box: [1, 1, 372, 210]; a brown and white section of a bed: [101, 91, 210, 204]; white table next to a brown box: [111, 106, 382, 212]; the wall is textured: [107, 0, 367, 148]; the corner of the books: [185, 86, 283, 185]; white and green keys on a keyboard: [107, 90, 206, 132]; the top of the box: [185, 85, 282, 124]; the counter is white: [282, 120, 380, 210]; the sky is overcast: [133, 4, 374, 83]; ; Region Captions: a gray shaped object with a black background: [77, 0, 306, 127]; a green block in minecraft: [0, 0, 117, 210]; a green block in minecraft: [0, 0, 116, 143]; a white png of a cliff with a black background: [117, 112, 266, 101]; a wooden block in minecraft: [104, 95, 171, 113]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue and green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and yellow roll of paper towels: [144, 6, 242, 153]; white tablecloth on the table: [0, 47, 380, 211]; green and yellow square on a vase: [153, 88, 231, 153]; green and yellow striped snowboard: [98, 2, 278, 169]; the back of a chair: [16, 0, 283, 62]; a black remote control: [3, 41, 94, 65]; a drain in the middle of the snow: [98, 67, 124, 81]; the black square on the table: [230, 44, 287, 65]; the green portion of the vase: [160, 14, 225, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 58, 383, 154]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 9, 123, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 9, 85, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[265, 0, 118, 90]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft map: [0, 58, 383, 154]; a black and white image of a room with a door: [0, 0, 383, 91]; a blue and green square in minecraft: [150, 9, 123, 140]; a blue and green bucket with a green background: [150, 9, 85, 140]; a grey piece of paper with a white border: [265, 0, 118, 90]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue and green block in minecraft; Dense Caption: green and yellow roll of paper towels: [144, 6, 242, 153]; white tablecloth on the table: [0, 47, 380, 211]; green and yellow square on a vase: [153, 88, 231, 153]; green and yellow striped snowboard: [98, 2, 278, 169]; the back of a chair: [16, 0, 283, 62]; a black remote control: [3, 41, 94, 65]; a drain in the middle of the snow: [98, 67, 124, 81]; the black square on the table: [230, 44, 287, 65]; the green portion of the vase: [160, 14, 225, 85]; ; Region Captions: a black and white image of a minecraft map: [0, 58, 383, 154]; a black and white image of a room with a door: [0, 0, 383, 91]; a blue and green square in minecraft: [150, 9, 123, 140]; a blue and green bucket with a green background: [150, 9, 85, 140]; a grey piece of paper with a white border: [265, 0, 118, 90]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and white suitcase on the floor: [117, 6, 273, 211]; small square brown basket: [66, 75, 129, 102]; the scene is indoors: [1, 2, 379, 210]; green and black square on a green vase: [130, 132, 263, 212]; white wall in the background: [0, 0, 123, 101]; the counter is white: [1, 97, 120, 212]; the vase is on the table: [45, 94, 322, 212]; the green portion of the sign: [139, 28, 237, 152]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 96, 383, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[66, 0, 317, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[70, 9, 199, 165]\n",
      "process_ann took 0.00 seconds\n",
      "[124, 9, 145, 190]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 95, 140, 117]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a tall pole: [0, 96, 383, 116]; a black and white image of a house: [66, 0, 317, 140]; a green block in minecraft: [70, 9, 199, 165]; a green block in minecraft: [124, 9, 145, 190]; a white sheet of paper on a black background: [0, 95, 140, 117]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: green and white suitcase on the floor: [117, 6, 273, 211]; small square brown basket: [66, 75, 129, 102]; the scene is indoors: [1, 2, 379, 210]; green and black square on a green vase: [130, 132, 263, 212]; white wall in the background: [0, 0, 123, 101]; the counter is white: [1, 97, 120, 212]; the vase is on the table: [45, 94, 322, 212]; the green portion of the sign: [139, 28, 237, 152]; ; Region Captions: a black and white image of a tall pole: [0, 96, 383, 116]; a black and white image of a house: [66, 0, 317, 140]; a green block in minecraft: [70, 9, 199, 165]; a green block in minecraft: [124, 9, 145, 190]; a white sheet of paper on a black background: [0, 95, 140, 117]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and black box: [238, 0, 383, 210]; green and white square on the umbrella: [0, 2, 185, 208]; a black box on the counter: [219, 0, 284, 26]; the green boxes on the table: [0, 1, 381, 210]; green diamond on a green background: [45, 24, 140, 131]; the floor is white: [177, 74, 235, 213]; the green portion of a kite: [69, 43, 156, 148]; the umbrella is green: [37, 53, 130, 158]; white table cloth on table: [182, 33, 310, 212]; the green portion of a tie: [275, 8, 374, 138]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 180, 208]\n",
      "process_ann took 0.00 seconds\n",
      "[245, 0, 138, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 17, 274, 195]\n",
      "process_ann took 0.00 seconds\n",
      "[83, 17, 192, 195]\n",
      "process_ann took 0.00 seconds\n",
      "[147, 17, 127, 195]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.81 seconds\n",
      "finished...\n",
      "\n",
      "a green block with the text'green': [0, 0, 180, 208]; a green block in minecraft: [245, 0, 138, 212]; a white and black png image of a slanted sl: [0, 17, 274, 195]; a white and gray png image of a white and gray png image: [83, 17, 192, 195]; a white and silver shaped object: [147, 17, 127, 195]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: a green and black box: [238, 0, 383, 210]; green and white square on the umbrella: [0, 2, 185, 208]; a black box on the counter: [219, 0, 284, 26]; the green boxes on the table: [0, 1, 381, 210]; green diamond on a green background: [45, 24, 140, 131]; the floor is white: [177, 74, 235, 213]; the green portion of a kite: [69, 43, 156, 148]; the umbrella is green: [37, 53, 130, 158]; white table cloth on table: [182, 33, 310, 212]; the green portion of a tie: [275, 8, 374, 138]; ; Region Captions: a green block with the text'green': [0, 0, 180, 208]; a green block in minecraft: [245, 0, 138, 212]; a white and black png image of a slanted sl: [0, 17, 274, 195]; a white and gray png image of a white and gray png image: [83, 17, 192, 195]; a white and silver shaped object: [147, 17, 127, 195]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and black box: [238, 0, 383, 210]; green and white square on the umbrella: [0, 2, 185, 208]; a black box on the counter: [219, 0, 284, 26]; the green boxes on the table: [0, 1, 381, 210]; the green diamond on the tie: [47, 35, 139, 139]; the floor is white: [177, 75, 235, 213]; white table cloth on table: [182, 33, 311, 212]; the green portion of a tie: [275, 8, 374, 138]; the green portion of a kite: [68, 53, 156, 158]; the umbrella is green: [37, 64, 130, 165]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 180, 207]\n",
      "process_ann took 0.00 seconds\n",
      "[245, 0, 138, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 17, 274, 195]\n",
      "process_ann took 0.00 seconds\n",
      "[83, 17, 192, 195]\n",
      "process_ann took 0.00 seconds\n",
      "[147, 17, 127, 195]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.80 seconds\n",
      "finished...\n",
      "\n",
      "a green block with the text's green block': [0, 0, 180, 207]; a green block in minecraft: [245, 0, 138, 212]; a white and black png image of a slanted sl: [0, 17, 274, 195]; a white and gray png image of a white and gray png image: [83, 17, 192, 195]; a white and silver shaped object: [147, 17, 127, 195]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: a green and black box: [238, 0, 383, 210]; green and white square on the umbrella: [0, 2, 185, 208]; a black box on the counter: [219, 0, 284, 26]; the green boxes on the table: [0, 1, 381, 210]; the green diamond on the tie: [47, 35, 139, 139]; the floor is white: [177, 75, 235, 213]; white table cloth on table: [182, 33, 311, 212]; the green portion of a tie: [275, 8, 374, 138]; the green portion of a kite: [68, 53, 156, 158]; the umbrella is green: [37, 64, 130, 165]; ; Region Captions: a green block with the text's green block': [0, 0, 180, 207]; a green block in minecraft: [245, 0, 138, 212]; a white and black png image of a slanted sl: [0, 17, 274, 195]; a white and gray png image of a white and gray png image: [83, 17, 192, 195]; a white and silver shaped object: [147, 17, 127, 195]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character with a sword and a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the yellow and blue sign: [87, 14, 200, 119]; a red sign with a white border: [101, 105, 194, 212]; square shaped brick: [209, 89, 268, 143]; snow covering the ground: [0, 87, 383, 211]; a green and black checkered banner: [182, 153, 261, 210]; green square of cardboard: [0, 51, 51, 101]; a blue diamond on the yellow kite: [143, 31, 178, 99]; a small square building: [228, 72, 302, 97]; a red flag: [92, 91, 272, 212]; wooden slat base for umbrella: [0, 87, 119, 147]; the boxes are brown: [188, 40, 313, 176]; a bench with a kite: [29, 16, 273, 212]; a green and black checkered pattern: [226, 154, 259, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 92, 383, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 177]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[162, 92, 221, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 256, 96]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man with a knife: [0, 92, 383, 121]; a black and white image of a city: [0, 0, 383, 177]; a cityscape with a black and white background: [0, 0, 383, 97]; a white wolf with a knife in its mouth: [162, 92, 221, 120]; a silhouette of a city with a skyscraper: [0, 0, 256, 96]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character with a sword and a block; Dense Caption: the yellow and blue sign: [87, 14, 200, 119]; a red sign with a white border: [101, 105, 194, 212]; square shaped brick: [209, 89, 268, 143]; snow covering the ground: [0, 87, 383, 211]; a green and black checkered banner: [182, 153, 261, 210]; green square of cardboard: [0, 51, 51, 101]; a blue diamond on the yellow kite: [143, 31, 178, 99]; a small square building: [228, 72, 302, 97]; a red flag: [92, 91, 272, 212]; wooden slat base for umbrella: [0, 87, 119, 147]; the boxes are brown: [188, 40, 313, 176]; a bench with a kite: [29, 16, 273, 212]; a green and black checkered pattern: [226, 154, 259, 210]; ; Region Captions: a black and white image of a man with a knife: [0, 92, 383, 121]; a black and white image of a city: [0, 0, 383, 177]; a cityscape with a black and white background: [0, 0, 383, 97]; a white wolf with a knife in its mouth: [162, 92, 221, 120]; a silhouette of a city with a skyscraper: [0, 0, 256, 96]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing next to a blue block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue square on the hydrant: [107, 26, 205, 113]; a blue and black cone: [101, 22, 215, 180]; snow covering the ground: [43, 73, 319, 212]; the brown part of the hydrant: [116, 97, 205, 178]; top of parking meter: [53, 42, 95, 76]; red and blue object: [53, 55, 103, 133]; red square on post: [57, 67, 94, 104]; a scene outside: [0, 3, 380, 209]; a black bag: [201, 63, 231, 87]; shadow of the object: [62, 113, 109, 134]; blue base of lego: [69, 96, 98, 129]; a black pipe on the side of the building: [88, 82, 118, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 80, 383, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[186, 0, 197, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 184, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[77, 29, 151, 147]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person walking in the snow: [0, 80, 383, 132]; a black silhouette of a man in a room: [0, 0, 383, 126]; a gray png file with the word california: [186, 0, 197, 85]; a silhouette of a man standing on a hill: [0, 0, 184, 126]; a blue and brown block in minecraft: [77, 29, 151, 147]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing next to a blue block; Dense Caption: a blue square on the hydrant: [107, 26, 205, 113]; a blue and black cone: [101, 22, 215, 180]; snow covering the ground: [43, 73, 319, 212]; the brown part of the hydrant: [116, 97, 205, 178]; top of parking meter: [53, 42, 95, 76]; red and blue object: [53, 55, 103, 133]; red square on post: [57, 67, 94, 104]; a scene outside: [0, 3, 380, 209]; a black bag: [201, 63, 231, 87]; shadow of the object: [62, 113, 109, 134]; blue base of lego: [69, 96, 98, 129]; a black pipe on the side of the building: [88, 82, 118, 103]; ; Region Captions: a black and white image of a person walking in the snow: [0, 80, 383, 132]; a black silhouette of a man in a room: [0, 0, 383, 126]; a gray png file with the word california: [186, 0, 197, 85]; a silhouette of a man standing on a hill: [0, 0, 184, 126]; a blue and brown block in minecraft: [77, 29, 151, 147]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a blue and blue block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and brown striped suitcase: [71, 0, 223, 140]; white table with cake: [0, 18, 382, 209]; yellow and blue tag: [72, 0, 116, 39]; the brown part of the kite: [122, 62, 213, 140]; a small square shaped object: [210, 23, 244, 52]; green and white portion of the cake: [111, 0, 214, 78]; red part of the cake: [69, 27, 122, 62]; a red piece of the cake: [64, 1, 126, 65]; brown squares on the bottom of the cake: [131, 75, 194, 126]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 44, 383, 168]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[214, 0, 169, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[111, 0, 102, 79]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 44, 383, 168]; a black and white image of a room: [0, 0, 383, 92]; a grey t shirt with a white logo on it: [214, 0, 169, 49]; a white paper with a black background: [2, 0, 381, 49]; a blue square block on a black background: [111, 0, 102, 79]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a blue and blue block; Dense Caption: a green and brown striped suitcase: [71, 0, 223, 140]; white table with cake: [0, 18, 382, 209]; yellow and blue tag: [72, 0, 116, 39]; the brown part of the kite: [122, 62, 213, 140]; a small square shaped object: [210, 23, 244, 52]; green and white portion of the cake: [111, 0, 214, 78]; red part of the cake: [69, 27, 122, 62]; a red piece of the cake: [64, 1, 126, 65]; brown squares on the bottom of the cake: [131, 75, 194, 126]; ; Region Captions: a black and white image of a snowy area: [0, 44, 383, 168]; a black and white image of a room: [0, 0, 383, 92]; a grey t shirt with a white logo on it: [214, 0, 169, 49]; a white paper with a black background: [2, 0, 381, 49]; a blue square block on a black background: [111, 0, 102, 79]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and brown object: [101, 2, 299, 145]; white tablecloth on a table: [2, 40, 382, 212]; green and white square on the top of the cake: [134, 0, 239, 81]; brown box on cup: [144, 67, 231, 143]; the brown object on the table: [231, 28, 267, 56]; a blue square on the end of a cake: [225, 54, 299, 131]; the corner of a book: [0, 64, 24, 116]; the table is white: [32, 140, 243, 210]; square design on the vase: [153, 79, 217, 128]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 49, 383, 163]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 142, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[138, 0, 99, 119]\n",
      "process_ann took 0.00 seconds\n",
      "[138, 0, 99, 83]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy mountain: [0, 49, 383, 163]; a black and white image of a room with a door: [0, 0, 383, 93]; a gray shaped object on a black background: [0, 0, 142, 94]; a blue square block on a black background: [138, 0, 99, 119]; a blue square block on a black background: [138, 0, 99, 83]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue block in minecraft; Dense Caption: a green and brown object: [101, 2, 299, 145]; white tablecloth on a table: [2, 40, 382, 212]; green and white square on the top of the cake: [134, 0, 239, 81]; brown box on cup: [144, 67, 231, 143]; the brown object on the table: [231, 28, 267, 56]; a blue square on the end of a cake: [225, 54, 299, 131]; the corner of a book: [0, 64, 24, 116]; the table is white: [32, 140, 243, 210]; square design on the vase: [153, 79, 217, 128]; ; Region Captions: a black and white image of a snowy mountain: [0, 49, 383, 163]; a black and white image of a room with a door: [0, 0, 383, 93]; a gray shaped object on a black background: [0, 0, 142, 94]; a blue square block on a black background: [138, 0, 99, 119]; a blue square block on a black background: [138, 0, 99, 83]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and white checkered suitcase: [140, 1, 372, 211]; a black object on the desk: [124, 29, 173, 54]; the baseboard is white: [1, 0, 168, 57]; green plastic on umbrella: [139, 67, 180, 163]; white snow on the ground: [4, 60, 122, 210]; the white table: [24, 38, 233, 212]; a vent on the side of the wall: [115, 16, 180, 61]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[142, 0, 241, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 49, 383, 163]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 48, 213, 164]\n",
      "process_ann took 0.00 seconds\n",
      "[266, 82, 117, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 77]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a green block in minecraft: [142, 0, 241, 212]; a black and white image of a person standing on a snowy hill: [0, 49, 383, 163]; a 3d image of a snowy area: [0, 48, 213, 164]; a white and grey skateboard on a black background: [266, 82, 117, 130]; a black and white image of a man with a hat: [0, 0, 383, 77]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: green and white checkered suitcase: [140, 1, 372, 211]; a black object on the desk: [124, 29, 173, 54]; the baseboard is white: [1, 0, 168, 57]; green plastic on umbrella: [139, 67, 180, 163]; white snow on the ground: [4, 60, 122, 210]; the white table: [24, 38, 233, 212]; a vent on the side of the wall: [115, 16, 180, 61]; ; Region Captions: a green block in minecraft: [142, 0, 241, 212]; a black and white image of a person standing on a snowy hill: [0, 49, 383, 163]; a 3d image of a snowy area: [0, 48, 213, 164]; a white and grey skateboard on a black background: [266, 82, 117, 130]; a black and white image of a man with a hat: [0, 0, 383, 77]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and orange checkered skirt: [1, 1, 298, 210]; green part of the kite: [130, 1, 273, 135]; a blue piece of paper: [1, 137, 160, 211]; orange square on the green and white striped fabric: [150, 113, 256, 211]; a black object on the bed: [267, 40, 336, 63]; brown and white checked shirt: [1, 2, 143, 165]; a white table: [244, 56, 381, 211]; bottom half of colorful kite: [1, 111, 262, 211]; a green and orange bag: [129, 2, 357, 212]; shadow of a laptop: [365, 88, 383, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 147, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[181, 60, 202, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 0, 146, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 0, 146, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 138, 158, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a brown pixelated texture for minecraft: [0, 0, 147, 166]; a white sand bag with a white sand: [181, 60, 202, 153]; green minecraft block: [131, 0, 146, 210]; a green pixelated background with the text'green': [131, 0, 146, 136]; a blue square with the text minecraft sand: [0, 138, 158, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: green and orange checkered skirt: [1, 1, 298, 210]; green part of the kite: [130, 1, 273, 135]; a blue piece of paper: [1, 137, 160, 211]; orange square on the green and white striped fabric: [150, 113, 256, 211]; a black object on the bed: [267, 40, 336, 63]; brown and white checked shirt: [1, 2, 143, 165]; a white table: [244, 56, 381, 211]; bottom half of colorful kite: [1, 111, 262, 211]; a green and orange bag: [129, 2, 357, 212]; shadow of a laptop: [365, 88, 383, 106]; ; Region Captions: a brown pixelated texture for minecraft: [0, 0, 147, 166]; a white sand bag with a white sand: [181, 60, 202, 153]; green minecraft block: [131, 0, 146, 210]; a green pixelated background with the text'green': [131, 0, 146, 136]; a blue square with the text minecraft sand: [0, 138, 158, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a square block with different colors on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "multicolored fabric to the left of the vase: [1, 0, 250, 209]; white table with two items on it: [87, 23, 352, 214]; the apple logo on the computer: [258, 48, 289, 64]; green section of the kite: [17, 1, 187, 129]; the wall is grey: [245, 0, 378, 42]; orange and green squares: [182, 1, 244, 152]; the table is white: [242, 37, 377, 210]; large brown square on a kite: [0, 4, 72, 170]; a drain in the middle of the floor: [254, 44, 294, 70]; a blue and green striped umbrella: [0, 4, 119, 210]; the orange and green half of a piece of cloth: [151, 2, 275, 182]; a green section of a kite: [154, 33, 210, 154]; a blue tablecloth: [1, 138, 117, 211]; green section of a kite: [184, 64, 237, 150]; orange stripe on the vase: [186, 1, 242, 81]; orange stripe on kite: [80, 88, 190, 198]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[120, 30, 263, 182]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 185, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[76, 1, 167, 208]\n",
      "process_ann took 0.00 seconds\n",
      "[76, 88, 111, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 12, 72, 157]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a white sheet of paper with a hole in it: [120, 30, 263, 182]; green pixelated background: [0, 0, 185, 135]; a minecraft block with two orange blocks: [76, 1, 167, 208]; a minecraft block with an orange background: [76, 88, 111, 122]; a brown and black plaid pattern: [0, 12, 72, 157]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a square block with different colors on it; Dense Caption: multicolored fabric to the left of the vase: [1, 0, 250, 209]; white table with two items on it: [87, 23, 352, 214]; the apple logo on the computer: [258, 48, 289, 64]; green section of the kite: [17, 1, 187, 129]; the wall is grey: [245, 0, 378, 42]; orange and green squares: [182, 1, 244, 152]; the table is white: [242, 37, 377, 210]; large brown square on a kite: [0, 4, 72, 170]; a drain in the middle of the floor: [254, 44, 294, 70]; a blue and green striped umbrella: [0, 4, 119, 210]; the orange and green half of a piece of cloth: [151, 2, 275, 182]; a green section of a kite: [154, 33, 210, 154]; a blue tablecloth: [1, 138, 117, 211]; green section of a kite: [184, 64, 237, 150]; orange stripe on the vase: [186, 1, 242, 81]; orange stripe on kite: [80, 88, 190, 198]; ; Region Captions: a white sheet of paper with a hole in it: [120, 30, 263, 182]; green pixelated background: [0, 0, 185, 135]; a minecraft block with two orange blocks: [76, 1, 167, 208]; a minecraft block with an orange background: [76, 88, 111, 122]; a brown and black plaid pattern: [0, 12, 72, 157]; \n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210430_170448 0\n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210430_171045 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "multi colored pole holding a fire hydrant: [147, 31, 219, 174]; snow covering the ground: [0, 77, 381, 211]; shadow of the hydrant: [155, 145, 216, 181]; the back wall is white: [44, 0, 357, 88]; a brick wall at the bottom of the hill: [4, 64, 120, 93]; a brick wall in the background: [289, 66, 382, 97]; the body of the sign: [149, 73, 192, 132]; snowboard on the ground: [110, 24, 263, 184]; blue section of the sign: [167, 123, 193, 168]; the yellow part of the sign: [158, 32, 208, 75]; a yellow plastic cover: [152, 114, 166, 148]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 83, 383, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[53, 0, 318, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 66, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 76, 40, 92]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.70 seconds\n",
      "finished...\n",
      "\n",
      "a person is standing on a white floor: [0, 83, 383, 129]; a black and white image of a building: [0, 0, 383, 123]; a grey png image of a building: [53, 0, 318, 82]; a grey shaped object with a white background: [0, 0, 66, 92]; a red and blue pixelated image of a minecraft character: [150, 76, 40, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: multi colored pole holding a fire hydrant: [147, 31, 219, 174]; snow covering the ground: [0, 77, 381, 211]; shadow of the hydrant: [155, 145, 216, 181]; the back wall is white: [44, 0, 357, 88]; a brick wall at the bottom of the hill: [4, 64, 120, 93]; a brick wall in the background: [289, 66, 382, 97]; the body of the sign: [149, 73, 192, 132]; snowboard on the ground: [110, 24, 263, 184]; blue section of the sign: [167, 123, 193, 168]; the yellow part of the sign: [158, 32, 208, 75]; a yellow plastic cover: [152, 114, 166, 148]; ; Region Captions: a person is standing on a white floor: [0, 83, 383, 129]; a black and white image of a building: [0, 0, 383, 123]; a grey png image of a building: [53, 0, 318, 82]; a grey shaped object with a white background: [0, 0, 66, 92]; a red and blue pixelated image of a minecraft character: [150, 76, 40, 92]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "wooden box: [151, 73, 353, 141]; a black and white checkered table cloth: [0, 77, 124, 211]; white sheets on the bed: [46, 108, 380, 211]; the room is dark: [27, 19, 352, 198]; a brown wood grain: [202, 78, 260, 136]; the wall is white: [0, 1, 381, 125]; the left side of the bench: [279, 74, 354, 134]; the wall is white: [36, 2, 349, 70]; the table is white: [176, 146, 309, 206]; the suitcase is brown: [104, 63, 343, 175]; the square design on the left side of the bed: [155, 77, 265, 140]; a pen on the bed: [3, 88, 31, 107]; a brown wood slat: [153, 79, 208, 139]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[55, 111, 328, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 82, 121, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[154, 79, 198, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[203, 81, 56, 55]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a cloudy sky: [0, 1, 383, 118]; a white floor with a black background: [55, 111, 328, 102]; a black and white block with a black and white pattern: [0, 82, 121, 131]; a set of wooden blocks in different colors: [154, 79, 198, 60]; a wooden table with a wooden top: [203, 81, 56, 55]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: wooden box: [151, 73, 353, 141]; a black and white checkered table cloth: [0, 77, 124, 211]; white sheets on the bed: [46, 108, 380, 211]; the room is dark: [27, 19, 352, 198]; a brown wood grain: [202, 78, 260, 136]; the wall is white: [0, 1, 381, 125]; the left side of the bench: [279, 74, 354, 134]; the wall is white: [36, 2, 349, 70]; the table is white: [176, 146, 309, 206]; the suitcase is brown: [104, 63, 343, 175]; the square design on the left side of the bed: [155, 77, 265, 140]; a pen on the bed: [3, 88, 31, 107]; a brown wood slat: [153, 79, 208, 139]; ; Region Captions: a black and white image of a building with a cloudy sky: [0, 1, 383, 118]; a white floor with a black background: [55, 111, 328, 102]; a black and white block with a black and white pattern: [0, 82, 121, 131]; a set of wooden blocks in different colors: [154, 79, 198, 60]; a wooden table with a wooden top: [203, 81, 56, 55]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in front of a room with blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [113, 67, 297, 153]; a checkered blanket: [0, 87, 82, 213]; multi colored bench: [326, 32, 382, 179]; two suitcases are on the bed: [0, 27, 382, 208]; shadow of the object: [309, 139, 383, 185]; red section of the object: [346, 76, 383, 139]; yellow and blue stripes: [336, 35, 383, 88]; blue stripe on the post: [334, 120, 373, 172]; the sky is grey: [35, 2, 344, 97]; a square wooden foot board: [169, 81, 223, 139]; the snow is white: [145, 151, 268, 208]; the left wooden part of the bench: [240, 75, 296, 127]; white table cloth: [76, 142, 319, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[25, 99, 358, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[117, 80, 177, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 79, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[335, 37, 48, 134]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building: [0, 1, 383, 131]; a 3d image of a skateboard on a black surface: [25, 99, 358, 113]; a stack of bricks in different colors: [117, 80, 177, 69]; a black and white block of bricks: [0, 91, 79, 122]; a pixelated image of a boy flying in the air: [335, 37, 48, 134]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in front of a room with blocks; Dense Caption: the box is brown: [113, 67, 297, 153]; a checkered blanket: [0, 87, 82, 213]; multi colored bench: [326, 32, 382, 179]; two suitcases are on the bed: [0, 27, 382, 208]; shadow of the object: [309, 139, 383, 185]; red section of the object: [346, 76, 383, 139]; yellow and blue stripes: [336, 35, 383, 88]; blue stripe on the post: [334, 120, 373, 172]; the sky is grey: [35, 2, 344, 97]; a square wooden foot board: [169, 81, 223, 139]; the snow is white: [145, 151, 268, 208]; the left wooden part of the bench: [240, 75, 296, 127]; white table cloth: [76, 142, 319, 209]; ; Region Captions: a black and white image of a building: [0, 1, 383, 131]; a 3d image of a skateboard on a black surface: [25, 99, 358, 113]; a stack of bricks in different colors: [117, 80, 177, 69]; a black and white block of bricks: [0, 91, 79, 122]; a pixelated image of a boy flying in the air: [335, 37, 48, 134]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [77, 74, 263, 164]; white sheets on the bed: [1, 75, 382, 211]; a checkered blanket: [0, 97, 39, 201]; the pillow is checkered: [338, 66, 383, 95]; the wall is white: [56, 15, 336, 167]; the wall is white: [38, 2, 348, 78]; the left wooden part of the bed: [212, 78, 262, 127]; the suitcase is brown: [100, 75, 229, 137]; a square wooden foot board: [142, 85, 198, 146]; the sheet is white in color: [159, 150, 274, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 383, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[82, 82, 178, 79]\n",
      "process_ann took 0.00 seconds\n",
      "[82, 91, 69, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[141, 87, 54, 59]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 1, 383, 146]; a white png image of a stairway: [0, 91, 383, 121]; a set of bricks in different colors: [82, 82, 178, 79]; a wooden block in minecraft: [82, 91, 69, 71]; a wooden block on a black background: [141, 87, 54, 59]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with different colored blocks; Dense Caption: the box is brown: [77, 74, 263, 164]; white sheets on the bed: [1, 75, 382, 211]; a checkered blanket: [0, 97, 39, 201]; the pillow is checkered: [338, 66, 383, 95]; the wall is white: [56, 15, 336, 167]; the wall is white: [38, 2, 348, 78]; the left wooden part of the bed: [212, 78, 262, 127]; the suitcase is brown: [100, 75, 229, 137]; a square wooden foot board: [142, 85, 198, 146]; the sheet is white in color: [159, 150, 274, 208]; ; Region Captions: a black and white image of a wall: [0, 1, 383, 146]; a white png image of a stairway: [0, 91, 383, 121]; a set of bricks in different colors: [82, 82, 178, 79]; a wooden block in minecraft: [82, 91, 69, 71]; a wooden block on a black background: [141, 87, 54, 59]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [77, 74, 263, 164]; white sheets on the bed: [1, 75, 382, 211]; a checkered blanket: [0, 97, 39, 201]; the pillow is checkered: [338, 66, 383, 95]; the wall is white: [56, 15, 336, 167]; the wall is white: [38, 2, 348, 78]; the left wooden part of the bed: [212, 78, 262, 127]; the suitcase is brown: [100, 75, 229, 137]; a square wooden foot board: [142, 85, 198, 146]; the sheet is white in color: [159, 150, 274, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 383, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[82, 82, 178, 79]\n",
      "process_ann took 0.00 seconds\n",
      "[82, 91, 69, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[141, 87, 54, 59]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 1, 383, 146]; a white png image of a stairway: [0, 91, 383, 121]; a set of bricks in different colors: [82, 82, 178, 79]; a wooden block in minecraft: [82, 91, 69, 71]; a wooden block on a black background: [141, 87, 54, 59]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with different colored blocks; Dense Caption: the box is brown: [77, 74, 263, 164]; white sheets on the bed: [1, 75, 382, 211]; a checkered blanket: [0, 97, 39, 201]; the pillow is checkered: [338, 66, 383, 95]; the wall is white: [56, 15, 336, 167]; the wall is white: [38, 2, 348, 78]; the left wooden part of the bed: [212, 78, 262, 127]; the suitcase is brown: [100, 75, 229, 137]; a square wooden foot board: [142, 85, 198, 146]; the sheet is white in color: [159, 150, 274, 208]; ; Region Captions: a black and white image of a wall: [0, 1, 383, 146]; a white png image of a stairway: [0, 91, 383, 121]; a set of bricks in different colors: [82, 82, 178, 79]; a wooden block in minecraft: [82, 91, 69, 71]; a wooden block on a black background: [141, 87, 54, 59]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [74, 74, 259, 164]; white sheets on the bed: [1, 74, 381, 211]; a checkered piece of cloth: [0, 98, 34, 195]; the pillow is checkered: [332, 65, 383, 97]; the left side of the trunk is light brown: [209, 77, 259, 126]; the wall is white: [42, 2, 351, 122]; a square wooden foot board: [139, 85, 194, 147]; the suitcase is brown in color: [110, 74, 224, 136]; a black cord: [356, 0, 383, 71]; three brown square boxes: [76, 90, 150, 163]; the corner of a table: [332, 1, 383, 95]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 149]\n",
      "process_ann took 0.01 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[78, 82, 179, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[78, 91, 70, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[179, 82, 77, 52]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.96 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 0, 383, 149]; a white png image of a white wall: [0, 90, 383, 122]; a set of different colored blocks in minecraft: [78, 82, 179, 81]; a wooden block in minecraft: [78, 91, 70, 71]; a block of bricks in a brown color: [179, 82, 77, 52]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: the box is brown: [74, 74, 259, 164]; white sheets on the bed: [1, 74, 381, 211]; a checkered piece of cloth: [0, 98, 34, 195]; the pillow is checkered: [332, 65, 383, 97]; the left side of the trunk is light brown: [209, 77, 259, 126]; the wall is white: [42, 2, 351, 122]; a square wooden foot board: [139, 85, 194, 147]; the suitcase is brown in color: [110, 74, 224, 136]; a black cord: [356, 0, 383, 71]; three brown square boxes: [76, 90, 150, 163]; the corner of a table: [332, 1, 383, 95]; ; Region Captions: a black and white image of a wall: [0, 0, 383, 149]; a white png image of a white wall: [0, 90, 383, 122]; a set of different colored blocks in minecraft: [78, 82, 179, 81]; a wooden block in minecraft: [78, 91, 70, 71]; a block of bricks in a brown color: [179, 82, 77, 52]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green square on the kite: [138, 62, 224, 152]; white table top: [2, 37, 376, 211]; the bag is green: [89, 45, 256, 178]; a black and white checkered object: [309, 79, 383, 208]; object in the snow: [44, 87, 106, 118]; the basket is dark: [141, 28, 199, 50]; the white wall next to the bed: [0, 0, 182, 50]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 45, 383, 167]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[182, 0, 201, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 180, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[312, 84, 71, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a small white building with a black door: [0, 45, 383, 167]; a 3d image of a room with a black wall: [0, 0, 383, 89]; a gray wall with a black background: [182, 0, 201, 88]; a gray piece of paper with a black background: [0, 0, 180, 49]; a black and white tiled pattern on a black background: [312, 84, 71, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green square on the kite: [138, 62, 224, 152]; white table top: [2, 37, 376, 211]; the bag is green: [89, 45, 256, 178]; a black and white checkered object: [309, 79, 383, 208]; object in the snow: [44, 87, 106, 118]; the basket is dark: [141, 28, 199, 50]; the white wall next to the bed: [0, 0, 182, 50]; ; Region Captions: a small white building with a black door: [0, 45, 383, 167]; a 3d image of a room with a black wall: [0, 0, 383, 89]; a gray wall with a black background: [182, 0, 201, 88]; a gray piece of paper with a black background: [0, 0, 180, 49]; a black and white tiled pattern on a black background: [312, 84, 71, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a set of wooden blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden box: [77, 113, 382, 211]; a checkered bedspread: [0, 110, 81, 211]; the sky is overcast: [33, 2, 351, 120]; a bed in the photo: [54, 39, 357, 209]; rows of light colored bricks: [151, 120, 236, 211]; sunlight on the table: [292, 122, 382, 212]; the sky is grey in color: [146, 17, 267, 84]; orange square on top of the book: [152, 120, 235, 148]; sunlight on the bench: [292, 123, 383, 156]; a box on the bed: [231, 143, 331, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 124, 106, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 122, 84, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[78, 120, 148, 92]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.79 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man in a hat: [0, 1, 383, 133]; a black and white image of a plane flying over a gray sky: [0, 1, 383, 88]; a wooden block in minecraft: [228, 124, 106, 89]; a wooden box in minecraft: [150, 122, 84, 90]; a wooden block in minecraft: [78, 120, 148, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a set of wooden blocks in minecraft; Dense Caption: a large wooden box: [77, 113, 382, 211]; a checkered bedspread: [0, 110, 81, 211]; the sky is overcast: [33, 2, 351, 120]; a bed in the photo: [54, 39, 357, 209]; rows of light colored bricks: [151, 120, 236, 211]; sunlight on the table: [292, 122, 382, 212]; the sky is grey in color: [146, 17, 267, 84]; orange square on top of the book: [152, 120, 235, 148]; sunlight on the bench: [292, 123, 383, 156]; a box on the bed: [231, 143, 331, 211]; ; Region Captions: a black and white image of a man in a hat: [0, 1, 383, 133]; a black and white image of a plane flying over a gray sky: [0, 1, 383, 88]; a wooden block in minecraft: [228, 124, 106, 89]; a wooden box in minecraft: [150, 122, 84, 90]; a wooden block in minecraft: [78, 120, 148, 92]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a set of wooden blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden box: [77, 113, 382, 211]; a checkered bedspread: [0, 110, 81, 211]; the sky is overcast: [33, 2, 351, 120]; a bed in the photo: [54, 39, 357, 209]; rows of light colored bricks: [151, 120, 236, 211]; sunlight on the table: [292, 122, 382, 212]; the sky is grey in color: [146, 17, 267, 84]; orange square on top of the book: [152, 120, 235, 148]; sunlight on the bench: [292, 123, 383, 156]; a box on the bed: [231, 143, 331, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 124, 106, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 122, 84, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[78, 120, 148, 92]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man in a hat: [0, 1, 383, 133]; a black and white image of a plane flying over a gray sky: [0, 1, 383, 88]; a wooden block in minecraft: [228, 124, 106, 89]; a wooden box in minecraft: [150, 122, 84, 90]; a wooden block in minecraft: [78, 120, 148, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a set of wooden blocks in minecraft; Dense Caption: a large wooden box: [77, 113, 382, 211]; a checkered bedspread: [0, 110, 81, 211]; the sky is overcast: [33, 2, 351, 120]; a bed in the photo: [54, 39, 357, 209]; rows of light colored bricks: [151, 120, 236, 211]; sunlight on the table: [292, 122, 382, 212]; the sky is grey in color: [146, 17, 267, 84]; orange square on top of the book: [152, 120, 235, 148]; sunlight on the bench: [292, 123, 383, 156]; a box on the bed: [231, 143, 331, 211]; ; Region Captions: a black and white image of a man in a hat: [0, 1, 383, 133]; a black and white image of a plane flying over a gray sky: [0, 1, 383, 88]; a wooden block in minecraft: [228, 124, 106, 89]; a wooden box in minecraft: [150, 122, 84, 90]; a wooden block in minecraft: [78, 120, 148, 92]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a set of wooden blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden box: [77, 113, 382, 211]; a checkered bedspread: [0, 110, 81, 211]; the sky is overcast: [33, 2, 351, 120]; a bed in the photo: [54, 39, 357, 209]; rows of light colored bricks: [151, 120, 236, 211]; sunlight on the table: [292, 122, 382, 212]; the sky is grey in color: [146, 17, 267, 84]; orange square on top of the book: [152, 120, 235, 148]; sunlight on the bench: [292, 123, 383, 156]; a box on the bed: [231, 143, 331, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 124, 106, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 122, 84, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[78, 120, 148, 92]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 1.36 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man in a hat: [0, 1, 383, 133]; a black and white image of a plane flying over a gray sky: [0, 1, 383, 88]; a wooden block in minecraft: [228, 124, 106, 89]; a wooden box in minecraft: [150, 122, 84, 90]; a wooden block in minecraft: [78, 120, 148, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a set of wooden blocks in minecraft; Dense Caption: a large wooden box: [77, 113, 382, 211]; a checkered bedspread: [0, 110, 81, 211]; the sky is overcast: [33, 2, 351, 120]; a bed in the photo: [54, 39, 357, 209]; rows of light colored bricks: [151, 120, 236, 211]; sunlight on the table: [292, 122, 382, 212]; the sky is grey in color: [146, 17, 267, 84]; orange square on top of the book: [152, 120, 235, 148]; sunlight on the bench: [292, 123, 383, 156]; a box on the bed: [231, 143, 331, 211]; ; Region Captions: a black and white image of a man in a hat: [0, 1, 383, 133]; a black and white image of a plane flying over a gray sky: [0, 1, 383, 88]; a wooden block in minecraft: [228, 124, 106, 89]; a wooden box in minecraft: [150, 122, 84, 90]; a wooden block in minecraft: [78, 120, 148, 92]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "large wooden box: [3, 77, 348, 195]; the sky is overcast: [36, 2, 344, 84]; the sky is overcast: [32, 4, 342, 171]; the bench is empty: [127, 84, 221, 172]; white snow on the ground: [29, 139, 349, 211]; the right side of the bench: [243, 81, 344, 169]; black and white checkered design on the right side of the umbrella: [0, 101, 19, 162]; a line of rivets in the board: [171, 83, 253, 170]; black and white square: [263, 104, 336, 166]; rows of holes in back of bench: [191, 107, 273, 172]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 124]\n",
      "process_ann took 0.00 seconds\n",
      "[6, 87, 335, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 125, 383, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[6, 92, 119, 96]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 1.00 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a table: [0, 1, 383, 211]; a black and white image of a room with a black wall: [0, 1, 383, 124]; a set of wooden blocks in different colors: [6, 87, 335, 101]; a black and white image of a black and white png: [0, 125, 383, 87]; a wooden table with a wooden top: [6, 92, 119, 96]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: large wooden box: [3, 77, 348, 195]; the sky is overcast: [36, 2, 344, 84]; the sky is overcast: [32, 4, 342, 171]; the bench is empty: [127, 84, 221, 172]; white snow on the ground: [29, 139, 349, 211]; the right side of the bench: [243, 81, 344, 169]; black and white checkered design on the right side of the umbrella: [0, 101, 19, 162]; a line of rivets in the board: [171, 83, 253, 170]; black and white square: [263, 104, 336, 166]; rows of holes in back of bench: [191, 107, 273, 172]; ; Region Captions: a black and white image of a table: [0, 1, 383, 211]; a black and white image of a room with a black wall: [0, 1, 383, 124]; a set of wooden blocks in different colors: [6, 87, 335, 101]; a black and white image of a black and white png: [0, 125, 383, 87]; a wooden table with a wooden top: [6, 92, 119, 96]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden storage unit: [1, 115, 323, 211]; the sky is overcast: [36, 2, 349, 119]; a bed in the sand: [34, 28, 335, 209]; the shadow of the bench on the left: [237, 147, 383, 212]; a red section of a roof: [57, 120, 168, 211]; the left arm of the bench: [225, 112, 316, 211]; a large body of water: [313, 149, 382, 211]; rows of rows of rows of horizontal lines: [159, 117, 234, 209]; the bench is empty: [97, 117, 186, 199]; orange metal roof on top of building: [62, 121, 166, 157]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 117, 314, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[59, 123, 106, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 127, 94, 86]\n",
      "process_ann took 0.00 seconds\n",
      "[240, 150, 143, 63]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a mountain: [0, 1, 383, 115]; a set of wooden blocks in different colors: [0, 117, 314, 95]; a wooden block in minecraft: [59, 123, 106, 89]; a wooden table with a wooden top: [0, 127, 94, 86]; a white and grey skateboard on a black background: [240, 150, 143, 63]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors on it; Dense Caption: a large wooden storage unit: [1, 115, 323, 211]; the sky is overcast: [36, 2, 349, 119]; a bed in the sand: [34, 28, 335, 209]; the shadow of the bench on the left: [237, 147, 383, 212]; a red section of a roof: [57, 120, 168, 211]; the left arm of the bench: [225, 112, 316, 211]; a large body of water: [313, 149, 382, 211]; rows of rows of rows of horizontal lines: [159, 117, 234, 209]; the bench is empty: [97, 117, 186, 199]; orange metal roof on top of building: [62, 121, 166, 157]; ; Region Captions: a black and white image of a mountain: [0, 1, 383, 115]; a set of wooden blocks in different colors: [0, 117, 314, 95]; a wooden block in minecraft: [59, 123, 106, 89]; a wooden table with a wooden top: [0, 127, 94, 86]; a white and grey skateboard on a black background: [240, 150, 143, 63]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a group of red, green and black blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black book: [12, 86, 149, 194]; green square on white table: [241, 77, 339, 154]; the table is white: [33, 50, 341, 209]; square red box: [165, 64, 206, 108]; the back of a chair: [61, 0, 287, 64]; small basket on table: [229, 48, 289, 68]; the bed is wooden: [68, 97, 119, 146]; a black remote control: [52, 47, 120, 66]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 62, 383, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[73, 0, 203, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[13, 92, 133, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[273, 0, 110, 66]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft block: [0, 62, 383, 150]; a black and white image of a room with a door: [0, 0, 383, 91]; a gray box with a black background: [73, 0, 203, 60]; a black block on a black background: [13, 92, 133, 99]; a gray sandstone state with a white background: [273, 0, 110, 66]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a group of red, green and black blocks in minecraft; Dense Caption: a black book: [12, 86, 149, 194]; green square on white table: [241, 77, 339, 154]; the table is white: [33, 50, 341, 209]; square red box: [165, 64, 206, 108]; the back of a chair: [61, 0, 287, 64]; small basket on table: [229, 48, 289, 68]; the bed is wooden: [68, 97, 119, 146]; a black remote control: [52, 47, 120, 66]; ; Region Captions: a black and white image of a minecraft block: [0, 62, 383, 150]; a black and white image of a room with a door: [0, 0, 383, 91]; a gray box with a black background: [73, 0, 203, 60]; a black block on a black background: [13, 92, 133, 99]; a gray sandstone state with a white background: [273, 0, 110, 66]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in front of some blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown and black box: [63, 96, 358, 198]; a checkered table cloth: [0, 104, 59, 203]; the boxes are made of cardboard: [0, 29, 381, 206]; a red table: [279, 132, 382, 211]; the sky is grey: [38, 1, 343, 117]; square shape on the bed: [152, 103, 232, 190]; the edge of a cardboard box: [279, 34, 384, 213]; the edge of a cardboard box: [333, 39, 383, 180]; white table under the books: [2, 161, 310, 212]; the sky is clear: [116, 48, 239, 97]; a blue stripe on a umbrella: [350, 83, 383, 175]; orange square on top of the bed: [152, 101, 230, 130]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 157]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 66]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 138, 349, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 159, 293, 54]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a cloud: [0, 1, 383, 157]; a black and white image of a building with a black and white logo: [0, 1, 383, 66]; a black and white image of a mountain: [0, 1, 383, 101]; a silver arrow with a black background: [0, 138, 349, 75]; a silver metal triangle with a black background: [0, 159, 293, 54]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in front of some blocks; Dense Caption: brown and black box: [63, 96, 358, 198]; a checkered table cloth: [0, 104, 59, 203]; the boxes are made of cardboard: [0, 29, 381, 206]; a red table: [279, 132, 382, 211]; the sky is grey: [38, 1, 343, 117]; square shape on the bed: [152, 103, 232, 190]; the edge of a cardboard box: [279, 34, 384, 213]; the edge of a cardboard box: [333, 39, 383, 180]; white table under the books: [2, 161, 310, 212]; the sky is clear: [116, 48, 239, 97]; a blue stripe on a umbrella: [350, 83, 383, 175]; orange square on top of the bed: [152, 101, 230, 130]; ; Region Captions: a black and white image of a building with a cloud: [0, 1, 383, 157]; a black and white image of a building with a black and white logo: [0, 1, 383, 66]; a black and white image of a mountain: [0, 1, 383, 101]; a silver arrow with a black background: [0, 138, 349, 75]; a silver metal triangle with a black background: [0, 159, 293, 54]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the wooden box is brown: [47, 61, 278, 158]; white snow on the ground: [1, 64, 381, 212]; a black and white checkered piece: [0, 83, 31, 165]; a brown wood grain: [130, 72, 191, 140]; the wall is white: [42, 1, 357, 86]; a line of wood: [186, 72, 229, 128]; the left side of the bench: [217, 64, 276, 123]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 82, 383, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 70, 218, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 78, 83, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[130, 75, 60, 65]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a white sandstone wall with a black background: [0, 82, 383, 130]; a black and white image of a wall: [0, 1, 383, 133]; a block of wood in minecraft: [54, 70, 218, 84]; a wooden block in minecraft: [54, 78, 83, 76]; a wooden block in minecraft: [130, 75, 60, 65]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: the wooden box is brown: [47, 61, 278, 158]; white snow on the ground: [1, 64, 381, 212]; a black and white checkered piece: [0, 83, 31, 165]; a brown wood grain: [130, 72, 191, 140]; the wall is white: [42, 1, 357, 86]; a line of wood: [186, 72, 229, 128]; the left side of the bench: [217, 64, 276, 123]; ; Region Captions: a white sandstone wall with a black background: [0, 82, 383, 130]; a black and white image of a wall: [0, 1, 383, 133]; a block of wood in minecraft: [54, 70, 218, 84]; a wooden block in minecraft: [54, 78, 83, 76]; a wooden block in minecraft: [130, 75, 60, 65]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the wooden box on the ground: [57, 55, 284, 151]; white snow on the ground: [1, 59, 381, 211]; a checkered design on the kite: [0, 74, 43, 169]; a brown wood grain: [135, 65, 200, 132]; the left side of the bench: [222, 58, 285, 117]; the sky is grey: [44, 2, 355, 77]; the wall is made of wood: [38, 17, 355, 161]; a gap between the two halves of the mattress: [122, 67, 151, 138]; the snow is white: [173, 139, 297, 205]; a line of orange and brown stripes: [142, 59, 248, 125]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 79, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[63, 63, 218, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[64, 71, 80, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a white sandstone wall with a black background: [0, 79, 383, 133]; a black and white image of a wall: [0, 1, 383, 123]; a block of wood in minecraft: [63, 63, 218, 81]; a wooden block in minecraft: [64, 71, 80, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: the wooden box on the ground: [57, 55, 284, 151]; white snow on the ground: [1, 59, 381, 211]; a checkered design on the kite: [0, 74, 43, 169]; a brown wood grain: [135, 65, 200, 132]; the left side of the bench: [222, 58, 285, 117]; the sky is grey: [44, 2, 355, 77]; the wall is made of wood: [38, 17, 355, 161]; a gap between the two halves of the mattress: [122, 67, 151, 138]; the snow is white: [173, 139, 297, 205]; a line of orange and brown stripes: [142, 59, 248, 125]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a white sandstone wall with a black background: [0, 79, 383, 133]; a black and white image of a wall: [0, 1, 383, 123]; a block of wood in minecraft: [63, 63, 218, 81]; a wooden block in minecraft: [64, 71, 80, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the wooden box on the ground: [97, 49, 329, 130]; a checkered blanket: [0, 56, 84, 192]; white snowy surface: [35, 75, 343, 213]; a square wooden foot board: [164, 56, 226, 121]; the sky is grey: [37, 1, 348, 85]; the photo was taken in the daytime: [1, 9, 380, 197]; a line of wood with holes in it: [216, 55, 277, 117]; the left side of the bench: [255, 52, 327, 116]; the snow is white: [169, 135, 299, 204]; the square design on the back of the bed: [102, 56, 225, 125]; white snow on the ground: [136, 120, 362, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 87, 383, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[102, 56, 223, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 63, 81, 124]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a white floor with a black background: [0, 87, 383, 125]; a black and white image of a building with a light shining on it: [0, 1, 383, 102]; a set of wooden blocks in different colors: [102, 56, 223, 69]; a black and white block of bricks: [0, 63, 81, 124]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: the wooden box on the ground: [97, 49, 329, 130]; a checkered blanket: [0, 56, 84, 192]; white snowy surface: [35, 75, 343, 213]; a square wooden foot board: [164, 56, 226, 121]; the sky is grey: [37, 1, 348, 85]; the photo was taken in the daytime: [1, 9, 380, 197]; a line of wood with holes in it: [216, 55, 277, 117]; the left side of the bench: [255, 52, 327, 116]; the snow is white: [169, 135, 299, 204]; the square design on the back of the bed: [102, 56, 225, 125]; white snow on the ground: [136, 120, 362, 209]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a white floor with a black background: [0, 87, 383, 125]; a black and white image of a building with a light shining on it: [0, 1, 383, 102]; a set of wooden blocks in different colors: [102, 56, 223, 69]; a black and white block of bricks: [0, 63, 81, 124]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing next to a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black square object: [239, 89, 357, 194]; lego person is holding a book: [199, 38, 248, 124]; wooden box on the counter: [0, 79, 118, 202]; white tablecloth on the table: [0, 68, 381, 210]; red part of fire hydrant: [202, 63, 244, 96]; blue post holding up board: [209, 94, 234, 120]; a yellow top of a red cake: [209, 41, 245, 72]; lego person on top of a cake: [172, 24, 283, 151]; a shadow on the ground: [201, 108, 240, 126]; a small basket: [174, 57, 211, 81]; a lego train on display: [148, 25, 322, 192]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 75, 383, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 188, 107]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 188, 187]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.81 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black and white floor: [0, 2, 383, 210]; a black and white image of a doorway: [0, 75, 383, 137]; a black and white image of a room with a white wall: [0, 0, 383, 106]; a black and white image with the words, i am a sailor: [0, 0, 188, 107]; a black and white image of a mountain: [0, 0, 188, 187]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing next to a block; Dense Caption: a black square object: [239, 89, 357, 194]; lego person is holding a book: [199, 38, 248, 124]; wooden box on the counter: [0, 79, 118, 202]; white tablecloth on the table: [0, 68, 381, 210]; red part of fire hydrant: [202, 63, 244, 96]; blue post holding up board: [209, 94, 234, 120]; a yellow top of a red cake: [209, 41, 245, 72]; lego person on top of a cake: [172, 24, 283, 151]; a shadow on the ground: [201, 108, 240, 126]; a small basket: [174, 57, 211, 81]; a lego train on display: [148, 25, 322, 192]; ; Region Captions: a black and white image of a room with a black and white floor: [0, 2, 383, 210]; a black and white image of a doorway: [0, 75, 383, 137]; a black and white image of a room with a white wall: [0, 0, 383, 106]; a black and white image with the words, i am a sailor: [0, 0, 188, 107]; a black and white image of a mountain: [0, 0, 188, 187]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a small room with a wooden floor and a wooden table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "yellow pages of a book: [138, 160, 273, 212]; dark colored box: [308, 67, 383, 116]; white wall behind the toilet: [1, 1, 380, 211]; white counter top: [229, 97, 382, 212]; the book is open: [94, 57, 342, 212]; the wall is white in color: [116, 52, 223, 139]; the keys on the bed: [341, 70, 382, 87]; the wall is white: [137, 77, 235, 154]; the wall is white in color: [154, 53, 257, 137]; the wall is white: [23, 11, 276, 161]; shadow on the wall: [120, 97, 222, 167]; the wall is white in color: [132, 34, 243, 118]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 349, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[232, 1, 151, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[232, 100, 151, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[137, 163, 135, 50]\n",
      "process_ann took 0.00 seconds\n",
      "[329, 0, 54, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a black background: [0, 1, 349, 211]; a white sheet of paper on a black background: [232, 1, 151, 211]; a white triangle on a black background: [232, 100, 151, 113]; a wooden triangle with a black background: [137, 163, 135, 50]; a gray triangle with a black background: [329, 0, 54, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a small room with a wooden floor and a wooden table; Dense Caption: yellow pages of a book: [138, 160, 273, 212]; dark colored box: [308, 67, 383, 116]; white wall behind the toilet: [1, 1, 380, 211]; white counter top: [229, 97, 382, 212]; the book is open: [94, 57, 342, 212]; the wall is white in color: [116, 52, 223, 139]; the keys on the bed: [341, 70, 382, 87]; the wall is white: [137, 77, 235, 154]; the wall is white in color: [154, 53, 257, 137]; the wall is white: [23, 11, 276, 161]; shadow on the wall: [120, 97, 222, 167]; the wall is white in color: [132, 34, 243, 118]; ; Region Captions: a gray wall with a black background: [0, 1, 349, 211]; a white sheet of paper on a black background: [232, 1, 151, 211]; a white triangle on a black background: [232, 100, 151, 113]; a wooden triangle with a black background: [137, 163, 135, 50]; a gray triangle with a black background: [329, 0, 54, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft screenshot of a room with a red floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the orange and white object: [108, 0, 317, 117]; the window has a white frame: [2, 2, 107, 56]; the base of the clock is orange: [121, 69, 326, 212]; the black and white rug on the floor: [0, 2, 136, 128]; the entire roof is white: [2, 1, 362, 210]; the yellow and brown square: [180, 128, 325, 212]; the square is orange: [153, 94, 247, 170]; white counter top: [1, 75, 191, 211]; the tiles are brown: [172, 115, 230, 161]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[217, 0, 166, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 83, 192, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[109, 0, 209, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 70, 200, 143]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a white wall: [0, 1, 383, 211]; a grey skateboard ramp with a black background: [217, 0, 166, 212]; a silver sheet of paper on a black background: [0, 83, 192, 129]; red block png: [109, 0, 209, 112]; the wooden floor in minecraft: [129, 70, 200, 143]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft screenshot of a room with a red floor; Dense Caption: the orange and white object: [108, 0, 317, 117]; the window has a white frame: [2, 2, 107, 56]; the base of the clock is orange: [121, 69, 326, 212]; the black and white rug on the floor: [0, 2, 136, 128]; the entire roof is white: [2, 1, 362, 210]; the yellow and brown square: [180, 128, 325, 212]; the square is orange: [153, 94, 247, 170]; white counter top: [1, 75, 191, 211]; the tiles are brown: [172, 115, 230, 161]; ; Region Captions: a black and white image of a room with a white wall: [0, 1, 383, 211]; a grey skateboard ramp with a black background: [217, 0, 166, 212]; a silver sheet of paper on a black background: [0, 83, 192, 129]; red block png: [109, 0, 209, 112]; the wooden floor in minecraft: [129, 70, 200, 143]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with some blocks on the ground\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black square object: [203, 82, 282, 166]; a white table: [0, 2, 382, 210]; the corner of a black book: [0, 14, 65, 74]; a square red square: [285, 50, 351, 109]; two black square things: [166, 46, 356, 180]; the hole is in the snow: [127, 66, 164, 94]; the top of a red flag: [219, 186, 268, 212]; the snow is white: [34, 13, 235, 171]; the snow is white in color: [36, 79, 134, 172]; the black square on the umbrella: [211, 92, 263, 151]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 7, 383, 205]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 32]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 180, 32]\n",
      "process_ann took 0.00 seconds\n",
      "[207, 86, 73, 79]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 18, 62, 53]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a white snow globe with two black holes: [0, 7, 383, 205]; a black and white image of a curved wall: [0, 0, 383, 32]; a gray png file with a black background: [0, 0, 180, 32]; a black block on a black background: [207, 86, 73, 79]; a black stone block with a blue door: [0, 18, 62, 53]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with some blocks on the ground; Dense Caption: a black square object: [203, 82, 282, 166]; a white table: [0, 2, 382, 210]; the corner of a black book: [0, 14, 65, 74]; a square red square: [285, 50, 351, 109]; two black square things: [166, 46, 356, 180]; the hole is in the snow: [127, 66, 164, 94]; the top of a red flag: [219, 186, 268, 212]; the snow is white: [34, 13, 235, 171]; the snow is white in color: [36, 79, 134, 172]; the black square on the umbrella: [211, 92, 263, 151]; ; Region Captions: a white snow globe with two black holes: [0, 7, 383, 205]; a black and white image of a curved wall: [0, 0, 383, 32]; a gray png file with a black background: [0, 0, 180, 32]; a black block on a black background: [207, 86, 73, 79]; a black stone block with a blue door: [0, 18, 62, 53]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the boxes are made of wood: [141, 77, 372, 212]; square patterned ottoman: [0, 57, 177, 140]; a brown and tan box: [184, 133, 382, 211]; red flag on the pole: [140, 0, 314, 21]; a bed in the room: [51, 28, 326, 211]; the number 1: [0, 120, 57, 177]; a blanket on the bed: [36, 57, 136, 85]; the table is made of wood: [180, 111, 239, 157]; the table is made of wood: [165, 104, 285, 210]; white wall behind bed: [1, 0, 149, 76]; white sheets on the bed: [1, 116, 171, 211]; the table is made of wood: [160, 97, 266, 163]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 1, 381, 175]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 1, 240, 175]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 120, 383, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 120, 169, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[188, 135, 195, 78]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a wall with a black wall and a white wall: [2, 1, 381, 175]; a gray wall with a black background: [143, 1, 240, 175]; a man is standing on a black wall: [0, 120, 383, 93]; a silver state map with a black background: [0, 120, 169, 93]; a wooden plank on a black background: [188, 135, 195, 78]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden floor; Dense Caption: the boxes are made of wood: [141, 77, 372, 212]; square patterned ottoman: [0, 57, 177, 140]; a brown and tan box: [184, 133, 382, 211]; red flag on the pole: [140, 0, 314, 21]; a bed in the room: [51, 28, 326, 211]; the number 1: [0, 120, 57, 177]; a blanket on the bed: [36, 57, 136, 85]; the table is made of wood: [180, 111, 239, 157]; the table is made of wood: [165, 104, 285, 210]; white wall behind bed: [1, 0, 149, 76]; white sheets on the bed: [1, 116, 171, 211]; the table is made of wood: [160, 97, 266, 163]; ; Region Captions: a wall with a black wall and a white wall: [2, 1, 381, 175]; a gray wall with a black background: [143, 1, 240, 175]; a man is standing on a black wall: [0, 120, 383, 93]; a silver state map with a black background: [0, 120, 169, 93]; a wooden plank on a black background: [188, 135, 195, 78]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft screenshot of a red and white block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "red fabric hanging from ceiling: [130, 0, 298, 70]; a black and white checkered bedspread: [0, 99, 165, 194]; a brown wooden table: [126, 122, 361, 212]; the walls are white: [0, 2, 381, 210]; a bed in the room: [32, 82, 312, 211]; the table is made of wood: [141, 139, 274, 211]; white sheet on bed: [1, 162, 137, 212]; a design on the blanket: [13, 101, 123, 129]; a brown and tan striped blanket: [205, 173, 361, 212]; a white wall: [1, 2, 131, 109]; the table is made of wood: [172, 154, 230, 198]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[72, 0, 311, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[137, 46, 246, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 135, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[128, 128, 235, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[134, 0, 162, 68]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.50 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a black door: [72, 0, 311, 212]; a black wall with a black ledge: [137, 46, 246, 166]; a gray square with a black background: [0, 0, 135, 112]; a wooden floor in minecraft: [128, 128, 235, 85]; red cube png: [134, 0, 162, 68]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft screenshot of a red and white block; Dense Caption: red fabric hanging from ceiling: [130, 0, 298, 70]; a black and white checkered bedspread: [0, 99, 165, 194]; a brown wooden table: [126, 122, 361, 212]; the walls are white: [0, 2, 381, 210]; a bed in the room: [32, 82, 312, 211]; the table is made of wood: [141, 139, 274, 211]; white sheet on bed: [1, 162, 137, 212]; a design on the blanket: [13, 101, 123, 129]; a brown and tan striped blanket: [205, 173, 361, 212]; a white wall: [1, 2, 131, 109]; the table is made of wood: [172, 154, 230, 198]; ; Region Captions: a gray wall with a black door: [72, 0, 311, 212]; a black wall with a black ledge: [137, 46, 246, 166]; a gray square with a black background: [0, 0, 135, 112]; a wooden floor in minecraft: [128, 128, 235, 85]; red cube png: [134, 0, 162, 68]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft screenshot of a red and white block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "red fabric hanging from ceiling: [130, 0, 298, 70]; a black and white checkered bedspread: [0, 99, 165, 194]; a brown wooden table: [126, 122, 361, 212]; the walls are white: [0, 2, 381, 210]; a bed in the room: [32, 82, 312, 211]; the table is made of wood: [141, 139, 274, 211]; white sheet on bed: [1, 162, 137, 212]; a design on the blanket: [13, 101, 123, 129]; a brown and tan striped blanket: [205, 173, 361, 212]; a white wall: [1, 2, 131, 109]; the table is made of wood: [172, 154, 230, 198]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[72, 0, 311, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[137, 46, 246, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 135, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[128, 128, 235, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[134, 0, 162, 68]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.50 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a black door: [72, 0, 311, 212]; a black wall with a black ledge: [137, 46, 246, 166]; a gray square with a black background: [0, 0, 135, 112]; a wooden floor in minecraft: [128, 128, 235, 85]; red cube png: [134, 0, 162, 68]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft screenshot of a red and white block; Dense Caption: red fabric hanging from ceiling: [130, 0, 298, 70]; a black and white checkered bedspread: [0, 99, 165, 194]; a brown wooden table: [126, 122, 361, 212]; the walls are white: [0, 2, 381, 210]; a bed in the room: [32, 82, 312, 211]; the table is made of wood: [141, 139, 274, 211]; white sheet on bed: [1, 162, 137, 212]; a design on the blanket: [13, 101, 123, 129]; a brown and tan striped blanket: [205, 173, 361, 212]; a white wall: [1, 2, 131, 109]; the table is made of wood: [172, 154, 230, 198]; ; Region Captions: a gray wall with a black door: [72, 0, 311, 212]; a black wall with a black ledge: [137, 46, 246, 166]; a gray square with a black background: [0, 0, 135, 112]; a wooden floor in minecraft: [128, 128, 235, 85]; red cube png: [134, 0, 162, 68]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a person standing in front of some blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white book: [189, 86, 342, 211]; white tablecloth on the table: [1, 32, 382, 210]; red fabric block: [77, 58, 154, 120]; black and green object: [197, 12, 252, 97]; the dark grey box: [268, 41, 383, 93]; a piece of red cloth: [342, 82, 383, 188]; the basket is brown: [12, 34, 106, 60]; a red blue and yellow flag: [105, 0, 157, 65]; a lego ice chest: [74, 1, 163, 121]; lego blocks on a cake: [50, 0, 252, 149]; blue plastic decorative piece: [109, 38, 155, 65]; the walls are white: [0, 1, 382, 59]; a green piece of paper: [199, 58, 245, 96]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 54, 383, 159]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 54, 224, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 63]\n",
      "process_ann took 0.00 seconds\n",
      "[194, 90, 147, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[241, 63, 142, 150]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 54, 383, 159]; a black and white image of a small black box: [0, 54, 224, 158]; a silhouette of a city with a black background: [0, 0, 383, 63]; a black block on a white background: [194, 90, 147, 123]; a white x with a black background: [241, 63, 142, 150]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a person standing in front of some blocks; Dense Caption: a black and white book: [189, 86, 342, 211]; white tablecloth on the table: [1, 32, 382, 210]; red fabric block: [77, 58, 154, 120]; black and green object: [197, 12, 252, 97]; the dark grey box: [268, 41, 383, 93]; a piece of red cloth: [342, 82, 383, 188]; the basket is brown: [12, 34, 106, 60]; a red blue and yellow flag: [105, 0, 157, 65]; a lego ice chest: [74, 1, 163, 121]; lego blocks on a cake: [50, 0, 252, 149]; blue plastic decorative piece: [109, 38, 155, 65]; the walls are white: [0, 1, 382, 59]; a green piece of paper: [199, 58, 245, 96]; ; Region Captions: a black and white image of a snowy area: [0, 54, 383, 159]; a black and white image of a small black box: [0, 54, 224, 158]; a silhouette of a city with a black background: [0, 0, 383, 63]; a black block on a white background: [194, 90, 147, 123]; a white x with a black background: [241, 63, 142, 150]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue object in the snow\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and white square: [170, 1, 310, 113]; snowboard is in the air: [17, 75, 109, 148]; a white blanket of snow: [0, 1, 382, 210]; a brown section of a stop sign: [179, 0, 311, 40]; green and white square: [184, 31, 278, 120]; a green sign is on the bottom: [201, 37, 254, 86]; a blue and green box: [95, 2, 327, 141]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[181, 9, 107, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[290, 0, 93, 50]\n",
      "process_ann took 0.00 seconds\n",
      "[177, 0, 206, 50]\n",
      "process_ann took 0.00 seconds\n",
      "[22, 82, 80, 59]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white object: [0, 1, 383, 211]; a blue square on a black background: [181, 9, 107, 99]; a white shaped piece of paper: [290, 0, 93, 50]; a white tie with a black background: [177, 0, 206, 50]; a grey circle with a black background: [22, 82, 80, 59]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue object in the snow; Dense Caption: green and white square: [170, 1, 310, 113]; snowboard is in the air: [17, 75, 109, 148]; a white blanket of snow: [0, 1, 382, 210]; a brown section of a stop sign: [179, 0, 311, 40]; green and white square: [184, 31, 278, 120]; a green sign is on the bottom: [201, 37, 254, 86]; a blue and green box: [95, 2, 327, 141]; ; Region Captions: a black and white image of a black and white object: [0, 1, 383, 211]; a blue square on a black background: [181, 9, 107, 99]; a white shaped piece of paper: [290, 0, 93, 50]; a white tie with a black background: [177, 0, 206, 50]; a grey circle with a black background: [22, 82, 80, 59]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing next to a red block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and white square: [119, 97, 217, 172]; a red green and blue item: [87, 1, 232, 174]; snow covering the ground: [1, 31, 381, 210]; a red blue and yellow striped object: [297, 3, 382, 182]; shadow of the snowboarder: [296, 129, 382, 191]; a black object on the table: [280, 27, 352, 52]; a blue section of a snowboard: [92, 80, 241, 195]; the wall is white: [0, 2, 372, 61]; blue square section of a cake: [316, 107, 382, 177]; red square on the bottom of the snowboard: [100, 2, 222, 99]; red section of the object: [299, 57, 382, 142]; red base of a blue object: [313, 134, 371, 178]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 44, 383, 168]\n",
      "process_ann took 0.00 seconds\n",
      "[98, 0, 126, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[98, 0, 126, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 58]\n",
      "process_ann took 0.00 seconds\n",
      "[122, 99, 93, 72]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white object: [0, 44, 383, 168]; a red and blue block in minecraft: [98, 0, 126, 171]; red brick texture: [98, 0, 126, 103]; a black and white image of a building: [0, 0, 383, 58]; a blue square on a black background: [122, 99, 93, 72]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing next to a red block; Dense Caption: green and white square: [119, 97, 217, 172]; a red green and blue item: [87, 1, 232, 174]; snow covering the ground: [1, 31, 381, 210]; a red blue and yellow striped object: [297, 3, 382, 182]; shadow of the snowboarder: [296, 129, 382, 191]; a black object on the table: [280, 27, 352, 52]; a blue section of a snowboard: [92, 80, 241, 195]; the wall is white: [0, 2, 372, 61]; blue square section of a cake: [316, 107, 382, 177]; red square on the bottom of the snowboard: [100, 2, 222, 99]; red section of the object: [299, 57, 382, 142]; red base of a blue object: [313, 134, 371, 178]; ; Region Captions: a black and white image of a black and white object: [0, 44, 383, 168]; a red and blue block in minecraft: [98, 0, 126, 171]; red brick texture: [98, 0, 126, 103]; a black and white image of a building: [0, 0, 383, 58]; a blue square on a black background: [122, 99, 93, 72]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "red ottoman in front of the couch: [163, 85, 231, 151]; a black and white checkered bedspread: [0, 109, 174, 211]; box is brown color: [83, 64, 190, 109]; brown box on white table: [184, 71, 319, 140]; red item on wall: [197, 3, 256, 55]; the bed has white sheets: [31, 65, 341, 211]; black and green patterned box: [0, 36, 65, 157]; the square pillow on the left side of the bed: [250, 82, 317, 139]; a table with a table cloth: [8, 25, 223, 207]; the corner of a red blanket: [186, 59, 269, 105]; a green piece of paper: [3, 91, 63, 153]; white table cloth: [200, 144, 376, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[152, 0, 231, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 148]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 93, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 114, 172, 99]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 0, 383, 211]; a small room with a door and a window: [152, 0, 231, 149]; a black and white image of a room with a door: [2, 0, 381, 148]; a black and white image of a mountain: [0, 93, 383, 120]; a black square on a black background: [0, 114, 172, 99]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with different colored blocks; Dense Caption: red ottoman in front of the couch: [163, 85, 231, 151]; a black and white checkered bedspread: [0, 109, 174, 211]; box is brown color: [83, 64, 190, 109]; brown box on white table: [184, 71, 319, 140]; red item on wall: [197, 3, 256, 55]; the bed has white sheets: [31, 65, 341, 211]; black and green patterned box: [0, 36, 65, 157]; the square pillow on the left side of the bed: [250, 82, 317, 139]; a table with a table cloth: [8, 25, 223, 207]; the corner of a red blanket: [186, 59, 269, 105]; a green piece of paper: [3, 91, 63, 153]; white table cloth: [200, 144, 376, 210]; ; Region Captions: a black and white image of a room: [0, 0, 383, 211]; a small room with a door and a window: [152, 0, 231, 149]; a black and white image of a room with a door: [2, 0, 381, 148]; a black and white image of a mountain: [0, 93, 383, 120]; a black square on a black background: [0, 114, 172, 99]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a red, green, and blue block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "black and green suitcase: [191, 47, 263, 149]; red fabric on a bench: [83, 88, 146, 140]; a black and white checkered tablecloth: [1, 130, 192, 211]; a large dark object with light and dark fliers: [306, 80, 383, 157]; white table cloth on table: [27, 62, 357, 212]; the suitcase is green: [162, 35, 294, 166]; white wall in the background: [1, 1, 150, 89]; green base of a sculpture: [195, 95, 256, 148]; a table with a red cloth: [20, 65, 193, 205]; a small basket in the corner: [107, 67, 166, 88]; blue and yellow box: [184, 52, 201, 128]; black square of cake: [196, 49, 260, 102]; the sheet is white: [221, 149, 321, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 84, 383, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 0, 241, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 0, 379, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 0, 240, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 132, 190, 81]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a building: [0, 84, 383, 128]; a silhouette of a building with a cloudy sky: [142, 0, 241, 210]; a black and white image of a city with a skyscraper: [4, 0, 379, 104]; a silhouette of a city with a skyscraper: [143, 0, 240, 104]; a black square on a black background: [0, 132, 190, 81]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a red, green, and blue block; Dense Caption: black and green suitcase: [191, 47, 263, 149]; red fabric on a bench: [83, 88, 146, 140]; a black and white checkered tablecloth: [1, 130, 192, 211]; a large dark object with light and dark fliers: [306, 80, 383, 157]; white table cloth on table: [27, 62, 357, 212]; the suitcase is green: [162, 35, 294, 166]; white wall in the background: [1, 1, 150, 89]; green base of a sculpture: [195, 95, 256, 148]; a table with a red cloth: [20, 65, 193, 205]; a small basket in the corner: [107, 67, 166, 88]; blue and yellow box: [184, 52, 201, 128]; black square of cake: [196, 49, 260, 102]; the sheet is white: [221, 149, 321, 209]; ; Region Captions: a white and black image of a building: [0, 84, 383, 128]; a silhouette of a building with a cloudy sky: [142, 0, 241, 210]; a black and white image of a city with a skyscraper: [4, 0, 379, 104]; a silhouette of a city with a skyscraper: [143, 0, 240, 104]; a black square on a black background: [0, 132, 190, 81]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is cardboard: [29, 107, 353, 211]; red hanging shade: [53, 0, 177, 66]; a checkered blanket on a bed: [0, 103, 55, 176]; a very blurry gray sky: [0, 1, 379, 210]; line of many white squares: [227, 125, 364, 212]; a brown wooden dresser: [73, 114, 171, 211]; the wall is white: [43, 2, 346, 124]; white counter top: [0, 164, 116, 212]; rows of horizontal lines: [139, 120, 234, 211]; the bed frame is made of wood: [22, 109, 116, 200]; the wall is white in color: [168, 62, 268, 113]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[25, 115, 342, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[229, 127, 137, 86]\n",
      "process_ann took 0.00 seconds\n",
      "[56, 0, 116, 63]\n",
      "process_ann took 0.00 seconds\n",
      "[75, 118, 96, 94]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a room with a black wall: [0, 0, 383, 211]; a block of wood in minecraft: [25, 115, 342, 98]; a wooden block in minecraft: [229, 127, 137, 86]; red block png: [56, 0, 116, 63]; a wooden block in minecraft: [75, 118, 96, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: the box is cardboard: [29, 107, 353, 211]; red hanging shade: [53, 0, 177, 66]; a checkered blanket on a bed: [0, 103, 55, 176]; a very blurry gray sky: [0, 1, 379, 210]; line of many white squares: [227, 125, 364, 212]; a brown wooden dresser: [73, 114, 171, 211]; the wall is white: [43, 2, 346, 124]; white counter top: [0, 164, 116, 212]; rows of horizontal lines: [139, 120, 234, 211]; the bed frame is made of wood: [22, 109, 116, 200]; the wall is white in color: [168, 62, 268, 113]; ; Region Captions: a 3d image of a room with a black wall: [0, 0, 383, 211]; a block of wood in minecraft: [25, 115, 342, 98]; a wooden block in minecraft: [229, 127, 137, 86]; red block png: [56, 0, 116, 63]; a wooden block in minecraft: [75, 118, 96, 94]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a red and green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red ottoman: [159, 112, 232, 191]; a black and green chair: [0, 66, 114, 212]; brown box is on white carpet: [197, 98, 352, 192]; the box is made of cardboard: [262, 112, 352, 190]; red item on the wall: [211, 33, 266, 80]; a small checkered box: [110, 92, 206, 133]; a living room: [0, 4, 381, 208]; a yellow paper with a blue circle on it: [160, 73, 193, 103]; black and green pillow on the bed: [0, 67, 73, 155]; a white floor: [112, 101, 369, 211]; a checkered box: [110, 94, 161, 132]; a set of red and gold furniture: [156, 32, 354, 193]; red pillow on the bed: [162, 89, 200, 124]; green color pillow kept in the bed: [2, 111, 71, 153]; paper bag on red box: [152, 68, 206, 129]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 0, 381, 188]\n",
      "process_ann took 0.00 seconds\n",
      "[177, 0, 206, 188]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 175, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[71, 118, 312, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 126, 111, 87]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a door: [2, 0, 381, 188]; a black and white image of a room with a window: [177, 0, 206, 188]; a gray speech bubble with a white background: [0, 0, 175, 117]; a white and silver building with a spire: [71, 118, 312, 94]; a black square block on a black background: [0, 126, 111, 87]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a red and green block; Dense Caption: a red ottoman: [159, 112, 232, 191]; a black and green chair: [0, 66, 114, 212]; brown box is on white carpet: [197, 98, 352, 192]; the box is made of cardboard: [262, 112, 352, 190]; red item on the wall: [211, 33, 266, 80]; a small checkered box: [110, 92, 206, 133]; a living room: [0, 4, 381, 208]; a yellow paper with a blue circle on it: [160, 73, 193, 103]; black and green pillow on the bed: [0, 67, 73, 155]; a white floor: [112, 101, 369, 211]; a checkered box: [110, 94, 161, 132]; a set of red and gold furniture: [156, 32, 354, 193]; red pillow on the bed: [162, 89, 200, 124]; green color pillow kept in the bed: [2, 111, 71, 153]; paper bag on red box: [152, 68, 206, 129]; ; Region Captions: a black and white image of a door: [2, 0, 381, 188]; a black and white image of a room with a window: [177, 0, 206, 188]; a gray speech bubble with a white background: [0, 0, 175, 117]; a white and silver building with a spire: [71, 118, 312, 94]; a black square block on a black background: [0, 126, 111, 87]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red and blue block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red ottoman: [158, 113, 233, 191]; box is dark brown: [109, 92, 206, 133]; black and green sofa: [0, 66, 115, 212]; the box is made of cardboard: [262, 112, 352, 190]; brown box is on white carpet: [198, 98, 352, 191]; red item on the wall: [211, 33, 266, 80]; a room with white walls: [0, 4, 381, 208]; red white and blue cardboard box: [55, 68, 104, 136]; a table with a red cloth: [34, 62, 270, 210]; yellow gift bag: [61, 75, 93, 103]; white carpet on the floor: [106, 116, 364, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 0, 381, 189]\n",
      "process_ann took 0.00 seconds\n",
      "[177, 0, 206, 189]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 175, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[95, 118, 288, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 126, 111, 87]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a small door with a small window in it: [2, 0, 381, 189]; a black and white image of a room with a window: [177, 0, 206, 189]; a gray speech bubble with a white arrow: [0, 0, 175, 115]; a silver arrow with a black background: [95, 118, 288, 95]; a black square block on a dark background: [0, 126, 111, 87]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red and blue block; Dense Caption: a red ottoman: [158, 113, 233, 191]; box is dark brown: [109, 92, 206, 133]; black and green sofa: [0, 66, 115, 212]; the box is made of cardboard: [262, 112, 352, 190]; brown box is on white carpet: [198, 98, 352, 191]; red item on the wall: [211, 33, 266, 80]; a room with white walls: [0, 4, 381, 208]; red white and blue cardboard box: [55, 68, 104, 136]; a table with a red cloth: [34, 62, 270, 210]; yellow gift bag: [61, 75, 93, 103]; white carpet on the floor: [106, 116, 364, 212]; ; Region Captions: a small door with a small window in it: [2, 0, 381, 189]; a black and white image of a room with a window: [177, 0, 206, 189]; a gray speech bubble with a white arrow: [0, 0, 175, 115]; a silver arrow with a black background: [95, 118, 288, 95]; a black square block on a dark background: [0, 126, 111, 87]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "table is round: [0, 9, 383, 208]; a black product box: [94, 62, 262, 190]; red stripe on white: [36, 167, 241, 212]; black and green flag: [288, 9, 383, 177]; a red and blue paper cup: [91, 25, 156, 95]; a small grey stone: [13, 99, 66, 125]; green section of the vase: [290, 82, 382, 166]; red square of fabric: [210, 61, 251, 91]; blue square on the bottom of the cup: [100, 65, 154, 95]; orange fabric: [0, 66, 29, 115]; shadow of the book: [9, 91, 73, 135]; a brown object on the table: [274, 44, 315, 67]; a red and blue paper cup: [58, 11, 174, 129]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 57, 383, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 371, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[100, 84, 283, 124]\n",
      "process_ann took 0.00 seconds\n",
      "[100, 83, 156, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[45, 83, 211, 126]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a door: [0, 57, 383, 155]; a black and white image of a building: [0, 0, 371, 70]; a black block with a red flower on it: [100, 84, 283, 124]; a black block on a white background: [100, 83, 156, 106]; a black block on a black background: [45, 83, 211, 126]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with different colored blocks; Dense Caption: table is round: [0, 9, 383, 208]; a black product box: [94, 62, 262, 190]; red stripe on white: [36, 167, 241, 212]; black and green flag: [288, 9, 383, 177]; a red and blue paper cup: [91, 25, 156, 95]; a small grey stone: [13, 99, 66, 125]; green section of the vase: [290, 82, 382, 166]; red square of fabric: [210, 61, 251, 91]; blue square on the bottom of the cup: [100, 65, 154, 95]; orange fabric: [0, 66, 29, 115]; shadow of the book: [9, 91, 73, 135]; a brown object on the table: [274, 44, 315, 67]; a red and blue paper cup: [58, 11, 174, 129]; ; Region Captions: a black and white image of a door: [0, 57, 383, 155]; a black and white image of a building: [0, 0, 371, 70]; a black block with a red flower on it: [100, 84, 283, 124]; a black block on a white background: [100, 83, 156, 106]; a black block on a black background: [45, 83, 211, 126]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a green and red color\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and yellow table: [114, 34, 379, 211]; red and blue paper: [232, 34, 307, 115]; a green piece of cloth: [292, 37, 382, 210]; blue square on the bottom of the red umbrella: [233, 76, 294, 114]; back of the chair: [125, 36, 231, 130]; a black and white table cloth: [139, 106, 320, 210]; a black and white checkered pillow: [49, 50, 131, 85]; the back of a chair: [97, 28, 241, 182]; white bedsheets: [1, 80, 154, 211]; red and blue paper: [206, 19, 318, 130]; the back wall is white: [43, 1, 302, 87]; the chair is black: [71, 21, 323, 160]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[128, 41, 219, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 61, 329, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 78, 159, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 78, 227, 134]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and green block in minecraft: [128, 41, 219, 171]; a 3d model of a room with a black background: [0, 0, 383, 128]; a white and black image of a door: [0, 61, 329, 151]; a white sand png: [0, 78, 159, 135]; a white png image of a snowy path: [0, 78, 227, 134]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a green and red color; Dense Caption: a black and yellow table: [114, 34, 379, 211]; red and blue paper: [232, 34, 307, 115]; a green piece of cloth: [292, 37, 382, 210]; blue square on the bottom of the red umbrella: [233, 76, 294, 114]; back of the chair: [125, 36, 231, 130]; a black and white table cloth: [139, 106, 320, 210]; a black and white checkered pillow: [49, 50, 131, 85]; the back of a chair: [97, 28, 241, 182]; white bedsheets: [1, 80, 154, 211]; red and blue paper: [206, 19, 318, 130]; the back wall is white: [43, 1, 302, 87]; the chair is black: [71, 21, 323, 160]; ; Region Captions: a black and green block in minecraft: [128, 41, 219, 171]; a 3d model of a room with a black background: [0, 0, 383, 128]; a white and black image of a door: [0, 61, 329, 151]; a white sand png: [0, 78, 159, 135]; a white png image of a snowy path: [0, 78, 227, 134]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft screenshot of a wall with a hole in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "black and white traffic sign: [6, 1, 382, 188]; the front of the airplane: [16, 56, 89, 115]; black and white checkered design: [85, 69, 346, 201]; the white stripes on the umbrella: [41, 5, 286, 136]; the sky is cloudy: [23, 132, 122, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 166, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 97, 381, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 97, 241, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[137, 88, 165, 91]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white puzzle piece with a black hole: [0, 1, 383, 211]; a white sheet with a hole in it: [0, 1, 166, 211]; a white pyramid with a black background: [2, 97, 381, 115]; a white triangle with a black background: [142, 97, 241, 115]; a black square on a black background: [137, 88, 165, 91]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft screenshot of a wall with a hole in it; Dense Caption: black and white traffic sign: [6, 1, 382, 188]; the front of the airplane: [16, 56, 89, 115]; black and white checkered design: [85, 69, 346, 201]; the white stripes on the umbrella: [41, 5, 286, 136]; the sky is cloudy: [23, 132, 122, 209]; ; Region Captions: a black and white puzzle piece with a black hole: [0, 1, 383, 211]; a white sheet with a hole in it: [0, 1, 166, 211]; a white pyramid with a black background: [2, 97, 381, 115]; a white triangle with a black background: [142, 97, 241, 115]; a black square on a black background: [137, 88, 165, 91]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red and brown block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red square tile: [243, 72, 323, 149]; a brown and white striped comforter: [1, 1, 257, 212]; a gray floor rug: [252, 49, 380, 94]; a white bed: [206, 74, 381, 212]; a brown wooden cabinet: [334, 66, 383, 164]; the wall is brown in color: [67, 34, 164, 140]; a brown wooden dresser: [152, 2, 270, 211]; white wall behind the suitcase: [244, 0, 368, 58]; two pillows on a bed: [235, 41, 382, 167]; the wall is brown in color: [63, 74, 167, 170]; the pillow is red in color: [253, 79, 304, 136]; the sheet is white in color: [252, 150, 350, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 260, 213]\n",
      "process_ann took 0.00 seconds\n",
      "[208, 94, 175, 119]\n",
      "process_ann took 0.00 seconds\n",
      "[208, 9, 175, 203]\n",
      "process_ann took 0.00 seconds\n",
      "[238, 0, 145, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[238, 0, 124, 55]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a brown and black minecraft texture: [0, 0, 260, 213]; a white triangle with a black background: [208, 94, 175, 119]; a black and white image of a hallway: [208, 9, 175, 203]; a grey shaped object with a black background: [238, 0, 145, 70]; a grey shaped object with a black background: [238, 0, 124, 55]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red and brown block; Dense Caption: a red square tile: [243, 72, 323, 149]; a brown and white striped comforter: [1, 1, 257, 212]; a gray floor rug: [252, 49, 380, 94]; a white bed: [206, 74, 381, 212]; a brown wooden cabinet: [334, 66, 383, 164]; the wall is brown in color: [67, 34, 164, 140]; a brown wooden dresser: [152, 2, 270, 211]; white wall behind the suitcase: [244, 0, 368, 58]; two pillows on a bed: [235, 41, 382, 167]; the wall is brown in color: [63, 74, 167, 170]; the pillow is red in color: [253, 79, 304, 136]; the sheet is white in color: [252, 150, 350, 210]; ; Region Captions: a brown and black minecraft texture: [0, 0, 260, 213]; a white triangle with a black background: [208, 94, 175, 119]; a black and white image of a hallway: [208, 9, 175, 203]; a grey shaped object with a black background: [238, 0, 145, 70]; a grey shaped object with a black background: [238, 0, 124, 55]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft wall with a red, black and brown pattern\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large white umbrella: [0, 1, 382, 211]; the shadow of the sign: [0, 123, 67, 191]; red portion of a kite: [342, 74, 383, 155]; black line on umbrella: [102, 43, 204, 132]; the blue and white portion of the umbrella: [108, 52, 362, 213]; a shadow on the side of the building: [0, 58, 112, 212]; the umbrella is black: [39, 7, 263, 143]; black line on the umbrella: [109, 70, 216, 160]; blue and white stripes: [51, 95, 302, 211]; the right side of the umbrella: [254, 3, 382, 188]; black square on the clock tower: [144, 131, 276, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[120, 1, 263, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[231, 81, 152, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 63, 111, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[229, 132, 154, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[281, 0, 102, 125]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and brown checkered pattern on a black background: [120, 1, 263, 211]; a red and white pixelated house: [231, 81, 152, 131]; a black circle on a white surface: [0, 63, 111, 150]; a triangle with a white background: [229, 132, 154, 81]; a black square with a black background: [281, 0, 102, 125]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft wall with a red, black and brown pattern; Dense Caption: a large white umbrella: [0, 1, 382, 211]; the shadow of the sign: [0, 123, 67, 191]; red portion of a kite: [342, 74, 383, 155]; black line on umbrella: [102, 43, 204, 132]; the blue and white portion of the umbrella: [108, 52, 362, 213]; a shadow on the side of the building: [0, 58, 112, 212]; the umbrella is black: [39, 7, 263, 143]; black line on the umbrella: [109, 70, 216, 160]; blue and white stripes: [51, 95, 302, 211]; the right side of the umbrella: [254, 3, 382, 188]; black square on the clock tower: [144, 131, 276, 212]; ; Region Captions: a black and brown checkered pattern on a black background: [120, 1, 263, 211]; a red and white pixelated house: [231, 81, 152, 131]; a black circle on a white surface: [0, 63, 111, 150]; a triangle with a white background: [229, 132, 154, 81]; a black square with a black background: [281, 0, 102, 125]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a brown and black wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large computer monitor: [1, 1, 382, 211]; red fabric behind a black white and orange flag: [358, 121, 383, 208]; black and blue shade on the window: [281, 0, 382, 211]; a shadow on the ground: [0, 187, 53, 212]; the wall is brown in color: [142, 75, 237, 172]; black and white striped wall: [211, 67, 293, 177]; black line on the wall: [113, 78, 208, 169]; black and white striped background: [176, 90, 275, 194]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 213]\n",
      "process_ann took 0.00 seconds\n",
      "[287, 2, 95, 185]\n",
      "process_ann took 0.00 seconds\n",
      "[63, 0, 67, 111]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 47, 109]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 28, 47, 171]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.53 seconds\n",
      "finished...\n",
      "\n",
      "a brown and black minecraft texture: [0, 0, 383, 213]; a black square on a black background: [287, 2, 95, 185]; a brown letter l on a black background: [63, 0, 67, 111]; a white sheet of paper on a black surface: [0, 90, 47, 109]; a white sheet on a black background: [0, 28, 47, 171]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a brown and black wall; Dense Caption: a large computer monitor: [1, 1, 382, 211]; red fabric behind a black white and orange flag: [358, 121, 383, 208]; black and blue shade on the window: [281, 0, 382, 211]; a shadow on the ground: [0, 187, 53, 212]; the wall is brown in color: [142, 75, 237, 172]; black and white striped wall: [211, 67, 293, 177]; black line on the wall: [113, 78, 208, 169]; black and white striped background: [176, 90, 275, 194]; ; Region Captions: a brown and black minecraft texture: [0, 0, 383, 213]; a black square on a black background: [287, 2, 95, 185]; a brown letter l on a black background: [63, 0, 67, 111]; a white sheet of paper on a black surface: [0, 90, 47, 109]; a white sheet on a black background: [0, 28, 47, 171]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the floor is white: [31, 54, 337, 206]; white tablecloth on the table: [0, 117, 382, 211]; a small patterned ottoman: [221, 109, 307, 134]; red square object on table: [186, 114, 220, 144]; the large blue and brown box: [63, 87, 158, 174]; blue square of cardboard: [112, 127, 155, 168]; a red box: [0, 130, 18, 189]; green and black colored box: [21, 93, 68, 156]; a blue square of material: [67, 90, 114, 131]; the snow is white: [211, 146, 331, 208]; the chair is black: [176, 76, 336, 179]; legos on the ground: [7, 66, 234, 186]; the wall is white: [1, 2, 260, 120]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 259, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 127, 383, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[261, 0, 122, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[23, 95, 44, 60]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a city with a skyscraper: [0, 0, 383, 142]; a gray and black icon with a city in the background: [0, 0, 259, 127]; a white snowy mountain with a black background: [0, 127, 383, 85]; a gray t shirt with the word nebraska on it: [261, 0, 122, 141]; a green and black striped shirt: [23, 95, 44, 60]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with different colored blocks; Dense Caption: the floor is white: [31, 54, 337, 206]; white tablecloth on the table: [0, 117, 382, 211]; a small patterned ottoman: [221, 109, 307, 134]; red square object on table: [186, 114, 220, 144]; the large blue and brown box: [63, 87, 158, 174]; blue square of cardboard: [112, 127, 155, 168]; a red box: [0, 130, 18, 189]; green and black colored box: [21, 93, 68, 156]; a blue square of material: [67, 90, 114, 131]; the snow is white: [211, 146, 331, 208]; the chair is black: [176, 76, 336, 179]; legos on the ground: [7, 66, 234, 186]; the wall is white: [1, 2, 260, 120]; ; Region Captions: a black and white image of a city with a skyscraper: [0, 0, 383, 142]; a gray and black icon with a city in the background: [0, 0, 259, 127]; a white snowy mountain with a black background: [0, 127, 383, 85]; a gray t shirt with the word nebraska on it: [261, 0, 122, 141]; a green and black striped shirt: [23, 95, 44, 60]; \n",
      "NEW GAME ../Frames_60/main_logs/141_212_108_99_20210430_172041 28\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character with a gun\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a sign that says here for business accounts: [122, 3, 252, 36]; snow covering the ground: [0, 95, 383, 211]; a toy train with many lights: [106, 176, 275, 211]; green and white sign: [136, 51, 232, 177]; a green and orange tower: [81, 51, 277, 211]; a red roof on a building: [270, 186, 356, 212]; a black square object: [346, 90, 383, 124]; the sky is gray: [0, 0, 382, 114]; red and black sign on top of building: [198, 172, 277, 191]; red lights on the building: [109, 169, 186, 198]; a red light on a sign: [181, 193, 201, 212]; the word metro: [174, 158, 208, 170]; red lights on the building: [109, 176, 184, 189]; brown building in the background: [84, 160, 149, 212]; sticker on the bus: [129, 195, 145, 211]; green diamond on a sign: [180, 112, 199, 130]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 102, 383, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 109]\n",
      "process_ann took 0.00 seconds\n",
      "[151, 0, 232, 109]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 149, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 102, 143, 111]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a tall building: [0, 102, 383, 110]; a black and gray png image of a t shirt: [2, 0, 381, 109]; a gray png image of a black and white png: [151, 0, 232, 109]; a gray state with a white background: [0, 0, 149, 112]; a white sandbox with a white sandbox: [0, 102, 143, 111]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character with a gun; Dense Caption: a sign that says here for business accounts: [122, 3, 252, 36]; snow covering the ground: [0, 95, 383, 211]; a toy train with many lights: [106, 176, 275, 211]; green and white sign: [136, 51, 232, 177]; a green and orange tower: [81, 51, 277, 211]; a red roof on a building: [270, 186, 356, 212]; a black square object: [346, 90, 383, 124]; the sky is gray: [0, 0, 382, 114]; red and black sign on top of building: [198, 172, 277, 191]; red lights on the building: [109, 169, 186, 198]; a red light on a sign: [181, 193, 201, 212]; the word metro: [174, 158, 208, 170]; red lights on the building: [109, 176, 184, 189]; brown building in the background: [84, 160, 149, 212]; sticker on the bus: [129, 195, 145, 211]; green diamond on a sign: [180, 112, 199, 130]; ; Region Captions: a black and white image of a tall building: [0, 102, 383, 110]; a black and gray png image of a t shirt: [2, 0, 381, 109]; a gray png image of a black and white png: [151, 0, 232, 109]; a gray state with a white background: [0, 0, 149, 112]; a white sandbox with a white sandbox: [0, 102, 143, 111]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two wooden blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "wooden box on the ground: [159, 62, 314, 132]; a black and white checkered table cloth: [0, 66, 123, 212]; white sheets on the bed: [0, 75, 382, 211]; the wall is white: [32, 1, 337, 157]; the suitcase is brown: [113, 56, 327, 176]; white snow on the ground: [111, 106, 360, 210]; the snow is white: [188, 137, 316, 206]; the sky is cloudy: [37, 2, 339, 73]; a line of holes in the side of the bench: [216, 67, 267, 120]; the sky is cloudy: [158, 14, 271, 64]; the snow is white: [157, 143, 276, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[70, 95, 313, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 120, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[161, 67, 153, 63]\n",
      "process_ann took 0.00 seconds\n",
      "[250, 67, 65, 54]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.77 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a light shining on it: [0, 1, 383, 110]; a white floor with a black stair: [70, 95, 313, 118]; a black and white block of sand: [0, 72, 120, 141]; a wooden block with different colors: [161, 67, 153, 63]; a wooden block on a black background: [250, 67, 65, 54]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two wooden blocks; Dense Caption: wooden box on the ground: [159, 62, 314, 132]; a black and white checkered table cloth: [0, 66, 123, 212]; white sheets on the bed: [0, 75, 382, 211]; the wall is white: [32, 1, 337, 157]; the suitcase is brown: [113, 56, 327, 176]; white snow on the ground: [111, 106, 360, 210]; the snow is white: [188, 137, 316, 206]; the sky is cloudy: [37, 2, 339, 73]; a line of holes in the side of the bench: [216, 67, 267, 120]; the sky is cloudy: [158, 14, 271, 64]; the snow is white: [157, 143, 276, 209]; ; Region Captions: a black and white image of a building with a light shining on it: [0, 1, 383, 110]; a white floor with a black stair: [70, 95, 313, 118]; a black and white block of sand: [0, 72, 120, 141]; a wooden block with different colors: [161, 67, 153, 63]; a wooden block on a black background: [250, 67, 65, 54]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in front of a wooden block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [40, 109, 211, 211]; a multicolored cloth: [313, 67, 383, 212]; a bed in the room: [42, 28, 349, 213]; red section of the object: [322, 110, 383, 165]; blue and white base of the hydrant: [327, 152, 379, 211]; yellow and blue stripes: [316, 70, 383, 120]; white wall behind bed: [28, 2, 302, 124]; a small stack of small square tiles: [282, 98, 326, 123]; shadow of the object: [308, 176, 380, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 202]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 120, 383, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[47, 117, 161, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[319, 73, 64, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[300, 0, 83, 178]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 0, 383, 202]; a white and gray image of a skateboard: [0, 120, 383, 93]; a wooden block in minecraft: [47, 117, 161, 96]; a minecraft character with a red shirt and blue pants: [319, 73, 64, 140]; a gray sign with the word st john's: [300, 0, 83, 178]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in front of a wooden block; Dense Caption: the box is brown: [40, 109, 211, 211]; a multicolored cloth: [313, 67, 383, 212]; a bed in the room: [42, 28, 349, 213]; red section of the object: [322, 110, 383, 165]; blue and white base of the hydrant: [327, 152, 379, 211]; yellow and blue stripes: [316, 70, 383, 120]; white wall behind bed: [28, 2, 302, 124]; a small stack of small square tiles: [282, 98, 326, 123]; shadow of the object: [308, 176, 380, 212]; ; Region Captions: a black and white image of a wall: [0, 0, 383, 202]; a white and gray image of a skateboard: [0, 120, 383, 93]; a wooden block in minecraft: [47, 117, 161, 96]; a minecraft character with a red shirt and blue pants: [319, 73, 64, 140]; a gray sign with the word st john's: [300, 0, 83, 178]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character sitting in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [40, 109, 211, 210]; white sheets on the bed: [13, 110, 381, 211]; a small wicker basket: [285, 98, 371, 126]; a bed in the room: [42, 27, 354, 212]; yellow and red flag: [368, 79, 384, 153]; white wall behind bed: [28, 2, 301, 119]; a red and yellow pillow: [370, 105, 383, 150]; the sheet is white in color: [235, 141, 340, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 382, 201]\n",
      "process_ann took 0.00 seconds\n",
      "[84, 120, 299, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[47, 117, 161, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[300, 0, 83, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[284, 103, 89, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 1, 382, 201]; a white sandstone rock with a white sand: [84, 120, 299, 93]; a wooden block in minecraft: [47, 117, 161, 96]; a gray map of the state of california: [300, 0, 83, 118]; a black stone wall with a black background: [284, 103, 89, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character sitting in a room; Dense Caption: the box is brown: [40, 109, 211, 210]; white sheets on the bed: [13, 110, 381, 211]; a small wicker basket: [285, 98, 371, 126]; a bed in the room: [42, 27, 354, 212]; yellow and red flag: [368, 79, 384, 153]; white wall behind bed: [28, 2, 301, 119]; a red and yellow pillow: [370, 105, 383, 150]; the sheet is white in color: [235, 141, 340, 209]; ; Region Captions: a black and white image of a wall: [0, 1, 382, 201]; a white sandstone rock with a white sand: [84, 120, 299, 93]; a wooden block in minecraft: [47, 117, 161, 96]; a gray map of the state of california: [300, 0, 83, 118]; a black stone wall with a black background: [284, 103, 89, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character sitting on a wooden floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [40, 109, 211, 210]; white sheets on the bed: [12, 111, 381, 211]; a small wicker basket: [285, 98, 370, 126]; a bed in the room: [42, 27, 354, 212]; a red and yellow birthday candle: [371, 80, 383, 151]; white wall behind bed: [29, 2, 301, 119]; orange candle on a cake: [373, 106, 383, 147]; the sheet is white in color: [235, 141, 341, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 202]\n",
      "process_ann took 0.00 seconds\n",
      "[83, 120, 300, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[47, 117, 161, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[300, 0, 83, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[284, 103, 89, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black man is standing in a room with a white wall: [0, 0, 383, 202]; a white sandstone rock with a white sandstone texture: [83, 120, 300, 93]; a wooden block in minecraft: [47, 117, 161, 96]; a gray map of the state of california: [300, 0, 83, 118]; a black stone wall with a black background: [284, 103, 89, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character sitting on a wooden floor; Dense Caption: the box is brown: [40, 109, 211, 210]; white sheets on the bed: [12, 111, 381, 211]; a small wicker basket: [285, 98, 370, 126]; a bed in the room: [42, 27, 354, 212]; a red and yellow birthday candle: [371, 80, 383, 151]; white wall behind bed: [29, 2, 301, 119]; orange candle on a cake: [373, 106, 383, 147]; the sheet is white in color: [235, 141, 341, 209]; ; Region Captions: a black man is standing in a room with a white wall: [0, 0, 383, 202]; a white sandstone rock with a white sandstone texture: [83, 120, 300, 93]; a wooden block in minecraft: [47, 117, 161, 96]; a gray map of the state of california: [300, 0, 83, 118]; a black stone wall with a black background: [284, 103, 89, 23]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two wooden blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "large brown wooden box: [160, 112, 312, 187]; a snow covered table: [0, 116, 121, 211]; the sky is dark: [36, 2, 349, 163]; snow on the ground: [0, 124, 382, 211]; a book on the table: [116, 57, 327, 195]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 162]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[88, 145, 295, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 116, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[161, 116, 152, 69]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a cloudy sky: [0, 1, 383, 162]; a black and white image of a mountain: [0, 0, 383, 115]; a metal wall with a white png: [88, 145, 295, 68]; a black and white block with a black and white background: [0, 121, 116, 92]; a wooden block with brown and brown colors: [161, 116, 152, 69]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two wooden blocks; Dense Caption: large brown wooden box: [160, 112, 312, 187]; a snow covered table: [0, 116, 121, 211]; the sky is dark: [36, 2, 349, 163]; snow on the ground: [0, 124, 382, 211]; a book on the table: [116, 57, 327, 195]; ; Region Captions: a black and white image of a building with a cloudy sky: [0, 1, 383, 162]; a black and white image of a mountain: [0, 0, 383, 115]; a metal wall with a white png: [88, 145, 295, 68]; a black and white block with a black and white background: [0, 121, 116, 92]; a wooden block with brown and brown colors: [161, 116, 152, 69]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden block in the middle\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "wooden box on the ground: [129, 75, 271, 153]; a checkered blanket: [0, 89, 85, 213]; white sheets on the bed: [1, 82, 383, 212]; the wall is white: [36, 2, 350, 97]; a bed in the middle of the room: [24, 19, 292, 194]; the snow is white: [176, 146, 294, 207]; the suitcase is brown: [105, 60, 313, 181]; a brown wood slat: [134, 84, 179, 149]; the snow is white: [223, 137, 340, 205]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[45, 91, 338, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 83, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 81, 141, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[269, 74, 114, 32]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a building with a black background: [0, 1, 383, 133]; a white png of a white wall: [45, 91, 338, 121]; a black and white block of sand: [0, 91, 83, 122]; a wooden block with different colors: [129, 81, 141, 70]; a black and white image of a black and white image: [269, 74, 114, 32]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden block in the middle; Dense Caption: wooden box on the ground: [129, 75, 271, 153]; a checkered blanket: [0, 89, 85, 213]; white sheets on the bed: [1, 82, 383, 212]; the wall is white: [36, 2, 350, 97]; a bed in the middle of the room: [24, 19, 292, 194]; the snow is white: [176, 146, 294, 207]; the suitcase is brown: [105, 60, 313, 181]; a brown wood slat: [134, 84, 179, 149]; the snow is white: [223, 137, 340, 205]; ; Region Captions: a 3d image of a building with a black background: [0, 1, 383, 133]; a white png of a white wall: [45, 91, 338, 121]; a black and white block of sand: [0, 91, 83, 122]; a wooden block with different colors: [129, 81, 141, 70]; a black and white image of a black and white image: [269, 74, 114, 32]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden block in the middle\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "wooden box on the ground: [129, 75, 271, 153]; a checkered blanket: [0, 89, 85, 213]; white sheets on the bed: [1, 82, 383, 212]; the wall is white: [36, 2, 350, 97]; a bed in the middle of the room: [24, 19, 292, 194]; the snow is white: [176, 146, 294, 207]; the suitcase is brown: [105, 60, 313, 181]; a brown wood slat: [134, 84, 179, 149]; the snow is white: [223, 137, 340, 205]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[45, 91, 338, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 83, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 81, 141, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[269, 74, 114, 32]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a building with a black background: [0, 1, 383, 133]; a white png of a white wall: [45, 91, 338, 121]; a black and white block of sand: [0, 91, 83, 122]; a wooden block with different colors: [129, 81, 141, 70]; a black and white image of a black and white image: [269, 74, 114, 32]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden block in the middle; Dense Caption: wooden box on the ground: [129, 75, 271, 153]; a checkered blanket: [0, 89, 85, 213]; white sheets on the bed: [1, 82, 383, 212]; the wall is white: [36, 2, 350, 97]; a bed in the middle of the room: [24, 19, 292, 194]; the snow is white: [176, 146, 294, 207]; the suitcase is brown: [105, 60, 313, 181]; a brown wood slat: [134, 84, 179, 149]; the snow is white: [223, 137, 340, 205]; ; Region Captions: a 3d image of a building with a black background: [0, 1, 383, 133]; a white png of a white wall: [45, 91, 338, 121]; a black and white block of sand: [0, 91, 83, 122]; a wooden block with different colors: [129, 81, 141, 70]; a black and white image of a black and white image: [269, 74, 114, 32]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden block in the middle\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "wooden box on the ground: [129, 75, 271, 153]; a checkered blanket: [0, 89, 85, 213]; white sheets on the bed: [1, 82, 383, 212]; the wall is white: [36, 2, 350, 97]; a bed in the middle of the room: [24, 19, 292, 194]; the snow is white: [176, 146, 294, 207]; the suitcase is brown: [105, 60, 313, 181]; a brown wood slat: [134, 84, 179, 149]; the snow is white: [223, 137, 340, 205]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[45, 91, 338, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 83, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 81, 141, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[269, 74, 114, 32]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a building with a black background: [0, 1, 383, 133]; a white png of a white wall: [45, 91, 338, 121]; a black and white block of sand: [0, 91, 83, 122]; a wooden block with different colors: [129, 81, 141, 70]; a black and white image of a black and white image: [269, 74, 114, 32]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden block in the middle; Dense Caption: wooden box on the ground: [129, 75, 271, 153]; a checkered blanket: [0, 89, 85, 213]; white sheets on the bed: [1, 82, 383, 212]; the wall is white: [36, 2, 350, 97]; a bed in the middle of the room: [24, 19, 292, 194]; the snow is white: [176, 146, 294, 207]; the suitcase is brown: [105, 60, 313, 181]; a brown wood slat: [134, 84, 179, 149]; the snow is white: [223, 137, 340, 205]; ; Region Captions: a 3d image of a building with a black background: [0, 1, 383, 133]; a white png of a white wall: [45, 91, 338, 121]; a black and white block of sand: [0, 91, 83, 122]; a wooden block with different colors: [129, 81, 141, 70]; a black and white image of a black and white image: [269, 74, 114, 32]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with wooden blocks and a white wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown and tan suitcase: [0, 103, 227, 212]; white bed sheet: [198, 95, 382, 211]; the wall is white: [36, 3, 349, 121]; a bed in a room: [36, 18, 351, 210]; a black pillow: [357, 76, 383, 109]; the bed is made: [49, 115, 162, 198]; a brown line on a mattress: [104, 143, 140, 212]; the bed is white: [249, 125, 373, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 144]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 108, 223, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[198, 105, 185, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[359, 80, 24, 27]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 127, 51, 52]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a grey wall: [0, 1, 383, 144]; a block of wood with the word wood: [0, 108, 223, 105]; a white snowy surface with a white sled: [198, 105, 185, 108]; a pile of black bricks on a black background: [359, 80, 24, 27]; a long wooden sword on a black background: [2, 127, 51, 52]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with wooden blocks and a white wall; Dense Caption: a brown and tan suitcase: [0, 103, 227, 212]; white bed sheet: [198, 95, 382, 211]; the wall is white: [36, 3, 349, 121]; a bed in a room: [36, 18, 351, 210]; a black pillow: [357, 76, 383, 109]; the bed is made: [49, 115, 162, 198]; a brown line on a mattress: [104, 143, 140, 212]; the bed is white: [249, 125, 373, 210]; ; Region Captions: a 3d image of a grey wall: [0, 1, 383, 144]; a block of wood with the word wood: [0, 108, 223, 105]; a white snowy surface with a white sled: [198, 105, 185, 108]; a pile of black bricks on a black background: [359, 80, 24, 27]; a long wooden sword on a black background: [2, 127, 51, 52]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with wooden blocks and a white wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown and tan suitcase: [0, 103, 227, 212]; white bed sheet: [198, 95, 382, 211]; the wall is white: [36, 3, 349, 121]; a bed in a room: [36, 18, 351, 210]; a black pillow: [357, 76, 383, 109]; the bed is made: [49, 115, 162, 198]; a brown line on a mattress: [104, 143, 140, 212]; the bed is white: [249, 125, 373, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 144]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 108, 223, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[198, 105, 185, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[359, 80, 24, 27]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 127, 51, 52]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a grey wall: [0, 1, 383, 144]; a block of wood with the word wood: [0, 108, 223, 105]; a white snowy surface with a white sled: [198, 105, 185, 108]; a pile of black bricks on a black background: [359, 80, 24, 27]; a long wooden sword on a black background: [2, 127, 51, 52]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with wooden blocks and a white wall; Dense Caption: a brown and tan suitcase: [0, 103, 227, 212]; white bed sheet: [198, 95, 382, 211]; the wall is white: [36, 3, 349, 121]; a bed in a room: [36, 18, 351, 210]; a black pillow: [357, 76, 383, 109]; the bed is made: [49, 115, 162, 198]; a brown line on a mattress: [104, 143, 140, 212]; the bed is white: [249, 125, 373, 210]; ; Region Captions: a 3d image of a grey wall: [0, 1, 383, 144]; a block of wood with the word wood: [0, 108, 223, 105]; a white snowy surface with a white sled: [198, 105, 185, 108]; a pile of black bricks on a black background: [359, 80, 24, 27]; a long wooden sword on a black background: [2, 127, 51, 52]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with wooden blocks and a white wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown and tan suitcase: [0, 103, 227, 212]; white bed sheet: [198, 95, 382, 211]; the wall is white: [36, 3, 349, 121]; a bed in a room: [36, 18, 351, 210]; a black pillow: [357, 76, 383, 109]; the bed is made: [49, 115, 162, 198]; a brown line on a mattress: [104, 143, 140, 212]; the bed is white: [249, 125, 373, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 144]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 108, 223, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[198, 105, 185, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[359, 80, 24, 27]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 127, 51, 52]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a grey wall: [0, 1, 383, 144]; a block of wood with the word wood: [0, 108, 223, 105]; a white snowy surface with a white sled: [198, 105, 185, 108]; a pile of black bricks on a black background: [359, 80, 24, 27]; a long wooden sword on a black background: [2, 127, 51, 52]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with wooden blocks and a white wall; Dense Caption: a brown and tan suitcase: [0, 103, 227, 212]; white bed sheet: [198, 95, 382, 211]; the wall is white: [36, 3, 349, 121]; a bed in a room: [36, 18, 351, 210]; a black pillow: [357, 76, 383, 109]; the bed is made: [49, 115, 162, 198]; a brown line on a mattress: [104, 143, 140, 212]; the bed is white: [249, 125, 373, 210]; ; Region Captions: a 3d image of a grey wall: [0, 1, 383, 144]; a block of wood with the word wood: [0, 108, 223, 105]; a white snowy surface with a white sled: [198, 105, 185, 108]; a pile of black bricks on a black background: [359, 80, 24, 27]; a long wooden sword on a black background: [2, 127, 51, 52]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a set of wooden blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large brown building: [54, 127, 380, 212]; a tall gray building: [0, 118, 77, 211]; the sky is dark: [37, 5, 349, 143]; a line on the bench: [223, 137, 250, 212]; a large area of gray overcast sky: [68, 31, 366, 206]; a line on a bench: [201, 137, 237, 208]; the sky is dark: [159, 73, 271, 130]; the line is black: [175, 140, 217, 202]; a building: [35, 85, 276, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 208]\n",
      "process_ann took 0.00 seconds\n",
      "[57, 133, 326, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 125, 74, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[19, 188, 40, 25]\n",
      "process_ann took 0.00 seconds\n",
      "[60, 172, 76, 16]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a cloudy sky: [0, 1, 383, 208]; a wooden block with a wooden texture: [57, 133, 326, 80]; a black and white block of a minecraft table: [0, 125, 74, 88]; a grey triangle on a black background: [19, 188, 40, 25]; a brown sword with a black handle: [60, 172, 76, 16]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a set of wooden blocks in minecraft; Dense Caption: a large brown building: [54, 127, 380, 212]; a tall gray building: [0, 118, 77, 211]; the sky is dark: [37, 5, 349, 143]; a line on the bench: [223, 137, 250, 212]; a large area of gray overcast sky: [68, 31, 366, 206]; a line on a bench: [201, 137, 237, 208]; the sky is dark: [159, 73, 271, 130]; the line is black: [175, 140, 217, 202]; a building: [35, 85, 276, 210]; ; Region Captions: a black and white image of a building with a cloudy sky: [0, 1, 383, 208]; a wooden block with a wooden texture: [57, 133, 326, 80]; a black and white block of a minecraft table: [0, 125, 74, 88]; a grey triangle on a black background: [19, 188, 40, 25]; a brown sword with a black handle: [60, 172, 76, 16]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden box in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the keyboard is yellow: [0, 54, 227, 209]; a bench in the snow: [34, 12, 350, 204]; the sky is grey: [35, 1, 349, 106]; snow on the ground: [139, 71, 371, 211]; the line is black: [40, 94, 149, 174]; the keyboard is white: [1, 50, 193, 136]; the bench is made of wood: [62, 73, 183, 172]; the snow is white: [234, 100, 370, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 77, 383, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 60, 222, 148]\n",
      "process_ann took 0.00 seconds\n",
      "[120, 60, 102, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[8, 69, 77, 46]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a grey png image of a black wall: [0, 1, 383, 104]; a white png image of a stairway: [0, 77, 383, 135]; a wooden block in minecraft: [0, 60, 222, 148]; a wooden block in minecraft: [120, 60, 102, 110]; a wooden sword with a gold handle: [8, 69, 77, 46]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden box in a minecraft game; Dense Caption: the keyboard is yellow: [0, 54, 227, 209]; a bench in the snow: [34, 12, 350, 204]; the sky is grey: [35, 1, 349, 106]; snow on the ground: [139, 71, 371, 211]; the line is black: [40, 94, 149, 174]; the keyboard is white: [1, 50, 193, 136]; the bench is made of wood: [62, 73, 183, 172]; the snow is white: [234, 100, 370, 208]; ; Region Captions: a grey png image of a black wall: [0, 1, 383, 104]; a white png image of a stairway: [0, 77, 383, 135]; a wooden block in minecraft: [0, 60, 222, 148]; a wooden block in minecraft: [120, 60, 102, 110]; a wooden sword with a gold handle: [8, 69, 77, 46]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man standing next to a pile of wood\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the brown cardboard box: [0, 14, 229, 177]; the traffic light is red: [297, 20, 382, 178]; snow on the ground: [0, 7, 381, 208]; the line is black: [41, 42, 150, 133]; blue stripe on the umbrella: [307, 72, 378, 132]; red section of the umbrella: [340, 23, 383, 106]; the snow is white: [151, 41, 358, 211]; the sky is blue: [0, 0, 380, 72]; the snowboard is red and white: [297, 101, 382, 177]; the keyboard is yellow: [16, 11, 226, 104]; the snow is white: [98, 137, 311, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 50, 383, 162]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 19, 224, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[305, 27, 78, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[313, 74, 63, 57]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a person is standing on a floor with a knife: [0, 50, 383, 162]; a wooden block in minecraft: [0, 19, 224, 151]; a gray slatted table with a black background: [0, 0, 383, 70]; a minecraft character with a red shirt and blue pants: [305, 27, 78, 127]; a blue block with a black background: [313, 74, 63, 57]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man standing next to a pile of wood; Dense Caption: the brown cardboard box: [0, 14, 229, 177]; the traffic light is red: [297, 20, 382, 178]; snow on the ground: [0, 7, 381, 208]; the line is black: [41, 42, 150, 133]; blue stripe on the umbrella: [307, 72, 378, 132]; red section of the umbrella: [340, 23, 383, 106]; the snow is white: [151, 41, 358, 211]; the sky is blue: [0, 0, 380, 72]; the snowboard is red and white: [297, 101, 382, 177]; the keyboard is yellow: [16, 11, 226, 104]; the snow is white: [98, 137, 311, 210]; ; Region Captions: a person is standing on a floor with a knife: [0, 50, 383, 162]; a wooden block in minecraft: [0, 19, 224, 151]; a gray slatted table with a black background: [0, 0, 383, 70]; a minecraft character with a red shirt and blue pants: [305, 27, 78, 127]; a blue block with a black background: [313, 74, 63, 57]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a red and green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and red traffic cone: [68, 1, 267, 197]; green and white square: [109, 110, 237, 191]; white table under hat: [1, 34, 382, 211]; red square on the bottom of the snowboard: [78, 2, 254, 113]; a yellow handle on the umbrella: [75, 41, 98, 84]; a black object on the side of the bed: [365, 22, 383, 43]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 40, 383, 172]\n",
      "process_ann took 0.00 seconds\n",
      "[74, 0, 183, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[110, 112, 126, 78]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 83, 115]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a tall black object: [0, 40, 383, 172]; red bricks png: [74, 0, 183, 114]; a 3d model of a wall with a door: [0, 0, 383, 116]; a green square block on a black background: [110, 112, 126, 78]; a grey textured wall with a black background: [0, 1, 83, 115]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a red and green block in minecraft; Dense Caption: green and red traffic cone: [68, 1, 267, 197]; green and white square: [109, 110, 237, 191]; white table under hat: [1, 34, 382, 211]; red square on the bottom of the snowboard: [78, 2, 254, 113]; a yellow handle on the umbrella: [75, 41, 98, 84]; a black object on the side of the bed: [365, 22, 383, 43]; ; Region Captions: a black and white image of a tall black object: [0, 40, 383, 172]; red bricks png: [74, 0, 183, 114]; a 3d model of a wall with a door: [0, 0, 383, 116]; a green square block on a black background: [110, 112, 126, 78]; a grey textured wall with a black background: [0, 1, 83, 115]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a red and green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and red box: [65, 0, 281, 211]; green and white square: [104, 110, 238, 209]; white table under red umbrella: [1, 43, 381, 211]; the handle of the cooler: [237, 1, 276, 103]; red stripe on the flag: [87, 4, 239, 118]; a square red and yellow part of the kite: [245, 33, 276, 75]; shadow of the book: [237, 89, 261, 107]; a blue section of a book: [239, 70, 256, 101]; shadow of the object: [234, 85, 266, 112]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 48, 383, 164]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 48, 161, 164]\n",
      "process_ann took 0.00 seconds\n",
      "[73, 0, 181, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 124]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 84, 336, 128]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man standing in a room: [0, 48, 383, 164]; a small white snowman standing on a snowy surface: [222, 48, 161, 164]; red pixel block: [73, 0, 181, 129]; a black and white image of a door: [0, 0, 383, 124]; a black and white image of a png: [0, 84, 336, 128]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a red and green block in minecraft; Dense Caption: green and red box: [65, 0, 281, 211]; green and white square: [104, 110, 238, 209]; white table under red umbrella: [1, 43, 381, 211]; the handle of the cooler: [237, 1, 276, 103]; red stripe on the flag: [87, 4, 239, 118]; a square red and yellow part of the kite: [245, 33, 276, 75]; shadow of the book: [237, 89, 261, 107]; a blue section of a book: [239, 70, 256, 101]; shadow of the object: [234, 85, 266, 112]; ; Region Captions: a black and white image of a man standing in a room: [0, 48, 383, 164]; a small white snowman standing on a snowy surface: [222, 48, 161, 164]; red pixel block: [73, 0, 181, 129]; a black and white image of a door: [0, 0, 383, 124]; a black and white image of a png: [0, 84, 336, 128]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a red, green and blue block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green white and red striped fabric: [0, 1, 305, 210]; green square on a box: [1, 130, 171, 212]; a piece of white paper: [254, 40, 381, 210]; a black object on the ground: [290, 26, 338, 47]; black and white pattern: [150, 1, 293, 125]; red square on the wall: [0, 3, 156, 151]; green and white box: [15, 102, 274, 212]; a black and white checkered cloth: [281, 6, 354, 58]; black object on white table: [357, 88, 383, 110]; white wall in the background: [294, 0, 382, 49]; the green squares are visible: [70, 152, 126, 202]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 161, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[1, 45, 382, 168]\n",
      "process_ann took 0.00 seconds\n",
      "[167, 45, 216, 168]\n",
      "process_ann took 0.00 seconds\n",
      "[148, 0, 154, 139]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 130, 170, 83]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "red brick texture for minecraft: [0, 0, 161, 160]; a small black and white image of a small black and white image: [1, 45, 382, 168]; a white sandbox with a black sandbox: [167, 45, 216, 168]; a brown and black square in minecraft: [148, 0, 154, 139]; a green square on a black background: [0, 130, 170, 83]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a red, green and blue block in minecraft; Dense Caption: green white and red striped fabric: [0, 1, 305, 210]; green square on a box: [1, 130, 171, 212]; a piece of white paper: [254, 40, 381, 210]; a black object on the ground: [290, 26, 338, 47]; black and white pattern: [150, 1, 293, 125]; red square on the wall: [0, 3, 156, 151]; green and white box: [15, 102, 274, 212]; a black and white checkered cloth: [281, 6, 354, 58]; black object on white table: [357, 88, 383, 110]; white wall in the background: [294, 0, 382, 49]; the green squares are visible: [70, 152, 126, 202]; ; Region Captions: red brick texture for minecraft: [0, 0, 161, 160]; a small black and white image of a small black and white image: [1, 45, 382, 168]; a white sandbox with a black sandbox: [167, 45, 216, 168]; a brown and black square in minecraft: [148, 0, 154, 139]; a green square on a black background: [0, 130, 170, 83]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large brown box: [1, 109, 136, 211]; lego person is carrying a snowboard: [179, 54, 246, 156]; a red strip on the wall: [322, 1, 383, 211]; a small patterned ottoman: [271, 79, 350, 112]; white bed sheet: [90, 99, 344, 212]; little yellow gift bag: [195, 58, 234, 94]; blue square on post: [201, 117, 229, 151]; the sign is red: [188, 83, 242, 122]; a scene happening during the day: [1, 2, 374, 210]; a lego toy on display: [146, 37, 281, 178]; shadow of the object: [192, 135, 238, 158]; a yellow toy on the luggage: [177, 92, 197, 129]; the floor is white: [187, 153, 295, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 365, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[96, 6, 267, 206]\n",
      "process_ann took 0.00 seconds\n",
      "[96, 105, 245, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 114, 133, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[325, 0, 58, 212]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing in a room: [0, 0, 365, 153]; a 3d image of a black floor with a hole in it: [96, 6, 267, 206]; a white floor with a black splatter on it: [96, 105, 245, 108]; a block of wood with the words'mahogany': [0, 114, 133, 99]; a red striped png with a black background: [325, 0, 58, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a large brown box: [1, 109, 136, 211]; lego person is carrying a snowboard: [179, 54, 246, 156]; a red strip on the wall: [322, 1, 383, 211]; a small patterned ottoman: [271, 79, 350, 112]; white bed sheet: [90, 99, 344, 212]; little yellow gift bag: [195, 58, 234, 94]; blue square on post: [201, 117, 229, 151]; the sign is red: [188, 83, 242, 122]; a scene happening during the day: [1, 2, 374, 210]; a lego toy on display: [146, 37, 281, 178]; shadow of the object: [192, 135, 238, 158]; a yellow toy on the luggage: [177, 92, 197, 129]; the floor is white: [187, 153, 295, 209]; ; Region Captions: a silhouette of a man standing in a room: [0, 0, 365, 153]; a 3d image of a black floor with a hole in it: [96, 6, 267, 206]; a white floor with a black splatter on it: [96, 105, 245, 108]; a block of wood with the words'mahogany': [0, 114, 133, 99]; a red striped png with a black background: [325, 0, 58, 212]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a green wall and a red door\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "yellow square on the bottom of the stack: [146, 161, 265, 212]; black slatted umbrella: [0, 2, 381, 204]; green and red umbrella: [335, 89, 383, 138]; the umbrella is yellow: [67, 66, 348, 209]; the umbrella is black: [29, 18, 272, 171]; a yellow and black sign: [117, 115, 306, 210]; the sky is white: [284, 160, 347, 205]; the ceiling is black: [161, 64, 269, 145]; the sky is clear: [244, 122, 382, 212]; the yellow tiles on the wall: [172, 166, 239, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 109, 383, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[242, 128, 141, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 108, 148, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 164, 112, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[125, 34, 63, 62]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man with a knife: [0, 109, 383, 103]; a silver sheet of paper on a black background: [242, 128, 141, 85]; a minecraft map with a black background: [0, 108, 148, 105]; a brown wooden board with a wooden frame: [150, 164, 112, 49]; a black and white png of a black and white png: [125, 34, 63, 62]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a green wall and a red door; Dense Caption: yellow square on the bottom of the stack: [146, 161, 265, 212]; black slatted umbrella: [0, 2, 381, 204]; green and red umbrella: [335, 89, 383, 138]; the umbrella is yellow: [67, 66, 348, 209]; the umbrella is black: [29, 18, 272, 171]; a yellow and black sign: [117, 115, 306, 210]; the sky is white: [284, 160, 347, 205]; the ceiling is black: [161, 64, 269, 145]; the sky is clear: [244, 122, 382, 212]; the yellow tiles on the wall: [172, 166, 239, 208]; ; Region Captions: a black and white image of a man with a knife: [0, 109, 383, 103]; a silver sheet of paper on a black background: [242, 128, 141, 85]; a minecraft map with a black background: [0, 108, 148, 105]; a brown wooden board with a wooden frame: [150, 164, 112, 49]; a black and white png of a black and white png: [125, 34, 63, 62]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a green wall and a red door\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "yellow square on the bottom of the stack: [146, 161, 265, 212]; black slatted umbrella: [0, 2, 381, 204]; green and red umbrella: [335, 89, 383, 138]; the umbrella is yellow: [67, 66, 348, 209]; the umbrella is black: [29, 18, 272, 171]; a yellow and black sign: [117, 115, 307, 210]; the sky is white: [285, 160, 347, 205]; the yellow tiles on the wall: [173, 166, 238, 208]; the ceiling is black: [161, 64, 269, 145]; the sky is clear: [244, 122, 382, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 109, 383, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[242, 128, 141, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 108, 148, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 164, 112, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[125, 34, 63, 62]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man with a knife: [0, 109, 383, 103]; a silver sheet of paper on a black background: [242, 128, 141, 85]; a black and white image of a building with a sign: [0, 108, 148, 105]; a wooden block with a wooden texture: [150, 164, 112, 49]; a black and white image of a black and white arrow: [125, 34, 63, 62]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a green wall and a red door; Dense Caption: yellow square on the bottom of the stack: [146, 161, 265, 212]; black slatted umbrella: [0, 2, 381, 204]; green and red umbrella: [335, 89, 383, 138]; the umbrella is yellow: [67, 66, 348, 209]; the umbrella is black: [29, 18, 272, 171]; a yellow and black sign: [117, 115, 307, 210]; the sky is white: [285, 160, 347, 205]; the yellow tiles on the wall: [173, 166, 238, 208]; the ceiling is black: [161, 64, 269, 145]; the sky is clear: [244, 122, 382, 212]; ; Region Captions: a black and white image of a man with a knife: [0, 109, 383, 103]; a silver sheet of paper on a black background: [242, 128, 141, 85]; a black and white image of a building with a sign: [0, 108, 148, 105]; a wooden block with a wooden texture: [150, 164, 112, 49]; a black and white image of a black and white arrow: [125, 34, 63, 62]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden shelf\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the boxes are brown: [0, 71, 238, 210]; white sheets on the bed: [54, 63, 354, 213]; a dark green ceiling light: [143, 0, 251, 27]; a black object on the bed: [334, 49, 383, 83]; a bed in the room: [36, 2, 322, 176]; the corner of a bed: [331, 0, 382, 84]; the corner of a laptop: [355, 0, 382, 56]; white bedspread on bed: [235, 83, 378, 209]; the line is black: [63, 89, 169, 175]; the walls are white: [1, 2, 382, 104]; a black object on wall: [118, 0, 270, 48]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[69, 76, 314, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 76, 236, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[148, 0, 98, 21]\n",
      "process_ann took 0.00 seconds\n",
      "[336, 54, 47, 27]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.78 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a door on it: [0, 0, 383, 104]; a white sandstone block with a white sandstone texture: [69, 76, 314, 137]; a wooden block in minecraft: [0, 76, 236, 136]; a black cube with a black background: [148, 0, 98, 21]; a black stone wall with a black sandstone texture: [336, 54, 47, 27]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden shelf; Dense Caption: the boxes are brown: [0, 71, 238, 210]; white sheets on the bed: [54, 63, 354, 213]; a dark green ceiling light: [143, 0, 251, 27]; a black object on the bed: [334, 49, 383, 83]; a bed in the room: [36, 2, 322, 176]; the corner of a bed: [331, 0, 382, 84]; the corner of a laptop: [355, 0, 382, 56]; white bedspread on bed: [235, 83, 378, 209]; the line is black: [63, 89, 169, 175]; the walls are white: [1, 2, 382, 104]; a black object on wall: [118, 0, 270, 48]; ; Region Captions: a gray wall with a door on it: [0, 0, 383, 104]; a white sandstone block with a white sandstone texture: [69, 76, 314, 137]; a wooden block in minecraft: [0, 76, 236, 136]; a black cube with a black background: [148, 0, 98, 21]; a black stone wall with a black sandstone texture: [336, 54, 47, 27]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden table and a wooden block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [0, 116, 232, 212]; black hanging light: [106, 0, 242, 67]; a dark colored basket: [313, 88, 383, 124]; a white bed spread: [221, 109, 381, 212]; a bed in a room: [0, 2, 382, 210]; two beds are next to each other: [44, 80, 344, 211]; the wall is white in color: [152, 69, 261, 116]; the table is made of wood: [69, 129, 197, 211]; the bed is made: [77, 114, 186, 182]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 154]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 122, 229, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 115, 161, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 2, 161, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[114, 0, 120, 62]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a door with a door: [0, 0, 383, 154]; a wooden block with the word'wood': [0, 122, 229, 91]; a white square with a white background: [222, 115, 161, 98]; a bed with a white sheet on top: [222, 2, 161, 211]; a black square block on a black background: [114, 0, 120, 62]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden table and a wooden block; Dense Caption: a brown wooden box: [0, 116, 232, 212]; black hanging light: [106, 0, 242, 67]; a dark colored basket: [313, 88, 383, 124]; a white bed spread: [221, 109, 381, 212]; a bed in a room: [0, 2, 382, 210]; two beds are next to each other: [44, 80, 344, 211]; the wall is white in color: [152, 69, 261, 116]; the table is made of wood: [69, 129, 197, 211]; the bed is made: [77, 114, 186, 182]; ; Region Captions: a 3d image of a door with a door: [0, 0, 383, 154]; a wooden block with the word'wood': [0, 122, 229, 91]; a white square with a white background: [222, 115, 161, 98]; a bed with a white sheet on top: [222, 2, 161, 211]; a black square block on a black background: [114, 0, 120, 62]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden table and a wooden block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [0, 116, 232, 212]; black hanging light: [107, 0, 242, 67]; a dark colored basket: [313, 88, 383, 124]; a white bed spread: [221, 109, 381, 212]; a bed in a room: [0, 2, 382, 210]; bed with white sheets: [52, 78, 353, 211]; the wall is white in color: [143, 69, 249, 115]; the table is made of wood: [69, 129, 197, 211]; the table is made of wood: [125, 117, 205, 168]; the table is wooden: [77, 114, 186, 182]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 122, 229, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 115, 161, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 2, 161, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[114, 0, 120, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[333, 0, 50, 93]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.50 seconds\n",
      "finished...\n",
      "\n",
      "a wooden block with the word wood: [0, 122, 229, 91]; a white square with a white background: [222, 115, 161, 98]; a bed with a white sheet on top: [222, 2, 161, 211]; a black square block on a black background: [114, 0, 120, 62]; a gray metal plate with a black background: [333, 0, 50, 93]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden table and a wooden block; Dense Caption: a brown wooden box: [0, 116, 232, 212]; black hanging light: [107, 0, 242, 67]; a dark colored basket: [313, 88, 383, 124]; a white bed spread: [221, 109, 381, 212]; a bed in a room: [0, 2, 382, 210]; bed with white sheets: [52, 78, 353, 211]; the wall is white in color: [143, 69, 249, 115]; the table is made of wood: [69, 129, 197, 211]; the table is made of wood: [125, 117, 205, 168]; the table is wooden: [77, 114, 186, 182]; ; Region Captions: a wooden block with the word wood: [0, 122, 229, 91]; a white square with a white background: [222, 115, 161, 98]; a bed with a white sheet on top: [222, 2, 161, 211]; a black square block on a black background: [114, 0, 120, 62]; a gray metal plate with a black background: [333, 0, 50, 93]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden block in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "large wooden box: [139, 46, 374, 210]; a black and white checkered bedspread: [0, 23, 151, 183]; the room is dark: [0, 4, 382, 208]; white sheets on the bed: [1, 97, 271, 212]; the wall is white: [41, 1, 352, 114]; the sheet is white in color: [68, 148, 161, 210]; a black and white photo: [0, 32, 56, 65]; the wall is white: [104, 1, 364, 66]; a white wall: [0, 0, 53, 35]; rows of dark brown tiles: [212, 63, 381, 159]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[139, 57, 244, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 30, 147, 148]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 103, 266, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[210, 2, 173, 89]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a wooden block in minecraft: [139, 57, 244, 155]; a black wall with a white arrow on it: [0, 0, 383, 91]; a black and white block of sand: [0, 30, 147, 148]; a triangle with a silver color: [0, 103, 266, 110]; a black and white image of a mountain: [210, 2, 173, 89]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden block in it; Dense Caption: large wooden box: [139, 46, 374, 210]; a black and white checkered bedspread: [0, 23, 151, 183]; the room is dark: [0, 4, 382, 208]; white sheets on the bed: [1, 97, 271, 212]; the wall is white: [41, 1, 352, 114]; the sheet is white in color: [68, 148, 161, 210]; a black and white photo: [0, 32, 56, 65]; the wall is white: [104, 1, 364, 66]; a white wall: [0, 0, 53, 35]; rows of dark brown tiles: [212, 63, 381, 159]; ; Region Captions: a wooden block in minecraft: [139, 57, 244, 155]; a black wall with a white arrow on it: [0, 0, 383, 91]; a black and white block of sand: [0, 30, 147, 148]; a triangle with a silver color: [0, 103, 266, 110]; a black and white image of a mountain: [210, 2, 173, 89]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with green and red blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the back of a green and blue chair: [39, 14, 227, 209]; a checkered box: [307, 113, 383, 211]; red and green diamond pattern on box: [0, 42, 68, 210]; the boxes are on the floor: [1, 14, 376, 211]; a blue and green box: [70, 165, 216, 212]; green square on a suitcase: [0, 137, 43, 212]; white wall in the background: [221, 1, 382, 117]; white carpet on the floor: [36, 96, 333, 213]; white countertop: [214, 92, 363, 212]; red square on the end of the bed: [213, 101, 235, 158]; the green fabric on the chair: [67, 30, 199, 163]; the floor is white: [234, 112, 301, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[45, 19, 173, 161]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 119]\n",
      "process_ann took 0.00 seconds\n",
      "[220, 0, 163, 119]\n",
      "process_ann took 0.00 seconds\n",
      "[67, 96, 289, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[214, 96, 142, 117]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "green minecraft texture: [45, 19, 173, 161]; a 3d model of a door with a door handle: [0, 0, 383, 119]; a gray wall with a white wall: [220, 0, 163, 119]; a white sheet of paper with a white background: [67, 96, 289, 117]; a white sheet of paper on a black background: [214, 96, 142, 117]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with green and red blocks; Dense Caption: the back of a green and blue chair: [39, 14, 227, 209]; a checkered box: [307, 113, 383, 211]; red and green diamond pattern on box: [0, 42, 68, 210]; the boxes are on the floor: [1, 14, 376, 211]; a blue and green box: [70, 165, 216, 212]; green square on a suitcase: [0, 137, 43, 212]; white wall in the background: [221, 1, 382, 117]; white carpet on the floor: [36, 96, 333, 213]; white countertop: [214, 92, 363, 212]; red square on the end of the bed: [213, 101, 235, 158]; the green fabric on the chair: [67, 30, 199, 163]; the floor is white: [234, 112, 301, 209]; ; Region Captions: green minecraft texture: [45, 19, 173, 161]; a 3d model of a door with a door handle: [0, 0, 383, 119]; a gray wall with a white wall: [220, 0, 163, 119]; a white sheet of paper with a white background: [67, 96, 289, 117]; a white sheet of paper on a black background: [214, 96, 142, 117]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with some blocks and a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box on the floor: [1, 171, 130, 212]; the ground is covered in snow: [30, 115, 345, 211]; green colored outdoor chair: [41, 91, 91, 155]; a black decorative pillow: [242, 108, 338, 137]; the chairs are brown and red: [1, 75, 150, 173]; a picture of a bedroom: [33, 7, 341, 198]; a red table cloth: [0, 125, 25, 177]; a red brick building: [99, 81, 142, 158]; the chair is on the floor: [15, 51, 227, 200]; a red side of a suitcase: [102, 123, 140, 157]; white bedspread on bed: [151, 135, 377, 210]; the snow is white: [204, 145, 337, 208]; three red chairs in a row: [1, 122, 141, 180]; a square of wood: [102, 92, 140, 126]; the wall is white: [0, 1, 282, 125]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 185]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 281, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 127, 383, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[283, 0, 100, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 175, 126, 38]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a city with a skyscraper: [0, 0, 383, 185]; a city with a cloudy sky and a building: [0, 0, 281, 130]; a white wolf with horns on it: [0, 127, 383, 85]; a gray t shirt with the word nebraska on it: [283, 0, 100, 136]; a green square with a black background: [0, 175, 126, 38]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with some blocks and a table; Dense Caption: green box on the floor: [1, 171, 130, 212]; the ground is covered in snow: [30, 115, 345, 211]; green colored outdoor chair: [41, 91, 91, 155]; a black decorative pillow: [242, 108, 338, 137]; the chairs are brown and red: [1, 75, 150, 173]; a picture of a bedroom: [33, 7, 341, 198]; a red table cloth: [0, 125, 25, 177]; a red brick building: [99, 81, 142, 158]; the chair is on the floor: [15, 51, 227, 200]; a red side of a suitcase: [102, 123, 140, 157]; white bedspread on bed: [151, 135, 377, 210]; the snow is white: [204, 145, 337, 208]; three red chairs in a row: [1, 122, 141, 180]; a square of wood: [102, 92, 140, 126]; the wall is white: [0, 1, 282, 125]; ; Region Captions: a black and white image of a city with a skyscraper: [0, 0, 383, 185]; a city with a cloudy sky and a building: [0, 0, 281, 130]; a white wolf with horns on it: [0, 127, 383, 85]; a gray t shirt with the word nebraska on it: [283, 0, 100, 136]; a green square with a black background: [0, 175, 126, 38]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with some blocks and a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box on the floor: [1, 171, 130, 212]; white bedspread on the bed: [30, 115, 345, 211]; green colored outdoor chair: [41, 91, 91, 155]; a black decorative pillow: [242, 108, 338, 137]; the chairs are brown and red: [1, 75, 150, 173]; a picture of a bedroom: [33, 7, 341, 198]; a red table cloth: [0, 125, 25, 177]; a red brick building: [99, 82, 143, 158]; the chair is on the floor: [15, 51, 227, 200]; white bedspread on bed: [151, 135, 377, 210]; a red side of a suitcase: [102, 123, 140, 157]; the snow is white: [204, 145, 337, 208]; three red chairs in a row: [1, 122, 141, 180]; a square of wood: [102, 92, 140, 126]; the wall is white: [0, 1, 282, 125]; green and white striped area rug: [0, 136, 140, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 185]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 281, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 127, 383, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[283, 0, 100, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 175, 126, 38]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a city with a skyscraper: [0, 0, 383, 185]; a black and white image of a city with a skyscraper: [0, 0, 281, 130]; a white wolf with horns on it: [0, 127, 383, 85]; a gray t shirt with the word nebraska on it: [283, 0, 100, 136]; a green square with a black background: [0, 175, 126, 38]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with some blocks and a table; Dense Caption: green box on the floor: [1, 171, 130, 212]; white bedspread on the bed: [30, 115, 345, 211]; green colored outdoor chair: [41, 91, 91, 155]; a black decorative pillow: [242, 108, 338, 137]; the chairs are brown and red: [1, 75, 150, 173]; a picture of a bedroom: [33, 7, 341, 198]; a red table cloth: [0, 125, 25, 177]; a red brick building: [99, 82, 143, 158]; the chair is on the floor: [15, 51, 227, 200]; white bedspread on bed: [151, 135, 377, 210]; a red side of a suitcase: [102, 123, 140, 157]; the snow is white: [204, 145, 337, 208]; three red chairs in a row: [1, 122, 141, 180]; a square of wood: [102, 92, 140, 126]; the wall is white: [0, 1, 282, 125]; green and white striped area rug: [0, 136, 140, 211]; ; Region Captions: a black and white image of a city with a skyscraper: [0, 0, 383, 185]; a black and white image of a city with a skyscraper: [0, 0, 281, 130]; a white wolf with horns on it: [0, 127, 383, 85]; a gray t shirt with the word nebraska on it: [283, 0, 100, 136]; a green square with a black background: [0, 175, 126, 38]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210413_192714 67\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a box and a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is made: [35, 40, 348, 210]; the basket is made of wicker: [139, 33, 222, 63]; the chair is brown: [222, 37, 281, 64]; the objects are brown: [111, 19, 312, 73]; object in the snow: [250, 78, 299, 102]; the wall is white: [1, 1, 380, 80]; object in the snow: [240, 71, 308, 112]; a laptop on the table: [189, 44, 335, 152]; the chairs are brown: [83, 16, 326, 107]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 56, 383, 156]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[182, 0, 201, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 180, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 39, 77, 22]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a small square in the middle of a snowy field: [0, 56, 383, 156]; a black and white image of a room with two objects: [0, 0, 383, 73]; a black and white image of a man standing in front of a wall: [182, 0, 201, 71]; a grey piece of paper with a black background: [0, 0, 180, 73]; a black cube with a black background: [142, 39, 77, 22]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a box and a box; Dense Caption: the bed is made: [35, 40, 348, 210]; the basket is made of wicker: [139, 33, 222, 63]; the chair is brown: [222, 37, 281, 64]; the objects are brown: [111, 19, 312, 73]; object in the snow: [250, 78, 299, 102]; the wall is white: [1, 1, 380, 80]; object in the snow: [240, 71, 308, 112]; a laptop on the table: [189, 44, 335, 152]; the chairs are brown: [83, 16, 326, 107]; ; Region Captions: a small square in the middle of a snowy field: [0, 56, 383, 156]; a black and white image of a room with two objects: [0, 0, 383, 73]; a black and white image of a man standing in front of a wall: [182, 0, 201, 71]; a grey piece of paper with a black background: [0, 0, 180, 73]; a black cube with a black background: [142, 39, 77, 22]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego snowboarder: [123, 23, 260, 211]; a white snowy field: [0, 58, 382, 211]; a red and yellow box: [140, 71, 240, 187]; the back of a sign: [139, 21, 220, 94]; a snow covered black tire: [4, 49, 75, 91]; a brick wall at the bottom of the hill: [276, 49, 382, 85]; shadow of the person on the ground: [138, 165, 230, 211]; blue base of the sign: [158, 145, 211, 211]; the sky is gray: [0, 2, 381, 82]; blue and white square: [153, 27, 212, 47]; two silver handles on a stop sign: [156, 90, 182, 128]; a yellow and white sign: [141, 20, 220, 55]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 70, 383, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[216, 70, 167, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 71, 180, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 353, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 71, 93, 142]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a man is standing on a skateboard: [0, 70, 383, 142]; a small white snowy area with a black hat: [216, 70, 167, 142]; a small white snowy mountain with a black background: [0, 71, 180, 142]; a grey t-shirt with a black background: [0, 0, 353, 71]; a red and blue pixelated character in minecraft: [143, 71, 93, 142]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a lego snowboarder: [123, 23, 260, 211]; a white snowy field: [0, 58, 382, 211]; a red and yellow box: [140, 71, 240, 187]; the back of a sign: [139, 21, 220, 94]; a snow covered black tire: [4, 49, 75, 91]; a brick wall at the bottom of the hill: [276, 49, 382, 85]; shadow of the person on the ground: [138, 165, 230, 211]; blue base of the sign: [158, 145, 211, 211]; the sky is gray: [0, 2, 381, 82]; blue and white square: [153, 27, 212, 47]; two silver handles on a stop sign: [156, 90, 182, 128]; a yellow and white sign: [141, 20, 220, 55]; ; Region Captions: a man is standing on a skateboard: [0, 70, 383, 142]; a small white snowy area with a black hat: [216, 70, 167, 142]; a small white snowy mountain with a black background: [0, 71, 180, 142]; a grey t-shirt with a black background: [0, 0, 353, 71]; a red and blue pixelated character in minecraft: [143, 71, 93, 142]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a white floor and a small object\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the persons head is bent: [206, 157, 305, 211]; a bed in a room: [0, 43, 382, 212]; a small square basket: [90, 34, 179, 61]; the wall is white: [32, 1, 353, 86]; a bed in the room: [37, 17, 349, 157]; the snow is white: [49, 90, 162, 176]; the bed is white: [24, 50, 241, 181]; the object is black: [52, 7, 210, 89]; white wall in the background: [135, 1, 382, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 54, 383, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 0, 248, 67]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 135, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[211, 162, 89, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy area with a black hole in the middle: [0, 54, 383, 158]; a black and white image of a room with a black wall: [0, 0, 383, 68]; a gray sheet of paper with a black background: [135, 0, 248, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a grey circle with a black background: [211, 162, 89, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a white floor and a small object; Dense Caption: the persons head is bent: [206, 157, 305, 211]; a bed in a room: [0, 43, 382, 212]; a small square basket: [90, 34, 179, 61]; the wall is white: [32, 1, 353, 86]; a bed in the room: [37, 17, 349, 157]; the snow is white: [49, 90, 162, 176]; the bed is white: [24, 50, 241, 181]; the object is black: [52, 7, 210, 89]; white wall in the background: [135, 1, 382, 67]; ; Region Captions: a white snowy area with a black hole in the middle: [0, 54, 383, 158]; a black and white image of a room with a black wall: [0, 0, 383, 68]; a gray sheet of paper with a black background: [135, 0, 248, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a grey circle with a black background: [211, 162, 89, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a white floor and a small object\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the persons head is bent: [206, 157, 305, 211]; a bed in a room: [0, 43, 382, 212]; a small square basket: [90, 34, 179, 61]; the wall is white: [32, 1, 353, 86]; a bed in the room: [37, 17, 349, 157]; the snow is white: [49, 90, 162, 176]; the bed is white: [24, 50, 241, 181]; the object is black: [52, 7, 210, 89]; white wall in the background: [135, 1, 382, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 54, 383, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 0, 248, 67]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 135, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[211, 162, 89, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy area with a black hole in the middle: [0, 54, 383, 158]; a black and white image of a room with a black wall: [0, 0, 383, 68]; a gray sheet of paper with a black background: [135, 0, 248, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a grey circle with a black background: [211, 162, 89, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a white floor and a small object; Dense Caption: the persons head is bent: [206, 157, 305, 211]; a bed in a room: [0, 43, 382, 212]; a small square basket: [90, 34, 179, 61]; the wall is white: [32, 1, 353, 86]; a bed in the room: [37, 17, 349, 157]; the snow is white: [49, 90, 162, 176]; the bed is white: [24, 50, 241, 181]; the object is black: [52, 7, 210, 89]; white wall in the background: [135, 1, 382, 67]; ; Region Captions: a white snowy area with a black hole in the middle: [0, 54, 383, 158]; a black and white image of a room with a black wall: [0, 0, 383, 68]; a gray sheet of paper with a black background: [135, 0, 248, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a grey circle with a black background: [211, 162, 89, 51]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a white floor and a small object\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the persons head is bent: [206, 157, 305, 211]; a bed in a room: [0, 43, 382, 212]; a small square basket: [90, 34, 179, 61]; the wall is white: [32, 1, 353, 86]; a bed in the room: [37, 17, 349, 157]; the snow is white: [49, 90, 162, 176]; the bed is white: [24, 50, 241, 181]; the object is black: [52, 7, 210, 89]; white wall in the background: [135, 1, 382, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 54, 383, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 0, 248, 67]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 135, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[211, 162, 89, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy area with a black hole in the middle: [0, 54, 383, 158]; a black and white image of a room with a black wall: [0, 0, 383, 68]; a gray sheet of paper with a black background: [135, 0, 248, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a grey circle with a black background: [211, 162, 89, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a white floor and a small object; Dense Caption: the persons head is bent: [206, 157, 305, 211]; a bed in a room: [0, 43, 382, 212]; a small square basket: [90, 34, 179, 61]; the wall is white: [32, 1, 353, 86]; a bed in the room: [37, 17, 349, 157]; the snow is white: [49, 90, 162, 176]; the bed is white: [24, 50, 241, 181]; the object is black: [52, 7, 210, 89]; white wall in the background: [135, 1, 382, 67]; ; Region Captions: a white snowy area with a black hole in the middle: [0, 54, 383, 158]; a black and white image of a room with a black wall: [0, 0, 383, 68]; a gray sheet of paper with a black background: [135, 0, 248, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a grey circle with a black background: [211, 162, 89, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a man flying in the air\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and red airplane: [214, 0, 303, 48]; the ground is covered in snow: [36, 45, 347, 210]; the basket is made of wood: [87, 29, 182, 64]; the snowboarder has a shadow: [218, 88, 267, 118]; the snow is white: [159, 51, 335, 172]; the snowboarder is casting a shadow: [208, 81, 277, 128]; a red and white striped sign: [233, 0, 286, 30]; a red white and blue flag: [196, 1, 326, 65]; gray wall behind snowboarder: [1, 0, 381, 76]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 54, 383, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[133, 0, 250, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 135, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[91, 37, 86, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a small black ball sitting on a snowy surface: [0, 54, 383, 158]; a black and white image of a skeleton in a room: [0, 0, 383, 68]; a black silhouette of a man with a bow tie: [133, 0, 250, 68]; a gray t shirt with the word tv on it: [0, 0, 135, 69]; a black block with a blue ring on it: [91, 37, 86, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a man flying in the air; Dense Caption: a blue and red airplane: [214, 0, 303, 48]; the ground is covered in snow: [36, 45, 347, 210]; the basket is made of wood: [87, 29, 182, 64]; the snowboarder has a shadow: [218, 88, 267, 118]; the snow is white: [159, 51, 335, 172]; the snowboarder is casting a shadow: [208, 81, 277, 128]; a red and white striped sign: [233, 0, 286, 30]; a red white and blue flag: [196, 1, 326, 65]; gray wall behind snowboarder: [1, 0, 381, 76]; ; Region Captions: a small black ball sitting on a snowy surface: [0, 54, 383, 158]; a black and white image of a skeleton in a room: [0, 0, 383, 68]; a black silhouette of a man with a bow tie: [133, 0, 250, 68]; a gray t shirt with the word tv on it: [0, 0, 135, 69]; a black block with a blue ring on it: [91, 37, 86, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a white floor and a black box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a bed in a room: [0, 45, 381, 212]; a small square box: [90, 33, 179, 61]; the wall is white: [29, 1, 352, 87]; a bed in the room: [35, 13, 347, 160]; the snow is white: [34, 78, 263, 208]; the keyboard is black: [54, 7, 212, 89]; white wall in the background: [135, 1, 381, 67]; a white wall: [0, 0, 141, 73]; the snow is white: [190, 90, 297, 174]; the remote is made of wicker: [81, 20, 192, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 54, 383, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[134, 0, 249, 67]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 135, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[91, 37, 87, 23]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy surface with a black background: [0, 54, 383, 158]; a black and white image of a room with a black corner: [0, 0, 383, 68]; a gray t shirt with the word t shirt on it: [134, 0, 249, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a black block with a black background: [91, 37, 87, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a white floor and a black box; Dense Caption: a bed in a room: [0, 45, 381, 212]; a small square box: [90, 33, 179, 61]; the wall is white: [29, 1, 352, 87]; a bed in the room: [35, 13, 347, 160]; the snow is white: [34, 78, 263, 208]; the keyboard is black: [54, 7, 212, 89]; white wall in the background: [135, 1, 381, 67]; a white wall: [0, 0, 141, 73]; the snow is white: [190, 90, 297, 174]; the remote is made of wicker: [81, 20, 192, 74]; ; Region Captions: a white snowy surface with a black background: [0, 54, 383, 158]; a black and white image of a room with a black corner: [0, 0, 383, 68]; a gray t shirt with the word t shirt on it: [134, 0, 249, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a black block with a black background: [91, 37, 87, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a white floor and a black box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a bed in a room: [0, 45, 381, 212]; a small square box: [90, 33, 179, 61]; the wall is white: [29, 1, 352, 87]; a bed in the room: [35, 13, 347, 160]; the snow is white: [34, 78, 263, 208]; the keyboard is black: [54, 7, 212, 89]; white wall in the background: [135, 1, 381, 67]; a white wall: [0, 0, 141, 73]; the snow is white: [190, 90, 297, 174]; the remote is made of wicker: [81, 20, 192, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 54, 383, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[134, 0, 249, 67]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 135, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[91, 37, 87, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy surface with a black background: [0, 54, 383, 158]; a black and white image of a room with a black corner: [0, 0, 383, 68]; a gray t shirt with the word t shirt on it: [134, 0, 249, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a black block with a black background: [91, 37, 87, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a white floor and a black box; Dense Caption: a bed in a room: [0, 45, 381, 212]; a small square box: [90, 33, 179, 61]; the wall is white: [29, 1, 352, 87]; a bed in the room: [35, 13, 347, 160]; the snow is white: [34, 78, 263, 208]; the keyboard is black: [54, 7, 212, 89]; white wall in the background: [135, 1, 381, 67]; a white wall: [0, 0, 141, 73]; the snow is white: [190, 90, 297, 174]; the remote is made of wicker: [81, 20, 192, 74]; ; Region Captions: a white snowy surface with a black background: [0, 54, 383, 158]; a black and white image of a room with a black corner: [0, 0, 383, 68]; a gray t shirt with the word t shirt on it: [134, 0, 249, 67]; a gray piece of paper with a black background: [0, 0, 135, 69]; a black block with a black background: [91, 37, 87, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a black square on the floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a bed in the room: [33, 99, 353, 211]; the object is black: [80, 131, 116, 147]; the photo is black and white: [23, 10, 362, 193]; the basket is small: [128, 90, 189, 111]; a small black pillow: [351, 96, 383, 126]; object in the snow: [76, 127, 121, 153]; the wall is white: [160, 2, 380, 103]; the wall is white: [1, 1, 156, 114]; a hole in the snow: [63, 120, 133, 167]; the snow is white in color: [180, 116, 288, 182]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 107, 383, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[158, 0, 225, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 157, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 96, 55, 13]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a room with a white wall and a black door: [0, 0, 383, 120]; a small white object with a black hole in it: [0, 107, 383, 105]; a gray square with a white background: [158, 0, 225, 114]; a gray t-shirt with a black background: [0, 0, 157, 120]; a black and white image of a black and white image: [131, 96, 55, 13]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a black square on the floor; Dense Caption: a bed in the room: [33, 99, 353, 211]; the object is black: [80, 131, 116, 147]; the photo is black and white: [23, 10, 362, 193]; the basket is small: [128, 90, 189, 111]; a small black pillow: [351, 96, 383, 126]; object in the snow: [76, 127, 121, 153]; the wall is white: [160, 2, 380, 103]; the wall is white: [1, 1, 156, 114]; a hole in the snow: [63, 120, 133, 167]; the snow is white in color: [180, 116, 288, 182]; ; Region Captions: a room with a white wall and a black door: [0, 0, 383, 120]; a small white object with a black hole in it: [0, 107, 383, 105]; a gray square with a white background: [158, 0, 225, 114]; a gray t-shirt with a black background: [0, 0, 157, 120]; a black and white image of a black and white image: [131, 96, 55, 13]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a red light and a red block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a bed in the room: [33, 98, 353, 211]; a black object in the snow: [80, 131, 116, 147]; the photo is black and white: [12, 9, 370, 197]; a small black pillow: [351, 97, 383, 126]; a small basket on the bed: [128, 90, 189, 111]; a hole in the snow: [76, 127, 121, 153]; the wall is white: [160, 1, 379, 104]; white wall of bedroom: [1, 1, 157, 114]; a hole in the snow: [63, 120, 133, 166]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 107, 383, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[158, 0, 225, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 157, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 96, 55, 13]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.70 seconds\n",
      "finished...\n",
      "\n",
      "a small white object with a black hole in it: [0, 107, 383, 105]; a gray paper clip with a black background: [2, 0, 381, 114]; a gray state with a white background: [158, 0, 225, 114]; a gray background with the words'adrian you are welcome': [0, 0, 157, 120]; a black and white image of a black and white image: [131, 96, 55, 13]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a red light and a red block; Dense Caption: a bed in the room: [33, 98, 353, 211]; a black object in the snow: [80, 131, 116, 147]; the photo is black and white: [12, 9, 370, 197]; a small black pillow: [351, 97, 383, 126]; a small basket on the bed: [128, 90, 189, 111]; a hole in the snow: [76, 127, 121, 153]; the wall is white: [160, 1, 379, 104]; white wall of bedroom: [1, 1, 157, 114]; a hole in the snow: [63, 120, 133, 166]; ; Region Captions: a small white object with a black hole in it: [0, 107, 383, 105]; a gray paper clip with a black background: [2, 0, 381, 114]; a gray state with a white background: [158, 0, 225, 114]; a gray background with the words'adrian you are welcome': [0, 0, 157, 120]; a black and white image of a black and white image: [131, 96, 55, 13]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a small room with a red ball and a white floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a snowy hillside: [33, 98, 353, 211]; a black object in the snow: [80, 131, 116, 147]; the photo is black and white: [20, 9, 364, 194]; a small black pillow: [351, 97, 383, 126]; a small basket on the bed: [128, 90, 189, 111]; a hole in the snow: [76, 127, 121, 153]; the wall is white: [160, 1, 379, 104]; the wall is white: [1, 1, 157, 114]; a hole in the snow: [63, 120, 133, 166]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 107, 383, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[158, 0, 225, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 157, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 96, 55, 13]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.77 seconds\n",
      "finished...\n",
      "\n",
      "a room with a wall and a door: [0, 0, 383, 120]; a small white object with a black hole in it: [0, 107, 383, 105]; a gray map of arizona with a white border: [158, 0, 225, 114]; a gray background with the words'adrian tees': [0, 0, 157, 120]; a black and white image of a black and white image: [131, 96, 55, 13]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a small room with a red ball and a white floor; Dense Caption: a snowy hillside: [33, 98, 353, 211]; a black object in the snow: [80, 131, 116, 147]; the photo is black and white: [20, 9, 364, 194]; a small black pillow: [351, 97, 383, 126]; a small basket on the bed: [128, 90, 189, 111]; a hole in the snow: [76, 127, 121, 153]; the wall is white: [160, 1, 379, 104]; the wall is white: [1, 1, 157, 114]; a hole in the snow: [63, 120, 133, 166]; ; Region Captions: a room with a wall and a door: [0, 0, 383, 120]; a small white object with a black hole in it: [0, 107, 383, 105]; a gray map of arizona with a white border: [158, 0, 225, 114]; a gray background with the words'adrian tees': [0, 0, 157, 120]; a black and white image of a black and white image: [131, 96, 55, 13]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft scene with a person standing in the middle of the room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [35, 86, 349, 210]; a person wearing a yellow hat: [290, 65, 323, 110]; the wall is white: [3, 1, 372, 97]; a brick wall at the end of the bed: [37, 77, 120, 99]; a bedroom: [1, 4, 381, 209]; a brown box on the side of the bed: [341, 84, 383, 117]; the shadow of the snowboarder: [275, 119, 334, 146]; yellow and blue hat: [296, 67, 319, 83]; a person wearing a yellow hat: [276, 60, 337, 114]; red shirt on the person: [296, 78, 311, 95]; a bed in the room: [28, 29, 283, 171]; a person wearing a red jacket: [294, 77, 312, 108]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 93, 383, 119]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[70, 0, 249, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 79, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[262, 0, 121, 89]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a small white square with a black hole in it: [0, 93, 383, 119]; a black and white image of a room with a window: [0, 0, 383, 101]; a gray square with a black background: [70, 0, 249, 93]; a gray square with a black background: [0, 0, 79, 102]; a grey laptop with a black screen: [262, 0, 121, 89]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft scene with a person standing in the middle of the room; Dense Caption: the ground is covered in snow: [35, 86, 349, 210]; a person wearing a yellow hat: [290, 65, 323, 110]; the wall is white: [3, 1, 372, 97]; a brick wall at the end of the bed: [37, 77, 120, 99]; a bedroom: [1, 4, 381, 209]; a brown box on the side of the bed: [341, 84, 383, 117]; the shadow of the snowboarder: [275, 119, 334, 146]; yellow and blue hat: [296, 67, 319, 83]; a person wearing a yellow hat: [276, 60, 337, 114]; red shirt on the person: [296, 78, 311, 95]; a bed in the room: [28, 29, 283, 171]; a person wearing a red jacket: [294, 77, 312, 108]; ; Region Captions: a small white square with a black hole in it: [0, 93, 383, 119]; a black and white image of a room with a window: [0, 0, 383, 101]; a gray square with a black background: [70, 0, 249, 93]; a gray square with a black background: [0, 0, 79, 102]; a grey laptop with a black screen: [262, 0, 121, 89]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a snowy white floor: [0, 146, 382, 211]; a person wearing a red jacket: [217, 125, 236, 158]; the brown box on the side of the bed: [235, 137, 289, 164]; square object in the snow: [194, 171, 240, 194]; the photo is black and white: [0, 2, 381, 208]; a man on the bed: [53, 90, 337, 210]; the wall is white: [1, 2, 207, 148]; a small square object: [175, 134, 222, 156]; the boxes are brown: [173, 122, 291, 168]; a black square object: [181, 163, 253, 205]; the boxes are brown: [163, 109, 309, 190]; a man on a bed: [131, 22, 337, 201]; the wall is white: [211, 1, 381, 179]; the sky is clear: [45, 18, 163, 102]; a person wearing a red jacket: [211, 121, 241, 163]; yellow and blue flag: [219, 125, 235, 137]; person wearing blue pants: [218, 144, 234, 157]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 177]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 212, 156]\n",
      "process_ann took 0.00 seconds\n",
      "[212, 0, 171, 179]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 151, 383, 61]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 140, 175, 18]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a 3d model of a room with a black wall: [0, 1, 383, 177]; a gray map of the state of nevada: [0, 1, 212, 156]; a gray wall with a black tv screen: [212, 0, 171, 179]; a small black object is flying in the sky: [0, 151, 383, 61]; a gray arrow with a black background: [0, 140, 175, 18]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: a snowy white floor: [0, 146, 382, 211]; a person wearing a red jacket: [217, 125, 236, 158]; the brown box on the side of the bed: [235, 137, 289, 164]; square object in the snow: [194, 171, 240, 194]; the photo is black and white: [0, 2, 381, 208]; a man on the bed: [53, 90, 337, 210]; the wall is white: [1, 2, 207, 148]; a small square object: [175, 134, 222, 156]; the boxes are brown: [173, 122, 291, 168]; a black square object: [181, 163, 253, 205]; the boxes are brown: [163, 109, 309, 190]; a man on a bed: [131, 22, 337, 201]; the wall is white: [211, 1, 381, 179]; the sky is clear: [45, 18, 163, 102]; a person wearing a red jacket: [211, 121, 241, 163]; yellow and blue flag: [219, 125, 235, 137]; person wearing blue pants: [218, 144, 234, 157]; ; Region Captions: a 3d model of a room with a black wall: [0, 1, 383, 177]; a gray map of the state of nevada: [0, 1, 212, 156]; a gray wall with a black tv screen: [212, 0, 171, 179]; a small black object is flying in the sky: [0, 151, 383, 61]; a gray arrow with a black background: [0, 140, 175, 18]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is made: [33, 105, 350, 211]; a square shaped object: [35, 88, 148, 131]; the box is brown: [148, 95, 213, 127]; a bedroom: [34, 12, 312, 196]; paper towels on the back of the bench: [129, 59, 159, 105]; the object in front of the person: [102, 185, 185, 212]; blue cloth hanging from the lamp: [136, 87, 154, 104]; a red piece of fabric: [132, 71, 156, 90]; a lego figure on a table: [121, 53, 168, 113]; the items are on the bed: [31, 55, 242, 151]; a white wall: [0, 0, 114, 125]; the wall is white: [96, 1, 368, 135]; a small toy on a bed: [122, 56, 214, 138]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[106, 0, 277, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 117, 383, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 110, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[37, 96, 173, 33]\n",
      "process_ann took 0.00 seconds\n",
      "[37, 96, 112, 33]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a man is standing on a ledge with a tv: [106, 0, 277, 143]; a white mountain with a black background: [0, 117, 383, 95]; a gray square with a white letter on it: [0, 0, 110, 122]; a block of stone with a sandstone texture: [37, 96, 173, 33]; a block of black coal on a black background: [37, 96, 112, 33]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person in it; Dense Caption: the bed is made: [33, 105, 350, 211]; a square shaped object: [35, 88, 148, 131]; the box is brown: [148, 95, 213, 127]; a bedroom: [34, 12, 312, 196]; paper towels on the back of the bench: [129, 59, 159, 105]; the object in front of the person: [102, 185, 185, 212]; blue cloth hanging from the lamp: [136, 87, 154, 104]; a red piece of fabric: [132, 71, 156, 90]; a lego figure on a table: [121, 53, 168, 113]; the items are on the bed: [31, 55, 242, 151]; a white wall: [0, 0, 114, 125]; the wall is white: [96, 1, 368, 135]; a small toy on a bed: [122, 56, 214, 138]; ; Region Captions: a man is standing on a ledge with a tv: [106, 0, 277, 143]; a white mountain with a black background: [0, 117, 383, 95]; a gray square with a white letter on it: [0, 0, 110, 122]; a block of stone with a sandstone texture: [37, 96, 173, 33]; a block of black coal on a black background: [37, 96, 112, 33]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [133, 77, 216, 127]; a bed in the room: [36, 25, 303, 184]; the bed is made: [33, 79, 348, 211]; lego man is carrying a snowboard: [0, 51, 50, 139]; a black and white box: [9, 70, 142, 126]; yellow and blue paper: [0, 53, 44, 82]; red part of the lego: [3, 75, 41, 111]; two small boxes are by the bed: [2, 59, 225, 141]; the square brown suitcase: [169, 84, 214, 125]; the snow is white: [23, 128, 252, 211]; yellow sticker on the suitcase: [50, 88, 71, 108]; the snow is white: [74, 137, 194, 204]; the wall is white: [81, 1, 371, 147]; blue lego person is wearing: [15, 105, 44, 136]; shadow of the object: [7, 119, 59, 141]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 104, 383, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[95, 0, 288, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 102, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[34, 78, 105, 42]\n",
      "process_ann took 0.00 seconds\n",
      "[170, 87, 43, 37]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a black cat standing on a white floor: [0, 104, 383, 108]; a gray wall with a black background: [95, 0, 288, 155]; a grey shaped object with a white background: [0, 0, 102, 106]; a black stone block with a yellow candle: [34, 78, 105, 42]; a wooden block on a black background: [170, 87, 43, 37]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a wooden box; Dense Caption: the box is brown: [133, 77, 216, 127]; a bed in the room: [36, 25, 303, 184]; the bed is made: [33, 79, 348, 211]; lego man is carrying a snowboard: [0, 51, 50, 139]; a black and white box: [9, 70, 142, 126]; yellow and blue paper: [0, 53, 44, 82]; red part of the lego: [3, 75, 41, 111]; two small boxes are by the bed: [2, 59, 225, 141]; the square brown suitcase: [169, 84, 214, 125]; the snow is white: [23, 128, 252, 211]; yellow sticker on the suitcase: [50, 88, 71, 108]; the snow is white: [74, 137, 194, 204]; the wall is white: [81, 1, 371, 147]; blue lego person is wearing: [15, 105, 44, 136]; shadow of the object: [7, 119, 59, 141]; ; Region Captions: a black cat standing on a white floor: [0, 104, 383, 108]; a gray wall with a black background: [95, 0, 288, 155]; a grey shaped object with a white background: [0, 0, 102, 106]; a black stone block with a yellow candle: [34, 78, 105, 42]; a wooden block on a black background: [170, 87, 43, 37]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [133, 77, 216, 127]; a bed in the room: [36, 25, 304, 184]; the bed is made: [33, 80, 348, 211]; lego man is carrying a snowboard: [0, 51, 50, 139]; a black and white box: [11, 70, 142, 126]; red part of the lego board: [3, 74, 43, 111]; yellow and blue paper: [0, 53, 44, 82]; two small boxes are by the bed: [2, 60, 225, 141]; the square brown suitcase: [169, 84, 214, 125]; the bed is white: [23, 128, 252, 211]; yellow sticker on the suitcase: [51, 86, 71, 107]; blue wooden table leg: [15, 105, 44, 136]; the wall is white: [80, 1, 371, 147]; the snow is white: [74, 137, 194, 204]; shadow of the object: [7, 119, 59, 141]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 104, 383, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[95, 0, 288, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 102, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[34, 78, 105, 42]\n",
      "process_ann took 0.00 seconds\n",
      "[170, 87, 43, 37]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a cat is standing on a white floor: [0, 104, 383, 108]; a gray wall with a black background: [95, 0, 288, 155]; a grey shaped object with a white background: [0, 0, 102, 106]; a block of stone with a fire on it: [34, 78, 105, 42]; a wooden block on a black background: [170, 87, 43, 37]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a wooden box; Dense Caption: the box is brown: [133, 77, 216, 127]; a bed in the room: [36, 25, 304, 184]; the bed is made: [33, 80, 348, 211]; lego man is carrying a snowboard: [0, 51, 50, 139]; a black and white box: [11, 70, 142, 126]; red part of the lego board: [3, 74, 43, 111]; yellow and blue paper: [0, 53, 44, 82]; two small boxes are by the bed: [2, 60, 225, 141]; the square brown suitcase: [169, 84, 214, 125]; the bed is white: [23, 128, 252, 211]; yellow sticker on the suitcase: [51, 86, 71, 107]; blue wooden table leg: [15, 105, 44, 136]; the wall is white: [80, 1, 371, 147]; the snow is white: [74, 137, 194, 204]; shadow of the object: [7, 119, 59, 141]; ; Region Captions: a cat is standing on a white floor: [0, 104, 383, 108]; a gray wall with a black background: [95, 0, 288, 155]; a grey shaped object with a white background: [0, 0, 102, 106]; a block of stone with a fire on it: [34, 78, 105, 42]; a wooden block on a black background: [170, 87, 43, 37]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing next to a pile of blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [188, 74, 275, 126]; the bed is made: [30, 74, 349, 211]; a black box of plastic: [114, 68, 196, 107]; lego person carrying a surfboard: [91, 52, 126, 116]; red part of the lego: [97, 69, 120, 97]; yellow top of a lego a umbrella: [92, 52, 123, 74]; a toy on the bed: [69, 33, 185, 138]; the box is brown: [172, 49, 303, 154]; the boxes are made of cardboard: [67, 40, 295, 139]; blue post on the end of the cake: [103, 93, 121, 116]; the bed is white: [18, 118, 247, 210]; yellow sticker on suitcase: [125, 80, 139, 97]; the boxes are brown: [115, 53, 325, 181]; the walls are white: [0, 6, 381, 166]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 95, 383, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[164, 0, 219, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 164, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[117, 73, 77, 32]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a person is walking on a snowy surface: [0, 95, 383, 117]; a black wall with a white wall: [2, 0, 381, 155]; a black wall with a white arrow on it: [164, 0, 219, 155]; a gray shaped piece of wood: [0, 0, 164, 99]; a black stone table with a candle on it: [117, 73, 77, 32]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing next to a pile of blocks; Dense Caption: the box is brown: [188, 74, 275, 126]; the bed is made: [30, 74, 349, 211]; a black box of plastic: [114, 68, 196, 107]; lego person carrying a surfboard: [91, 52, 126, 116]; red part of the lego: [97, 69, 120, 97]; yellow top of a lego a umbrella: [92, 52, 123, 74]; a toy on the bed: [69, 33, 185, 138]; the box is brown: [172, 49, 303, 154]; the boxes are made of cardboard: [67, 40, 295, 139]; blue post on the end of the cake: [103, 93, 121, 116]; the bed is white: [18, 118, 247, 210]; yellow sticker on suitcase: [125, 80, 139, 97]; the boxes are brown: [115, 53, 325, 181]; the walls are white: [0, 6, 381, 166]; ; Region Captions: a person is walking on a snowy surface: [0, 95, 383, 117]; a black wall with a white wall: [2, 0, 381, 155]; a black wall with a white arrow on it: [164, 0, 219, 155]; a gray shaped piece of wood: [0, 0, 164, 99]; a black stone table with a candle on it: [117, 73, 77, 32]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing next to a block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and black suitcase: [146, 94, 238, 197]; the brown wooden basket: [207, 70, 300, 125]; white tablecloth on the table: [0, 82, 381, 211]; small lego piece: [120, 48, 158, 109]; square brown wicker basket: [148, 65, 212, 99]; red section of the cake: [121, 65, 156, 90]; black and white cake: [120, 59, 215, 106]; the boxes are made of cardboard: [105, 61, 301, 202]; the box is brown: [195, 43, 324, 151]; a toy on the bed: [86, 30, 217, 138]; blue square on the cup: [130, 87, 151, 108]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 89, 383, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[185, 0, 198, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 89, 172, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 184, 94]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.77 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a white wall: [0, 0, 383, 149]; a black and white image of a person standing on a snowy hill: [0, 89, 383, 123]; a black and white image of a wall: [185, 0, 198, 150]; a white sheet of paper on a black background: [0, 89, 172, 123]; a gray piece of paper with the word nebraska: [0, 0, 184, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing next to a block in minecraft; Dense Caption: green and black suitcase: [146, 94, 238, 197]; the brown wooden basket: [207, 70, 300, 125]; white tablecloth on the table: [0, 82, 381, 211]; small lego piece: [120, 48, 158, 109]; square brown wicker basket: [148, 65, 212, 99]; red section of the cake: [121, 65, 156, 90]; black and white cake: [120, 59, 215, 106]; the boxes are made of cardboard: [105, 61, 301, 202]; the box is brown: [195, 43, 324, 151]; a toy on the bed: [86, 30, 217, 138]; blue square on the cup: [130, 87, 151, 108]; ; Region Captions: a black and white image of a room with a white wall: [0, 0, 383, 149]; a black and white image of a person standing on a snowy hill: [0, 89, 383, 123]; a black and white image of a wall: [185, 0, 198, 150]; a white sheet of paper on a black background: [0, 89, 172, 123]; a gray piece of paper with the word nebraska: [0, 0, 184, 94]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing next to a block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and black suitcase: [146, 94, 238, 197]; the brown wooden basket: [207, 70, 300, 125]; white tablecloth on the table: [0, 82, 381, 211]; small lego piece: [120, 48, 157, 110]; square brown wicker basket: [149, 65, 212, 99]; red section of the cake: [121, 65, 155, 90]; the black and white basket: [120, 59, 216, 106]; the boxes are made of cardboard: [105, 61, 301, 202]; the box is brown: [195, 43, 324, 151]; blue square on the cup: [130, 87, 151, 108]; a toy on the bed: [86, 30, 217, 137]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 89, 383, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[185, 0, 198, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 89, 170, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 184, 94]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.77 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a white wall: [0, 0, 383, 150]; a black and white image of a person standing on a snowy hill: [0, 89, 383, 123]; a black and white image of a wall: [185, 0, 198, 150]; a white sheet of paper on a black background: [0, 89, 170, 123]; a gray piece of paper with the word nevada on it: [0, 0, 184, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing next to a block in minecraft; Dense Caption: green and black suitcase: [146, 94, 238, 197]; the brown wooden basket: [207, 70, 300, 125]; white tablecloth on the table: [0, 82, 381, 211]; small lego piece: [120, 48, 157, 110]; square brown wicker basket: [149, 65, 212, 99]; red section of the cake: [121, 65, 155, 90]; the black and white basket: [120, 59, 216, 106]; the boxes are made of cardboard: [105, 61, 301, 202]; the box is brown: [195, 43, 324, 151]; blue square on the cup: [130, 87, 151, 108]; a toy on the bed: [86, 30, 217, 137]; ; Region Captions: a black and white image of a room with a white wall: [0, 0, 383, 150]; a black and white image of a person standing on a snowy hill: [0, 89, 383, 123]; a black and white image of a wall: [185, 0, 198, 150]; a white sheet of paper on a black background: [0, 89, 170, 123]; a gray piece of paper with the word nevada on it: [0, 0, 184, 94]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing next to a block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and black suitcase: [146, 94, 238, 197]; the brown basket on the floor: [207, 70, 300, 125]; white tablecloth on the table: [0, 82, 381, 211]; small lego piece: [120, 48, 158, 110]; square black box with white dots: [148, 65, 212, 99]; red part of the cake: [121, 64, 156, 89]; the black and white basket: [121, 59, 216, 106]; the suitcases are on the floor: [109, 64, 299, 202]; the box is brown: [195, 44, 324, 151]; a toy on the bed: [87, 30, 217, 136]; blue square on the cup: [130, 87, 151, 108]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 89, 383, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[185, 0, 198, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 89, 170, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 184, 94]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a chair: [0, 0, 383, 150]; a black and white image of a person standing on a snowy hill: [0, 89, 383, 123]; a black and white image of a wall: [185, 0, 198, 150]; a white sheet of paper on a black background: [0, 89, 170, 123]; a gray paper with the word san diego: [0, 0, 184, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing next to a block in minecraft; Dense Caption: green and black suitcase: [146, 94, 238, 197]; the brown basket on the floor: [207, 70, 300, 125]; white tablecloth on the table: [0, 82, 381, 211]; small lego piece: [120, 48, 158, 110]; square black box with white dots: [148, 65, 212, 99]; red part of the cake: [121, 64, 156, 89]; the black and white basket: [121, 59, 216, 106]; the suitcases are on the floor: [109, 64, 299, 202]; the box is brown: [195, 44, 324, 151]; a toy on the bed: [87, 30, 217, 136]; blue square on the cup: [130, 87, 151, 108]; ; Region Captions: a black and white image of a room with a chair: [0, 0, 383, 150]; a black and white image of a person standing on a snowy hill: [0, 89, 383, 123]; a black and white image of a wall: [185, 0, 198, 150]; a white sheet of paper on a black background: [0, 89, 170, 123]; a gray paper with the word san diego: [0, 0, 184, 94]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green piece of paper: [287, 74, 381, 212]; the kite is in the air: [102, 126, 213, 212]; white table top: [0, 27, 381, 211]; a black plastic crate: [291, 27, 383, 83]; the remote is black: [51, 17, 135, 45]; the wall is white: [42, 0, 359, 94]; white snow on the ground: [72, 55, 197, 121]; the snow is white: [149, 73, 246, 144]; white snow on the ground: [27, 53, 241, 133]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 39, 372, 173]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 51]\n",
      "process_ann took 0.00 seconds\n",
      "[291, 78, 92, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[105, 131, 104, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[295, 32, 88, 50]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy mountain with a black background: [0, 39, 372, 173]; a black and white image of a room with a door: [0, 0, 383, 51]; a green block in minecraft: [291, 78, 92, 134]; a gray sheet on a black background: [105, 131, 104, 82]; a black and white block of bricks: [295, 32, 88, 50]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: a green piece of paper: [287, 74, 381, 212]; the kite is in the air: [102, 126, 213, 212]; white table top: [0, 27, 381, 211]; a black plastic crate: [291, 27, 383, 83]; the remote is black: [51, 17, 135, 45]; the wall is white: [42, 0, 359, 94]; white snow on the ground: [72, 55, 197, 121]; the snow is white: [149, 73, 246, 144]; white snow on the ground: [27, 53, 241, 133]; ; Region Captions: a white snowy mountain with a black background: [0, 39, 372, 173]; a black and white image of a room with a door: [0, 0, 383, 51]; a green block in minecraft: [291, 78, 92, 134]; a gray sheet on a black background: [105, 131, 104, 82]; a black and white block of bricks: [295, 32, 88, 50]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a small square in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "kite in the air: [183, 126, 297, 212]; a snowy white field: [0, 22, 381, 212]; a small basket on the bed: [187, 15, 250, 37]; the snow is white: [32, 22, 319, 142]; the wall is white: [0, 2, 381, 62]; small object in snow: [94, 43, 120, 57]; a small square pillow: [0, 19, 32, 48]; the snow is white in color: [51, 65, 159, 149]; the headboard is made of wood: [2, 4, 254, 49]; the objects are black: [12, 5, 254, 108]; the snow is white: [20, 45, 235, 207]; a hole in the snow: [89, 38, 129, 65]; the snow is white in color: [162, 48, 272, 113]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 32, 383, 180]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 224, 37]\n",
      "process_ann took 0.00 seconds\n",
      "[225, 0, 158, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[186, 131, 107, 82]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a small square with a black hole in it: [0, 32, 383, 180]; a black and white image of a room: [0, 0, 383, 56]; a gray paper with a black background: [0, 0, 224, 37]; a white wall with a black smudge on it: [225, 0, 158, 56]; a gray sheet on a black background: [186, 131, 107, 82]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a small square in a minecraft room; Dense Caption: kite in the air: [183, 126, 297, 212]; a snowy white field: [0, 22, 381, 212]; a small basket on the bed: [187, 15, 250, 37]; the snow is white: [32, 22, 319, 142]; the wall is white: [0, 2, 381, 62]; small object in snow: [94, 43, 120, 57]; a small square pillow: [0, 19, 32, 48]; the snow is white in color: [51, 65, 159, 149]; the headboard is made of wood: [2, 4, 254, 49]; the objects are black: [12, 5, 254, 108]; the snow is white: [20, 45, 235, 207]; a hole in the snow: [89, 38, 129, 65]; the snow is white in color: [162, 48, 272, 113]; ; Region Captions: a small square with a black hole in it: [0, 32, 383, 180]; a black and white image of a room: [0, 0, 383, 56]; a gray paper with a black background: [0, 0, 224, 37]; a white wall with a black smudge on it: [225, 0, 158, 56]; a gray sheet on a black background: [186, 131, 107, 82]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic square on the table: [266, 39, 383, 181]; black square in the snow: [91, 103, 200, 191]; white table top: [0, 2, 382, 210]; the black box on the table: [275, 0, 382, 54]; red and white flag: [321, 0, 360, 41]; the snow is white and green: [143, 35, 361, 211]; a basket on the table: [5, 0, 102, 16]; white snow on the ground: [37, 23, 250, 101]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 6, 383, 206]\n",
      "process_ann took 0.00 seconds\n",
      "[271, 47, 112, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[95, 108, 101, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[277, 0, 106, 50]\n",
      "process_ann took 0.00 seconds\n",
      "[299, 47, 84, 47]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a small square in the middle of a snowy area: [0, 6, 383, 206]; a green block in minecraft: [271, 47, 112, 131]; a gray sheet of paper on a black surface: [95, 108, 101, 80]; a black and gold skeleton with a gold ring: [277, 0, 106, 50]; a green square with a black background: [299, 47, 84, 47]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green plastic square on the table: [266, 39, 383, 181]; black square in the snow: [91, 103, 200, 191]; white table top: [0, 2, 382, 210]; the black box on the table: [275, 0, 382, 54]; red and white flag: [321, 0, 360, 41]; the snow is white and green: [143, 35, 361, 211]; a basket on the table: [5, 0, 102, 16]; white snow on the ground: [37, 23, 250, 101]; ; Region Captions: a small square in the middle of a snowy area: [0, 6, 383, 206]; a green block in minecraft: [271, 47, 112, 131]; a gray sheet of paper on a black surface: [95, 108, 101, 80]; a black and gold skeleton with a gold ring: [277, 0, 106, 50]; a green square with a black background: [299, 47, 84, 47]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic square on the table: [266, 39, 383, 181]; black square in the snow: [91, 103, 200, 191]; white table top: [0, 2, 382, 210]; the black box on the table: [275, 0, 382, 55]; red and blue birthday candle: [316, 0, 360, 48]; the snow is white and green: [142, 35, 361, 211]; a basket on the table: [5, 0, 102, 16]; white snow on the ground: [37, 23, 250, 102]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 7, 383, 205]\n",
      "process_ann took 0.00 seconds\n",
      "[97, 46, 286, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[271, 47, 112, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[95, 108, 101, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[277, 0, 106, 50]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a small square with a black background: [0, 7, 383, 205]; a green block in minecraft: [97, 46, 286, 132]; a green block in minecraft: [271, 47, 112, 131]; a gray sheet of paper on a black surface: [95, 108, 101, 80]; a black and gold skeleton with a gold ring: [277, 0, 106, 50]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green plastic square on the table: [266, 39, 383, 181]; black square in the snow: [91, 103, 200, 191]; white table top: [0, 2, 382, 210]; the black box on the table: [275, 0, 382, 55]; red and blue birthday candle: [316, 0, 360, 48]; the snow is white and green: [142, 35, 361, 211]; a basket on the table: [5, 0, 102, 16]; white snow on the ground: [37, 23, 250, 102]; ; Region Captions: a small square with a black background: [0, 7, 383, 205]; a green block in minecraft: [97, 46, 286, 132]; a green block in minecraft: [271, 47, 112, 131]; a gray sheet of paper on a black surface: [95, 108, 101, 80]; a black and gold skeleton with a gold ring: [277, 0, 106, 50]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic box on white table: [266, 25, 383, 182]; black square in the snow: [92, 103, 200, 191]; a black metal basket: [274, 0, 383, 46]; white snow on the ground: [0, 2, 383, 210]; the snow is white and green: [154, 30, 343, 212]; a basket on the table: [5, 0, 102, 15]; green color on the suitcase: [290, 25, 383, 57]; blue and red ribbon: [306, 0, 350, 17]; white snow on the ground: [34, 22, 247, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 7, 383, 205]\n",
      "process_ann took 0.00 seconds\n",
      "[271, 30, 112, 148]\n",
      "process_ann took 0.00 seconds\n",
      "[271, 82, 112, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[95, 108, 101, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[277, 0, 106, 46]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a snowy mountain: [0, 7, 383, 205]; a green block in minecraft: [271, 30, 112, 148]; a green square on a black background: [271, 82, 112, 95]; a gray sheet of paper on a black surface: [95, 108, 101, 80]; a black and white textured controller: [277, 0, 106, 46]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green plastic box on white table: [266, 25, 383, 182]; black square in the snow: [92, 103, 200, 191]; a black metal basket: [274, 0, 383, 46]; white snow on the ground: [0, 2, 383, 210]; the snow is white and green: [154, 30, 343, 212]; a basket on the table: [5, 0, 102, 15]; green color on the suitcase: [290, 25, 383, 57]; blue and red ribbon: [306, 0, 350, 17]; white snow on the ground: [34, 22, 247, 103]; ; Region Captions: a 3d image of a snowy mountain: [0, 7, 383, 205]; a green block in minecraft: [271, 30, 112, 148]; a green square on a black background: [271, 82, 112, 95]; a gray sheet of paper on a black surface: [95, 108, 101, 80]; a black and white textured controller: [277, 0, 106, 46]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in front of a green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green checkered chair: [202, 33, 327, 202]; a red white and blue object: [146, 46, 178, 116]; white tablecloth on the table: [0, 77, 383, 210]; wooden box on the table: [284, 75, 383, 152]; red part of hydrant: [150, 66, 171, 93]; a black piece of paper: [53, 194, 149, 211]; the green part of the pillow: [208, 35, 287, 101]; black box on white bed: [196, 66, 211, 98]; blue base of the lego piece: [146, 84, 179, 116]; green and white lego chair: [112, 23, 361, 205]; the wall is white: [0, 2, 383, 87]; blue and red stripes: [154, 89, 171, 113]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 85, 383, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 265, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[209, 39, 113, 159]\n",
      "process_ann took 0.00 seconds\n",
      "[209, 95, 113, 103]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.51 seconds\n",
      "finished...\n",
      "\n",
      "a man is walking down a hallway: [0, 85, 383, 127]; a black and white image of a building: [0, 0, 383, 89]; a gray paper clip with a black background: [0, 0, 265, 83]; a green block with a green background: [209, 39, 113, 159]; a green block in minecraft: [209, 95, 113, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in front of a green block; Dense Caption: green checkered chair: [202, 33, 327, 202]; a red white and blue object: [146, 46, 178, 116]; white tablecloth on the table: [0, 77, 383, 210]; wooden box on the table: [284, 75, 383, 152]; red part of hydrant: [150, 66, 171, 93]; a black piece of paper: [53, 194, 149, 211]; the green part of the pillow: [208, 35, 287, 101]; black box on white bed: [196, 66, 211, 98]; blue base of the lego piece: [146, 84, 179, 116]; green and white lego chair: [112, 23, 361, 205]; the wall is white: [0, 2, 383, 87]; blue and red stripes: [154, 89, 171, 113]; ; Region Captions: a man is walking down a hallway: [0, 85, 383, 127]; a black and white image of a building: [0, 0, 383, 89]; a gray paper clip with a black background: [0, 0, 265, 83]; a green block with a green background: [209, 39, 113, 159]; a green block in minecraft: [209, 95, 113, 103]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red blue and yellow flag: [293, 0, 375, 82]; kite is in the air: [151, 113, 256, 204]; a wide expanse of snow: [0, 10, 382, 210]; the green object near the person: [350, 125, 383, 212]; a basket in the background: [134, 5, 199, 28]; red part of the kite: [299, 12, 370, 53]; a mark on the snow: [22, 43, 54, 57]; blue base of the umbrella: [299, 48, 339, 79]; snow on the ground: [96, 44, 206, 109]; a yellow and blue square: [321, 0, 372, 21]; shadow of the object: [289, 64, 338, 85]; the snowboard is in the air: [42, 2, 349, 113]; red and blue base of the kite: [301, 17, 357, 76]; snow is on the ground: [30, 27, 265, 147]; a hole in the snow: [18, 39, 59, 62]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 24, 383, 188]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[175, 0, 208, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[154, 118, 99, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 171, 32]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a square: [0, 24, 383, 188]; a black and white image of a room with a light: [0, 0, 383, 49]; a black and white image of a building: [175, 0, 208, 49]; a gray square on a black background: [154, 118, 99, 83]; a gray paper towel with a black background: [0, 0, 171, 32]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a minecraft room; Dense Caption: a red blue and yellow flag: [293, 0, 375, 82]; kite is in the air: [151, 113, 256, 204]; a wide expanse of snow: [0, 10, 382, 210]; the green object near the person: [350, 125, 383, 212]; a basket in the background: [134, 5, 199, 28]; red part of the kite: [299, 12, 370, 53]; a mark on the snow: [22, 43, 54, 57]; blue base of the umbrella: [299, 48, 339, 79]; snow on the ground: [96, 44, 206, 109]; a yellow and blue square: [321, 0, 372, 21]; shadow of the object: [289, 64, 338, 85]; the snowboard is in the air: [42, 2, 349, 113]; red and blue base of the kite: [301, 17, 357, 76]; snow is on the ground: [30, 27, 265, 147]; a hole in the snow: [18, 39, 59, 62]; ; Region Captions: a black and white image of a square: [0, 24, 383, 188]; a black and white image of a room with a light: [0, 0, 383, 49]; a black and white image of a building: [175, 0, 208, 49]; a gray square on a black background: [154, 118, 99, 83]; a gray paper towel with a black background: [0, 0, 171, 32]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft scene with a man and a woman\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box next to black box: [160, 54, 205, 97]; the ground is covered in snow: [34, 77, 351, 211]; a multicolored lego man: [113, 56, 132, 96]; dark spot in the snow: [169, 97, 202, 111]; legos on the ground: [83, 45, 227, 117]; the walls are white: [0, 1, 382, 99]; the black object on the ground: [96, 67, 165, 89]; two green boxes on a table: [99, 53, 209, 99]; the lego is green: [59, 36, 275, 161]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 85, 383, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[134, 0, 249, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 136, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[98, 71, 65, 17]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a small white square with a black background: [0, 85, 383, 127]; a black and white image of a wall: [2, 0, 381, 98]; a black and gray picture of a black and gray picture: [134, 0, 249, 98]; a gray wall with a black background: [0, 0, 136, 95]; a black and white image of a black and white image: [98, 71, 65, 17]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft scene with a man and a woman; Dense Caption: green box next to black box: [160, 54, 205, 97]; the ground is covered in snow: [34, 77, 351, 211]; a multicolored lego man: [113, 56, 132, 96]; dark spot in the snow: [169, 97, 202, 111]; legos on the ground: [83, 45, 227, 117]; the walls are white: [0, 1, 382, 99]; the black object on the ground: [96, 67, 165, 89]; two green boxes on a table: [99, 53, 209, 99]; the lego is green: [59, 36, 275, 161]; ; Region Captions: a small white square with a black background: [0, 85, 383, 127]; a black and white image of a wall: [2, 0, 381, 98]; a black and gray picture of a black and gray picture: [134, 0, 249, 98]; a gray wall with a black background: [0, 0, 136, 95]; a black and white image of a black and white image: [98, 71, 65, 17]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a black floor and a black wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is made: [34, 100, 351, 211]; a bed with a snowboard: [36, 26, 348, 181]; shadow of object on snow: [323, 152, 382, 187]; the basket is small: [113, 90, 179, 111]; object in the snow: [8, 131, 69, 158]; a small black pillow: [341, 94, 383, 126]; the wall is white: [150, 2, 379, 98]; the walls are white: [0, 1, 381, 117]; white wall behind bed: [1, 1, 146, 116]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 107, 383, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[144, 0, 239, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 144, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a white door: [0, 0, 383, 121]; a 3d model of a snowy area with a small object: [0, 2, 383, 210]; a white sphere with a hole in it: [0, 107, 383, 105]; a gray square with a black background: [144, 0, 239, 112]; a gray tv screen with a black background: [0, 0, 144, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a black floor and a black wall; Dense Caption: the bed is made: [34, 100, 351, 211]; a bed with a snowboard: [36, 26, 348, 181]; shadow of object on snow: [323, 152, 382, 187]; the basket is small: [113, 90, 179, 111]; object in the snow: [8, 131, 69, 158]; a small black pillow: [341, 94, 383, 126]; the wall is white: [150, 2, 379, 98]; the walls are white: [0, 1, 381, 117]; white wall behind bed: [1, 1, 146, 116]; ; Region Captions: a gray wall with a white door: [0, 0, 383, 121]; a 3d model of a snowy area with a small object: [0, 2, 383, 210]; a white sphere with a hole in it: [0, 107, 383, 105]; a gray square with a black background: [144, 0, 239, 112]; a gray tv screen with a black background: [0, 0, 144, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [33, 79, 350, 211]; green colored box: [131, 68, 179, 115]; red and yellow item on the white table: [98, 68, 133, 128]; a brown wicker basket: [0, 84, 90, 125]; the walls are white: [28, 7, 331, 142]; legos on a platform: [96, 64, 181, 127]; the basket is small: [252, 81, 336, 104]; red cloth wrapped around the fire hydrant: [98, 85, 133, 107]; green box on the ground: [131, 87, 160, 118]; legos on the ground: [60, 59, 218, 143]; blue base of a fire hydrant: [106, 104, 126, 125]; a gray square on the bed: [181, 110, 212, 125]; the wall is white: [14, 2, 293, 79]; a yellow top of a cake: [99, 69, 126, 88]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 98, 383, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 293, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[288, 0, 95, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 88, 33]\n",
      "process_ann took 0.00 seconds\n",
      "[133, 72, 43, 41]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a small white snowy mountain with a black cat on it: [0, 98, 383, 114]; a silhouette of a city with a black background: [0, 0, 293, 103]; a gray square with a black background: [288, 0, 95, 105]; a black stone block with a black background: [0, 90, 88, 33]; a green square with a square on it: [133, 72, 43, 41]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a green block; Dense Caption: the ground is covered in snow: [33, 79, 350, 211]; green colored box: [131, 68, 179, 115]; red and yellow item on the white table: [98, 68, 133, 128]; a brown wicker basket: [0, 84, 90, 125]; the walls are white: [28, 7, 331, 142]; legos on a platform: [96, 64, 181, 127]; the basket is small: [252, 81, 336, 104]; red cloth wrapped around the fire hydrant: [98, 85, 133, 107]; green box on the ground: [131, 87, 160, 118]; legos on the ground: [60, 59, 218, 143]; blue base of a fire hydrant: [106, 104, 126, 125]; a gray square on the bed: [181, 110, 212, 125]; the wall is white: [14, 2, 293, 79]; a yellow top of a cake: [99, 69, 126, 88]; ; Region Captions: a small white snowy mountain with a black cat on it: [0, 98, 383, 114]; a silhouette of a city with a black background: [0, 0, 293, 103]; a gray square with a black background: [288, 0, 95, 105]; a black stone block with a black background: [0, 90, 88, 33]; a green square with a square on it: [133, 72, 43, 41]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with some blocks and a green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "white tablecloth on the table: [37, 60, 348, 209]; green colored box: [184, 30, 250, 81]; the basket is made of plastic: [42, 46, 153, 80]; red and yellow item in the background: [165, 34, 186, 71]; green box on the floor: [189, 55, 211, 78]; small black object: [234, 79, 269, 93]; a black square object with white dots: [330, 48, 383, 77]; the room is dark: [6, 7, 376, 140]; lego blocks on the floor: [123, 20, 318, 104]; shadow on the wall: [0, 1, 97, 92]; a green colored box: [186, 31, 215, 79]; the basket is dark: [31, 32, 162, 97]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 67, 383, 145]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[84, 0, 299, 65]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 93, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 152, 89]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy area with a small black cat: [0, 67, 383, 145]; a silhouette of a city with a black background: [0, 0, 383, 89]; a cityscape with a dark sky and buildings: [84, 0, 299, 65]; a gray square with a black background: [0, 0, 93, 89]; a grey shaped object with a white background: [0, 0, 152, 89]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with some blocks and a green block; Dense Caption: white tablecloth on the table: [37, 60, 348, 209]; green colored box: [184, 30, 250, 81]; the basket is made of plastic: [42, 46, 153, 80]; red and yellow item in the background: [165, 34, 186, 71]; green box on the floor: [189, 55, 211, 78]; small black object: [234, 79, 269, 93]; a black square object with white dots: [330, 48, 383, 77]; the room is dark: [6, 7, 376, 140]; lego blocks on the floor: [123, 20, 318, 104]; shadow on the wall: [0, 1, 97, 92]; a green colored box: [186, 31, 215, 79]; the basket is dark: [31, 32, 162, 97]; ; Region Captions: a white snowy area with a small black cat: [0, 67, 383, 145]; a silhouette of a city with a black background: [0, 0, 383, 89]; a cityscape with a dark sky and buildings: [84, 0, 299, 65]; a gray square with a black background: [0, 0, 93, 89]; a grey shaped object with a white background: [0, 0, 152, 89]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing next to a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and blue tote bag: [245, 39, 371, 148]; dark patterned ottoman: [1, 73, 162, 149]; red and yellow pencils: [190, 52, 225, 114]; white table is round: [30, 93, 356, 212]; a bed in the room: [38, 19, 345, 184]; the box is brown: [180, 75, 254, 105]; green and white box: [137, 31, 348, 154]; a green box: [249, 91, 321, 142]; a blue cup: [197, 91, 215, 112]; white wall in the room: [0, 0, 71, 89]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 99, 383, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[53, 0, 330, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 78, 160, 67]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a table and chairs: [0, 1, 383, 211]; a minecraft map with a black background: [0, 99, 383, 113]; a black and white image of a city: [0, 0, 383, 143]; a silhouette of a city with a skyscraper: [53, 0, 330, 98]; a black block with a blue window: [0, 78, 160, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing next to a box; Dense Caption: green and blue tote bag: [245, 39, 371, 148]; dark patterned ottoman: [1, 73, 162, 149]; red and yellow pencils: [190, 52, 225, 114]; white table is round: [30, 93, 356, 212]; a bed in the room: [38, 19, 345, 184]; the box is brown: [180, 75, 254, 105]; green and white box: [137, 31, 348, 154]; a green box: [249, 91, 321, 142]; a blue cup: [197, 91, 215, 112]; white wall in the room: [0, 0, 71, 89]; ; Region Captions: a black and white image of a room with a table and chairs: [0, 1, 383, 211]; a minecraft map with a black background: [0, 99, 383, 113]; a black and white image of a city: [0, 0, 383, 143]; a silhouette of a city with a skyscraper: [53, 0, 330, 98]; a black block with a blue window: [0, 78, 160, 67]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block sitting on a white surface\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box: [0, 9, 207, 180]; wooden box is brown: [85, 57, 162, 86]; white snow on ground: [0, 84, 382, 211]; the bag is green: [25, 37, 129, 158]; a green box: [0, 97, 46, 161]; green square on the left: [135, 71, 205, 144]; gray wall behind the green table: [0, 1, 382, 108]; green square on umbrella: [46, 74, 139, 165]; green square on the umbrella: [0, 13, 86, 98]; the counter is white: [212, 106, 373, 208]; the wall is white: [211, 3, 378, 91]; green and blue box: [0, 12, 96, 168]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 383, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[22, 84, 179, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[22, 83, 119, 90]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small black object: [0, 1, 383, 211]; a black and white image of a snowy surface: [0, 94, 383, 118]; a black and white image of a mountain: [0, 0, 383, 106]; a green block in minecraft: [22, 84, 179, 89]; a green block in minecraft: [22, 83, 119, 90]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block sitting on a white surface; Dense Caption: green box: [0, 9, 207, 180]; wooden box is brown: [85, 57, 162, 86]; white snow on ground: [0, 84, 382, 211]; the bag is green: [25, 37, 129, 158]; a green box: [0, 97, 46, 161]; green square on the left: [135, 71, 205, 144]; gray wall behind the green table: [0, 1, 382, 108]; green square on umbrella: [46, 74, 139, 165]; green square on the umbrella: [0, 13, 86, 98]; the counter is white: [212, 106, 373, 208]; the wall is white: [211, 3, 378, 91]; green and blue box: [0, 12, 96, 168]; ; Region Captions: a black and white image of a small black object: [0, 1, 383, 211]; a black and white image of a snowy surface: [0, 94, 383, 118]; a black and white image of a mountain: [0, 0, 383, 106]; a green block in minecraft: [22, 84, 179, 89]; a green block in minecraft: [22, 83, 119, 90]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green folded cloth: [0, 80, 80, 211]; the brown square box: [69, 45, 142, 104]; white sheets on the bed: [35, 71, 345, 213]; a small toy next to the book: [1, 14, 70, 92]; red book on top of a stack of books: [4, 35, 68, 73]; a box on the bed: [27, 7, 221, 179]; yellow and blue paper: [0, 13, 50, 42]; brown cardboard boxes are on the bed: [0, 13, 144, 106]; the wall is white: [122, 4, 360, 167]; blue post it note: [32, 64, 65, 94]; the box is made of cardboard: [1, 21, 141, 211]; a fire extinguisher: [23, 52, 41, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 75, 378, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 85, 79, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 17, 65, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 65, 43]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 0, 383, 212]; a white png image of a slanted triangle: [0, 75, 378, 138]; a green square on a black background: [0, 85, 79, 128]; a minecraft character with a red shirt and blue headphones: [0, 17, 65, 75]; a black and white image of a hat: [0, 0, 65, 43]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: green folded cloth: [0, 80, 80, 211]; the brown square box: [69, 45, 142, 104]; white sheets on the bed: [35, 71, 345, 213]; a small toy next to the book: [1, 14, 70, 92]; red book on top of a stack of books: [4, 35, 68, 73]; a box on the bed: [27, 7, 221, 179]; yellow and blue paper: [0, 13, 50, 42]; brown cardboard boxes are on the bed: [0, 13, 144, 106]; the wall is white: [122, 4, 360, 167]; blue post it note: [32, 64, 65, 94]; the box is made of cardboard: [1, 21, 141, 211]; a fire extinguisher: [23, 52, 41, 74]; ; Region Captions: a black and white image of a wall: [0, 0, 383, 212]; a white png image of a slanted triangle: [0, 75, 378, 138]; a green square on a black background: [0, 85, 79, 128]; a minecraft character with a red shirt and blue headphones: [0, 17, 65, 75]; a black and white image of a hat: [0, 0, 65, 43]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green striped pillow: [0, 4, 83, 210]; the brown square box: [82, 46, 142, 103]; the bed is made: [36, 77, 346, 213]; yellow box with blue and white stripes: [23, 9, 73, 49]; lego red toy cake: [22, 9, 93, 101]; red square of cardboard: [26, 36, 89, 76]; a blue small box: [54, 70, 88, 100]; boxes are stacked on the bed: [14, 7, 146, 107]; a box of multi colored books: [17, 5, 192, 172]; the wall is white: [126, 4, 361, 166]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[11, 77, 367, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 9, 79, 203]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 86, 79, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 9, 46, 107]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 0, 383, 211]; a white png image of a slanted wing: [11, 77, 367, 136]; a green pixelated triangle on a black background: [0, 9, 79, 203]; a green square on a black background: [0, 86, 79, 127]; a green triangle with a black background: [0, 9, 46, 107]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: a green striped pillow: [0, 4, 83, 210]; the brown square box: [82, 46, 142, 103]; the bed is made: [36, 77, 346, 213]; yellow box with blue and white stripes: [23, 9, 73, 49]; lego red toy cake: [22, 9, 93, 101]; red square of cardboard: [26, 36, 89, 76]; a blue small box: [54, 70, 88, 100]; boxes are stacked on the bed: [14, 7, 146, 107]; a box of multi colored books: [17, 5, 192, 172]; the wall is white: [126, 4, 361, 166]; ; Region Captions: a black and white image of a wall: [0, 0, 383, 211]; a white png image of a slanted wing: [11, 77, 367, 136]; a green pixelated triangle on a black background: [0, 9, 79, 203]; a green square on a black background: [0, 86, 79, 127]; a green triangle with a black background: [0, 9, 46, 107]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and white box: [1, 0, 338, 206]; the green portion of the vase: [103, 0, 323, 140]; a green box with yellow stripes: [0, 1, 141, 186]; green section of the umbrella: [144, 1, 199, 140]; white lines on the green sign: [199, 0, 293, 125]; green section of the vase: [110, 0, 188, 139]; a green section of a clock: [180, 27, 251, 140]; a black and white tile floor: [82, 0, 113, 37]; the table is white: [77, 76, 333, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 36, 383, 176]\n",
      "process_ann took 0.00 seconds\n",
      "[102, 0, 224, 145]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 143, 181]\n",
      "process_ann took 0.00 seconds\n",
      "[62, 81, 321, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 73, 144, 109]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.80 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white tetrahedron: [0, 36, 383, 176]; a green block with the words minecraft python: [102, 0, 224, 145]; a green block of grass: [0, 1, 143, 181]; a white sheet of paper with a black background: [62, 81, 321, 131]; a green block in minecraft: [0, 73, 144, 109]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: a green and white box: [1, 0, 338, 206]; the green portion of the vase: [103, 0, 323, 140]; a green box with yellow stripes: [0, 1, 141, 186]; green section of the umbrella: [144, 1, 199, 140]; white lines on the green sign: [199, 0, 293, 125]; green section of the vase: [110, 0, 188, 139]; a green section of a clock: [180, 27, 251, 140]; a black and white tile floor: [82, 0, 113, 37]; the table is white: [77, 76, 333, 210]; ; Region Captions: a black and white image of a black and white tetrahedron: [0, 36, 383, 176]; a green block with the words minecraft python: [102, 0, 224, 145]; a green block of grass: [0, 1, 143, 181]; a white sheet of paper with a black background: [62, 81, 321, 131]; a green block in minecraft: [0, 73, 144, 109]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and white box: [2, 0, 305, 197]; a green and white box: [0, 1, 129, 188]; the floor is white: [71, 55, 344, 212]; the green portion of the vase: [70, 0, 289, 125]; green section of the umbrella: [87, 0, 172, 125]; a black and white tile floor: [49, 0, 82, 28]; a green panel on the umbrella: [143, 0, 203, 105]; a green section of a kite: [116, 8, 187, 133]; the wall is grey: [267, 1, 382, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 26, 383, 186]\n",
      "process_ann took 0.00 seconds\n",
      "[72, 0, 218, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 2, 130, 184]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 65, 130, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[52, 0, 331, 105]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a mountain: [0, 26, 383, 186]; a green block with the word mr mr: [72, 0, 218, 133]; a green block with a green background: [0, 2, 130, 184]; a green block of grass: [0, 65, 130, 121]; a black and white image of a door: [52, 0, 331, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: a green and white box: [2, 0, 305, 197]; a green and white box: [0, 1, 129, 188]; the floor is white: [71, 55, 344, 212]; the green portion of the vase: [70, 0, 289, 125]; green section of the umbrella: [87, 0, 172, 125]; a black and white tile floor: [49, 0, 82, 28]; a green panel on the umbrella: [143, 0, 203, 105]; a green section of a kite: [116, 8, 187, 133]; the wall is grey: [267, 1, 382, 106]; ; Region Captions: a black and white image of a mountain: [0, 26, 383, 186]; a green block with the word mr mr: [72, 0, 218, 133]; a green block with a green background: [0, 2, 130, 184]; a green block of grass: [0, 65, 130, 121]; a black and white image of a door: [52, 0, 331, 105]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing next to a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic basket on white table: [121, 11, 193, 81]; black square in the snow: [207, 105, 324, 205]; a red blue and yellow flag: [278, 0, 379, 84]; a white table with a kite: [0, 1, 383, 210]; shadow of the toothbrush: [273, 62, 327, 90]; a stain on the snow: [47, 24, 79, 39]; blue plastic part of umbrella: [284, 43, 329, 81]; a stain on the snow: [43, 20, 83, 45]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 5, 383, 207]\n",
      "process_ann took 0.00 seconds\n",
      "[210, 70, 110, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[211, 111, 109, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[125, 16, 62, 61]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 29]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.51 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a square: [0, 5, 383, 207]; a gray mat on a black background: [210, 70, 110, 133]; a gray sheet on a black background: [211, 111, 109, 91]; a green cube with a square shape: [125, 16, 62, 61]; a black and white image of a hallway: [0, 0, 383, 29]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing next to a green block in minecraft; Dense Caption: green plastic basket on white table: [121, 11, 193, 81]; black square in the snow: [207, 105, 324, 205]; a red blue and yellow flag: [278, 0, 379, 84]; a white table with a kite: [0, 1, 383, 210]; shadow of the toothbrush: [273, 62, 327, 90]; a stain on the snow: [47, 24, 79, 39]; blue plastic part of umbrella: [284, 43, 329, 81]; a stain on the snow: [43, 20, 83, 45]; ; Region Captions: a black and white image of a square: [0, 5, 383, 207]; a gray mat on a black background: [210, 70, 110, 133]; a gray sheet on a black background: [211, 111, 109, 91]; a green cube with a square shape: [125, 16, 62, 61]; a black and white image of a hallway: [0, 0, 383, 29]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a man standing in front of a square\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box for snowboarders: [229, 2, 383, 154]; green box next to white pillow: [0, 61, 85, 128]; the floor is white: [37, 23, 346, 211]; a lego person is standing: [165, 21, 205, 81]; large square object in the snow: [140, 104, 203, 140]; a black object on the ground: [2, 35, 67, 64]; green colored table cloth: [231, 13, 301, 117]; the floor is white: [39, 139, 256, 210]; blue base of the lego piece: [181, 58, 200, 79]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 29, 383, 183]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 361, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[305, 3, 78, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[291, 73, 92, 77]\n",
      "process_ann took 0.00 seconds\n",
      "[234, 18, 68, 98]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft map with a black and white background: [0, 29, 383, 183]; a black and white image of a city skyline: [2, 0, 361, 56]; a green square block with a square shape: [305, 3, 78, 87]; a green block of grass on a black background: [291, 73, 92, 77]; a green box with a green lining: [234, 18, 68, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a man standing in front of a square; Dense Caption: green box for snowboarders: [229, 2, 383, 154]; green box next to white pillow: [0, 61, 85, 128]; the floor is white: [37, 23, 346, 211]; a lego person is standing: [165, 21, 205, 81]; large square object in the snow: [140, 104, 203, 140]; a black object on the ground: [2, 35, 67, 64]; green colored table cloth: [231, 13, 301, 117]; the floor is white: [39, 139, 256, 210]; blue base of the lego piece: [181, 58, 200, 79]; ; Region Captions: a minecraft map with a black and white background: [0, 29, 383, 183]; a black and white image of a city skyline: [2, 0, 361, 56]; a green square block with a square shape: [305, 3, 78, 87]; a green block of grass on a black background: [291, 73, 92, 77]; a green box with a green lining: [234, 18, 68, 98]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a green block and a green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is white: [35, 35, 348, 207]; a person figure on a wall: [221, 1, 258, 38]; bright green plastic bucket: [311, 9, 382, 78]; green box on snow: [210, 38, 247, 75]; lego ice cream cones: [40, 8, 347, 106]; a black box on the table: [54, 24, 134, 48]; the shadow of the snowboarder: [54, 70, 92, 87]; the snow is white: [41, 88, 258, 206]; lego figure on cake: [204, 1, 265, 79]; the brown basket on the bed: [269, 26, 322, 50]; green cup on the table: [201, 32, 256, 82]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 41, 383, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 54]\n",
      "process_ann took 0.00 seconds\n",
      "[85, 0, 296, 42]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 91, 54]\n",
      "process_ann took 0.00 seconds\n",
      "[313, 13, 70, 61]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a small square with a black hole in it: [0, 41, 383, 171]; a silhouette of a man in a city: [0, 0, 383, 54]; a man is standing on a black background: [85, 0, 296, 42]; a gray paper with a black border: [0, 0, 91, 54]; a green block with a green background: [313, 13, 70, 61]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a green block and a green block; Dense Caption: the ground is white: [35, 35, 348, 207]; a person figure on a wall: [221, 1, 258, 38]; bright green plastic bucket: [311, 9, 382, 78]; green box on snow: [210, 38, 247, 75]; lego ice cream cones: [40, 8, 347, 106]; a black box on the table: [54, 24, 134, 48]; the shadow of the snowboarder: [54, 70, 92, 87]; the snow is white: [41, 88, 258, 206]; lego figure on cake: [204, 1, 265, 79]; the brown basket on the bed: [269, 26, 322, 50]; green cup on the table: [201, 32, 256, 82]; ; Region Captions: a small square with a black hole in it: [0, 41, 383, 171]; a silhouette of a man in a city: [0, 0, 383, 54]; a man is standing on a black background: [85, 0, 296, 42]; a gray paper with a black border: [0, 0, 91, 54]; a green block with a green background: [313, 13, 70, 61]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and lime green paper: [64, 0, 279, 184]; white table with green boxes: [0, 2, 380, 208]; a brown wooden base: [252, 39, 291, 93]; green and white square on umbrella: [116, 0, 267, 104]; a lego piece: [0, 40, 26, 83]; green and white square on umbrella: [139, 98, 252, 182]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 45, 383, 167]\n",
      "process_ann took 0.00 seconds\n",
      "[69, 0, 203, 180]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[80, 0, 191, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[265, 0, 118, 160]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a stairway: [0, 45, 383, 167]; a green block in minecraft: [69, 0, 203, 180]; a 3d model of a room with a door: [0, 0, 383, 160]; a green pixelated bag with a green handle: [80, 0, 191, 108]; a gray png file with a black background: [265, 0, 118, 160]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green and lime green paper: [64, 0, 279, 184]; white table with green boxes: [0, 2, 380, 208]; a brown wooden base: [252, 39, 291, 93]; green and white square on umbrella: [116, 0, 267, 104]; a lego piece: [0, 40, 26, 83]; green and white square on umbrella: [139, 98, 252, 182]; ; Region Captions: a black and white image of a stairway: [0, 45, 383, 167]; a green block in minecraft: [69, 0, 203, 180]; a 3d model of a room with a door: [0, 0, 383, 160]; a green pixelated bag with a green handle: [80, 0, 191, 108]; a gray png file with a black background: [265, 0, 118, 160]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and black bag: [64, 0, 280, 184]; white table top: [0, 2, 381, 210]; green and white square on umbrella: [117, 0, 267, 104]; a brown wooden base: [252, 39, 291, 93]; a toy is on the floor: [59, 1, 95, 58]; green and white square on umbrella: [138, 98, 252, 182]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 45, 383, 167]\n",
      "process_ann took 0.00 seconds\n",
      "[69, 0, 203, 180]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 159]\n",
      "process_ann took 0.00 seconds\n",
      "[79, 0, 192, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[265, 0, 118, 160]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small black and white object: [0, 45, 383, 167]; a green block with a green background: [69, 0, 203, 180]; a 3d model of a room with a black wall: [0, 0, 383, 159]; a green pixelated bag with a green pixel: [79, 0, 192, 108]; a gray png file with a black background: [265, 0, 118, 160]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: a green and black bag: [64, 0, 280, 184]; white table top: [0, 2, 381, 210]; green and white square on umbrella: [117, 0, 267, 104]; a brown wooden base: [252, 39, 291, 93]; a toy is on the floor: [59, 1, 95, 58]; green and white square on umbrella: [138, 98, 252, 182]; ; Region Captions: a black and white image of a small black and white object: [0, 45, 383, 167]; a green block with a green background: [69, 0, 203, 180]; a 3d model of a room with a black wall: [0, 0, 383, 159]; a green pixelated bag with a green pixel: [79, 0, 192, 108]; a gray png file with a black background: [265, 0, 118, 160]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft screen shot of a green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic diamond on a cloth: [275, 0, 383, 211]; kite in the sky: [175, 32, 240, 69]; white snow on the ground: [0, 1, 382, 210]; green box on the building: [134, 0, 179, 18]; the snow is white: [51, 78, 159, 169]; the snow is white: [69, 97, 178, 185]; kite in the sky: [158, 22, 244, 80]; the snow is white: [49, 89, 244, 204]; snowboarder in the air: [113, 2, 270, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 344, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[280, 0, 103, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[280, 0, 103, 168]\n",
      "process_ann took 0.00 seconds\n",
      "[292, 19, 91, 194]\n",
      "process_ann took 0.00 seconds\n",
      "[292, 95, 91, 118]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.51 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a square: [0, 0, 344, 212]; a green pixelated sandbox: [280, 0, 103, 117]; a green sand png: [280, 0, 103, 168]; a green grass png: [292, 19, 91, 194]; a green square on a black background: [292, 95, 91, 118]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft screen shot of a green block; Dense Caption: green plastic diamond on a cloth: [275, 0, 383, 211]; kite in the sky: [175, 32, 240, 69]; white snow on the ground: [0, 1, 382, 210]; green box on the building: [134, 0, 179, 18]; the snow is white: [51, 78, 159, 169]; the snow is white: [69, 97, 178, 185]; kite in the sky: [158, 22, 244, 80]; the snow is white: [49, 89, 244, 204]; snowboarder in the air: [113, 2, 270, 103]; ; Region Captions: a black and white image of a square: [0, 0, 344, 212]; a green pixelated sandbox: [280, 0, 103, 117]; a green sand png: [280, 0, 103, 168]; a green grass png: [292, 19, 91, 194]; a green square on a black background: [292, 95, 91, 118]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and white box: [1, 0, 346, 210]; the back of the green table: [105, 0, 319, 142]; a green box with yellow stripes: [0, 1, 139, 188]; green section of the box: [98, 0, 171, 139]; a green section of a kite: [177, 0, 276, 126]; green section of the umbrella: [125, 0, 196, 142]; green section of a kite: [107, 83, 318, 212]; a black and white object: [86, 0, 113, 44]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 0, 323, 152]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 46, 383, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[101, 0, 224, 152]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 90, 329, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[192, 90, 191, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a green square block with a black background: [2, 0, 323, 152]; a black and white mountain with a white arrow: [0, 46, 383, 166]; a green square block with a black background: [101, 0, 224, 152]; a white and black png image of a curved wall: [54, 90, 329, 122]; a silver sheet of paper on a black background: [192, 90, 191, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: a green and white box: [1, 0, 346, 210]; the back of the green table: [105, 0, 319, 142]; a green box with yellow stripes: [0, 1, 139, 188]; green section of the box: [98, 0, 171, 139]; a green section of a kite: [177, 0, 276, 126]; green section of the umbrella: [125, 0, 196, 142]; green section of a kite: [107, 83, 318, 212]; a black and white object: [86, 0, 113, 44]; ; Region Captions: a green square block with a black background: [2, 0, 323, 152]; a black and white mountain with a white arrow: [0, 46, 383, 166]; a green square block with a black background: [101, 0, 224, 152]; a white and black png image of a curved wall: [54, 90, 329, 122]; a silver sheet of paper on a black background: [192, 90, 191, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and white box: [2, 1, 354, 210]; a green box with yellow stripes: [0, 1, 144, 191]; the green portion of the vase: [124, 0, 327, 147]; green section of the vase: [108, 0, 171, 134]; lime green section of a vase: [123, 91, 320, 212]; green section of the umbrella: [193, 32, 294, 140]; a black and white checkered floor: [100, 7, 125, 53]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[112, 0, 228, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 338, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 45, 383, 167]\n",
      "process_ann took 0.00 seconds\n",
      "[62, 100, 321, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[211, 100, 172, 112]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a green box with the words minecraft: [112, 0, 228, 210]; a green block with a green background: [2, 0, 338, 160]; a black and white image of a mountain: [0, 45, 383, 167]; a white and black png image of a cliff: [62, 100, 321, 112]; a silver sheet of metal on a black background: [211, 100, 172, 112]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: a green and white box: [2, 1, 354, 210]; a green box with yellow stripes: [0, 1, 144, 191]; the green portion of the vase: [124, 0, 327, 147]; green section of the vase: [108, 0, 171, 134]; lime green section of a vase: [123, 91, 320, 212]; green section of the umbrella: [193, 32, 294, 140]; a black and white checkered floor: [100, 7, 125, 53]; ; Region Captions: a green box with the words minecraft: [112, 0, 228, 210]; a green block with a green background: [2, 0, 338, 160]; a black and white image of a mountain: [0, 45, 383, 167]; a white and black png image of a cliff: [62, 100, 321, 112]; a silver sheet of metal on a black background: [211, 100, 172, 112]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box on white table: [106, 0, 241, 94]; white table top: [0, 40, 381, 211]; the object is black: [48, 97, 118, 141]; green box for a wii: [173, 0, 234, 51]; small square shaped object: [88, 25, 120, 57]; green box on white table: [57, 0, 290, 162]; the green box on the bed: [109, 3, 175, 90]; a red white and blue box: [151, 0, 176, 46]; green box on the white table: [171, 0, 237, 94]; a black object is on the table: [31, 88, 281, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 48, 383, 164]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 0, 155, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 150, 53]\n",
      "process_ann took 0.00 seconds\n",
      "[174, 0, 59, 91]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small square: [0, 48, 383, 164]; a black and white image of a room with a black cat: [0, 0, 383, 102]; a gray wall with a black sign: [228, 0, 155, 102]; a black and white image of a man standing on a wall: [0, 0, 150, 53]; a green square block in minecraft: [174, 0, 59, 91]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green box on white table: [106, 0, 241, 94]; white table top: [0, 40, 381, 211]; the object is black: [48, 97, 118, 141]; green box for a wii: [173, 0, 234, 51]; small square shaped object: [88, 25, 120, 57]; green box on white table: [57, 0, 290, 162]; the green box on the bed: [109, 3, 175, 90]; a red white and blue box: [151, 0, 176, 46]; green box on the white table: [171, 0, 237, 94]; a black object is on the table: [31, 88, 281, 209]; ; Region Captions: a black and white image of a small square: [0, 48, 383, 164]; a black and white image of a room with a black cat: [0, 0, 383, 102]; a gray wall with a black sign: [228, 0, 155, 102]; a black and white image of a man standing on a wall: [0, 0, 150, 53]; a green square block in minecraft: [174, 0, 59, 91]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box on white table: [106, 0, 241, 94]; white table top: [0, 40, 381, 211]; the object is black: [48, 97, 118, 141]; green box for a wii: [173, 0, 234, 51]; small square shaped object: [88, 25, 120, 57]; green box on white table: [58, 0, 290, 162]; green box on the white table: [109, 3, 175, 90]; green box on the white table: [171, 0, 237, 94]; a red white and blue box: [151, 0, 176, 46]; a black piece of paper: [31, 88, 280, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 48, 383, 164]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 0, 155, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 150, 53]\n",
      "process_ann took 0.00 seconds\n",
      "[174, 0, 59, 91]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft map: [0, 48, 383, 164]; a black and white image of a room with a black cat: [0, 0, 383, 102]; a black and white image of a wall: [228, 0, 155, 102]; a black and white image of a man standing on a wall: [0, 0, 150, 53]; a green square block in minecraft: [174, 0, 59, 91]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green box on white table: [106, 0, 241, 94]; white table top: [0, 40, 381, 211]; the object is black: [48, 97, 118, 141]; green box for a wii: [173, 0, 234, 51]; small square shaped object: [88, 25, 120, 57]; green box on white table: [58, 0, 290, 162]; green box on the white table: [109, 3, 175, 90]; green box on the white table: [171, 0, 237, 94]; a red white and blue box: [151, 0, 176, 46]; a black piece of paper: [31, 88, 280, 209]; ; Region Captions: a black and white image of a minecraft map: [0, 48, 383, 164]; a black and white image of a room with a black cat: [0, 0, 383, 102]; a black and white image of a wall: [228, 0, 155, 102]; a black and white image of a man standing on a wall: [0, 0, 150, 53]; a green square block in minecraft: [174, 0, 59, 91]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green bag on white table: [103, 0, 242, 95]; white tablecloth on the table: [0, 41, 381, 211]; the object is black: [48, 97, 118, 141]; green box for a wii: [173, 0, 234, 50]; lego blocks on the table: [56, 0, 292, 160]; small paper train decoration: [123, 4, 161, 47]; green box is on the table: [109, 3, 175, 89]; a red piece of paper: [122, 23, 164, 50]; small black box behind the clock: [88, 25, 119, 57]; green box on white table: [171, 0, 238, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 48, 383, 164]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 0, 233, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 172, 53]\n",
      "process_ann took 0.00 seconds\n",
      "[174, 1, 59, 90]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft map: [0, 48, 383, 164]; a black and white image of a building: [0, 0, 383, 102]; a black and white image of a wall: [150, 0, 233, 102]; a black and white image of a man standing in front of a wall: [0, 0, 172, 53]; a green square block in minecraft: [174, 1, 59, 90]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a green block; Dense Caption: green bag on white table: [103, 0, 242, 95]; white tablecloth on the table: [0, 41, 381, 211]; the object is black: [48, 97, 118, 141]; green box for a wii: [173, 0, 234, 50]; lego blocks on the table: [56, 0, 292, 160]; small paper train decoration: [123, 4, 161, 47]; green box is on the table: [109, 3, 175, 89]; a red piece of paper: [122, 23, 164, 50]; small black box behind the clock: [88, 25, 119, 57]; green box on white table: [171, 0, 238, 94]; ; Region Captions: a black and white image of a minecraft map: [0, 48, 383, 164]; a black and white image of a building: [0, 0, 383, 102]; a black and white image of a wall: [150, 0, 233, 102]; a black and white image of a man standing in front of a wall: [0, 0, 172, 53]; a green square block in minecraft: [174, 1, 59, 90]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green colored lego pieces: [85, 0, 239, 122]; white table top: [0, 38, 381, 211]; green box for a wii: [172, 0, 235, 51]; green square on the green umbrella: [93, 49, 164, 119]; a red and white tag: [93, 5, 122, 55]; green lego on white floor: [38, 0, 276, 186]; the bed is white: [50, 113, 329, 211]; green box on white table: [169, 0, 237, 96]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 48, 383, 164]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[149, 0, 234, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 144, 53]\n",
      "process_ann took 0.00 seconds\n",
      "[174, 1, 59, 90]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small black and white object: [0, 48, 383, 164]; a black and white image of a building: [0, 0, 383, 102]; a black and white image of a wall: [149, 0, 234, 102]; a black cat is standing on a white wall: [0, 0, 144, 53]; a green square block in minecraft: [174, 1, 59, 90]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green colored lego pieces: [85, 0, 239, 122]; white table top: [0, 38, 381, 211]; green box for a wii: [172, 0, 235, 51]; green square on the green umbrella: [93, 49, 164, 119]; a red and white tag: [93, 5, 122, 55]; green lego on white floor: [38, 0, 276, 186]; the bed is white: [50, 113, 329, 211]; green box on white table: [169, 0, 237, 96]; ; Region Captions: a black and white image of a small black and white object: [0, 48, 383, 164]; a black and white image of a building: [0, 0, 383, 102]; a black and white image of a wall: [149, 0, 234, 102]; a black cat is standing on a white wall: [0, 0, 144, 53]; a green square block in minecraft: [174, 1, 59, 90]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block with a green block in the middle\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box is on the floor: [0, 1, 300, 205]; green and white square: [145, 0, 279, 78]; red and blue flag: [26, 0, 83, 57]; green plastic table cloth: [0, 57, 102, 205]; green and lime green paper: [142, 1, 282, 149]; green section of a kite: [156, 58, 263, 145]; a green box: [102, 13, 197, 117]; a green plastic post: [43, 57, 105, 172]; green and white stripes: [168, 0, 192, 71]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 27, 383, 185]\n",
      "process_ann took 0.00 seconds\n",
      "[148, 0, 127, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 124]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 59, 99, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[261, 0, 122, 124]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a door: [0, 27, 383, 185]; a green square block in minecraft: [148, 0, 127, 143]; a 3d image of a room with a white wall: [0, 0, 383, 124]; a green block in minecraft: [0, 59, 99, 142]; a gray plate with a black background: [261, 0, 122, 124]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block with a green block in the middle; Dense Caption: green box is on the floor: [0, 1, 300, 205]; green and white square: [145, 0, 279, 78]; red and blue flag: [26, 0, 83, 57]; green plastic table cloth: [0, 57, 102, 205]; green and lime green paper: [142, 1, 282, 149]; green section of a kite: [156, 58, 263, 145]; a green box: [102, 13, 197, 117]; a green plastic post: [43, 57, 105, 172]; green and white stripes: [168, 0, 192, 71]; ; Region Captions: a black and white image of a door: [0, 27, 383, 185]; a green square block in minecraft: [148, 0, 127, 143]; a 3d image of a room with a white wall: [0, 0, 383, 124]; a green block in minecraft: [0, 59, 99, 142]; a gray plate with a black background: [261, 0, 122, 124]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green colored table cloth: [93, 0, 381, 200]; green square on umbrella: [100, 46, 247, 197]; a black and white checkered box: [123, 0, 157, 30]; a brick wall: [234, 0, 269, 36]; green and white square: [260, 0, 382, 66]; a green table cloth: [204, 26, 303, 115]; a green and white box: [241, 0, 382, 130]; green section of umbrella: [241, 22, 328, 119]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 13, 383, 199]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 12, 158, 200]\n",
      "process_ann took 0.00 seconds\n",
      "[113, 75, 270, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[104, 49, 143, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[104, 49, 243, 146]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a white and black png image of a slanted wall: [0, 13, 383, 199]; a white floor with a black splatter: [0, 12, 158, 200]; a silver sheet of paper with a curved edge: [113, 75, 270, 137]; a green block in minecraft: [104, 49, 143, 146]; a green block in minecraft: [104, 49, 243, 146]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: green colored table cloth: [93, 0, 381, 200]; green square on umbrella: [100, 46, 247, 197]; a black and white checkered box: [123, 0, 157, 30]; a brick wall: [234, 0, 269, 36]; green and white square: [260, 0, 382, 66]; a green table cloth: [204, 26, 303, 115]; a green and white box: [241, 0, 382, 130]; green section of umbrella: [241, 22, 328, 119]; ; Region Captions: a white and black png image of a slanted wall: [0, 13, 383, 199]; a white floor with a black splatter: [0, 12, 158, 200]; a silver sheet of paper with a curved edge: [113, 75, 270, 137]; a green block in minecraft: [104, 49, 143, 146]; a green block in minecraft: [104, 49, 243, 146]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic box on white table: [111, 61, 229, 182]; a lego snowboard: [262, 0, 332, 95]; white table with green boxes: [0, 20, 382, 211]; the basket is brown: [32, 16, 132, 47]; a toy on a bed: [44, 0, 347, 147]; a green vent on the top of the box: [120, 95, 202, 175]; shadow of the object: [259, 74, 306, 98]; the red part of the plane: [266, 20, 330, 62]; blue base of the lego piece: [270, 57, 305, 91]; a yellow and white tag: [285, 0, 327, 33]; white arrow on green background: [123, 64, 223, 107]; the headboard is black: [45, 0, 348, 69]; a black and white object: [322, 24, 383, 71]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 38, 383, 174]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 46]\n",
      "process_ann took 0.00 seconds\n",
      "[114, 66, 111, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 87, 46]\n",
      "process_ann took 0.00 seconds\n",
      "[322, 28, 61, 41]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black square in the middle of a snowy field: [0, 38, 383, 174]; a black and white image of a room: [0, 0, 383, 46]; a green cube with a square pattern: [114, 66, 111, 113]; a gray piece of paper with a black background: [0, 0, 87, 46]; a black block with a black background: [322, 28, 61, 41]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: green plastic box on white table: [111, 61, 229, 182]; a lego snowboard: [262, 0, 332, 95]; white table with green boxes: [0, 20, 382, 211]; the basket is brown: [32, 16, 132, 47]; a toy on a bed: [44, 0, 347, 147]; a green vent on the top of the box: [120, 95, 202, 175]; shadow of the object: [259, 74, 306, 98]; the red part of the plane: [266, 20, 330, 62]; blue base of the lego piece: [270, 57, 305, 91]; a yellow and white tag: [285, 0, 327, 33]; white arrow on green background: [123, 64, 223, 107]; the headboard is black: [45, 0, 348, 69]; a black and white object: [322, 24, 383, 71]; ; Region Captions: a black square in the middle of a snowy field: [0, 38, 383, 174]; a black and white image of a room: [0, 0, 383, 46]; a green cube with a square pattern: [114, 66, 111, 113]; a gray piece of paper with a black background: [0, 0, 87, 46]; a black block with a black background: [322, 28, 61, 41]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic box on white table: [113, 41, 234, 162]; a red white and blue toy on a table: [289, 0, 370, 81]; white table with cake: [0, 5, 382, 210]; the basket is brown: [29, 0, 132, 24]; shadow of the object: [283, 60, 334, 84]; yellow and black ribbon: [330, 30, 362, 62]; red and white striped sign: [303, 0, 368, 47]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 16, 383, 196]\n",
      "process_ann took 0.00 seconds\n",
      "[117, 46, 113, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 50]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 24]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 0, 254, 25]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black square in the middle of a snowy field: [0, 16, 383, 196]; a green cube with a square pattern: [117, 46, 113, 113]; a black and white image of a speaker: [0, 0, 383, 50]; a black and white image of a door: [0, 0, 383, 24]; a black and white image of a bottle of wine: [129, 0, 254, 25]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: green plastic box on white table: [113, 41, 234, 162]; a red white and blue toy on a table: [289, 0, 370, 81]; white table with cake: [0, 5, 382, 210]; the basket is brown: [29, 0, 132, 24]; shadow of the object: [283, 60, 334, 84]; yellow and black ribbon: [330, 30, 362, 62]; red and white striped sign: [303, 0, 368, 47]; ; Region Captions: a black square in the middle of a snowy field: [0, 16, 383, 196]; a green cube with a square pattern: [117, 46, 113, 113]; a black and white image of a speaker: [0, 0, 383, 50]; a black and white image of a door: [0, 0, 383, 24]; a black and white image of a bottle of wine: [129, 0, 254, 25]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic container: [115, 58, 232, 177]; white table with cake: [1, 21, 383, 211]; a red white and yellow cake: [177, 0, 236, 66]; the basket is on the table: [38, 12, 136, 42]; the basket is black: [326, 18, 383, 67]; a green box on a white table: [93, 16, 259, 184]; the black and white objects are on the table: [22, 6, 381, 63]; a brown wooden figure: [166, 43, 188, 63]; a green box: [125, 61, 228, 102]; a yellow birthday cake: [186, 0, 225, 35]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 33, 383, 179]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 43]\n",
      "process_ann took 0.00 seconds\n",
      "[118, 47, 111, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 119, 42]\n",
      "process_ann took 0.00 seconds\n",
      "[329, 23, 54, 42]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building in the snow: [0, 33, 383, 179]; a black and white image of a room with two doors: [0, 0, 383, 43]; a green cube with a square pattern: [118, 47, 111, 127]; a black and grey t shirt with a slit in the middle: [0, 0, 119, 42]; a black keyboard with a blue light on it: [329, 23, 54, 42]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in minecraft; Dense Caption: green plastic container: [115, 58, 232, 177]; white table with cake: [1, 21, 383, 211]; a red white and yellow cake: [177, 0, 236, 66]; the basket is on the table: [38, 12, 136, 42]; the basket is black: [326, 18, 383, 67]; a green box on a white table: [93, 16, 259, 184]; the black and white objects are on the table: [22, 6, 381, 63]; a brown wooden figure: [166, 43, 188, 63]; a green box: [125, 61, 228, 102]; a yellow birthday cake: [186, 0, 225, 35]; ; Region Captions: a black and white image of a building in the snow: [0, 33, 383, 179]; a black and white image of a room with two doors: [0, 0, 383, 43]; a green cube with a square pattern: [118, 47, 111, 127]; a black and grey t shirt with a slit in the middle: [0, 0, 119, 42]; a black keyboard with a blue light on it: [329, 23, 54, 42]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green cube in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic basket on white table: [115, 57, 233, 177]; white table with cake: [1, 22, 383, 211]; a toy figure on a cake: [190, 1, 238, 67]; the basket is black: [326, 18, 383, 67]; the basket is on the table: [38, 12, 136, 41]; the objects are brown: [15, 6, 382, 64]; a green box on a white table: [78, 5, 296, 183]; a person wearing a blue shirt: [195, 43, 225, 68]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 33, 383, 179]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 43]\n",
      "process_ann took 0.00 seconds\n",
      "[118, 61, 111, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[89, 0, 109, 34]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 118, 42]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black square in the snow: [0, 33, 383, 179]; a black and white image of a door: [0, 0, 383, 43]; a green cube with a square pattern: [118, 61, 111, 113]; a gray piece of paper with a white background: [89, 0, 109, 34]; a black and grey t shirt with a white logo: [0, 0, 118, 42]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green cube in minecraft; Dense Caption: green plastic basket on white table: [115, 57, 233, 177]; white table with cake: [1, 22, 383, 211]; a toy figure on a cake: [190, 1, 238, 67]; the basket is black: [326, 18, 383, 67]; the basket is on the table: [38, 12, 136, 41]; the objects are brown: [15, 6, 382, 64]; a green box on a white table: [78, 5, 296, 183]; a person wearing a blue shirt: [195, 43, 225, 68]; ; Region Captions: a black square in the snow: [0, 33, 383, 179]; a black and white image of a door: [0, 0, 383, 43]; a green cube with a square pattern: [118, 61, 111, 113]; a gray piece of paper with a white background: [89, 0, 109, 34]; a black and grey t shirt with a white logo: [0, 0, 118, 42]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block with a man standing next to it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green plastic box: [30, 51, 270, 212]; person carrying a skateboard: [232, 0, 330, 60]; a green and white field: [0, 1, 382, 211]; blue pants on person: [259, 12, 297, 53]; green plastic box: [333, 0, 383, 62]; red and white jacket: [253, 0, 328, 26]; the persons shadow: [248, 36, 296, 61]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[28, 54, 241, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[255, 0, 70, 55]\n",
      "process_ann took 0.00 seconds\n",
      "[334, 0, 49, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[75, 75, 35, 93]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man in a suit: [0, 0, 383, 212]; a green square block on a black background: [28, 54, 241, 158]; a red and blue minecraft character: [255, 0, 70, 55]; a green square with a green border: [334, 0, 49, 60]; a green arrow with a black background: [75, 75, 35, 93]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block with a man standing next to it; Dense Caption: a green plastic box: [30, 51, 270, 212]; person carrying a skateboard: [232, 0, 330, 60]; a green and white field: [0, 1, 382, 211]; blue pants on person: [259, 12, 297, 53]; green plastic box: [333, 0, 383, 62]; red and white jacket: [253, 0, 328, 26]; the persons shadow: [248, 36, 296, 61]; ; Region Captions: a black and white image of a man in a suit: [0, 0, 383, 212]; a green square block on a black background: [28, 54, 241, 158]; a red and blue minecraft character: [255, 0, 70, 55]; a green square with a green border: [334, 0, 49, 60]; a green arrow with a black background: [75, 75, 35, 93]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a 3d model of a white floor with a black dot\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the frisbee is black: [300, 34, 358, 68]; a white background: [0, 1, 382, 211]; the frisbee is black: [283, 25, 363, 78]; the snow is white: [48, 52, 296, 206]; the sky is clear: [46, 12, 256, 137]; a plane flying in the sky: [107, 3, 355, 143]; the sky is clear: [184, 66, 282, 146]; the sky is clear: [159, 36, 251, 121]; the sky is clear: [92, 63, 193, 146]; the frisbee is black: [256, 16, 378, 109]; the sky is clear: [112, 81, 210, 165]; the edge of the wing: [0, 0, 84, 23]; the snow is white: [132, 86, 340, 208]; the sky is clear: [174, 91, 277, 174]; the sky is clear: [102, 36, 201, 119]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[304, 42, 49, 19]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 57, 12]\n",
      "process_ann took 0.00 seconds\n",
      "[275, 205, 7, 8]\n",
      "process_ann took 0.00 seconds\n",
      "[172, 170, 6, 6]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a white surface with a black hole in it: [0, 1, 383, 211]; a grey circle with a black background: [304, 42, 49, 19]; a black and white image of a person: [0, 0, 57, 12]; a man is standing on a white background: [275, 205, 7, 8]; a white square with a black background: [172, 170, 6, 6]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a 3d model of a white floor with a black dot; Dense Caption: the frisbee is black: [300, 34, 358, 68]; a white background: [0, 1, 382, 211]; the frisbee is black: [283, 25, 363, 78]; the snow is white: [48, 52, 296, 206]; the sky is clear: [46, 12, 256, 137]; a plane flying in the sky: [107, 3, 355, 143]; the sky is clear: [184, 66, 282, 146]; the sky is clear: [159, 36, 251, 121]; the sky is clear: [92, 63, 193, 146]; the frisbee is black: [256, 16, 378, 109]; the sky is clear: [112, 81, 210, 165]; the edge of the wing: [0, 0, 84, 23]; the snow is white: [132, 86, 340, 208]; the sky is clear: [174, 91, 277, 174]; the sky is clear: [102, 36, 201, 119]; ; Region Captions: a white surface with a black hole in it: [0, 1, 383, 211]; a grey circle with a black background: [304, 42, 49, 19]; a black and white image of a person: [0, 0, 57, 12]; a man is standing on a white background: [275, 205, 7, 8]; a white square with a black background: [172, 170, 6, 6]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block sitting on a white surface\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green plastic piece: [319, 35, 383, 144]; frisbee is round: [65, 1, 116, 28]; a white background with green lines: [0, 1, 381, 210]; the sky is clear: [55, 52, 275, 204]; the sky is clear: [112, 60, 211, 151]; frisbee in the air: [55, 0, 130, 39]; the sky is clear: [139, 39, 237, 135]; the sky is clear: [102, 89, 202, 175]; green board in the sky: [283, 19, 382, 173]; the sky is clear: [129, 77, 229, 170]; three white squares on green sign: [339, 57, 383, 125]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[320, 39, 63, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[69, 5, 43, 18]\n",
      "process_ann took 0.00 seconds\n",
      "[330, 38, 53, 54]\n",
      "process_ann took 0.00 seconds\n",
      "[359, 77, 24, 20]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small black hole: [0, 0, 383, 212]; a green square with a black background: [320, 39, 63, 103]; a grey circle on a black background: [69, 5, 43, 18]; a green arrow with a black background: [330, 38, 53, 54]; a green pencil with a black background: [359, 77, 24, 20]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block sitting on a white surface; Dense Caption: a green plastic piece: [319, 35, 383, 144]; frisbee is round: [65, 1, 116, 28]; a white background with green lines: [0, 1, 381, 210]; the sky is clear: [55, 52, 275, 204]; the sky is clear: [112, 60, 211, 151]; frisbee in the air: [55, 0, 130, 39]; the sky is clear: [139, 39, 237, 135]; the sky is clear: [102, 89, 202, 175]; green board in the sky: [283, 19, 382, 173]; the sky is clear: [129, 77, 229, 170]; three white squares on green sign: [339, 57, 383, 125]; ; Region Captions: a black and white image of a small black hole: [0, 0, 383, 212]; a green square with a black background: [320, 39, 63, 103]; a grey circle on a black background: [69, 5, 43, 18]; a green arrow with a black background: [330, 38, 53, 54]; a green pencil with a black background: [359, 77, 24, 20]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green square with a black circle on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green plastic diamond on a traffic sign: [292, 0, 383, 119]; frisbee is round: [19, 0, 75, 26]; white snow on the ground: [0, 1, 382, 210]; the snow is white: [56, 54, 276, 204]; the sky is clear: [102, 58, 201, 152]; the sky is clear: [81, 79, 185, 168]; frisbee in the air: [11, 0, 91, 40]; the sky is clear: [111, 88, 212, 177]; a green arrow on a sign: [322, 43, 379, 102]; the sky is clear: [121, 37, 218, 137]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[295, 0, 88, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[22, 0, 50, 23]\n",
      "process_ann took 0.00 seconds\n",
      "[347, 12, 36, 16]\n",
      "process_ann took 0.00 seconds\n",
      "[349, 47, 34, 16]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a skateboard: [0, 0, 383, 212]; a green square with a black background: [295, 0, 88, 117]; a grey circle with a black background: [22, 0, 50, 23]; a green arrow with a black background: [347, 12, 36, 16]; a green arrow with a black background: [349, 47, 34, 16]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green square with a black circle on it; Dense Caption: green plastic diamond on a traffic sign: [292, 0, 383, 119]; frisbee is round: [19, 0, 75, 26]; white snow on the ground: [0, 1, 382, 210]; the snow is white: [56, 54, 276, 204]; the sky is clear: [102, 58, 201, 152]; the sky is clear: [81, 79, 185, 168]; frisbee in the air: [11, 0, 91, 40]; the sky is clear: [111, 88, 212, 177]; a green arrow on a sign: [322, 43, 379, 102]; the sky is clear: [121, 37, 218, 137]; ; Region Captions: a black and white image of a skateboard: [0, 0, 383, 212]; a green square with a black background: [295, 0, 88, 117]; a grey circle with a black background: [22, 0, 50, 23]; a green arrow with a black background: [347, 12, 36, 16]; a green arrow with a black background: [349, 47, 34, 16]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green square in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green box: [105, 33, 275, 195]; white table with green boxes: [0, 1, 382, 210]; green and white sign: [307, 0, 368, 39]; green box on the ground: [179, 0, 219, 16]; green box on white table: [307, 0, 383, 86]; the sign is green: [136, 56, 251, 168]; a green and white box: [118, 37, 260, 121]; a green color in board: [168, 138, 207, 174]; the backrest of the green plastic chair: [125, 109, 262, 189]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[110, 5, 232, 187]\n",
      "process_ann took 0.00 seconds\n",
      "[109, 37, 164, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[309, 0, 74, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[309, 0, 74, 85]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a group of cubes: [0, 1, 383, 211]; a green square block on a black background: [110, 5, 232, 187]; a green square block in minecraft: [109, 37, 164, 155]; a green square on a black background: [309, 0, 74, 49]; a green pixelated grass texture: [309, 0, 74, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green square in minecraft; Dense Caption: a green box: [105, 33, 275, 195]; white table with green boxes: [0, 1, 382, 210]; green and white sign: [307, 0, 368, 39]; green box on the ground: [179, 0, 219, 16]; green box on white table: [307, 0, 383, 86]; the sign is green: [136, 56, 251, 168]; a green and white box: [118, 37, 260, 121]; a green color in board: [168, 138, 207, 174]; the backrest of the green plastic chair: [125, 109, 262, 189]; ; Region Captions: a black and white image of a group of cubes: [0, 1, 383, 211]; a green square block on a black background: [110, 5, 232, 187]; a green square block in minecraft: [109, 37, 164, 155]; a green square on a black background: [309, 0, 74, 49]; a green pixelated grass texture: [309, 0, 74, 85]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green square in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green box: [104, 35, 275, 199]; white table with green boxes: [0, 1, 382, 209]; green box on white table: [179, 0, 219, 21]; green colored lego blocks: [305, 0, 383, 93]; green colored wooden slat: [305, 0, 368, 43]; the arrow is pointing left: [137, 67, 250, 174]; a green and white box: [118, 41, 260, 125]; a green and white back: [129, 115, 259, 189]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[109, 2, 249, 195]\n",
      "process_ann took 0.00 seconds\n",
      "[109, 42, 163, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[244, 0, 139, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[308, 0, 75, 89]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a square: [0, 0, 383, 212]; a green square block on a black background: [109, 2, 249, 195]; a green square block in minecraft: [109, 42, 163, 155]; a green pixelated hat in minecraft: [244, 0, 139, 89]; a green grassy field in minecraft: [308, 0, 75, 89]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green square in minecraft; Dense Caption: a green box: [104, 35, 275, 199]; white table with green boxes: [0, 1, 382, 209]; green box on white table: [179, 0, 219, 21]; green colored lego blocks: [305, 0, 383, 93]; green colored wooden slat: [305, 0, 368, 43]; the arrow is pointing left: [137, 67, 250, 174]; a green and white box: [118, 41, 260, 125]; a green and white back: [129, 115, 259, 189]; ; Region Captions: a black and white image of a square: [0, 0, 383, 212]; a green square block on a black background: [109, 2, 249, 195]; a green square block in minecraft: [109, 42, 163, 155]; a green pixelated hat in minecraft: [244, 0, 139, 89]; a green grassy field in minecraft: [308, 0, 75, 89]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green cube in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box on the table: [0, 90, 107, 195]; the chairs are green: [30, 38, 336, 210]; green colored ottoman: [213, 70, 270, 128]; a small basket: [153, 58, 206, 85]; green legos: [195, 19, 323, 129]; lego figurine of a video game character: [230, 27, 253, 67]; green colored brick block: [117, 65, 149, 95]; green colored basket on the table: [259, 39, 318, 113]; green colored basket on the table: [202, 44, 242, 99]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 78, 383, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 197, 86]\n",
      "process_ann took 0.00 seconds\n",
      "[198, 0, 185, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 102, 98]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 78, 383, 134]; a 3d image of a city with a shadow: [0, 0, 383, 108]; a gray png image of a black and white png: [0, 0, 197, 86]; a silhouette of a man sitting on a chair: [198, 0, 185, 108]; a green block with a square shape: [0, 94, 102, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green cube in a minecraft game; Dense Caption: green box on the table: [0, 90, 107, 195]; the chairs are green: [30, 38, 336, 210]; green colored ottoman: [213, 70, 270, 128]; a small basket: [153, 58, 206, 85]; green legos: [195, 19, 323, 129]; lego figurine of a video game character: [230, 27, 253, 67]; green colored brick block: [117, 65, 149, 95]; green colored basket on the table: [259, 39, 318, 113]; green colored basket on the table: [202, 44, 242, 99]; ; Region Captions: a black and white image of a snowy area: [0, 78, 383, 134]; a 3d image of a city with a shadow: [0, 0, 383, 108]; a gray png image of a black and white png: [0, 0, 197, 86]; a silhouette of a man sitting on a chair: [198, 0, 185, 108]; a green block with a square shape: [0, 94, 102, 98]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with green cubes and a green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green box on the table: [0, 48, 99, 133]; white table with green boxes: [0, 6, 382, 209]; lego man in front of a cake: [190, 2, 221, 54]; a small green box: [134, 0, 168, 55]; green box on the floor: [217, 38, 289, 103]; green colored chair: [217, 0, 382, 105]; red and blue toy on top of the television: [196, 15, 217, 52]; green and lime green bench: [113, 1, 353, 145]; the chair is green: [15, 16, 237, 154]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 227, 42]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 52, 96, 77]\n",
      "process_ann took 0.00 seconds\n",
      "[219, 0, 68, 101]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 2, 383, 210]; a black and white image of a city: [0, 0, 383, 76]; a silhouette of a building with a tall tower: [0, 0, 227, 42]; a green cube with a square shape: [0, 52, 96, 77]; a green cube sitting on a black background: [219, 0, 68, 101]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with green cubes and a green block; Dense Caption: green box on the table: [0, 48, 99, 133]; white table with green boxes: [0, 6, 382, 209]; lego man in front of a cake: [190, 2, 221, 54]; a small green box: [134, 0, 168, 55]; green box on the floor: [217, 38, 289, 103]; green colored chair: [217, 0, 382, 105]; red and blue toy on top of the television: [196, 15, 217, 52]; green and lime green bench: [113, 1, 353, 145]; the chair is green: [15, 16, 237, 154]; ; Region Captions: a black and white image of a snowy area: [0, 2, 383, 210]; a black and white image of a city: [0, 0, 383, 76]; a silhouette of a building with a tall tower: [0, 0, 227, 42]; a green cube with a square shape: [0, 52, 96, 77]; a green cube sitting on a black background: [219, 0, 68, 101]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green cube in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and white square object: [0, 65, 91, 184]; green paper box on table: [240, 49, 365, 151]; white table with green boxes: [0, 35, 382, 210]; green plastic pencil box: [146, 2, 183, 66]; square shaped fabric: [201, 24, 256, 58]; green paper on the table: [241, 0, 328, 81]; green colored lego blocks: [153, 0, 361, 159]; a red box on the wall: [142, 0, 171, 17]; white snow on the ground: [26, 51, 237, 208]; green label on a bottle: [148, 6, 180, 39]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 46, 383, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 381, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 380, 48]\n",
      "process_ann took 0.00 seconds\n",
      "[245, 62, 120, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 86, 106]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 381, 81]; a black and white image of a building: [0, 0, 380, 48]; a green block in minecraft: [245, 62, 120, 84]; a green block with a square shape: [0, 72, 86, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green cube in minecraft; Dense Caption: green and white square object: [0, 65, 91, 184]; green paper box on table: [240, 49, 365, 151]; white table with green boxes: [0, 35, 382, 210]; green plastic pencil box: [146, 2, 183, 66]; square shaped fabric: [201, 24, 256, 58]; green paper on the table: [241, 0, 328, 81]; green colored lego blocks: [153, 0, 361, 159]; a red box on the wall: [142, 0, 171, 17]; white snow on the ground: [26, 51, 237, 208]; green label on a bottle: [148, 6, 180, 39]; ; Region Captions: a black and white image of a snowy area: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 381, 81]; a black and white image of a building: [0, 0, 380, 48]; a green block in minecraft: [245, 62, 120, 84]; a green block with a square shape: [0, 72, 86, 106]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green cube in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and white box: [0, 65, 91, 184]; green box on table: [239, 1, 370, 150]; white table with green boxes: [0, 35, 382, 210]; green plastic pencil box: [146, 2, 183, 66]; square shaped fabric: [201, 24, 256, 58]; green paper on the table: [241, 0, 328, 81]; red box on the wall: [142, 0, 172, 16]; white snow on the ground: [27, 50, 237, 208]; green label on a bottle: [148, 6, 180, 39]; green boxes on the table: [147, 5, 365, 185]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 47, 383, 165]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 381, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 380, 48]\n",
      "process_ann took 0.00 seconds\n",
      "[245, 62, 120, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 86, 106]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 47, 383, 165]; a black and white image of a city: [0, 0, 381, 81]; a black and white image of a building: [0, 0, 380, 48]; a green block in minecraft: [245, 62, 120, 84]; a green block with a square shape: [0, 72, 86, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green cube in minecraft; Dense Caption: a green and white box: [0, 65, 91, 184]; green box on table: [239, 1, 370, 150]; white table with green boxes: [0, 35, 382, 210]; green plastic pencil box: [146, 2, 183, 66]; square shaped fabric: [201, 24, 256, 58]; green paper on the table: [241, 0, 328, 81]; red box on the wall: [142, 0, 172, 16]; white snow on the ground: [27, 50, 237, 208]; green label on a bottle: [148, 6, 180, 39]; green boxes on the table: [147, 5, 365, 185]; ; Region Captions: a black and white image of a snowy area: [0, 47, 383, 165]; a black and white image of a city: [0, 0, 381, 81]; a black and white image of a building: [0, 0, 380, 48]; a green block in minecraft: [245, 62, 120, 84]; a green block with a square shape: [0, 72, 86, 106]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green cube in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and white box: [0, 65, 91, 184]; green box on table: [239, 1, 369, 150]; white table with green boxes: [0, 35, 382, 210]; green plastic pencil box: [146, 2, 183, 66]; square shaped fabric: [201, 24, 256, 57]; green paper on the table: [241, 0, 328, 81]; a red box on the wall: [142, 0, 173, 18]; green label on a bottle: [148, 6, 180, 39]; green boxes on the table: [146, 5, 365, 185]; white table top: [97, 74, 238, 207]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 46, 383, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 381, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 380, 48]\n",
      "process_ann took 0.00 seconds\n",
      "[245, 62, 120, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 86, 106]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 381, 81]; a black and white image of a building: [0, 0, 380, 48]; a green block in minecraft: [245, 62, 120, 84]; a green block with a square shape: [0, 72, 86, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green cube in minecraft; Dense Caption: a green and white box: [0, 65, 91, 184]; green box on table: [239, 1, 369, 150]; white table with green boxes: [0, 35, 382, 210]; green plastic pencil box: [146, 2, 183, 66]; square shaped fabric: [201, 24, 256, 57]; green paper on the table: [241, 0, 328, 81]; a red box on the wall: [142, 0, 173, 18]; green label on a bottle: [148, 6, 180, 39]; green boxes on the table: [146, 5, 365, 185]; white table top: [97, 74, 238, 207]; ; Region Captions: a black and white image of a snowy area: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 381, 81]; a black and white image of a building: [0, 0, 380, 48]; a green block in minecraft: [245, 62, 120, 84]; a green block with a square shape: [0, 72, 86, 106]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green cube in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a green and white box: [0, 65, 91, 184]; green box on table: [239, 1, 369, 150]; white table with green boxes: [0, 35, 382, 210]; green plastic pencil box: [146, 2, 183, 66]; square shaped fabric: [201, 24, 256, 57]; green paper on the table: [241, 0, 328, 81]; red box on the wall: [142, 0, 173, 16]; green label on a bottle: [148, 5, 180, 39]; green boxes on the table: [146, 5, 365, 185]; white snow on the ground: [49, 59, 234, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 46, 383, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 381, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 380, 48]\n",
      "process_ann took 0.00 seconds\n",
      "[245, 62, 120, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 86, 106]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 381, 81]; a black and white image of a building: [0, 0, 380, 48]; a green block in minecraft: [245, 62, 120, 84]; a green block with a square shape: [0, 72, 86, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green cube in minecraft; Dense Caption: a green and white box: [0, 65, 91, 184]; green box on table: [239, 1, 369, 150]; white table with green boxes: [0, 35, 382, 210]; green plastic pencil box: [146, 2, 183, 66]; square shaped fabric: [201, 24, 256, 57]; green paper on the table: [241, 0, 328, 81]; red box on the wall: [142, 0, 173, 16]; green label on a bottle: [148, 5, 180, 39]; green boxes on the table: [146, 5, 365, 185]; white snow on the ground: [49, 59, 234, 209]; ; Region Captions: a black and white image of a snowy area: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 381, 81]; a black and white image of a building: [0, 0, 380, 48]; a green block in minecraft: [245, 62, 120, 84]; a green block with a square shape: [0, 72, 86, 106]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210413_194755 21\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a multicolored bed post: [294, 33, 383, 212]; the basket is made of wicker: [0, 93, 103, 134]; the wall is white: [5, 1, 345, 109]; white bedspread on the bed: [1, 106, 325, 211]; the room is a bedroom: [2, 2, 370, 209]; a yellow and blue box: [321, 34, 382, 158]; red and black box: [292, 122, 382, 211]; a red and white box: [293, 120, 329, 212]; the snow is white: [92, 139, 211, 208]; a blue square on a yellow book: [364, 86, 383, 140]; the back of a chair: [281, 94, 333, 120]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 113, 323, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[297, 126, 86, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 36, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[322, 154, 61, 59]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a gray box with a lid on it: [0, 0, 383, 113]; a white snowy surface with a white snowy surface: [0, 113, 323, 99]; a red and black striped wall: [297, 126, 86, 87]; a gray square with a black background: [0, 0, 36, 101]; a red square on a black background: [322, 154, 61, 59]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character in a room; Dense Caption: a multicolored bed post: [294, 33, 383, 212]; the basket is made of wicker: [0, 93, 103, 134]; the wall is white: [5, 1, 345, 109]; white bedspread on the bed: [1, 106, 325, 211]; the room is a bedroom: [2, 2, 370, 209]; a yellow and blue box: [321, 34, 382, 158]; red and black box: [292, 122, 382, 211]; a red and white box: [293, 120, 329, 212]; the snow is white: [92, 139, 211, 208]; a blue square on a yellow book: [364, 86, 383, 140]; the back of a chair: [281, 94, 333, 120]; ; Region Captions: a gray box with a lid on it: [0, 0, 383, 113]; a white snowy surface with a white snowy surface: [0, 113, 323, 99]; a red and black striped wall: [297, 126, 86, 87]; a gray square with a black background: [0, 0, 36, 101]; a red square on a black background: [322, 154, 61, 59]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white snowy field: [0, 2, 382, 210]; a red and yellow fire hydrant: [151, 1, 263, 125]; shadow of the object: [165, 90, 232, 132]; blue section of the hydrant: [178, 66, 220, 118]; a snowboarder on a snowboard: [86, 0, 293, 168]; three brown squares in the snow: [248, 9, 334, 38]; a yellow rectangle on a cake: [172, 0, 239, 19]; black stripe on the suitcase: [217, 10, 239, 87]; red stripe on the cake: [182, 18, 223, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 6, 383, 206]\n",
      "process_ann took 0.00 seconds\n",
      "[164, 0, 86, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[178, 10, 72, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 23]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 129, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person standing on a snowy ground: [0, 6, 383, 206]; a red and blue pixelated minecraft character: [164, 0, 86, 118]; a red box with a black lid: [178, 10, 72, 76]; a black and white image of a hallway: [0, 0, 383, 23]; a black and grey striped t shirt: [0, 0, 129, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a white snowy field: [0, 2, 382, 210]; a red and yellow fire hydrant: [151, 1, 263, 125]; shadow of the object: [165, 90, 232, 132]; blue section of the hydrant: [178, 66, 220, 118]; a snowboarder on a snowboard: [86, 0, 293, 168]; three brown squares in the snow: [248, 9, 334, 38]; a yellow rectangle on a cake: [172, 0, 239, 19]; black stripe on the suitcase: [217, 10, 239, 87]; red stripe on the cake: [182, 18, 223, 74]; ; Region Captions: a black and white image of a person standing on a snowy ground: [0, 6, 383, 206]; a red and blue pixelated minecraft character: [164, 0, 86, 118]; a red box with a black lid: [178, 10, 72, 76]; a black and white image of a hallway: [0, 0, 383, 23]; a black and grey striped t shirt: [0, 0, 129, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a person is holding a snowboard: [262, 0, 305, 70]; a wide expanse of snow: [0, 15, 382, 210]; the remote on the right is made of wicker: [48, 12, 142, 44]; the box is brown: [148, 12, 193, 35]; red section of the post: [266, 17, 296, 49]; the snow is white: [40, 64, 258, 203]; the wall is gray: [10, 2, 380, 59]; snowboarder in the snow: [226, 0, 313, 80]; yellow and blue stripes: [268, 0, 304, 22]; blue base of the lego piece: [264, 43, 284, 68]; a black square object with white dots: [294, 13, 383, 40]; a black square on the ground: [222, 48, 260, 69]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[81, 0, 265, 30]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 143, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 85, 56]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft map with a black and white background: [0, 2, 383, 210]; a black and white image of a city: [0, 0, 383, 56]; a black and white image of a black and white shirt: [81, 0, 265, 30]; a black and white image of a small black and white cat: [0, 0, 143, 56]; a gray piece of paper with a black background: [0, 0, 85, 56]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: a person is holding a snowboard: [262, 0, 305, 70]; a wide expanse of snow: [0, 15, 382, 210]; the remote on the right is made of wicker: [48, 12, 142, 44]; the box is brown: [148, 12, 193, 35]; red section of the post: [266, 17, 296, 49]; the snow is white: [40, 64, 258, 203]; the wall is gray: [10, 2, 380, 59]; snowboarder in the snow: [226, 0, 313, 80]; yellow and blue stripes: [268, 0, 304, 22]; blue base of the lego piece: [264, 43, 284, 68]; a black square object with white dots: [294, 13, 383, 40]; a black square on the ground: [222, 48, 260, 69]; ; Region Captions: a minecraft map with a black and white background: [0, 2, 383, 210]; a black and white image of a city: [0, 0, 383, 56]; a black and white image of a black and white shirt: [81, 0, 265, 30]; a black and white image of a small black and white cat: [0, 0, 143, 56]; a gray piece of paper with a black background: [0, 0, 85, 56]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large white bed: [0, 16, 382, 210]; a person standing in the snow: [165, 0, 193, 38]; the black box on the side of the hill: [49, 12, 142, 43]; the black and white wall: [14, 3, 380, 55]; a black square object with white dots: [291, 13, 383, 39]; gray letters on a white background: [200, 26, 268, 74]; the snow is white: [37, 61, 263, 202]; yellow top of fire hydrant: [171, 0, 185, 11]; the snow is white: [103, 15, 348, 163]; blue pants on a person: [173, 22, 185, 36]; a black square in the snow: [221, 48, 263, 68]; red and yellow item on the ground: [147, 0, 203, 43]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 31, 383, 181]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 124, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 85, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[51, 17, 89, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a minecraft map: [0, 31, 383, 181]; a black and white image of a city: [0, 0, 383, 56]; a white and grey teddy bear with a black background: [0, 0, 124, 56]; a gray piece of paper with a black background: [0, 0, 85, 56]; a black block with a black background: [51, 17, 89, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: a large white bed: [0, 16, 382, 210]; a person standing in the snow: [165, 0, 193, 38]; the black box on the side of the hill: [49, 12, 142, 43]; the black and white wall: [14, 3, 380, 55]; a black square object with white dots: [291, 13, 383, 39]; gray letters on a white background: [200, 26, 268, 74]; the snow is white: [37, 61, 263, 202]; yellow top of fire hydrant: [171, 0, 185, 11]; the snow is white: [103, 15, 348, 163]; blue pants on a person: [173, 22, 185, 36]; a black square in the snow: [221, 48, 263, 68]; red and yellow item on the ground: [147, 0, 203, 43]; ; Region Captions: a white and black image of a minecraft map: [0, 31, 383, 181]; a black and white image of a city: [0, 0, 383, 56]; a white and grey teddy bear with a black background: [0, 0, 124, 56]; a gray piece of paper with a black background: [0, 0, 85, 56]; a black block with a black background: [51, 17, 89, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a snowy white slope: [36, 76, 354, 210]; a person standing in the snow: [183, 55, 205, 85]; a hedge at the bottom of the hill: [127, 64, 188, 85]; black square in the snow: [147, 100, 190, 122]; the grey sky: [0, 1, 381, 99]; a brown box: [200, 67, 230, 84]; the number is three: [144, 80, 279, 126]; a person skiing on the snow: [98, 55, 315, 158]; a person standing in the snow: [182, 52, 231, 87]; blue snow pants: [186, 73, 198, 85]; black letters on the ground: [207, 83, 277, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 81, 383, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[161, 0, 222, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 160, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 73, 129, 21]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.79 seconds\n",
      "finished...\n",
      "\n",
      "a small square in the snow: [0, 81, 383, 131]; a black and white image of a room with a window: [0, 0, 383, 94]; a black and gray picture of a black and gray picture: [161, 0, 222, 94]; a gray tv with the words, tv - tv: [0, 0, 160, 92]; a gray curved arrow with a black background: [0, 73, 129, 21]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: a snowy white slope: [36, 76, 354, 210]; a person standing in the snow: [183, 55, 205, 85]; a hedge at the bottom of the hill: [127, 64, 188, 85]; black square in the snow: [147, 100, 190, 122]; the grey sky: [0, 1, 381, 99]; a brown box: [200, 67, 230, 84]; the number is three: [144, 80, 279, 126]; a person skiing on the snow: [98, 55, 315, 158]; a person standing in the snow: [182, 52, 231, 87]; blue snow pants: [186, 73, 198, 85]; black letters on the ground: [207, 83, 277, 103]; ; Region Captions: a small square in the snow: [0, 81, 383, 131]; a black and white image of a room with a window: [0, 0, 383, 94]; a black and gray picture of a black and gray picture: [161, 0, 222, 94]; a gray tv with the words, tv - tv: [0, 0, 160, 92]; a gray curved arrow with a black background: [0, 73, 129, 21]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a blue and white square\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bag is blue: [139, 68, 182, 110]; the bed is made: [31, 60, 348, 211]; a white gift box: [205, 69, 245, 111]; brown box on the bed: [269, 59, 318, 89]; a brown box on the side of the bed: [0, 52, 87, 76]; shadows of the items on the table: [94, 61, 303, 134]; lego man in red shirt: [244, 41, 267, 84]; the back wall is white: [30, 1, 293, 70]; square cut out in the white tablecloth: [240, 105, 293, 129]; two small square boxes: [111, 64, 255, 115]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 69, 383, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[262, 0, 121, 111]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 44, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[141, 72, 38, 36]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft map with a black and white background: [0, 69, 383, 143]; a room with a black and white background: [0, 0, 383, 112]; a gray sandbox with a black background: [262, 0, 121, 111]; a gray triangle with a black background: [0, 0, 44, 59]; a blue block on a black background: [141, 72, 38, 36]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a blue and white square; Dense Caption: the bag is blue: [139, 68, 182, 110]; the bed is made: [31, 60, 348, 211]; a white gift box: [205, 69, 245, 111]; brown box on the bed: [269, 59, 318, 89]; a brown box on the side of the bed: [0, 52, 87, 76]; shadows of the items on the table: [94, 61, 303, 134]; lego man in red shirt: [244, 41, 267, 84]; the back wall is white: [30, 1, 293, 70]; square cut out in the white tablecloth: [240, 105, 293, 129]; two small square boxes: [111, 64, 255, 115]; ; Region Captions: a minecraft map with a black and white background: [0, 69, 383, 143]; a room with a black and white background: [0, 0, 383, 112]; a gray sandbox with a black background: [262, 0, 121, 111]; a gray triangle with a black background: [0, 0, 44, 59]; a blue block on a black background: [141, 72, 38, 36]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown box: [4, 70, 147, 124]; a lego person is holding a snowboard: [159, 47, 202, 131]; yellow and gray suitcase: [321, 111, 383, 211]; the floor is white: [37, 78, 351, 212]; the square box of tissue on the table: [299, 80, 369, 124]; red part of the lego: [160, 69, 199, 107]; the wall is white: [44, 0, 361, 91]; white snow on the ground: [25, 127, 279, 211]; shadow of the object: [161, 114, 202, 133]; blue square on hydrant: [170, 101, 192, 127]; a yellow and blue paper: [167, 49, 197, 76]; brown cardboard box on white snow: [195, 70, 225, 98]; a black and white tag: [181, 88, 197, 109]; the snow is white: [89, 140, 215, 203]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 92, 380, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 0, 329, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 76, 146, 43]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 68, 83]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man walking down a snowy path: [0, 92, 380, 121]; a silhouette of a city with a black background: [0, 0, 383, 112]; a silhouette of a city with a dark sky: [54, 0, 329, 91]; a black block with a blue light on it: [0, 76, 146, 43]; a grey square with a black background: [0, 0, 68, 83]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a brown box: [4, 70, 147, 124]; a lego person is holding a snowboard: [159, 47, 202, 131]; yellow and gray suitcase: [321, 111, 383, 211]; the floor is white: [37, 78, 351, 212]; the square box of tissue on the table: [299, 80, 369, 124]; red part of the lego: [160, 69, 199, 107]; the wall is white: [44, 0, 361, 91]; white snow on the ground: [25, 127, 279, 211]; shadow of the object: [161, 114, 202, 133]; blue square on hydrant: [170, 101, 192, 127]; a yellow and blue paper: [167, 49, 197, 76]; brown cardboard box on white snow: [195, 70, 225, 98]; a black and white tag: [181, 88, 197, 109]; the snow is white: [89, 140, 215, 203]; ; Region Captions: a black and white image of a man walking down a snowy path: [0, 92, 380, 121]; a silhouette of a city with a black background: [0, 0, 383, 112]; a silhouette of a city with a dark sky: [54, 0, 329, 91]; a black block with a blue light on it: [0, 76, 146, 43]; a grey square with a black background: [0, 0, 68, 83]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wicker basket: [5, 67, 146, 120]; yellow and gray suitcase: [320, 109, 383, 211]; lego person is holding a book: [158, 44, 204, 130]; the floor is white: [38, 76, 352, 213]; the square box on the ground: [298, 77, 369, 122]; the red part of the cake: [160, 67, 200, 102]; the wall is white: [43, 0, 358, 91]; a blue and yellow paper: [168, 46, 197, 75]; white tablecloth on table: [26, 125, 274, 211]; blue and black toy: [167, 87, 198, 127]; a black and white tag: [179, 87, 194, 109]; shadow of the object: [162, 112, 201, 130]; a lego toy on the bed: [70, 32, 280, 171]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 90, 364, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 111]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 0, 329, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 74, 146, 43]\n",
      "process_ann took 0.00 seconds\n",
      "[305, 90, 78, 123]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a skateboarder is riding down a snowy path: [0, 90, 364, 122]; a silhouette of a city with a building in the background: [0, 0, 383, 111]; a silhouette of a city with a black background: [54, 0, 329, 89]; a black block with a blue background: [0, 74, 146, 43]; a gold bar with a blue and black background: [305, 90, 78, 123]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a brown wicker basket: [5, 67, 146, 120]; yellow and gray suitcase: [320, 109, 383, 211]; lego person is holding a book: [158, 44, 204, 130]; the floor is white: [38, 76, 352, 213]; the square box on the ground: [298, 77, 369, 122]; the red part of the cake: [160, 67, 200, 102]; the wall is white: [43, 0, 358, 91]; a blue and yellow paper: [168, 46, 197, 75]; white tablecloth on table: [26, 125, 274, 211]; blue and black toy: [167, 87, 198, 127]; a black and white tag: [179, 87, 194, 109]; shadow of the object: [162, 112, 201, 130]; a lego toy on the bed: [70, 32, 280, 171]; ; Region Captions: a skateboarder is riding down a snowy path: [0, 90, 364, 122]; a silhouette of a city with a building in the background: [0, 0, 383, 111]; a silhouette of a city with a black background: [54, 0, 329, 89]; a black block with a blue background: [0, 74, 146, 43]; a gold bar with a blue and black background: [305, 90, 78, 123]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a few blocks and a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "dark woven basket: [5, 66, 147, 119]; the box is brown: [160, 66, 225, 94]; the white square box: [298, 76, 370, 120]; yellow object on the bed: [320, 108, 383, 211]; white table top: [0, 77, 380, 211]; the walls are white: [43, 11, 351, 146]; the wall is white: [3, 1, 380, 87]; the bed is made of wood: [31, 33, 251, 127]; the bed is white: [30, 114, 270, 211]; small object on the bed: [245, 89, 284, 109]; the snow is white: [81, 131, 206, 203]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 88, 366, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 0, 329, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 146, 44]\n",
      "process_ann took 0.00 seconds\n",
      "[322, 112, 61, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 68, 80]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy area with a white sled: [0, 88, 366, 125]; a black and gray image of a building: [54, 0, 329, 88]; a black block with a blue light on it: [0, 72, 146, 44]; a gold bar on a black background: [322, 112, 61, 101]; a grey square with a black background: [0, 0, 68, 80]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a few blocks and a table; Dense Caption: dark woven basket: [5, 66, 147, 119]; the box is brown: [160, 66, 225, 94]; the white square box: [298, 76, 370, 120]; yellow object on the bed: [320, 108, 383, 211]; white table top: [0, 77, 380, 211]; the walls are white: [43, 11, 351, 146]; the wall is white: [3, 1, 380, 87]; the bed is made of wood: [31, 33, 251, 127]; the bed is white: [30, 114, 270, 211]; small object on the bed: [245, 89, 284, 109]; the snow is white: [81, 131, 206, 203]; ; Region Captions: a white snowy area with a white sled: [0, 88, 366, 125]; a black and gray image of a building: [54, 0, 329, 88]; a black block with a blue light on it: [0, 72, 146, 44]; a gold bar on a black background: [322, 112, 61, 101]; a grey square with a black background: [0, 0, 68, 80]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a blue, yellow and red block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "dark patterned box: [5, 65, 147, 117]; blue square on the table: [252, 81, 337, 143]; the box is brown: [160, 66, 225, 94]; white tablecloth on the table: [0, 76, 378, 211]; blue and yellow box: [312, 26, 383, 212]; the room is a bedroom: [43, 3, 347, 166]; yellow section of the object: [321, 113, 383, 211]; the bed is white: [30, 112, 261, 211]; a blue painted surface: [339, 27, 383, 127]; the bed is made of wood: [30, 28, 246, 122]; the chair is blue: [206, 27, 362, 188]; the wall is white: [3, 1, 379, 89]; a white box behind the umbrella: [304, 77, 349, 120]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 89, 366, 124]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 164]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 0, 329, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[323, 30, 60, 182]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 146, 44]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy mountain with a white sled: [0, 89, 366, 124]; a black and white image of a city with a paper airplane: [0, 0, 383, 164]; a black and white image of a city with smoke: [54, 0, 329, 88]; a blue and yellow flag on a black background: [323, 30, 60, 182]; a black block with a blue light on it: [0, 72, 146, 44]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a blue, yellow and red block; Dense Caption: dark patterned box: [5, 65, 147, 117]; blue square on the table: [252, 81, 337, 143]; the box is brown: [160, 66, 225, 94]; white tablecloth on the table: [0, 76, 378, 211]; blue and yellow box: [312, 26, 383, 212]; the room is a bedroom: [43, 3, 347, 166]; yellow section of the object: [321, 113, 383, 211]; the bed is white: [30, 112, 261, 211]; a blue painted surface: [339, 27, 383, 127]; the bed is made of wood: [30, 28, 246, 122]; the chair is blue: [206, 27, 362, 188]; the wall is white: [3, 1, 379, 89]; a white box behind the umbrella: [304, 77, 349, 120]; ; Region Captions: a white snowy mountain with a white sled: [0, 89, 366, 124]; a black and white image of a city with a paper airplane: [0, 0, 383, 164]; a black and white image of a city with smoke: [54, 0, 329, 88]; a blue and yellow flag on a black background: [323, 30, 60, 182]; a black block with a blue light on it: [0, 72, 146, 44]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue and yellow block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "yellow and blue plastic cup: [127, 0, 291, 176]; the wooden box on the right: [0, 23, 100, 86]; large blue paper on the table: [277, 46, 383, 143]; table is cover with white tablecloth: [0, 2, 383, 210]; the basket is dark: [273, 11, 340, 44]; blue stripe on the yellow suitcase: [142, 68, 266, 175]; corner of a yellow and blue umbrella: [308, 116, 383, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 36, 383, 176]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 51, 245, 161]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 0, 146, 172]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 0, 146, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[279, 50, 104, 133]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building: [0, 36, 383, 176]; a white snowy mountain with a black background: [0, 51, 245, 161]; a yellow and blue block with a blue and yellow border: [135, 0, 146, 172]; a gold box with the word gold: [135, 0, 146, 103]; a blue pixelated image of a roof: [279, 50, 104, 133]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue and yellow block in minecraft; Dense Caption: yellow and blue plastic cup: [127, 0, 291, 176]; the wooden box on the right: [0, 23, 100, 86]; large blue paper on the table: [277, 46, 383, 143]; table is cover with white tablecloth: [0, 2, 383, 210]; the basket is dark: [273, 11, 340, 44]; blue stripe on the yellow suitcase: [142, 68, 266, 175]; corner of a yellow and blue umbrella: [308, 116, 383, 212]; ; Region Captions: a black and white image of a building: [0, 36, 383, 176]; a white snowy mountain with a black background: [0, 51, 245, 161]; a yellow and blue block with a blue and yellow border: [135, 0, 146, 172]; a gold box with the word gold: [135, 0, 146, 103]; a blue pixelated image of a roof: [279, 50, 104, 133]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue and yellow block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the yellow and blue umbrellas: [1, 1, 383, 174]; a blue box on the white plane: [176, 6, 237, 75]; the umbrella is blue and yellow: [236, 1, 383, 156]; yellow and blue sections of the umbrella: [1, 1, 182, 162]; yellow square on a sign: [3, 1, 170, 88]; the table is white: [45, 51, 349, 211]; blue and white sign: [41, 79, 183, 174]; a blue section of the sign: [254, 0, 383, 85]; the umbrella is yellow and blue: [71, 14, 170, 139]; the sign is blue and yellow: [33, 36, 213, 187]; yellow section of the sign: [238, 43, 298, 151]; yellow square section of the sign: [266, 81, 383, 152]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 175, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[256, 0, 127, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[240, 43, 143, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[42, 68, 137, 91]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building: [0, 1, 383, 211]; a yellow square block on a black background: [0, 0, 175, 90]; a blue square block on a black background: [256, 0, 127, 83]; a gold block with a pixelated design: [240, 43, 143, 108]; a blue square with a black background: [42, 68, 137, 91]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue and yellow block in minecraft; Dense Caption: the yellow and blue umbrellas: [1, 1, 383, 174]; a blue box on the white plane: [176, 6, 237, 75]; the umbrella is blue and yellow: [236, 1, 383, 156]; yellow and blue sections of the umbrella: [1, 1, 182, 162]; yellow square on a sign: [3, 1, 170, 88]; the table is white: [45, 51, 349, 211]; blue and white sign: [41, 79, 183, 174]; a blue section of the sign: [254, 0, 383, 85]; the umbrella is yellow and blue: [71, 14, 170, 139]; the sign is blue and yellow: [33, 36, 213, 187]; yellow section of the sign: [238, 43, 298, 151]; yellow square section of the sign: [266, 81, 383, 152]; ; Region Captions: a black and white image of a building: [0, 1, 383, 211]; a yellow square block on a black background: [0, 0, 175, 90]; a blue square block on a black background: [256, 0, 127, 83]; a gold block with a pixelated design: [240, 43, 143, 108]; a blue square with a black background: [42, 68, 137, 91]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a group of blue and yellow blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue box on the floor: [11, 11, 162, 151]; the stack of blue and yellow boxes: [135, 1, 332, 162]; a blue and yellow box: [1, 2, 381, 202]; blue stack of paper on table: [298, 3, 383, 128]; yellow object in the forefront: [323, 155, 382, 211]; a blue box top: [15, 12, 132, 79]; a wood piece of furniture: [0, 0, 84, 44]; the table is white: [52, 156, 176, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[139, 0, 187, 159]\n",
      "process_ann took 0.00 seconds\n",
      "[12, 14, 148, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[139, 0, 187, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[148, 44, 230, 116]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a tiger: [0, 1, 383, 211]; a yellow and blue block in minecraft: [139, 0, 187, 159]; a blue block in minecraft: [12, 14, 148, 133]; a yellow box with a yellow background: [139, 0, 187, 97]; a blue arrow with a black background: [148, 44, 230, 116]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a group of blue and yellow blocks in minecraft; Dense Caption: a blue box on the floor: [11, 11, 162, 151]; the stack of blue and yellow boxes: [135, 1, 332, 162]; a blue and yellow box: [1, 2, 381, 202]; blue stack of paper on table: [298, 3, 383, 128]; yellow object in the forefront: [323, 155, 382, 211]; a blue box top: [15, 12, 132, 79]; a wood piece of furniture: [0, 0, 84, 44]; the table is white: [52, 156, 176, 209]; ; Region Captions: a black and white image of a tiger: [0, 1, 383, 211]; a yellow and blue block in minecraft: [139, 0, 187, 159]; a blue block in minecraft: [12, 14, 148, 133]; a yellow box with a yellow background: [139, 0, 187, 97]; a blue arrow with a black background: [148, 44, 230, 116]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with blue and yellow blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the yellow and blue boxes: [43, 0, 317, 121]; white tablecloth on the table: [1, 40, 382, 211]; a brown wooden box: [0, 42, 50, 92]; the lego is blue: [138, 3, 200, 99]; blue and yellow box: [205, 0, 308, 112]; blue colored cardboard box: [74, 57, 150, 112]; the yellow part of the basket: [223, 59, 285, 113]; the bucket is blue: [51, 0, 154, 114]; a blue section of a bin: [144, 51, 198, 99]; the floor is white: [40, 101, 334, 209]; a small brown basket: [196, 26, 216, 47]; yellow section of the cake: [53, 0, 143, 63]; blue part of the wall: [224, 0, 305, 68]; shadow of the object: [275, 79, 313, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 46, 383, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 1, 141, 109]\n",
      "process_ann took 0.00 seconds\n",
      "[54, 1, 95, 109]\n",
      "process_ann took 0.00 seconds\n",
      "[138, 5, 59, 93]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft map: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 383, 70]; a blue and yellow block in minecraft: [54, 1, 141, 109]; a blue and yellow square block: [54, 1, 95, 109]; a blue and yellow square box: [138, 5, 59, 93]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with blue and yellow blocks; Dense Caption: the yellow and blue boxes: [43, 0, 317, 121]; white tablecloth on the table: [1, 40, 382, 211]; a brown wooden box: [0, 42, 50, 92]; the lego is blue: [138, 3, 200, 99]; blue and yellow box: [205, 0, 308, 112]; blue colored cardboard box: [74, 57, 150, 112]; the yellow part of the basket: [223, 59, 285, 113]; the bucket is blue: [51, 0, 154, 114]; a blue section of a bin: [144, 51, 198, 99]; the floor is white: [40, 101, 334, 209]; a small brown basket: [196, 26, 216, 47]; yellow section of the cake: [53, 0, 143, 63]; blue part of the wall: [224, 0, 305, 68]; shadow of the object: [275, 79, 313, 103]; ; Region Captions: a black and white image of a minecraft map: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 383, 70]; a blue and yellow block in minecraft: [54, 1, 141, 109]; a blue and yellow square block: [54, 1, 95, 109]; a blue and yellow square box: [138, 5, 59, 93]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with blue and yellow blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the yellow and blue boxes: [63, 0, 320, 118]; the room is a bedroom: [0, 1, 381, 210]; the box is brown: [0, 40, 60, 95]; the lego is yellow and blue: [149, 4, 208, 98]; blue colored cardboard box: [87, 55, 159, 109]; the yellow square on the left: [230, 58, 293, 111]; blue and yellow stairs: [211, 0, 316, 109]; the floor is white: [39, 82, 340, 209]; the boxes are made of cardboard: [70, 2, 209, 109]; a blue section of a bin: [154, 50, 206, 97]; blue colored section of a container: [127, 58, 154, 104]; yellow section of the cake: [70, 1, 153, 61]; shadow of the book: [282, 78, 319, 102]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 46, 383, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[71, 2, 132, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[71, 2, 86, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[179, 0, 204, 47]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 383, 68]; a blue and yellow block in minecraft: [71, 2, 132, 105]; a blue and yellow block with a blue and yellow square: [71, 2, 86, 105]; a black and white image of a city: [179, 0, 204, 47]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with blue and yellow blocks; Dense Caption: the yellow and blue boxes: [63, 0, 320, 118]; the room is a bedroom: [0, 1, 381, 210]; the box is brown: [0, 40, 60, 95]; the lego is yellow and blue: [149, 4, 208, 98]; blue colored cardboard box: [87, 55, 159, 109]; the yellow square on the left: [230, 58, 293, 111]; blue and yellow stairs: [211, 0, 316, 109]; the floor is white: [39, 82, 340, 209]; the boxes are made of cardboard: [70, 2, 209, 109]; a blue section of a bin: [154, 50, 206, 97]; blue colored section of a container: [127, 58, 154, 104]; yellow section of the cake: [70, 1, 153, 61]; shadow of the book: [282, 78, 319, 102]; ; Region Captions: a black and white image of a building: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 383, 68]; a blue and yellow block in minecraft: [71, 2, 132, 105]; a blue and yellow block with a blue and yellow square: [71, 2, 86, 105]; a black and white image of a city: [179, 0, 204, 47]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with some blocks and a blue block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "stack of yellow and blue boxes: [148, 3, 209, 98]; a white and black checkered table cloth: [0, 71, 99, 189]; the items are on the bed: [39, 1, 331, 208]; blue and white box: [69, 1, 163, 111]; a pair of blue and yellow boxes: [70, 0, 319, 119]; a blue box on the floor: [88, 54, 159, 109]; the yellow square object: [230, 58, 293, 111]; blue and yellow stairs: [211, 0, 316, 109]; a box of tissues: [0, 10, 38, 80]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 46, 383, 166]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 81, 96, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[72, 2, 85, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[179, 0, 204, 47]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a black and white building: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 383, 69]; a gray square block on a black background: [0, 81, 96, 105]; a blue and white box with a white background: [72, 2, 85, 105]; a black and white image of a building: [179, 0, 204, 47]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with some blocks and a blue block; Dense Caption: stack of yellow and blue boxes: [148, 3, 209, 98]; a white and black checkered table cloth: [0, 71, 99, 189]; the items are on the bed: [39, 1, 331, 208]; blue and white box: [69, 1, 163, 111]; a pair of blue and yellow boxes: [70, 0, 319, 119]; a blue box on the floor: [88, 54, 159, 109]; the yellow square object: [230, 58, 293, 111]; blue and yellow stairs: [211, 0, 316, 109]; a box of tissues: [0, 10, 38, 80]; ; Region Captions: a 3d image of a black and white building: [0, 46, 383, 166]; a black and white image of a city: [0, 0, 383, 69]; a gray square block on a black background: [0, 81, 96, 105]; a blue and white box with a white background: [72, 2, 85, 105]; a black and white image of a building: [179, 0, 204, 47]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing next to some blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white lamp shade: [69, 68, 157, 152]; the chair is blue and yellow: [241, 4, 367, 142]; a large woven basket: [0, 49, 82, 141]; the box is blue and white: [181, 9, 259, 124]; some type of snow for the children to play: [0, 3, 382, 210]; blue colored cardboard box: [183, 67, 250, 124]; red and blue model of a cell phone: [140, 41, 166, 95]; blue square on the bottom of the yellow umbrella: [241, 71, 339, 142]; yellow and blue card with a p on it: [135, 19, 168, 49]; white table cloth: [32, 144, 262, 211]; a brown wooden box: [100, 43, 185, 79]; a toy on the table: [128, 17, 174, 95]; blue block: [346, 68, 383, 134]; a blue and yellow box: [98, 6, 335, 148]; blue and yellow flag: [349, 60, 384, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 68, 383, 144]\n",
      "process_ann took 0.00 seconds\n",
      "[244, 6, 122, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 356, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[250, 6, 116, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[185, 11, 108, 112]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a room with a door: [0, 68, 383, 144]; a gold and blue block on a black background: [244, 6, 122, 134]; a silhouette of a city with a skyscraper: [0, 0, 356, 73]; a gold box with a pixelated background: [250, 6, 116, 80]; a blue and white jar with a lid: [185, 11, 108, 112]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing next to some blocks in minecraft; Dense Caption: a white lamp shade: [69, 68, 157, 152]; the chair is blue and yellow: [241, 4, 367, 142]; a large woven basket: [0, 49, 82, 141]; the box is blue and white: [181, 9, 259, 124]; some type of snow for the children to play: [0, 3, 382, 210]; blue colored cardboard box: [183, 67, 250, 124]; red and blue model of a cell phone: [140, 41, 166, 95]; blue square on the bottom of the yellow umbrella: [241, 71, 339, 142]; yellow and blue card with a p on it: [135, 19, 168, 49]; white table cloth: [32, 144, 262, 211]; a brown wooden box: [100, 43, 185, 79]; a toy on the table: [128, 17, 174, 95]; blue block: [346, 68, 383, 134]; a blue and yellow box: [98, 6, 335, 148]; blue and yellow flag: [349, 60, 384, 212]; ; Region Captions: a 3d image of a room with a door: [0, 68, 383, 144]; a gold and blue block on a black background: [244, 6, 122, 134]; a silhouette of a city with a skyscraper: [0, 0, 356, 73]; a gold box with a pixelated background: [250, 6, 116, 80]; a blue and white jar with a lid: [185, 11, 108, 112]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue square with a white background\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and white patterned wall: [0, 1, 381, 211]; the blue lines on the wall: [35, 97, 345, 212]; a blue section of a wall: [190, 78, 264, 209]; the blue and white striped wall: [23, 43, 242, 213]; blue and white stripes: [161, 86, 253, 185]; square in the middle of the image: [226, 82, 262, 113]; a white wall behind a window: [0, 137, 43, 212]; square in the middle of the large group: [242, 151, 298, 177]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[85, 85, 144, 25]\n",
      "process_ann took 0.00 seconds\n",
      "[43, 85, 157, 25]\n",
      "process_ann took 0.00 seconds\n",
      "[76, 55, 94, 29]\n",
      "process_ann took 0.00 seconds\n",
      "[76, 55, 188, 29]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 18, 52, 66]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a blue square with a black background: [85, 85, 144, 25]; a blue background with a black and white striped pattern: [43, 85, 157, 25]; a blue and white logo with the word st: [76, 55, 94, 29]; a blue and black striped shirt with a white t shirt: [76, 55, 188, 29]; a blue and white logo with a triangle in the middle: [0, 18, 52, 66]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue square with a white background; Dense Caption: a blue and white patterned wall: [0, 1, 381, 211]; the blue lines on the wall: [35, 97, 345, 212]; a blue section of a wall: [190, 78, 264, 209]; the blue and white striped wall: [23, 43, 242, 213]; blue and white stripes: [161, 86, 253, 185]; square in the middle of the image: [226, 82, 262, 113]; a white wall behind a window: [0, 137, 43, 212]; square in the middle of the large group: [242, 151, 298, 177]; ; Region Captions: a blue square with a black background: [85, 85, 144, 25]; a blue background with a black and white striped pattern: [43, 85, 157, 25]; a blue and white logo with the word st: [76, 55, 94, 29]; a blue and black striped shirt with a white t shirt: [76, 55, 188, 29]; a blue and white logo with a triangle in the middle: [0, 18, 52, 66]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue and yellow block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white table: [0, 125, 381, 212]; the bench is yellow: [151, 84, 316, 181]; shadow of the bench: [177, 168, 245, 208]; the stack is yellow and blue: [164, 88, 218, 171]; a blue square box: [247, 116, 298, 174]; a blue and yellow box: [213, 93, 235, 150]; a small black box: [115, 109, 160, 132]; a set of lego train: [46, 48, 320, 208]; the yellow part of the toy: [166, 126, 217, 170]; the walls are white: [0, 1, 381, 139]; blue section of the suitcase: [167, 89, 215, 130]; white snow covering the ground: [2, 136, 152, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 0, 381, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[156, 0, 227, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 129, 383, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 154, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[160, 91, 71, 78]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and gray wall with a black and gray wall: [2, 0, 381, 137]; a black and gray picture of a black and gray picture: [156, 0, 227, 136]; a black and white image of a man walking on a snowy path: [0, 129, 383, 83]; a gray tv stand with a white screen: [0, 0, 154, 141]; a blue and yellow block with a blue and yellow square: [160, 91, 71, 78]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue and yellow block in a minecraft game; Dense Caption: a white table: [0, 125, 381, 212]; the bench is yellow: [151, 84, 316, 181]; shadow of the bench: [177, 168, 245, 208]; the stack is yellow and blue: [164, 88, 218, 171]; a blue square box: [247, 116, 298, 174]; a blue and yellow box: [213, 93, 235, 150]; a small black box: [115, 109, 160, 132]; a set of lego train: [46, 48, 320, 208]; the yellow part of the toy: [166, 126, 217, 170]; the walls are white: [0, 1, 381, 139]; blue section of the suitcase: [167, 89, 215, 130]; white snow covering the ground: [2, 136, 152, 212]; ; Region Captions: a black and gray wall with a black and gray wall: [2, 0, 381, 137]; a black and gray picture of a black and gray picture: [156, 0, 227, 136]; a black and white image of a man walking on a snowy path: [0, 129, 383, 83]; a gray tv stand with a white screen: [0, 0, 154, 141]; a blue and yellow block with a blue and yellow square: [160, 91, 71, 78]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue and yellow block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white table: [0, 125, 381, 212]; the suitcases are on the ground: [151, 84, 316, 181]; shadow of the bench: [177, 168, 245, 208]; the stack is yellow and blue: [164, 88, 218, 171]; a blue square box: [247, 116, 298, 174]; a blue and yellow box: [213, 93, 235, 150]; a small black box: [115, 109, 160, 132]; a set of lego train: [46, 48, 320, 208]; the yellow part of the toy: [166, 126, 217, 170]; the walls are white: [0, 1, 381, 139]; blue section of the suitcase: [167, 89, 215, 130]; white snow covering the ground: [2, 136, 152, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 0, 381, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[156, 0, 227, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 129, 383, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 154, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[160, 91, 71, 78]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black and gray wall with a black and gray wall: [2, 0, 381, 137]; a black and gray picture of a black and gray picture: [156, 0, 227, 136]; a man is walking on a snowy path: [0, 129, 383, 83]; a gray tv stand with a white screen: [0, 0, 154, 141]; a blue and yellow block with a blue and yellow square: [160, 91, 71, 78]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue and yellow block in a minecraft game; Dense Caption: a white table: [0, 125, 381, 212]; the suitcases are on the ground: [151, 84, 316, 181]; shadow of the bench: [177, 168, 245, 208]; the stack is yellow and blue: [164, 88, 218, 171]; a blue square box: [247, 116, 298, 174]; a blue and yellow box: [213, 93, 235, 150]; a small black box: [115, 109, 160, 132]; a set of lego train: [46, 48, 320, 208]; the yellow part of the toy: [166, 126, 217, 170]; the walls are white: [0, 1, 381, 139]; blue section of the suitcase: [167, 89, 215, 130]; white snow covering the ground: [2, 136, 152, 212]; ; Region Captions: a black and gray wall with a black and gray wall: [2, 0, 381, 137]; a black and gray picture of a black and gray picture: [156, 0, 227, 136]; a man is walking on a snowy path: [0, 129, 383, 83]; a gray tv stand with a white screen: [0, 0, 154, 141]; a blue and yellow block with a blue and yellow square: [160, 91, 71, 78]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue and yellow block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white snowy ground: [0, 122, 381, 212]; the suitcases are on the ground: [132, 77, 304, 176]; shadow of the bench: [170, 164, 236, 202]; the stack is yellow and blue: [156, 84, 213, 167]; a blue icebox: [240, 114, 286, 168]; a small black basket: [106, 106, 153, 129]; the suitcases are on the ground: [56, 54, 285, 207]; the walls are white: [0, 1, 381, 134]; blue and yellow bench: [206, 90, 227, 147]; the yellow part of the kite: [159, 123, 209, 166]; the wall is white: [1, 1, 144, 132]; white snow covering the ground: [2, 133, 148, 212]; the wall is white: [144, 1, 367, 114]; blue section of the clock: [160, 86, 208, 127]; a piece of wood on the ground: [282, 133, 307, 147]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 125, 383, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[148, 0, 235, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 145, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[161, 88, 47, 77]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.80 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man in a snowy area: [0, 125, 383, 87]; a black and white image of a building with a clock: [2, 0, 381, 133]; a black and gray picture of a black and gray picture: [148, 0, 235, 132]; a gray styrofoam cup with a white rim: [0, 0, 145, 137]; a blue and yellow block with a yellow stripe: [161, 88, 47, 77]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue and yellow block in a minecraft game; Dense Caption: a white snowy ground: [0, 122, 381, 212]; the suitcases are on the ground: [132, 77, 304, 176]; shadow of the bench: [170, 164, 236, 202]; the stack is yellow and blue: [156, 84, 213, 167]; a blue icebox: [240, 114, 286, 168]; a small black basket: [106, 106, 153, 129]; the suitcases are on the ground: [56, 54, 285, 207]; the walls are white: [0, 1, 381, 134]; blue and yellow bench: [206, 90, 227, 147]; the yellow part of the kite: [159, 123, 209, 166]; the wall is white: [1, 1, 144, 132]; white snow covering the ground: [2, 133, 148, 212]; the wall is white: [144, 1, 367, 114]; blue section of the clock: [160, 86, 208, 127]; a piece of wood on the ground: [282, 133, 307, 147]; ; Region Captions: a black and white image of a man in a snowy area: [0, 125, 383, 87]; a black and white image of a building with a clock: [2, 0, 381, 133]; a black and gray picture of a black and gray picture: [148, 0, 235, 132]; a gray styrofoam cup with a white rim: [0, 0, 145, 137]; a blue and yellow block with a yellow stripe: [161, 88, 47, 77]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210413_195348 18\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character with a sword\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "snow covering the ground: [0, 94, 382, 212]; a sign that says that it is a website address: [99, 5, 217, 35]; a red and white sign: [106, 184, 276, 211]; red green and yellow box: [116, 41, 205, 183]; a lego snowboard with a train: [68, 39, 317, 212]; green stripes on the hydrant: [139, 96, 201, 177]; a red object: [272, 185, 359, 212]; the white wall behind the lego box: [1, 1, 382, 108]; yellow square box: [119, 44, 187, 103]; a black and white checkered pillow: [311, 83, 381, 114]; a small red light: [181, 192, 201, 212]; red and blue neon sign: [108, 176, 185, 188]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 99, 383, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[93, 0, 290, 100]\n",
      "process_ann took 0.00 seconds\n",
      "[186, 100, 197, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 105, 138, 107]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.80 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a sign that says sleemo: [0, 0, 383, 110]; a minecraft sandbox with a sandbox and a: [0, 99, 383, 113]; a grey box with a black letter on it: [93, 0, 290, 100]; a map of a mountain with a mountain in the middle: [186, 100, 197, 112]; a white sand beach with a white sand: [0, 105, 138, 107]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character with a sword; Dense Caption: snow covering the ground: [0, 94, 382, 212]; a sign that says that it is a website address: [99, 5, 217, 35]; a red and white sign: [106, 184, 276, 211]; red green and yellow box: [116, 41, 205, 183]; a lego snowboard with a train: [68, 39, 317, 212]; green stripes on the hydrant: [139, 96, 201, 177]; a red object: [272, 185, 359, 212]; the white wall behind the lego box: [1, 1, 382, 108]; yellow square box: [119, 44, 187, 103]; a black and white checkered pillow: [311, 83, 381, 114]; a small red light: [181, 192, 201, 212]; red and blue neon sign: [108, 176, 185, 188]; ; Region Captions: a black and white image of a sign that says sleemo: [0, 0, 383, 110]; a minecraft sandbox with a sandbox and a: [0, 99, 383, 113]; a grey box with a black letter on it: [93, 0, 290, 100]; a map of a mountain with a mountain in the middle: [186, 100, 197, 112]; a white sand beach with a white sand: [0, 105, 138, 107]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red and yellow object: [75, 64, 201, 212]; top of hydrant is yellow: [91, 68, 182, 160]; snow covering the ground: [0, 120, 382, 212]; a red and yellow object: [56, 38, 354, 209]; shadow of object on snow: [195, 160, 249, 190]; the sky is gray: [0, 1, 381, 130]; two shadows cast on the snow: [195, 131, 278, 193]; shadow of object on snow: [234, 134, 276, 159]; yellow and blue stripe on hydrant: [94, 68, 180, 92]; a brick wall: [336, 109, 383, 142]; blue and white square: [105, 107, 172, 136]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[102, 0, 281, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 125, 383, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[178, 125, 205, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[87, 71, 108, 142]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a door: [0, 0, 383, 135]; a black and white picture of a black and white picture: [102, 0, 281, 127]; a white and black image of a door: [0, 125, 383, 87]; a white and black image of a door: [178, 125, 205, 88]; a minecraft character with a red shirt: [87, 71, 108, 142]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a red and yellow object: [75, 64, 201, 212]; top of hydrant is yellow: [91, 68, 182, 160]; snow covering the ground: [0, 120, 382, 212]; a red and yellow object: [56, 38, 354, 209]; shadow of object on snow: [195, 160, 249, 190]; the sky is gray: [0, 1, 381, 130]; two shadows cast on the snow: [195, 131, 278, 193]; shadow of object on snow: [234, 134, 276, 159]; yellow and blue stripe on hydrant: [94, 68, 180, 92]; a brick wall: [336, 109, 383, 142]; blue and white square: [105, 107, 172, 136]; ; Region Captions: a black and white image of a room with a door: [0, 0, 383, 135]; a black and white picture of a black and white picture: [102, 0, 281, 127]; a white and black image of a door: [0, 125, 383, 87]; a white and black image of a door: [178, 125, 205, 88]; a minecraft character with a red shirt: [87, 71, 108, 142]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man in a red jacket is standing in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [33, 50, 352, 212]; the lego is multicolored: [0, 11, 76, 198]; the black square basket: [61, 43, 153, 71]; black stripes on the pole: [0, 63, 68, 142]; blue paint on the bench: [0, 135, 62, 193]; the brown box on the right: [154, 44, 203, 68]; gray square object in snow: [175, 74, 272, 131]; square shaped object in snow: [178, 97, 229, 125]; the wall is white: [50, 1, 358, 75]; shadow of the object: [1, 151, 81, 211]; the snow is white: [183, 127, 305, 201]; the objects are brown: [54, 37, 215, 75]; a black square object: [357, 50, 383, 82]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 64, 383, 148]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[104, 0, 279, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 110, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 138, 58, 48]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 64, 383, 148]; a black and white image of a city: [0, 0, 383, 82]; a black and white image of a tv: [104, 0, 279, 71]; a grey square with a white background: [0, 0, 110, 69]; a blue square with a black background: [0, 138, 58, 48]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man in a red jacket is standing in a minecraft room; Dense Caption: the ground is covered in snow: [33, 50, 352, 212]; the lego is multicolored: [0, 11, 76, 198]; the black square basket: [61, 43, 153, 71]; black stripes on the pole: [0, 63, 68, 142]; blue paint on the bench: [0, 135, 62, 193]; the brown box on the right: [154, 44, 203, 68]; gray square object in snow: [175, 74, 272, 131]; square shaped object in snow: [178, 97, 229, 125]; the wall is white: [50, 1, 358, 75]; shadow of the object: [1, 151, 81, 211]; the snow is white: [183, 127, 305, 201]; the objects are brown: [54, 37, 215, 75]; a black square object: [357, 50, 383, 82]; ; Region Captions: a black and white image of a snowy area: [0, 64, 383, 148]; a black and white image of a city: [0, 0, 383, 82]; a black and white image of a tv: [104, 0, 279, 71]; a grey square with a white background: [0, 0, 110, 69]; a blue square with a black background: [0, 138, 58, 48]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego ice cream cone is in the snow: [66, 16, 138, 124]; the ground is covered in snow: [35, 35, 347, 212]; black stripes on the base of the snowboard: [70, 50, 134, 92]; the shadow of a snowboarder: [254, 180, 347, 211]; yellow and blue square: [70, 18, 123, 56]; two square objects in the snow: [201, 70, 297, 111]; blue base of the umbrella: [91, 88, 128, 120]; a brown brick building: [124, 40, 194, 63]; the brown and yellow box in the right: [194, 41, 240, 63]; shadow of the object: [88, 105, 138, 130]; two black objects in the snow: [180, 54, 311, 133]; snowboarder in the snow: [58, 10, 189, 142]; snowboarders on the ground: [47, 12, 314, 136]; the sky is gray: [0, 0, 380, 74]; blue line on the hydrant: [100, 22, 115, 50]; the fence is brown: [124, 35, 241, 66]; black square in the snow: [204, 84, 248, 107]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 59, 383, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 72]\n",
      "process_ann took 0.00 seconds\n",
      "[158, 0, 225, 72]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 159, 72]\n",
      "process_ann took 0.00 seconds\n",
      "[71, 21, 62, 99]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person walking on the ground: [0, 59, 383, 153]; a silhouette of a building with a light shining on it: [0, 0, 383, 72]; a man is standing on a wall: [158, 0, 225, 72]; a black and white image of a wall: [0, 0, 159, 72]; a minecraft character with a red shirt and blue pants: [71, 21, 62, 99]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room in minecraft; Dense Caption: a lego ice cream cone is in the snow: [66, 16, 138, 124]; the ground is covered in snow: [35, 35, 347, 212]; black stripes on the base of the snowboard: [70, 50, 134, 92]; the shadow of a snowboarder: [254, 180, 347, 211]; yellow and blue square: [70, 18, 123, 56]; two square objects in the snow: [201, 70, 297, 111]; blue base of the umbrella: [91, 88, 128, 120]; a brown brick building: [124, 40, 194, 63]; the brown and yellow box in the right: [194, 41, 240, 63]; shadow of the object: [88, 105, 138, 130]; two black objects in the snow: [180, 54, 311, 133]; snowboarder in the snow: [58, 10, 189, 142]; snowboarders on the ground: [47, 12, 314, 136]; the sky is gray: [0, 0, 380, 74]; blue line on the hydrant: [100, 22, 115, 50]; the fence is brown: [124, 35, 241, 66]; black square in the snow: [204, 84, 248, 107]; ; Region Captions: a black and white image of a person walking on the ground: [0, 59, 383, 153]; a silhouette of a building with a light shining on it: [0, 0, 383, 72]; a man is standing on a wall: [158, 0, 225, 72]; a black and white image of a wall: [0, 0, 159, 72]; a minecraft character with a red shirt and blue pants: [71, 21, 62, 99]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a small room with a black block on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a small square basket: [141, 29, 218, 56]; the bed is made: [35, 42, 348, 209]; the wall is white: [0, 2, 381, 84]; the phone is black: [138, 1, 220, 56]; a bed in the room: [28, 10, 264, 140]; the snow is white: [190, 83, 297, 165]; the basket is made of wood: [132, 21, 228, 66]; the snow is white: [28, 80, 237, 208]; the handle of the lid: [162, 0, 188, 35]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 49, 383, 163]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[175, 0, 208, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 174, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 33, 75, 21]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a white surface with a black background: [0, 49, 383, 163]; a black and white image of a room with a light: [0, 0, 383, 73]; a gray piece of paper with a white background: [175, 0, 208, 59]; a gray wall with a black splatter: [0, 0, 174, 73]; a black block with a black background: [142, 33, 75, 21]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a small room with a black block on it; Dense Caption: a small square basket: [141, 29, 218, 56]; the bed is made: [35, 42, 348, 209]; the wall is white: [0, 2, 381, 84]; the phone is black: [138, 1, 220, 56]; a bed in the room: [28, 10, 264, 140]; the snow is white: [190, 83, 297, 165]; the basket is made of wood: [132, 21, 228, 66]; the snow is white: [28, 80, 237, 208]; the handle of the lid: [162, 0, 188, 35]; ; Region Captions: a white surface with a black background: [0, 49, 383, 163]; a black and white image of a room with a light: [0, 0, 383, 73]; a gray piece of paper with a white background: [175, 0, 208, 59]; a gray wall with a black splatter: [0, 0, 174, 73]; a black block with a black background: [142, 33, 75, 21]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a small woven basket: [265, 60, 382, 117]; the ground is white: [35, 73, 349, 211]; shadow of object on snow: [48, 100, 142, 151]; a lego ice cream cone is on the snow: [10, 39, 55, 96]; the wall is white: [23, 1, 359, 85]; the brown box on the ground: [48, 59, 102, 86]; yellow and blue paper: [12, 39, 45, 58]; the boxes are made of wood: [8, 34, 105, 97]; shadow of object on ground: [26, 81, 166, 172]; red wooden table leg: [12, 54, 52, 78]; blue base of a small lamp: [25, 74, 51, 95]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 82, 383, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[266, 65, 117, 51]\n",
      "process_ann took 0.00 seconds\n",
      "[50, 107, 89, 38]\n",
      "process_ann took 0.00 seconds\n",
      "[357, 0, 26, 67]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft map with a black and white background: [0, 82, 383, 130]; a black and white image of a building: [0, 0, 383, 83]; a black block with a black background: [266, 65, 117, 51]; a long piece of metal on a black background: [50, 107, 89, 38]; a black and white image of a triangle: [357, 0, 26, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: a small woven basket: [265, 60, 382, 117]; the ground is white: [35, 73, 349, 211]; shadow of object on snow: [48, 100, 142, 151]; a lego ice cream cone is on the snow: [10, 39, 55, 96]; the wall is white: [23, 1, 359, 85]; the brown box on the ground: [48, 59, 102, 86]; yellow and blue paper: [12, 39, 45, 58]; the boxes are made of wood: [8, 34, 105, 97]; shadow of object on ground: [26, 81, 166, 172]; red wooden table leg: [12, 54, 52, 78]; blue base of a small lamp: [25, 74, 51, 95]; ; Region Captions: a minecraft map with a black and white background: [0, 82, 383, 130]; a black and white image of a building: [0, 0, 383, 83]; a black block with a black background: [266, 65, 117, 51]; a long piece of metal on a black background: [50, 107, 89, 38]; a black and white image of a triangle: [357, 0, 26, 67]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a man standing in front of a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large woven basket: [265, 60, 382, 117]; white bedsheets on the bed: [35, 72, 349, 211]; shadow of object on ground: [48, 100, 142, 152]; the wall is white: [31, 1, 354, 85]; two brown square boxes: [30, 59, 103, 86]; blue object on the ground: [0, 78, 18, 100]; shadow of object on ground: [29, 85, 163, 170]; red and yellow striped flag: [0, 41, 22, 83]; the boxes are brown: [3, 42, 106, 91]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 83, 383, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 377, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[266, 65, 117, 51]\n",
      "process_ann took 0.00 seconds\n",
      "[50, 107, 89, 38]\n",
      "process_ann took 0.00 seconds\n",
      "[19, 63, 82, 21]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a minecraft map: [0, 83, 383, 129]; a man is standing in front of a black wall: [0, 0, 377, 83]; a black block with a black background: [266, 65, 117, 51]; a long piece of metal on a black background: [50, 107, 89, 38]; a brown block with a gold arrow on it: [19, 63, 82, 21]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a man standing in front of a box; Dense Caption: a large woven basket: [265, 60, 382, 117]; white bedsheets on the bed: [35, 72, 349, 211]; shadow of object on ground: [48, 100, 142, 152]; the wall is white: [31, 1, 354, 85]; two brown square boxes: [30, 59, 103, 86]; blue object on the ground: [0, 78, 18, 100]; shadow of object on ground: [29, 85, 163, 170]; red and yellow striped flag: [0, 41, 22, 83]; the boxes are brown: [3, 42, 106, 91]; ; Region Captions: a white and black image of a minecraft map: [0, 83, 383, 129]; a man is standing in front of a black wall: [0, 0, 377, 83]; a black block with a black background: [266, 65, 117, 51]; a long piece of metal on a black background: [50, 107, 89, 38]; a brown block with a gold arrow on it: [19, 63, 82, 21]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with red and blue blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "blue square on white plate: [246, 77, 356, 176]; a red cloth wrapped around a toy: [114, 69, 181, 128]; the snow is white: [37, 65, 349, 211]; the top of a book: [135, 171, 246, 211]; two brown square boxes: [151, 53, 210, 80]; a black basket in the background: [40, 51, 118, 85]; red and yellow cake: [112, 34, 146, 76]; legos on the ground: [75, 30, 210, 150]; the boxes are made of cardboard: [43, 4, 347, 133]; red box on white table: [103, 35, 187, 130]; yellow and white square: [116, 35, 140, 57]; a white wall: [1, 0, 109, 86]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 79, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 201]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 106, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[252, 83, 99, 88]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft map: [0, 79, 383, 133]; a silhouette of a man sitting in a room: [0, 0, 383, 201]; a black and white image of a room with a lamp: [0, 0, 383, 90]; a gray square with a black background: [0, 0, 106, 83]; a blue block on a black background: [252, 83, 99, 88]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with red and blue blocks; Dense Caption: blue square on white plate: [246, 77, 356, 176]; a red cloth wrapped around a toy: [114, 69, 181, 128]; the snow is white: [37, 65, 349, 211]; the top of a book: [135, 171, 246, 211]; two brown square boxes: [151, 53, 210, 80]; a black basket in the background: [40, 51, 118, 85]; red and yellow cake: [112, 34, 146, 76]; legos on the ground: [75, 30, 210, 150]; the boxes are made of cardboard: [43, 4, 347, 133]; red box on white table: [103, 35, 187, 130]; yellow and white square: [116, 35, 140, 57]; a white wall: [1, 0, 109, 86]; ; Region Captions: a black and white image of a minecraft map: [0, 79, 383, 133]; a silhouette of a man sitting in a room: [0, 0, 383, 201]; a black and white image of a room with a lamp: [0, 0, 383, 90]; a gray square with a black background: [0, 0, 106, 83]; a blue block on a black background: [252, 83, 99, 88]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red block and a red block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red square object: [220, 94, 299, 173]; a dark patterned bed: [48, 71, 172, 113]; there are two pillows: [33, 55, 342, 211]; two brown square boxes: [177, 75, 241, 102]; a white wall: [0, 0, 118, 118]; the bed is made: [32, 44, 268, 153]; a red box on the ground: [194, 84, 321, 190]; white blanket on the bed: [18, 112, 214, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 96, 383, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[109, 0, 274, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 116, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 172, 113]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a small black cat standing on a snowy hill: [0, 96, 383, 116]; a black and white image of a room with a door: [0, 0, 383, 113]; a black and white image of a sign: [109, 0, 274, 106]; a gray shaped block with a white background: [0, 0, 116, 113]; a grey shaped object with a white background: [0, 0, 172, 113]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red block and a red block; Dense Caption: a red square object: [220, 94, 299, 173]; a dark patterned bed: [48, 71, 172, 113]; there are two pillows: [33, 55, 342, 211]; two brown square boxes: [177, 75, 241, 102]; a white wall: [0, 0, 118, 118]; the bed is made: [32, 44, 268, 153]; a red box on the ground: [194, 84, 321, 190]; white blanket on the bed: [18, 112, 214, 210]; ; Region Captions: a small black cat standing on a snowy hill: [0, 96, 383, 116]; a black and white image of a room with a door: [0, 0, 383, 113]; a black and white image of a sign: [109, 0, 274, 106]; a gray shaped block with a white background: [0, 0, 116, 113]; a grey shaped object with a white background: [0, 0, 172, 113]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red, blue, and green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red fabric object: [200, 87, 261, 147]; a purple green and blue object: [305, 47, 383, 143]; the basket is made of wicker: [0, 74, 133, 117]; two brown square boxes: [140, 75, 201, 100]; white tablecloth on the table: [0, 88, 381, 212]; the green portion of the pail: [315, 49, 383, 100]; a blue decorative base: [308, 93, 382, 144]; the bed is made: [24, 32, 280, 177]; black square on the ground: [338, 167, 382, 208]; a white wall: [0, 0, 63, 85]; the wall is white: [44, 1, 340, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 96, 383, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[310, 50, 73, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 60, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 79, 131, 36]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft map with a black and white background: [0, 96, 383, 116]; a black and white image of a building with a clock: [0, 0, 383, 94]; a green and blue block on a black background: [310, 50, 73, 93]; a gray square with a black background: [0, 0, 60, 83]; a black block with a black background: [0, 79, 131, 36]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red, blue, and green block; Dense Caption: a red fabric object: [200, 87, 261, 147]; a purple green and blue object: [305, 47, 383, 143]; the basket is made of wicker: [0, 74, 133, 117]; two brown square boxes: [140, 75, 201, 100]; white tablecloth on the table: [0, 88, 381, 212]; the green portion of the pail: [315, 49, 383, 100]; a blue decorative base: [308, 93, 382, 144]; the bed is made: [24, 32, 280, 177]; black square on the ground: [338, 167, 382, 208]; a white wall: [0, 0, 63, 85]; the wall is white: [44, 1, 340, 94]; ; Region Captions: a minecraft map with a black and white background: [0, 96, 383, 116]; a black and white image of a building with a clock: [0, 0, 383, 94]; a green and blue block on a black background: [310, 50, 73, 93]; a gray square with a black background: [0, 0, 60, 83]; a black block with a black background: [0, 79, 131, 36]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red cloth object: [201, 87, 260, 147]; the basket is dark: [1, 74, 133, 117]; a purple green and blue box: [307, 48, 382, 143]; the basket is brown: [140, 75, 201, 100]; white tablecloth on the table: [0, 88, 382, 212]; yellow object on bed: [336, 111, 383, 206]; the green portion of the pail: [315, 49, 383, 100]; the bed is made: [24, 29, 280, 184]; a white wall: [0, 0, 63, 85]; the wall is white: [44, 1, 338, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[309, 50, 74, 154]\n",
      "process_ann took 0.00 seconds\n",
      "[310, 51, 73, 92]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft map with a snowy area: [0, 90, 383, 122]; a black and white image of a room with a black wall: [0, 0, 383, 171]; a black and white image of a city: [0, 0, 383, 94]; a green, yellow and blue block: [309, 50, 74, 154]; a green and blue square on a black background: [310, 51, 73, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with different colored blocks; Dense Caption: a red cloth object: [201, 87, 260, 147]; the basket is dark: [1, 74, 133, 117]; a purple green and blue box: [307, 48, 382, 143]; the basket is brown: [140, 75, 201, 100]; white tablecloth on the table: [0, 88, 382, 212]; yellow object on bed: [336, 111, 383, 206]; the green portion of the pail: [315, 49, 383, 100]; the bed is made: [24, 29, 280, 184]; a white wall: [0, 0, 63, 85]; the wall is white: [44, 1, 338, 94]; ; Region Captions: a minecraft map with a snowy area: [0, 90, 383, 122]; a black and white image of a room with a black wall: [0, 0, 383, 171]; a black and white image of a city: [0, 0, 383, 94]; a green, yellow and blue block: [309, 50, 74, 154]; a green and blue square on a black background: [310, 51, 73, 92]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red cloth object: [201, 87, 260, 147]; the basket is dark: [1, 74, 133, 117]; a purple green and blue box: [307, 48, 382, 143]; the basket is brown: [140, 75, 201, 100]; white tablecloth on the table: [0, 88, 382, 212]; yellow object on bed: [336, 111, 383, 206]; the green portion of the pail: [315, 49, 383, 100]; the bed is made: [24, 29, 280, 184]; a white wall: [0, 0, 63, 85]; the wall is white: [44, 1, 338, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[309, 50, 74, 154]\n",
      "process_ann took 0.00 seconds\n",
      "[310, 51, 73, 92]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft map with a snowy area: [0, 90, 383, 122]; a black and white image of a room with a black chair: [0, 0, 383, 171]; a black and white image of a building with a clock: [0, 0, 383, 94]; a green, yellow and blue block: [309, 50, 74, 154]; a green and blue square on a black background: [310, 51, 73, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with different colored blocks; Dense Caption: a red cloth object: [201, 87, 260, 147]; the basket is dark: [1, 74, 133, 117]; a purple green and blue box: [307, 48, 382, 143]; the basket is brown: [140, 75, 201, 100]; white tablecloth on the table: [0, 88, 382, 212]; yellow object on bed: [336, 111, 383, 206]; the green portion of the pail: [315, 49, 383, 100]; the bed is made: [24, 29, 280, 184]; a white wall: [0, 0, 63, 85]; the wall is white: [44, 1, 338, 94]; ; Region Captions: a minecraft map with a snowy area: [0, 90, 383, 122]; a black and white image of a room with a black chair: [0, 0, 383, 171]; a black and white image of a building with a clock: [0, 0, 383, 94]; a green, yellow and blue block: [309, 50, 74, 154]; a green and blue square on a black background: [310, 51, 73, 92]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a lot of different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red cloth object: [201, 88, 260, 146]; the basket is made of wicker: [1, 74, 133, 117]; purple and green box: [307, 48, 382, 143]; two brown square boxes: [140, 75, 201, 100]; white tablecloth on the table: [0, 87, 382, 212]; yellow object on the bed: [336, 111, 383, 206]; lego red and blue chair: [241, 57, 281, 102]; the green portion of the pail: [315, 49, 383, 100]; a white wall: [0, 0, 63, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[309, 50, 74, 154]\n",
      "process_ann took 0.00 seconds\n",
      "[310, 51, 73, 92]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black and white floor: [0, 0, 383, 212]; a minecraft map with a snowy area: [0, 90, 383, 122]; a black and white image of a city with a bottle: [0, 0, 383, 94]; a green, yellow and blue block: [309, 50, 74, 154]; a green and blue square on a black background: [310, 51, 73, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a lot of different colored blocks; Dense Caption: a red cloth object: [201, 88, 260, 146]; the basket is made of wicker: [1, 74, 133, 117]; purple and green box: [307, 48, 382, 143]; two brown square boxes: [140, 75, 201, 100]; white tablecloth on the table: [0, 87, 382, 212]; yellow object on the bed: [336, 111, 383, 206]; lego red and blue chair: [241, 57, 281, 102]; the green portion of the pail: [315, 49, 383, 100]; a white wall: [0, 0, 63, 85]; ; Region Captions: a black and white image of a room with a black and white floor: [0, 0, 383, 212]; a minecraft map with a snowy area: [0, 90, 383, 122]; a black and white image of a city with a bottle: [0, 0, 383, 94]; a green, yellow and blue block: [309, 50, 74, 154]; a green and blue square on a black background: [310, 51, 73, 92]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a few blocks and a mario\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red cloth object: [201, 88, 260, 146]; the basket is on the bed: [0, 74, 133, 117]; a purple green and blue box: [307, 48, 383, 143]; the box is brown: [140, 75, 201, 100]; white tablecloth on the table: [0, 87, 382, 211]; yellow object on the bed: [336, 111, 383, 206]; a blue and red flag: [85, 0, 183, 48]; the green portion of the pail: [315, 49, 383, 100]; a red chair in a room: [36, 10, 323, 201]; a white wall: [0, 0, 63, 84]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[309, 50, 74, 154]\n",
      "process_ann took 0.00 seconds\n",
      "[310, 51, 73, 92]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft room with a black and white background: [0, 0, 383, 212]; a minecraft map with a snowy area: [0, 90, 383, 122]; a black and white image of a man in a black shirt: [0, 0, 383, 94]; a green, yellow and blue block: [309, 50, 74, 154]; a green and blue square on a black background: [310, 51, 73, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a few blocks and a mario; Dense Caption: a red cloth object: [201, 88, 260, 146]; the basket is on the bed: [0, 74, 133, 117]; a purple green and blue box: [307, 48, 383, 143]; the box is brown: [140, 75, 201, 100]; white tablecloth on the table: [0, 87, 382, 211]; yellow object on the bed: [336, 111, 383, 206]; a blue and red flag: [85, 0, 183, 48]; the green portion of the pail: [315, 49, 383, 100]; a red chair in a room: [36, 10, 323, 201]; a white wall: [0, 0, 63, 84]; ; Region Captions: a minecraft room with a black and white background: [0, 0, 383, 212]; a minecraft map with a snowy area: [0, 90, 383, 122]; a black and white image of a man in a black shirt: [0, 0, 383, 94]; a green, yellow and blue block: [309, 50, 74, 154]; a green and blue square on a black background: [310, 51, 73, 92]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft scene with some blocks and a tv\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "yellow square on the end of the bed: [239, 80, 348, 164]; red and yellow box: [136, 26, 195, 119]; white tablecloth on the table: [1, 54, 382, 210]; the green colored object on the table: [228, 29, 309, 101]; a brown wicker basket: [0, 54, 85, 104]; lego blocks on the floor: [82, 18, 347, 167]; square red section of the base: [143, 76, 190, 118]; green square on the top of the cake: [244, 29, 307, 75]; a black and white patterned basket: [300, 53, 383, 85]; two brown square boxes: [91, 53, 143, 82]; the wall is white: [0, 0, 380, 68]; the chair is red and yellow: [95, 21, 224, 159]; yellow part of the cake: [138, 28, 189, 78]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 74, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[242, 84, 105, 78]\n",
      "process_ann took 0.00 seconds\n",
      "[140, 31, 47, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[119, 31, 73, 85]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft map: [0, 74, 383, 138]; a city with a skyscraper in the background: [0, 0, 383, 76]; a yellow block on a black background: [242, 84, 105, 78]; a yellow and red striped bag: [140, 31, 47, 85]; a red, yellow and blue flag: [119, 31, 73, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft scene with some blocks and a tv; Dense Caption: yellow square on the end of the bed: [239, 80, 348, 164]; red and yellow box: [136, 26, 195, 119]; white tablecloth on the table: [1, 54, 382, 210]; the green colored object on the table: [228, 29, 309, 101]; a brown wicker basket: [0, 54, 85, 104]; lego blocks on the floor: [82, 18, 347, 167]; square red section of the base: [143, 76, 190, 118]; green square on the top of the cake: [244, 29, 307, 75]; a black and white patterned basket: [300, 53, 383, 85]; two brown square boxes: [91, 53, 143, 82]; the wall is white: [0, 0, 380, 68]; the chair is red and yellow: [95, 21, 224, 159]; yellow part of the cake: [138, 28, 189, 78]; ; Region Captions: a black and white image of a minecraft map: [0, 74, 383, 138]; a city with a skyscraper in the background: [0, 0, 383, 76]; a yellow block on a black background: [242, 84, 105, 78]; a yellow and red striped bag: [140, 31, 47, 85]; a red, yellow and blue flag: [119, 31, 73, 85]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a person standing next to it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and blue toy: [121, 21, 261, 156]; white tablecloth on the table: [0, 59, 382, 211]; lego blocks on the floor: [92, 17, 359, 165]; a red white and blue candle: [293, 63, 330, 136]; orange square on the green fabric: [181, 24, 255, 99]; yellow square of the cake: [100, 68, 137, 112]; brown wooden box on a white table: [324, 64, 383, 107]; the letter a on a cake: [288, 27, 353, 144]; blue square on the green and yellow book: [135, 88, 185, 143]; shadow of the toothbrush: [277, 113, 331, 141]; the vase is colorful: [127, 22, 189, 152]; a black box on the floor: [60, 51, 128, 70]; the white wall behind the table: [70, 0, 338, 69]; yellow and blue card with a p on it: [294, 32, 352, 70]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 66, 383, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[89, 0, 257, 63]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 97, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 29, 55, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[136, 89, 109, 65]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small black and white building: [0, 66, 383, 146]; a black and white image of a city: [89, 0, 257, 63]; a gray paper clip with a black background: [0, 0, 97, 73]; a green and blue square on a black background: [129, 29, 55, 113]; a blue and green square on a black background: [136, 89, 109, 65]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a person standing next to it; Dense Caption: green and blue toy: [121, 21, 261, 156]; white tablecloth on the table: [0, 59, 382, 211]; lego blocks on the floor: [92, 17, 359, 165]; a red white and blue candle: [293, 63, 330, 136]; orange square on the green fabric: [181, 24, 255, 99]; yellow square of the cake: [100, 68, 137, 112]; brown wooden box on a white table: [324, 64, 383, 107]; the letter a on a cake: [288, 27, 353, 144]; blue square on the green and yellow book: [135, 88, 185, 143]; shadow of the toothbrush: [277, 113, 331, 141]; the vase is colorful: [127, 22, 189, 152]; a black box on the floor: [60, 51, 128, 70]; the white wall behind the table: [70, 0, 338, 69]; yellow and blue card with a p on it: [294, 32, 352, 70]; ; Region Captions: a black and white image of a small black and white building: [0, 66, 383, 146]; a black and white image of a city: [89, 0, 257, 63]; a gray paper clip with a black background: [0, 0, 97, 73]; a green and blue square on a black background: [129, 29, 55, 113]; a blue and green square on a black background: [136, 89, 109, 65]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with colorful blocks in the background\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "red and yellow box: [175, 93, 213, 150]; a yellow piece of luggage: [215, 125, 270, 186]; white snow covering the ground: [0, 123, 382, 212]; green and blue box: [258, 92, 300, 160]; legos on the ground: [47, 47, 339, 206]; a small black box: [86, 109, 168, 133]; the suitcases are yellow red and green: [165, 84, 311, 189]; a blue section of a wall: [262, 123, 300, 159]; the walls are white: [0, 1, 381, 140]; white blanket on the bed: [2, 136, 169, 211]; square red section of the pillar: [176, 119, 211, 149]; the floor is white: [34, 53, 201, 189]; the snow is white: [67, 147, 173, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 161]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 126, 383, 86]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 0, 252, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 128, 139]\n",
      "process_ann took 0.00 seconds\n",
      "[218, 128, 49, 57]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.74 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man in a room with a wall: [0, 0, 383, 161]; a black and white image of a snowy mountain: [0, 126, 383, 86]; a silhouette of a city with a skyscraper: [131, 0, 252, 134]; a gray t shirt with the word nebraska on it: [0, 0, 128, 139]; a yellow block on a black background: [218, 128, 49, 57]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with colorful blocks in the background; Dense Caption: red and yellow box: [175, 93, 213, 150]; a yellow piece of luggage: [215, 125, 270, 186]; white snow covering the ground: [0, 123, 382, 212]; green and blue box: [258, 92, 300, 160]; legos on the ground: [47, 47, 339, 206]; a small black box: [86, 109, 168, 133]; the suitcases are yellow red and green: [165, 84, 311, 189]; a blue section of a wall: [262, 123, 300, 159]; the walls are white: [0, 1, 381, 140]; white blanket on the bed: [2, 136, 169, 211]; square red section of the pillar: [176, 119, 211, 149]; the floor is white: [34, 53, 201, 189]; the snow is white: [67, 147, 173, 208]; ; Region Captions: a silhouette of a man in a room with a wall: [0, 0, 383, 161]; a black and white image of a snowy mountain: [0, 126, 383, 86]; a silhouette of a city with a skyscraper: [131, 0, 252, 134]; a gray t shirt with the word nebraska on it: [0, 0, 128, 139]; a yellow block on a black background: [218, 128, 49, 57]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with colorful blocks in the background\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "red and yellow box: [175, 93, 213, 150]; a yellow piece of luggage: [215, 125, 270, 186]; white snow covering the ground: [0, 123, 382, 212]; green and blue box: [258, 92, 300, 160]; legos on the ground: [47, 47, 339, 206]; a small black box: [86, 109, 168, 133]; the suitcases are yellow red and green: [165, 84, 311, 189]; a blue section of a wall: [262, 123, 300, 159]; the walls are white: [0, 1, 381, 140]; white blanket on the bed: [2, 136, 169, 211]; square red section of the pillar: [176, 120, 210, 149]; the floor is white: [34, 53, 201, 189]; the snow is white: [67, 147, 173, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 161]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 127, 383, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 0, 252, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 128, 139]\n",
      "process_ann took 0.00 seconds\n",
      "[218, 128, 49, 57]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man in a room with a wall: [0, 0, 383, 161]; a black and white image of a snowy mountain: [0, 127, 383, 85]; a silhouette of a city with a tree in the background: [131, 0, 252, 134]; a gray t shirt with the word nebraska on it: [0, 0, 128, 139]; a yellow block on a black background: [218, 128, 49, 57]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with colorful blocks in the background; Dense Caption: red and yellow box: [175, 93, 213, 150]; a yellow piece of luggage: [215, 125, 270, 186]; white snow covering the ground: [0, 123, 382, 212]; green and blue box: [258, 92, 300, 160]; legos on the ground: [47, 47, 339, 206]; a small black box: [86, 109, 168, 133]; the suitcases are yellow red and green: [165, 84, 311, 189]; a blue section of a wall: [262, 123, 300, 159]; the walls are white: [0, 1, 381, 140]; white blanket on the bed: [2, 136, 169, 211]; square red section of the pillar: [176, 120, 210, 149]; the floor is white: [34, 53, 201, 189]; the snow is white: [67, 147, 173, 208]; ; Region Captions: a silhouette of a man in a room with a wall: [0, 0, 383, 161]; a black and white image of a snowy mountain: [0, 127, 383, 85]; a silhouette of a city with a tree in the background: [131, 0, 252, 134]; a gray t shirt with the word nebraska on it: [0, 0, 128, 139]; a yellow block on a black background: [218, 128, 49, 57]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210413_195827 44\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character with a sword\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and orange cone shaped sign: [181, 0, 302, 184]; snow covering the ground: [1, 56, 382, 211]; the orange sign on the post: [190, 0, 297, 82]; green and brown striped sign: [186, 71, 281, 179]; a green and orange construction sign: [106, 2, 330, 208]; a digital display: [108, 188, 277, 212]; a snow covered fence: [4, 54, 68, 94]; a red box: [271, 184, 359, 212]; a red light on a sign: [181, 192, 201, 212]; a toy train under a green umbrella: [105, 158, 277, 211]; a blue and green snow globe: [278, 111, 323, 153]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 72, 383, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 195, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "[191, 0, 103, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[287, 0, 96, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.80 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing on a platform: [0, 72, 383, 140]; a map of new york state: [0, 72, 195, 140]; a black and white image of a man standing in front of a black wall: [0, 0, 383, 74]; a block of orange and white: [191, 0, 103, 83]; a gray png image of a black png: [287, 0, 96, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character with a sword; Dense Caption: green and orange cone shaped sign: [181, 0, 302, 184]; snow covering the ground: [1, 56, 382, 211]; the orange sign on the post: [190, 0, 297, 82]; green and brown striped sign: [186, 71, 281, 179]; a green and orange construction sign: [106, 2, 330, 208]; a digital display: [108, 188, 277, 212]; a snow covered fence: [4, 54, 68, 94]; a red box: [271, 184, 359, 212]; a red light on a sign: [181, 192, 201, 212]; a toy train under a green umbrella: [105, 158, 277, 211]; a blue and green snow globe: [278, 111, 323, 153]; ; Region Captions: a silhouette of a man standing on a platform: [0, 72, 383, 140]; a map of new york state: [0, 72, 195, 140]; a black and white image of a man standing in front of a black wall: [0, 0, 383, 74]; a block of orange and white: [191, 0, 103, 83]; a gray png image of a black png: [287, 0, 96, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a square in a room with a white floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "kite in the air: [68, 121, 157, 183]; a snow covered ground: [39, 58, 348, 213]; a square shaped object: [146, 45, 223, 71]; object in the snow: [46, 108, 182, 199]; the wall is white: [0, 1, 381, 92]; a black and white photo: [32, 8, 323, 159]; the object is in the background: [136, 32, 237, 81]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 65, 383, 147]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[183, 0, 200, 78]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 181, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 52, 146, 33]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a small black diamond in the snow: [0, 65, 383, 147]; a black and white image of a room with a corner: [0, 0, 383, 84]; a black and white image of a man with a hat: [183, 0, 200, 78]; a gray teflon tipped slingshot: [0, 0, 181, 84]; a black and gray striped knife: [0, 52, 146, 33]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a square in a room with a white floor; Dense Caption: kite in the air: [68, 121, 157, 183]; a snow covered ground: [39, 58, 348, 213]; a square shaped object: [146, 45, 223, 71]; object in the snow: [46, 108, 182, 199]; the wall is white: [0, 1, 381, 92]; a black and white photo: [32, 8, 323, 159]; the object is in the background: [136, 32, 237, 81]; ; Region Captions: a small black diamond in the snow: [0, 65, 383, 147]; a black and white image of a room with a corner: [0, 0, 383, 84]; a black and white image of a man with a hat: [183, 0, 200, 78]; a gray teflon tipped slingshot: [0, 0, 181, 84]; a black and gray striped knife: [0, 52, 146, 33]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a square in a room with a square in the middle\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black object: [45, 127, 147, 209]; a bed in a room: [35, 53, 348, 212]; a small square basket: [159, 34, 245, 67]; a bed in the room: [41, 8, 346, 150]; the walls are white: [0, 2, 382, 91]; the snow is white in color: [103, 74, 200, 130]; the snow is white in color: [188, 81, 298, 157]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 59, 383, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 77]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 199, 77]\n",
      "process_ann took 0.00 seconds\n",
      "[201, 0, 182, 74]\n",
      "process_ann took 0.00 seconds\n",
      "[204, 0, 179, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a small square in the middle of a snowy field: [0, 59, 383, 153]; a black and white image of a room with a door: [0, 0, 383, 77]; a gray t shirt with a black background: [0, 0, 199, 77]; a black and white image of a tv screen: [201, 0, 182, 74]; a man is standing on a hill with a black background: [204, 0, 179, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a square in a room with a square in the middle; Dense Caption: a black object: [45, 127, 147, 209]; a bed in a room: [35, 53, 348, 212]; a small square basket: [159, 34, 245, 67]; a bed in the room: [41, 8, 346, 150]; the walls are white: [0, 2, 382, 91]; the snow is white in color: [103, 74, 200, 130]; the snow is white in color: [188, 81, 298, 157]; ; Region Captions: a small square in the middle of a snowy field: [0, 59, 383, 153]; a black and white image of a room with a door: [0, 0, 383, 77]; a gray t shirt with a black background: [0, 0, 199, 77]; a black and white image of a tv screen: [201, 0, 182, 74]; a man is standing on a hill with a black background: [204, 0, 179, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a bed and a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the shadow of the snowboarder: [152, 144, 243, 212]; the box is brown: [182, 68, 254, 102]; a brown wicker basket: [65, 63, 181, 105]; a bed in a room: [0, 80, 381, 212]; the boxes are made of cardboard: [55, 28, 288, 120]; the bed is made: [44, 19, 314, 193]; the basket is made of wicker: [50, 47, 190, 118]; the wall is white: [119, 12, 343, 131]; the walls are white: [0, 1, 381, 115]; a yellow square pillow: [200, 71, 226, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 89, 383, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[128, 0, 255, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 133, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[155, 148, 85, 65]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a mountain: [0, 89, 383, 123]; a black and white image of a room with a black wall: [0, 0, 383, 112]; a black and gray wall with a black and gray wall: [128, 0, 255, 112]; a gray shaped block with a white background: [0, 0, 133, 102]; a gray square on a black background: [155, 148, 85, 65]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a bed and a table; Dense Caption: the shadow of the snowboarder: [152, 144, 243, 212]; the box is brown: [182, 68, 254, 102]; a brown wicker basket: [65, 63, 181, 105]; a bed in a room: [0, 80, 381, 212]; the boxes are made of cardboard: [55, 28, 288, 120]; the bed is made: [44, 19, 314, 193]; the basket is made of wicker: [50, 47, 190, 118]; the wall is white: [119, 12, 343, 131]; the walls are white: [0, 1, 381, 115]; a yellow square pillow: [200, 71, 226, 98]; ; Region Captions: a black and white image of a mountain: [0, 89, 383, 123]; a black and white image of a room with a black wall: [0, 0, 383, 112]; a black and gray wall with a black and gray wall: [128, 0, 255, 112]; a gray shaped block with a white background: [0, 0, 133, 102]; a gray square on a black background: [155, 148, 85, 65]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green square on white table: [148, 47, 238, 139]; white table top: [1, 24, 382, 213]; the basket is made of wicker: [112, 15, 200, 44]; green object on white table: [119, 34, 266, 159]; white wall behind table: [0, 1, 381, 64]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 36, 383, 176]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 63]\n",
      "process_ann took 0.00 seconds\n",
      "[151, 0, 232, 44]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 150, 63]\n",
      "process_ann took 0.00 seconds\n",
      "[152, 52, 83, 85]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black square sitting on top of a white surface: [0, 36, 383, 176]; a black and white image of a room with a black floor: [0, 0, 383, 63]; a gray png file with a black background: [151, 0, 232, 44]; a gray teddy bear with a black background: [0, 0, 150, 63]; a green block on a black background: [152, 52, 83, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: green square on white table: [148, 47, 238, 139]; white table top: [1, 24, 382, 213]; the basket is made of wicker: [112, 15, 200, 44]; green object on white table: [119, 34, 266, 159]; white wall behind table: [0, 1, 381, 64]; ; Region Captions: a black square sitting on top of a white surface: [0, 36, 383, 176]; a black and white image of a room with a black floor: [0, 0, 383, 63]; a gray png file with a black background: [151, 0, 232, 44]; a gray teddy bear with a black background: [0, 0, 150, 63]; a green block on a black background: [152, 52, 83, 85]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person in a minecraft game standing next to a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [169, 58, 306, 147]; lego man in room: [38, 17, 175, 159]; the boxes are made of cardboard: [34, 11, 314, 191]; the black and white checkered box behind the stop sign: [30, 51, 180, 116]; yellow gift bag with blue writing: [48, 17, 121, 69]; blue pants on the person: [77, 108, 135, 156]; red and black checkered tablecloth: [55, 59, 139, 116]; white carpet on floor: [0, 76, 382, 210]; blue triangle on box: [82, 21, 108, 60]; shadow of a snowboarder: [75, 129, 140, 166]; the lego is holding a surfboard: [46, 17, 140, 117]; black and white stripes: [100, 60, 138, 116]; a white tag on a bag: [139, 81, 155, 100]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 87, 383, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[133, 0, 250, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[173, 65, 129, 79]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 137, 89]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person on a snowy hill: [0, 87, 383, 125]; a black and white image of a room with a black chair: [0, 0, 383, 160]; a gray wall with a black arrow on it: [133, 0, 250, 160]; a block of wood in minecraft: [173, 65, 129, 79]; a silhouette of a man in a hat: [0, 0, 137, 89]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person in a minecraft game standing next to a box; Dense Caption: the box is brown: [169, 58, 306, 147]; lego man in room: [38, 17, 175, 159]; the boxes are made of cardboard: [34, 11, 314, 191]; the black and white checkered box behind the stop sign: [30, 51, 180, 116]; yellow gift bag with blue writing: [48, 17, 121, 69]; blue pants on the person: [77, 108, 135, 156]; red and black checkered tablecloth: [55, 59, 139, 116]; white carpet on floor: [0, 76, 382, 210]; blue triangle on box: [82, 21, 108, 60]; shadow of a snowboarder: [75, 129, 140, 166]; the lego is holding a surfboard: [46, 17, 140, 117]; black and white stripes: [100, 60, 138, 116]; a white tag on a bag: [139, 81, 155, 100]; ; Region Captions: a black and white image of a person on a snowy hill: [0, 87, 383, 125]; a black and white image of a room with a black chair: [0, 0, 383, 160]; a gray wall with a black arrow on it: [133, 0, 250, 160]; a block of wood in minecraft: [173, 65, 129, 79]; a silhouette of a man in a hat: [0, 0, 137, 89]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown box: [217, 76, 359, 162]; black stripes on the pole: [140, 76, 195, 120]; white tablecloth on the table: [0, 90, 382, 211]; lego person is holding a snowboard: [116, 43, 221, 158]; blue square of umbrella: [149, 113, 180, 154]; shadow of the object: [139, 134, 191, 162]; a square yellow and blue tag: [139, 45, 185, 82]; the boxes are made of cardboard: [78, 31, 357, 185]; blue sticker on the yellow fridge: [162, 48, 176, 76]; blue and black base of umbrella: [145, 80, 180, 152]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 98, 383, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[185, 0, 198, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 327, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 184, 103]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a chair: [0, 0, 383, 160]; a person is walking down a snowy path: [0, 98, 383, 114]; a black and gray png image of a tv: [185, 0, 198, 160]; a black and white image of a wall: [0, 0, 327, 103]; a gray png file with the word california: [0, 0, 184, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a brown box: [217, 76, 359, 162]; black stripes on the pole: [140, 76, 195, 120]; white tablecloth on the table: [0, 90, 382, 211]; lego person is holding a snowboard: [116, 43, 221, 158]; blue square of umbrella: [149, 113, 180, 154]; shadow of the object: [139, 134, 191, 162]; a square yellow and blue tag: [139, 45, 185, 82]; the boxes are made of cardboard: [78, 31, 357, 185]; blue sticker on the yellow fridge: [162, 48, 176, 76]; blue and black base of umbrella: [145, 80, 180, 152]; ; Region Captions: a black and white image of a room with a chair: [0, 0, 383, 160]; a person is walking down a snowy path: [0, 98, 383, 114]; a black and gray png image of a tv: [185, 0, 198, 160]; a black and white image of a wall: [0, 0, 327, 103]; a gray png file with the word california: [0, 0, 184, 103]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown and white box: [156, 115, 382, 211]; a black and white checkered tablecloth: [0, 114, 123, 211]; the sky is dark: [38, 3, 349, 187]; a line of white light: [228, 119, 341, 211]; two beds are next to each other: [10, 96, 374, 210]; a brown wooden foot board: [158, 120, 246, 211]; the sky is overcast: [86, 5, 359, 105]; a sheet of plywood: [230, 120, 335, 150]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 172]\n",
      "process_ann took 0.00 seconds\n",
      "[159, 123, 224, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 122, 119, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[231, 123, 107, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[159, 123, 88, 90]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.74 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a cloudy sky: [0, 1, 383, 172]; a wooden block with a brown and white stripe: [159, 123, 224, 90]; a black and white square block: [0, 122, 119, 91]; a wooden plank on a black background: [231, 123, 107, 90]; a wooden box with a wooden frame: [159, 123, 88, 90]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: a brown and white box: [156, 115, 382, 211]; a black and white checkered tablecloth: [0, 114, 123, 211]; the sky is dark: [38, 3, 349, 187]; a line of white light: [228, 119, 341, 211]; two beds are next to each other: [10, 96, 374, 210]; a brown wooden foot board: [158, 120, 246, 211]; the sky is overcast: [86, 5, 359, 105]; a sheet of plywood: [230, 120, 335, 150]; ; Region Captions: a black and white image of a building with a cloudy sky: [0, 1, 383, 172]; a wooden block with a brown and white stripe: [159, 123, 224, 90]; a black and white square block: [0, 122, 119, 91]; a wooden plank on a black background: [231, 123, 107, 90]; a wooden box with a wooden frame: [159, 123, 88, 90]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a room with a window\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the floor is white: [34, 145, 344, 211]; green pillow on the bed: [63, 151, 113, 190]; a large screen on the stage: [117, 1, 321, 159]; the photo is black and white: [0, 2, 381, 206]; a small basket on the table: [263, 142, 331, 164]; a wire mesh is on the top of the tower: [122, 0, 203, 21]; the wall is white in color: [158, 30, 263, 125]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[133, 0, 174, 154]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 139, 161]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 153, 383, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[287, 0, 96, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[66, 156, 44, 31]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a gray square with a black background: [133, 0, 174, 154]; a grey box with a white arrow on it: [0, 0, 139, 161]; a white bird with a black background: [0, 153, 383, 60]; a grey box with a white lid: [287, 0, 96, 158]; a green block on a black background: [66, 156, 44, 31]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a room with a window; Dense Caption: the floor is white: [34, 145, 344, 211]; green pillow on the bed: [63, 151, 113, 190]; a large screen on the stage: [117, 1, 321, 159]; the photo is black and white: [0, 2, 381, 206]; a small basket on the table: [263, 142, 331, 164]; a wire mesh is on the top of the tower: [122, 0, 203, 21]; the wall is white in color: [158, 30, 263, 125]; ; Region Captions: a gray square with a black background: [133, 0, 174, 154]; a grey box with a white arrow on it: [0, 0, 139, 161]; a white bird with a black background: [0, 153, 383, 60]; a grey box with a white lid: [287, 0, 96, 158]; a green block on a black background: [66, 156, 44, 31]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft bed with a wooden frame\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the square box on the ground: [121, 51, 261, 108]; a checkered blanket on a bed: [0, 51, 105, 191]; white snow on the ground: [34, 77, 347, 212]; a line of yellow tote boxes: [169, 54, 217, 105]; the sky is cloudy: [35, 1, 349, 71]; the bench is brown: [25, 20, 279, 184]; a brown wood slat: [122, 54, 172, 107]; a brown wood slat: [212, 53, 260, 103]; a line of holes in the top of the bench: [169, 52, 216, 67]; a reflection on the book: [170, 49, 217, 79]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 85, 383, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 58, 104, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[171, 56, 45, 48]\n",
      "process_ann took 0.00 seconds\n",
      "[123, 57, 47, 17]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a white png image of a snowy surface: [0, 85, 383, 127]; a black and white image of a building with a cloudy sky: [0, 1, 383, 90]; a black and white block of bricks: [0, 58, 104, 128]; a wooden block on a black background: [171, 56, 45, 48]; a wooden plank on a black background: [123, 57, 47, 17]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft bed with a wooden frame; Dense Caption: the square box on the ground: [121, 51, 261, 108]; a checkered blanket on a bed: [0, 51, 105, 191]; white snow on the ground: [34, 77, 347, 212]; a line of yellow tote boxes: [169, 54, 217, 105]; the sky is cloudy: [35, 1, 349, 71]; the bench is brown: [25, 20, 279, 184]; a brown wood slat: [122, 54, 172, 107]; a brown wood slat: [212, 53, 260, 103]; a line of holes in the top of the bench: [169, 52, 216, 67]; a reflection on the book: [170, 49, 217, 79]; ; Region Captions: a white png image of a snowy surface: [0, 85, 383, 127]; a black and white image of a building with a cloudy sky: [0, 1, 383, 90]; a black and white block of bricks: [0, 58, 104, 128]; a wooden block on a black background: [171, 56, 45, 48]; a wooden plank on a black background: [123, 57, 47, 17]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a green block and a black block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black speaker: [142, 54, 235, 146]; white tablecloth on the table: [0, 14, 382, 209]; green colored pillow on the bed: [270, 39, 353, 106]; the brown box on the right: [1, 29, 117, 79]; a blue and yellow flag: [341, 5, 383, 85]; the basket is brown: [223, 22, 299, 47]; the flag is green blue white and red: [267, 6, 383, 111]; the black box on the table: [106, 36, 283, 167]; the wall is white: [37, 1, 349, 81]; a brown wood slat: [43, 35, 89, 71]; a yellow and white tag: [353, 5, 383, 34]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 42, 383, 170]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 72]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 254, 72]\n",
      "process_ann took 0.00 seconds\n",
      "[145, 59, 87, 86]\n",
      "process_ann took 0.00 seconds\n",
      "[234, 0, 149, 49]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft map: [0, 42, 383, 170]; a black and white image of a wall: [0, 0, 383, 72]; a black and white image of a building: [0, 0, 254, 72]; a black cube on a white background: [145, 59, 87, 86]; a man is standing on a stairway: [234, 0, 149, 49]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a green block and a black block; Dense Caption: a black speaker: [142, 54, 235, 146]; white tablecloth on the table: [0, 14, 382, 209]; green colored pillow on the bed: [270, 39, 353, 106]; the brown box on the right: [1, 29, 117, 79]; a blue and yellow flag: [341, 5, 383, 85]; the basket is brown: [223, 22, 299, 47]; the flag is green blue white and red: [267, 6, 383, 111]; the black box on the table: [106, 36, 283, 167]; the wall is white: [37, 1, 349, 81]; a brown wood slat: [43, 35, 89, 71]; a yellow and white tag: [353, 5, 383, 34]; ; Region Captions: a black and white image of a minecraft map: [0, 42, 383, 170]; a black and white image of a wall: [0, 0, 383, 72]; a black and white image of a building: [0, 0, 254, 72]; a black cube on a white background: [145, 59, 87, 86]; a man is standing on a stairway: [234, 0, 149, 49]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a green block and a green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the basket is made of plastic: [102, 41, 181, 71]; green colored square on the right: [295, 56, 382, 140]; white table top: [1, 44, 381, 211]; the remote is black: [75, 11, 214, 115]; black keys on a keyboard: [346, 12, 383, 80]; the white wall next to the bed: [109, 0, 375, 56]; the bed is made: [127, 4, 369, 167]; the book is green: [278, 9, 383, 150]; a white wall: [0, 1, 120, 133]; the bed is white: [50, 87, 256, 207]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 56, 383, 156]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 379, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[115, 0, 264, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 118, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[298, 16, 85, 121]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a white png of a snowy road: [0, 56, 383, 156]; a room with a door and a wall: [0, 0, 379, 129]; a grey png file with a black background: [115, 0, 264, 56]; a grey wall with a black splatter: [0, 0, 118, 130]; a black and green block on top of a green grass: [298, 16, 85, 121]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a green block and a green block; Dense Caption: the basket is made of plastic: [102, 41, 181, 71]; green colored square on the right: [295, 56, 382, 140]; white table top: [1, 44, 381, 211]; the remote is black: [75, 11, 214, 115]; black keys on a keyboard: [346, 12, 383, 80]; the white wall next to the bed: [109, 0, 375, 56]; the bed is made: [127, 4, 369, 167]; the book is green: [278, 9, 383, 150]; a white wall: [0, 1, 120, 133]; the bed is white: [50, 87, 256, 207]; ; Region Captions: a white png of a snowy road: [0, 56, 383, 156]; a room with a door and a wall: [0, 0, 379, 129]; a grey png file with a black background: [115, 0, 264, 56]; a grey wall with a black splatter: [0, 0, 118, 130]; a black and green block on top of a green grass: [298, 16, 85, 121]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a person standing on a square\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black square object: [268, 52, 366, 118]; white tablecloth on the table: [1, 32, 381, 211]; a black and green paper bag: [109, 4, 203, 96]; a red and yellow object: [121, 14, 146, 48]; a green piece of luggage: [112, 48, 197, 93]; shadow of the sculpture: [238, 110, 323, 154]; the back of a chair: [65, 0, 326, 45]; a black box on the table: [257, 25, 329, 47]; the middle black cake: [147, 4, 197, 56]; a black bench: [239, 46, 371, 151]; a toy on the table: [79, 4, 272, 149]; the snow is white: [45, 114, 167, 192]; a black square object: [65, 26, 124, 46]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 42, 383, 170]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[88, 0, 218, 39]\n",
      "process_ann took 0.00 seconds\n",
      "[114, 6, 81, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[271, 57, 93, 59]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a square in a minecraft world: [0, 42, 383, 170]; a silhouette of a city with a building in the background: [0, 0, 383, 57]; a black and white image of a city with tall buildings: [88, 0, 218, 39]; a black and green block on top of a green grass: [114, 6, 81, 87]; a black block on a white background: [271, 57, 93, 59]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a person standing on a square; Dense Caption: a black square object: [268, 52, 366, 118]; white tablecloth on the table: [1, 32, 381, 211]; a black and green paper bag: [109, 4, 203, 96]; a red and yellow object: [121, 14, 146, 48]; a green piece of luggage: [112, 48, 197, 93]; shadow of the sculpture: [238, 110, 323, 154]; the back of a chair: [65, 0, 326, 45]; a black box on the table: [257, 25, 329, 47]; the middle black cake: [147, 4, 197, 56]; a black bench: [239, 46, 371, 151]; a toy on the table: [79, 4, 272, 149]; the snow is white: [45, 114, 167, 192]; a black square object: [65, 26, 124, 46]; ; Region Captions: a black and white image of a square in a minecraft world: [0, 42, 383, 170]; a silhouette of a city with a building in the background: [0, 0, 383, 57]; a black and white image of a city with tall buildings: [88, 0, 218, 39]; a black and green block on top of a green grass: [114, 6, 81, 87]; a black block on a white background: [271, 57, 93, 59]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a person in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [200, 67, 278, 124]; toy truck in the snow: [64, 37, 123, 117]; a bed in a room: [28, 46, 347, 211]; square shaped dark box: [123, 59, 211, 95]; the boxes are brown: [177, 38, 311, 164]; yellow and blue fire hydrant: [71, 41, 106, 68]; blue wooden bench leg: [70, 82, 117, 110]; red and yellow sign: [73, 62, 112, 90]; shadow of object on ground: [0, 144, 56, 198]; a toy on the snow: [40, 27, 150, 146]; black object in the forefront: [0, 86, 27, 150]; the boxes are made of cardboard: [44, 27, 311, 152]; the snow is white: [41, 110, 243, 211]; shadow of the person: [79, 100, 116, 116]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 82, 383, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 174]\n",
      "process_ann took 0.00 seconds\n",
      "[192, 0, 191, 173]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 189, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[126, 64, 83, 29]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.76 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a person walking down a hallway: [0, 82, 383, 130]; a black and white image of a wall: [2, 0, 381, 174]; a gray wall with a black arrow on it: [192, 0, 191, 173]; a pixelated image of a man standing in front of a building: [0, 0, 189, 85]; a black box with a black handle: [126, 64, 83, 29]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a person in a room; Dense Caption: the box is brown: [200, 67, 278, 124]; toy truck in the snow: [64, 37, 123, 117]; a bed in a room: [28, 46, 347, 211]; square shaped dark box: [123, 59, 211, 95]; the boxes are brown: [177, 38, 311, 164]; yellow and blue fire hydrant: [71, 41, 106, 68]; blue wooden bench leg: [70, 82, 117, 110]; red and yellow sign: [73, 62, 112, 90]; shadow of object on ground: [0, 144, 56, 198]; a toy on the snow: [40, 27, 150, 146]; black object in the forefront: [0, 86, 27, 150]; the boxes are made of cardboard: [44, 27, 311, 152]; the snow is white: [41, 110, 243, 211]; shadow of the person: [79, 100, 116, 116]; ; Region Captions: a 3d image of a person walking down a hallway: [0, 82, 383, 130]; a black and white image of a wall: [2, 0, 381, 174]; a gray wall with a black arrow on it: [192, 0, 191, 173]; a pixelated image of a man standing in front of a building: [0, 0, 189, 85]; a black box with a black handle: [126, 64, 83, 29]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden table and some boxes\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [200, 67, 278, 124]; white bedspread on the bed: [28, 71, 347, 211]; small square shaped wicker basket: [124, 60, 207, 94]; the box is brown: [177, 40, 316, 165]; a black pillow: [0, 85, 27, 150]; a shadow on the ground: [0, 143, 56, 198]; the boxes are made of cardboard: [100, 15, 288, 129]; a bed in the room: [19, 25, 273, 185]; the corner of a black and white book: [0, 83, 58, 200]; the bed is white: [41, 104, 241, 211]; the box is brown: [205, 69, 253, 116]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 83, 383, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 174]\n",
      "process_ann took 0.00 seconds\n",
      "[191, 0, 192, 174]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 189, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 53, 103]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a white png image of a snowy road: [0, 83, 383, 129]; a black and white image of a wall: [2, 0, 381, 174]; a black and white image of a wall: [191, 0, 192, 174]; a gray png file with the word nyc: [0, 0, 189, 85]; a black and white png of a minecraft roof: [0, 90, 53, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden table and some boxes; Dense Caption: the box is brown: [200, 67, 278, 124]; white bedspread on the bed: [28, 71, 347, 211]; small square shaped wicker basket: [124, 60, 207, 94]; the box is brown: [177, 40, 316, 165]; a black pillow: [0, 85, 27, 150]; a shadow on the ground: [0, 143, 56, 198]; the boxes are made of cardboard: [100, 15, 288, 129]; a bed in the room: [19, 25, 273, 185]; the corner of a black and white book: [0, 83, 58, 200]; the bed is white: [41, 104, 241, 211]; the box is brown: [205, 69, 253, 116]; ; Region Captions: a white png image of a snowy road: [0, 83, 383, 129]; a black and white image of a wall: [2, 0, 381, 174]; a black and white image of a wall: [191, 0, 192, 174]; a gray png file with the word nyc: [0, 0, 189, 85]; a black and white png of a minecraft roof: [0, 90, 53, 103]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "wooden box with two drawers: [158, 74, 382, 179]; a black and white checkered table cloth: [0, 69, 131, 212]; a bed in the middle of the room: [34, 38, 351, 210]; the sky is overcast: [35, 1, 351, 84]; white sheets on the bed: [47, 120, 381, 211]; a line of yellow tiles: [232, 78, 339, 174]; a sheet of plywood: [233, 78, 337, 109]; a cloudy grey sky: [21, 4, 306, 153]; a brown wooden foot board: [160, 77, 245, 168]; the table is white: [152, 169, 277, 211]; the sky is overcast: [172, 12, 299, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[57, 90, 326, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[57, 126, 326, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 76, 130, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[235, 82, 104, 91]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a cloudy sky: [0, 1, 383, 123]; a black and white image of a room: [57, 90, 326, 122]; a silver triangle with a black background: [57, 126, 326, 87]; a black and white block with a white logo: [0, 76, 130, 137]; a wooden block on a black background: [235, 82, 104, 91]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: wooden box with two drawers: [158, 74, 382, 179]; a black and white checkered table cloth: [0, 69, 131, 212]; a bed in the middle of the room: [34, 38, 351, 210]; the sky is overcast: [35, 1, 351, 84]; white sheets on the bed: [47, 120, 381, 211]; a line of yellow tiles: [232, 78, 339, 174]; a sheet of plywood: [233, 78, 337, 109]; a cloudy grey sky: [21, 4, 306, 153]; a brown wooden foot board: [160, 77, 245, 168]; the table is white: [152, 169, 277, 211]; the sky is overcast: [172, 12, 299, 67]; ; Region Captions: a black and white image of a building with a cloudy sky: [0, 1, 383, 123]; a black and white image of a room: [57, 90, 326, 122]; a silver triangle with a black background: [57, 126, 326, 87]; a black and white block with a white logo: [0, 76, 130, 137]; a wooden block on a black background: [235, 82, 104, 91]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the black keyboard on the bed: [14, 139, 209, 211]; a table with a vase on it: [34, 75, 352, 212]; black and green sign: [200, 54, 262, 150]; a green piece of paper: [204, 103, 254, 148]; dark colored basket in front of window: [106, 76, 176, 99]; black square that holds the snowboard: [206, 57, 257, 105]; the wall is white: [110, 1, 363, 93]; a black box on the table: [320, 77, 383, 103]; shadow of a snowboarder: [343, 114, 382, 137]; the walls are white: [0, 2, 383, 124]; the chair is black: [141, 39, 322, 170]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 92, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[130, 0, 253, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[208, 94, 175, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 131, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a room with a door and a wall: [0, 0, 383, 122]; a white and black image of a door: [0, 92, 383, 120]; a gray square with a black background: [130, 0, 253, 92]; a small black and white image of a snowy area: [208, 94, 175, 118]; a gray wall with the words mtf: [0, 0, 131, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: the black keyboard on the bed: [14, 139, 209, 211]; a table with a vase on it: [34, 75, 352, 212]; black and green sign: [200, 54, 262, 150]; a green piece of paper: [204, 103, 254, 148]; dark colored basket in front of window: [106, 76, 176, 99]; black square that holds the snowboard: [206, 57, 257, 105]; the wall is white: [110, 1, 363, 93]; a black box on the table: [320, 77, 383, 103]; shadow of a snowboarder: [343, 114, 382, 137]; the walls are white: [0, 2, 383, 124]; the chair is black: [141, 39, 322, 170]; ; Region Captions: a room with a door and a wall: [0, 0, 383, 122]; a white and black image of a door: [0, 92, 383, 120]; a gray square with a black background: [130, 0, 253, 92]; a small black and white image of a snowy area: [208, 94, 175, 118]; a gray wall with the words mtf: [0, 0, 131, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden block in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "square shaped ottoman with checkered design: [61, 74, 216, 135]; a large wooden trunk: [192, 94, 382, 211]; a bed in the room: [50, 35, 356, 210]; white bed sheet: [0, 98, 221, 212]; the stickers on the mattress: [115, 77, 181, 92]; a white wall: [1, 1, 192, 104]; a wooden dresser: [202, 105, 303, 211]; a bed in the room: [31, 30, 201, 139]; the table is wooden: [208, 98, 320, 169]; wooden trunk at the foot of the bed: [186, 93, 257, 162]; a light brown wooden table top: [205, 101, 301, 142]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[190, 0, 193, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 104, 223, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 188, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[191, 98, 192, 115]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a room with a wall and a door: [0, 0, 383, 158]; a gray wall with a black slanted edge: [190, 0, 193, 158]; a white sheet of paper on a black background: [0, 104, 223, 108]; a gray arrow with a white background: [0, 0, 188, 104]; a wooden block in minecraft: [191, 98, 192, 115]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden block in it; Dense Caption: square shaped ottoman with checkered design: [61, 74, 216, 135]; a large wooden trunk: [192, 94, 382, 211]; a bed in the room: [50, 35, 356, 210]; white bed sheet: [0, 98, 221, 212]; the stickers on the mattress: [115, 77, 181, 92]; a white wall: [1, 1, 192, 104]; a wooden dresser: [202, 105, 303, 211]; a bed in the room: [31, 30, 201, 139]; the table is wooden: [208, 98, 320, 169]; wooden trunk at the foot of the bed: [186, 93, 257, 162]; a light brown wooden table top: [205, 101, 301, 142]; ; Region Captions: a room with a wall and a door: [0, 0, 383, 158]; a gray wall with a black slanted edge: [190, 0, 193, 158]; a white sheet of paper on a black background: [0, 104, 223, 108]; a gray arrow with a white background: [0, 0, 188, 104]; a wooden block in minecraft: [191, 98, 192, 115]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing in front of a square block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "red and yellow item on top of the cake: [220, 1, 257, 57]; white table cloth on table: [0, 21, 383, 210]; black and white checkered table cloth: [280, 51, 383, 143]; the base is green: [129, 33, 213, 88]; black square in the snow: [217, 110, 302, 173]; the red jacket the person is wearing: [223, 17, 254, 40]; small black trash can: [243, 31, 286, 73]; black square section of the pole: [158, 0, 214, 47]; the snow is white: [36, 68, 255, 209]; the snow is white in color: [28, 88, 143, 182]; yellow top of red fire hydrant: [231, 1, 253, 26]; a set of black seats: [116, 1, 370, 143]; a black box in the background: [314, 16, 382, 47]; a black and green pillar: [119, 2, 223, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 14, 383, 198]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[283, 55, 100, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 147, 50]\n",
      "process_ann took 0.00 seconds\n",
      "[126, 0, 156, 85]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft map with a black and white background: [0, 14, 383, 198]; a black and white image of a city: [0, 0, 383, 49]; a black block on a white background: [283, 55, 100, 83]; a grey piece of paper with a black background: [0, 0, 147, 50]; a block of green and black blocks: [126, 0, 156, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing in front of a square block; Dense Caption: red and yellow item on top of the cake: [220, 1, 257, 57]; white table cloth on table: [0, 21, 383, 210]; black and white checkered table cloth: [280, 51, 383, 143]; the base is green: [129, 33, 213, 88]; black square in the snow: [217, 110, 302, 173]; the red jacket the person is wearing: [223, 17, 254, 40]; small black trash can: [243, 31, 286, 73]; black square section of the pole: [158, 0, 214, 47]; the snow is white: [36, 68, 255, 209]; the snow is white in color: [28, 88, 143, 182]; yellow top of red fire hydrant: [231, 1, 253, 26]; a set of black seats: [116, 1, 370, 143]; a black box in the background: [314, 16, 382, 47]; a black and green pillar: [119, 2, 223, 94]; ; Region Captions: a minecraft map with a black and white background: [0, 14, 383, 198]; a black and white image of a city: [0, 0, 383, 49]; a black block on a white background: [283, 55, 100, 83]; a grey piece of paper with a black background: [0, 0, 147, 50]; a block of green and black blocks: [126, 0, 156, 85]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person is standing in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "black cake with white icing: [285, 51, 383, 141]; the base is green: [132, 33, 216, 87]; white table cloth on table: [0, 21, 383, 210]; a red and yellow object: [273, 1, 321, 66]; a black piece of paper: [223, 110, 309, 174]; black part of the pole: [161, 0, 218, 47]; small black trash can: [245, 31, 289, 73]; black and green base: [123, 2, 228, 93]; white snow on the ground: [34, 66, 258, 209]; yellow and blue square: [285, 0, 319, 29]; a piece of paper: [205, 107, 345, 189]; the snow is white in color: [28, 87, 142, 183]; legos on a table: [120, 0, 369, 137]; the snow is white: [55, 107, 173, 197]; lego with a yellow and red train: [240, 0, 321, 78]; a black square object: [317, 17, 383, 45]; the snowboard is green: [92, 7, 266, 144]; two black square pillows: [222, 47, 382, 174]; the snow is white: [167, 60, 346, 198]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 32, 383, 180]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 49]\n",
      "process_ann took 0.00 seconds\n",
      "[287, 55, 96, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 148, 50]\n",
      "process_ann took 0.00 seconds\n",
      "[128, 0, 88, 85]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a square in a minecraft world: [0, 32, 383, 180]; a black and white image of a city: [0, 0, 383, 49]; a black block on a black background: [287, 55, 96, 83]; a grey paper clip with a black background: [0, 0, 148, 50]; a block of green grass on a black background: [128, 0, 88, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person is standing in a minecraft game; Dense Caption: black cake with white icing: [285, 51, 383, 141]; the base is green: [132, 33, 216, 87]; white table cloth on table: [0, 21, 383, 210]; a red and yellow object: [273, 1, 321, 66]; a black piece of paper: [223, 110, 309, 174]; black part of the pole: [161, 0, 218, 47]; small black trash can: [245, 31, 289, 73]; black and green base: [123, 2, 228, 93]; white snow on the ground: [34, 66, 258, 209]; yellow and blue square: [285, 0, 319, 29]; a piece of paper: [205, 107, 345, 189]; the snow is white in color: [28, 87, 142, 183]; legos on a table: [120, 0, 369, 137]; the snow is white: [55, 107, 173, 197]; lego with a yellow and red train: [240, 0, 321, 78]; a black square object: [317, 17, 383, 45]; the snowboard is green: [92, 7, 266, 144]; two black square pillows: [222, 47, 382, 174]; the snow is white: [167, 60, 346, 198]; ; Region Captions: a black and white image of a square in a minecraft world: [0, 32, 383, 180]; a black and white image of a city: [0, 0, 383, 49]; a black block on a black background: [287, 55, 96, 83]; a grey paper clip with a black background: [0, 0, 148, 50]; a block of green grass on a black background: [128, 0, 88, 85]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red white and blue pole: [91, 0, 170, 99]; gray and white square tiles: [146, 55, 382, 211]; white table top: [1, 0, 382, 210]; a green piece of paper: [233, 51, 381, 137]; black and lime green flag: [0, 1, 87, 159]; circle of light grey concrete: [120, 73, 171, 100]; a red part of the sign: [121, 9, 160, 64]; a lego figure on a table: [41, 0, 247, 182]; the green triangle above the right: [0, 0, 54, 73]; a brown and black sign: [77, 0, 164, 27]; blue base of the umbrella: [126, 51, 159, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 20, 383, 192]\n",
      "process_ann took 0.00 seconds\n",
      "[147, 83, 236, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[23, 0, 360, 52]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 84, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[161, 0, 222, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a doorway: [0, 20, 383, 192]; a black block on a black background: [147, 83, 236, 130]; a small room with a black wall and a white door: [23, 0, 360, 52]; a green and black pixelated block: [0, 0, 84, 155]; a grey tv screen with a black background: [161, 0, 222, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing in a minecraft game; Dense Caption: a red white and blue pole: [91, 0, 170, 99]; gray and white square tiles: [146, 55, 382, 211]; white table top: [1, 0, 382, 210]; a green piece of paper: [233, 51, 381, 137]; black and lime green flag: [0, 1, 87, 159]; circle of light grey concrete: [120, 73, 171, 100]; a red part of the sign: [121, 9, 160, 64]; a lego figure on a table: [41, 0, 247, 182]; the green triangle above the right: [0, 0, 54, 73]; a brown and black sign: [77, 0, 164, 27]; blue base of the umbrella: [126, 51, 159, 94]; ; Region Captions: a black and white image of a doorway: [0, 20, 383, 192]; a black block on a black background: [147, 83, 236, 130]; a small room with a black wall and a white door: [23, 0, 360, 52]; a green and black pixelated block: [0, 0, 84, 155]; a grey tv screen with a black background: [161, 0, 222, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with green blocks and a green block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green paper napkins in a container: [125, 30, 213, 115]; a black and white checkered table cloth: [142, 43, 372, 212]; white table top: [1, 1, 381, 210]; red and white sign: [179, 0, 225, 40]; basket on table: [76, 0, 162, 26]; black and lime green decoration: [0, 0, 87, 158]; green square on the table: [233, 52, 381, 137]; green paper on table: [96, 10, 246, 134]; the green triangle above the right: [0, 0, 54, 72]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 20, 383, 192]\n",
      "process_ann took 0.00 seconds\n",
      "[147, 83, 236, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[23, 0, 360, 52]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 84, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[162, 0, 221, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.50 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a building: [0, 20, 383, 192]; a black block on a black background: [147, 83, 236, 130]; a black and white image of a building: [23, 0, 360, 52]; a green and black pixelated block: [0, 0, 84, 155]; a man is standing on a wall: [162, 0, 221, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with green blocks and a green block; Dense Caption: green paper napkins in a container: [125, 30, 213, 115]; a black and white checkered table cloth: [142, 43, 372, 212]; white table top: [1, 1, 381, 210]; red and white sign: [179, 0, 225, 40]; basket on table: [76, 0, 162, 26]; black and lime green decoration: [0, 0, 87, 158]; green square on the table: [233, 52, 381, 137]; green paper on table: [96, 10, 246, 134]; the green triangle above the right: [0, 0, 54, 72]; ; Region Captions: a white and black image of a building: [0, 20, 383, 192]; a black block on a black background: [147, 83, 236, 130]; a black and white image of a building: [23, 0, 360, 52]; a green and black pixelated block: [0, 0, 84, 155]; a man is standing on a wall: [162, 0, 221, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft map with green and black blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green and black checkered tie: [228, 0, 382, 150]; black and green squares on the tie: [0, 1, 134, 212]; the ground is white: [1, 1, 382, 210]; the circle is black: [150, 23, 182, 40]; the snowboard is in the air: [145, 18, 188, 46]; a white snow on the ground: [73, 2, 322, 147]; black and grey horizontal lines on a green sign: [0, 3, 94, 153]; black speaker on the green and white screen: [232, 57, 366, 142]; the snowboard is in the air: [132, 12, 202, 60]; green triangle on the kite: [252, 1, 382, 78]; the snow is white: [99, 2, 244, 112]; green section of a kite: [1, 103, 126, 211]; the snow is white: [55, 38, 245, 211]; the sky is cloudy: [181, 149, 302, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[58, 1, 325, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[234, 0, 149, 144]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 131, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 5, 131, 208]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 96, 152]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a white square with a hole in it: [58, 1, 325, 211]; a green and black block in minecraft: [234, 0, 149, 144]; a green block of grass: [0, 90, 131, 122]; a green block with a black background: [0, 5, 131, 208]; a black tiled roof on a black background: [0, 0, 96, 152]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft map with green and black blocks; Dense Caption: green and black checkered tie: [228, 0, 382, 150]; black and green squares on the tie: [0, 1, 134, 212]; the ground is white: [1, 1, 382, 210]; the circle is black: [150, 23, 182, 40]; the snowboard is in the air: [145, 18, 188, 46]; a white snow on the ground: [73, 2, 322, 147]; black and grey horizontal lines on a green sign: [0, 3, 94, 153]; black speaker on the green and white screen: [232, 57, 366, 142]; the snowboard is in the air: [132, 12, 202, 60]; green triangle on the kite: [252, 1, 382, 78]; the snow is white: [99, 2, 244, 112]; green section of a kite: [1, 103, 126, 211]; the snow is white: [55, 38, 245, 211]; the sky is cloudy: [181, 149, 302, 208]; ; Region Captions: a white square with a hole in it: [58, 1, 325, 211]; a green and black block in minecraft: [234, 0, 149, 144]; a green block of grass: [0, 90, 131, 122]; a green block with a black background: [0, 5, 131, 208]; a black tiled roof on a black background: [0, 0, 96, 152]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block with a green block on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green paper on the table: [100, 54, 232, 209]; white tablecloth on table: [0, 88, 382, 211]; green and black lego: [266, 23, 352, 170]; green colored lego pieces: [79, 15, 360, 207]; a square yellow and blue candle: [289, 25, 341, 67]; black base of a snowboard: [270, 111, 342, 168]; the wall is white: [104, 1, 360, 116]; green part of the cake: [276, 66, 348, 118]; red part of the cake: [288, 47, 343, 69]; white wall in the background: [1, 1, 152, 104]; a black square of cloth: [342, 88, 383, 114]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 100, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[153, 0, 230, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[100, 58, 127, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 150, 98]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a building with a sandbox: [0, 0, 383, 116]; a black and white image of a black and white image: [0, 100, 383, 112]; a silhouette of a city with a skyscraper: [153, 0, 230, 99]; a green block in minecraft: [100, 58, 127, 151]; a gray state with a white outline: [0, 0, 150, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block with a green block on it; Dense Caption: green paper on the table: [100, 54, 232, 209]; white tablecloth on table: [0, 88, 382, 211]; green and black lego: [266, 23, 352, 170]; green colored lego pieces: [79, 15, 360, 207]; a square yellow and blue candle: [289, 25, 341, 67]; black base of a snowboard: [270, 111, 342, 168]; the wall is white: [104, 1, 360, 116]; green part of the cake: [276, 66, 348, 118]; red part of the cake: [288, 47, 343, 69]; white wall in the background: [1, 1, 152, 104]; a black square of cloth: [342, 88, 383, 114]; ; Region Captions: a silhouette of a building with a sandbox: [0, 0, 383, 116]; a black and white image of a black and white image: [0, 100, 383, 112]; a silhouette of a city with a skyscraper: [153, 0, 230, 99]; a green block in minecraft: [100, 58, 127, 151]; a gray state with a white outline: [0, 0, 150, 98]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "table is round and white: [1, 21, 382, 211]; red box on top of a cake: [223, 19, 269, 82]; the basket is made of fabric: [314, 42, 383, 79]; green triangle on the box: [0, 53, 54, 199]; green fabric on table: [274, 110, 383, 211]; black square on green umbrella: [141, 87, 208, 157]; a rectangular wooden block: [229, 20, 263, 58]; green and black box: [132, 3, 230, 157]; green checkered pattern on box: [126, 4, 338, 181]; the box is green: [163, 25, 268, 146]; white table cloth on table: [11, 58, 138, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 58, 383, 154]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 67]\n",
      "process_ann took 0.00 seconds\n",
      "[134, 6, 129, 168]\n",
      "process_ann took 0.00 seconds\n",
      "[278, 113, 105, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[123, 0, 260, 62]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a room with a door: [0, 58, 383, 154]; a silhouette of a city with tall buildings: [0, 0, 383, 67]; a green block with black and white stripes: [134, 6, 129, 168]; a green square block on a black background: [278, 113, 105, 99]; a silhouette of a city with buildings in the background: [123, 0, 260, 62]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing in a minecraft game; Dense Caption: table is round and white: [1, 21, 382, 211]; red box on top of a cake: [223, 19, 269, 82]; the basket is made of fabric: [314, 42, 383, 79]; green triangle on the box: [0, 53, 54, 199]; green fabric on table: [274, 110, 383, 211]; black square on green umbrella: [141, 87, 208, 157]; a rectangular wooden block: [229, 20, 263, 58]; green and black box: [132, 3, 230, 157]; green checkered pattern on box: [126, 4, 338, 181]; the box is green: [163, 25, 268, 146]; white table cloth on table: [11, 58, 138, 209]; ; Region Captions: a 3d image of a room with a door: [0, 58, 383, 154]; a silhouette of a city with tall buildings: [0, 0, 383, 67]; a green block with black and white stripes: [134, 6, 129, 168]; a green square block on a black background: [278, 113, 105, 99]; a silhouette of a city with buildings in the background: [123, 0, 260, 62]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green and black block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "black square on table: [217, 49, 290, 115]; green plastic file holder: [1, 1, 185, 210]; a green and white table cloth: [1, 1, 381, 210]; black square on white tablecloth: [240, 112, 323, 169]; the black box on the white table: [347, 39, 383, 90]; the table is white: [32, 48, 253, 212]; the table is white: [151, 52, 367, 210]; the chair is green: [20, 2, 266, 150]; two black square chairs: [217, 43, 321, 164]; black square blocks on the end of the kite: [144, 10, 225, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[67, 60, 316, 152]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 0, 241, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 0, 241, 43]\n",
      "process_ann took 0.00 seconds\n",
      "[188, 53, 100, 61]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a white sandstone cliff with a black background: [67, 60, 316, 152]; a black and white image of a city: [2, 0, 381, 64]; a black and white image of a png file: [142, 0, 241, 64]; a gray t - shirt with a black background: [142, 0, 241, 43]; a black and green block with a green stripe: [188, 53, 100, 61]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green and black block in minecraft; Dense Caption: black square on table: [217, 49, 290, 115]; green plastic file holder: [1, 1, 185, 210]; a green and white table cloth: [1, 1, 381, 210]; black square on white tablecloth: [240, 112, 323, 169]; the black box on the white table: [347, 39, 383, 90]; the table is white: [32, 48, 253, 212]; the table is white: [151, 52, 367, 210]; the chair is green: [20, 2, 266, 150]; two black square chairs: [217, 43, 321, 164]; black square blocks on the end of the kite: [144, 10, 225, 92]; ; Region Captions: a white sandstone cliff with a black background: [67, 60, 316, 152]; a black and white image of a city: [2, 0, 381, 64]; a black and white image of a png file: [142, 0, 241, 64]; a gray t - shirt with a black background: [142, 0, 241, 43]; a black and green block with a green stripe: [188, 53, 100, 61]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green and black block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "black square on table: [217, 49, 290, 115]; green plastic file holder: [1, 1, 185, 210]; a green and white table cloth: [1, 1, 381, 210]; black square on white tablecloth: [240, 112, 323, 169]; the black box on the white table: [347, 39, 383, 90]; the table is white: [32, 48, 253, 212]; the table is white: [151, 52, 367, 210]; the chair is green: [20, 2, 266, 150]; two black square chairs: [217, 43, 321, 164]; black square blocks on the end of the kite: [144, 10, 225, 91]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[67, 60, 316, 152]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 0, 241, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 0, 241, 43]\n",
      "process_ann took 0.00 seconds\n",
      "[188, 53, 100, 61]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a white sandstone cliff with a black background: [67, 60, 316, 152]; a black and white image of a city: [2, 0, 381, 64]; a black and white image of a png file: [142, 0, 241, 64]; a gray t - shirt with a black background: [142, 0, 241, 43]; a black and green block with a green stripe: [188, 53, 100, 61]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green and black block in minecraft; Dense Caption: black square on table: [217, 49, 290, 115]; green plastic file holder: [1, 1, 185, 210]; a green and white table cloth: [1, 1, 381, 210]; black square on white tablecloth: [240, 112, 323, 169]; the black box on the white table: [347, 39, 383, 90]; the table is white: [32, 48, 253, 212]; the table is white: [151, 52, 367, 210]; the chair is green: [20, 2, 266, 150]; two black square chairs: [217, 43, 321, 164]; black square blocks on the end of the kite: [144, 10, 225, 91]; ; Region Captions: a white sandstone cliff with a black background: [67, 60, 316, 152]; a black and white image of a city: [2, 0, 381, 64]; a black and white image of a png file: [142, 0, 241, 64]; a gray t - shirt with a black background: [142, 0, 241, 43]; a black and green block with a green stripe: [188, 53, 100, 61]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green and black block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "black square on table: [217, 49, 290, 115]; green plastic file holder: [1, 1, 185, 210]; a green and white table cloth: [1, 1, 381, 210]; black square on white tablecloth: [240, 112, 323, 169]; the black square object on the right: [347, 39, 383, 90]; the table is white: [32, 48, 253, 212]; the table is white: [151, 52, 367, 210]; two black square chairs: [217, 43, 321, 164]; the chair is green: [20, 2, 266, 150]; black square blocks on the end of the kite: [144, 10, 225, 91]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[67, 60, 316, 152]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 0, 241, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 0, 241, 43]\n",
      "process_ann took 0.00 seconds\n",
      "[188, 53, 100, 61]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a white pixelated image of a snowy mountain: [67, 60, 316, 152]; a black and white image of a city: [2, 0, 381, 64]; a black and white image of a png file: [142, 0, 241, 64]; a gray t - shirt with a black background: [142, 0, 241, 43]; a black and green block with a green stripe: [188, 53, 100, 61]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green and black block in minecraft; Dense Caption: black square on table: [217, 49, 290, 115]; green plastic file holder: [1, 1, 185, 210]; a green and white table cloth: [1, 1, 381, 210]; black square on white tablecloth: [240, 112, 323, 169]; the black square object on the right: [347, 39, 383, 90]; the table is white: [32, 48, 253, 212]; the table is white: [151, 52, 367, 210]; two black square chairs: [217, 43, 321, 164]; the chair is green: [20, 2, 266, 150]; black square blocks on the end of the kite: [144, 10, 225, 91]; ; Region Captions: a white pixelated image of a snowy mountain: [67, 60, 316, 152]; a black and white image of a city: [2, 0, 381, 64]; a black and white image of a png file: [142, 0, 241, 64]; a gray t - shirt with a black background: [142, 0, 241, 43]; a black and green block with a green stripe: [188, 53, 100, 61]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the book in front of the monitor: [307, 37, 383, 87]; black colored square of fabric: [196, 48, 260, 111]; green and lime green fabric: [1, 1, 146, 210]; the photo was taken indoors: [0, 1, 381, 210]; square cut out in the snow: [220, 108, 294, 157]; the table is white: [140, 56, 364, 211]; the chairs are black: [95, 4, 289, 122]; black and green square: [115, 10, 201, 95]; the wall is white: [111, 0, 381, 60]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[65, 53, 318, 159]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 198, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 138, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[111, 0, 272, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[111, 0, 272, 42]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.70 seconds\n",
      "finished...\n",
      "\n",
      "a small black square in the middle of a white snowy area: [65, 53, 318, 159]; a green block in minecraft: [0, 0, 198, 212]; a green block in minecraft: [0, 0, 138, 212]; a black and white image of a png file: [111, 0, 272, 60]; a gray and white png of a st: [111, 0, 272, 42]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft game; Dense Caption: the book in front of the monitor: [307, 37, 383, 87]; black colored square of fabric: [196, 48, 260, 111]; green and lime green fabric: [1, 1, 146, 210]; the photo was taken indoors: [0, 1, 381, 210]; square cut out in the snow: [220, 108, 294, 157]; the table is white: [140, 56, 364, 211]; the chairs are black: [95, 4, 289, 122]; black and green square: [115, 10, 201, 95]; the wall is white: [111, 0, 381, 60]; ; Region Captions: a small black square in the middle of a white snowy area: [65, 53, 318, 159]; a green block in minecraft: [0, 0, 198, 212]; a green block in minecraft: [0, 0, 138, 212]; a black and white image of a png file: [111, 0, 272, 60]; a gray and white png of a st: [111, 0, 272, 42]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing next to a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "wooden box on snow: [92, 73, 256, 148]; lego multicolored toy: [260, 50, 329, 132]; a checkered blanket: [0, 80, 72, 195]; white snow on the ground: [1, 90, 382, 211]; blue fire hydrant on sidewalk: [276, 96, 304, 127]; a light brown wooden trunk: [154, 78, 210, 138]; the orange and white object: [263, 73, 326, 108]; two small wicker baskets: [63, 32, 347, 176]; the sky is cloudy: [39, 1, 347, 91]; yellow top of lego set: [274, 54, 317, 86]; a toy on the snow: [237, 36, 344, 160]; the snow is white: [164, 145, 286, 205]; shadow of a snowboarder: [261, 108, 310, 135]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 100, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[94, 79, 160, 66]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 86, 70, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[94, 82, 64, 63]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing in the fog: [0, 1, 383, 125]; a person is standing on a floor with a white background: [0, 100, 383, 112]; a brown and white block in minecraft: [94, 79, 160, 66]; a black and white block of bricks: [0, 86, 70, 106]; a wooden block on a black background: [94, 82, 64, 63]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing next to a box; Dense Caption: wooden box on snow: [92, 73, 256, 148]; lego multicolored toy: [260, 50, 329, 132]; a checkered blanket: [0, 80, 72, 195]; white snow on the ground: [1, 90, 382, 211]; blue fire hydrant on sidewalk: [276, 96, 304, 127]; a light brown wooden trunk: [154, 78, 210, 138]; the orange and white object: [263, 73, 326, 108]; two small wicker baskets: [63, 32, 347, 176]; the sky is cloudy: [39, 1, 347, 91]; yellow top of lego set: [274, 54, 317, 86]; a toy on the snow: [237, 36, 344, 160]; the snow is white: [164, 145, 286, 205]; shadow of a snowboarder: [261, 108, 310, 135]; ; Region Captions: a silhouette of a man standing in the fog: [0, 1, 383, 125]; a person is standing on a floor with a white background: [0, 100, 383, 112]; a brown and white block in minecraft: [94, 79, 160, 66]; a black and white block of bricks: [0, 86, 70, 106]; a wooden block on a black background: [94, 82, 64, 63]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a small table with a wooden top and a white wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large brown open umbrella: [8, 144, 329, 212]; sky is cloudy: [0, 2, 382, 208]; a white object in front of a giraffe: [286, 128, 382, 212]; the shadow of the umbrella: [145, 145, 265, 212]; the sky is dark and cloudy: [19, 80, 302, 208]; the sky is clear: [155, 69, 259, 140]; the sky is overcast: [40, 6, 347, 133]; the sky is dark: [18, 25, 276, 172]; the sky is clear: [18, 88, 148, 159]; shadow on the bench: [190, 151, 245, 208]; the letter a on the sign: [3, 176, 118, 212]; the roof is brown: [126, 119, 359, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 204]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 152, 320, 61]\n",
      "process_ann took 0.00 seconds\n",
      "[116, 152, 204, 61]\n",
      "process_ann took 0.00 seconds\n",
      "[286, 134, 97, 79]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 177, 119, 36]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a black corner: [0, 1, 383, 204]; a triangle made of wood and brown: [0, 152, 320, 61]; a wooden floor in minecraft: [116, 152, 204, 61]; a silver plate on a black background: [286, 134, 97, 79]; a wooden slat with a wooden slat: [0, 177, 119, 36]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a small table with a wooden top and a white wall; Dense Caption: a large brown open umbrella: [8, 144, 329, 212]; sky is cloudy: [0, 2, 382, 208]; a white object in front of a giraffe: [286, 128, 382, 212]; the shadow of the umbrella: [145, 145, 265, 212]; the sky is dark and cloudy: [19, 80, 302, 208]; the sky is clear: [155, 69, 259, 140]; the sky is overcast: [40, 6, 347, 133]; the sky is dark: [18, 25, 276, 172]; the sky is clear: [18, 88, 148, 159]; shadow on the bench: [190, 151, 245, 208]; the letter a on the sign: [3, 176, 118, 212]; the roof is brown: [126, 119, 359, 211]; ; Region Captions: a gray wall with a black corner: [0, 1, 383, 204]; a triangle made of wood and brown: [0, 152, 320, 61]; a wooden floor in minecraft: [116, 152, 204, 61]; a silver plate on a black background: [286, 134, 97, 79]; a wooden slat with a wooden slat: [0, 177, 119, 36]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a wooden table and a white wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown building: [30, 159, 301, 211]; sky is dark and cloudy: [0, 2, 381, 210]; the brown and tan tower: [9, 119, 380, 211]; a white object in front of a bird: [284, 135, 382, 212]; the sky is clear: [152, 78, 260, 151]; the sky is dark: [19, 42, 283, 191]; the building is made of bricks: [149, 161, 279, 213]; the sky is overcast: [41, 7, 344, 135]; the sky is clear: [116, 90, 224, 156]; a white bed: [131, 72, 372, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[285, 140, 98, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[32, 193, 78, 20]\n",
      "process_ann took 0.00 seconds\n",
      "[195, 168, 68, 45]\n",
      "process_ann took 0.00 seconds\n",
      "[171, 174, 45, 39]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a black corner: [0, 1, 383, 211]; a silver plate with a black background: [285, 140, 98, 73]; a tan shaped arrowhead with a black background: [32, 193, 78, 20]; a wooden sword with a black background: [195, 168, 68, 45]; a wooden sword with a brown handle: [171, 174, 45, 39]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a wooden table and a white wall; Dense Caption: a brown building: [30, 159, 301, 211]; sky is dark and cloudy: [0, 2, 381, 210]; the brown and tan tower: [9, 119, 380, 211]; a white object in front of a bird: [284, 135, 382, 212]; the sky is clear: [152, 78, 260, 151]; the sky is dark: [19, 42, 283, 191]; the building is made of bricks: [149, 161, 279, 213]; the sky is overcast: [41, 7, 344, 135]; the sky is clear: [116, 90, 224, 156]; a white bed: [131, 72, 372, 209]; ; Region Captions: a gray wall with a black corner: [0, 1, 383, 211]; a silver plate with a black background: [285, 140, 98, 73]; a tan shaped arrowhead with a black background: [32, 193, 78, 20]; a wooden sword with a black background: [195, 168, 68, 45]; a wooden sword with a brown handle: [171, 174, 45, 39]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden box and a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [186, 60, 289, 117]; yellow and black suitcase: [0, 87, 64, 195]; a square shaped ottoman: [76, 53, 193, 102]; the bed is made: [37, 46, 349, 212]; small lego figure on top of a refrigerator: [156, 7, 187, 63]; a white wall: [0, 1, 155, 88]; two brown baskets on a table: [61, 23, 304, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 83, 383, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[149, 0, 234, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 152, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 60, 100]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a snowy path: [0, 83, 383, 129]; a silhouette of a man standing on a ledge: [149, 0, 234, 135]; a black and white image of a man standing in a room: [2, 0, 381, 135]; a gray arrow with a white background: [0, 0, 152, 89]; a gold block on a black background: [0, 91, 60, 100]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden box and a wooden box; Dense Caption: the box is brown: [186, 60, 289, 117]; yellow and black suitcase: [0, 87, 64, 195]; a square shaped ottoman: [76, 53, 193, 102]; the bed is made: [37, 46, 349, 212]; small lego figure on top of a refrigerator: [156, 7, 187, 63]; a white wall: [0, 1, 155, 88]; two brown baskets on a table: [61, 23, 304, 127]; ; Region Captions: a white and black image of a snowy path: [0, 83, 383, 129]; a silhouette of a man standing on a ledge: [149, 0, 234, 135]; a black and white image of a man standing in a room: [2, 0, 381, 135]; a gray arrow with a white background: [0, 0, 152, 89]; a gold block on a black background: [0, 91, 60, 100]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green object on the right: [320, 97, 383, 203]; the basket is made of plastic: [92, 61, 184, 91]; white table top: [0, 71, 382, 211]; the phone is black: [72, 14, 205, 126]; the bed is made: [45, 7, 357, 158]; the bed is white: [36, 100, 271, 210]; the black object on the right: [359, 61, 383, 82]; the wall is white: [83, 1, 379, 80]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 79, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[120, 0, 263, 77]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 124, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[323, 102, 60, 98]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a white png image of a snowy road: [0, 79, 383, 133]; a room with a black wall and a white floor: [0, 0, 383, 126]; a gray square with a black background: [120, 0, 263, 77]; a gray piece of paper with a black background: [0, 0, 124, 126]; a green block on a black background: [323, 102, 60, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft room; Dense Caption: green object on the right: [320, 97, 383, 203]; the basket is made of plastic: [92, 61, 184, 91]; white table top: [0, 71, 382, 211]; the phone is black: [72, 14, 205, 126]; the bed is made: [45, 7, 357, 158]; the bed is white: [36, 100, 271, 210]; the black object on the right: [359, 61, 383, 82]; the wall is white: [83, 1, 379, 80]; ; Region Captions: a white png image of a snowy road: [0, 79, 383, 133]; a room with a black wall and a white floor: [0, 0, 383, 126]; a gray square with a black background: [120, 0, 263, 77]; a gray piece of paper with a black background: [0, 0, 124, 126]; a green block on a black background: [323, 102, 60, 98]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green block in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green object on the right: [315, 96, 383, 206]; the basket is made of wicker: [86, 61, 183, 95]; white table top: [0, 72, 382, 211]; a box on a bed: [69, 16, 202, 126]; the walls are white: [47, 6, 356, 151]; the bed is white: [34, 100, 267, 210]; a black remote control: [352, 61, 383, 87]; the wall is white: [96, 1, 378, 79]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 81, 383, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[116, 0, 267, 79]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 121, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[319, 103, 64, 100]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a white png of a white floor: [0, 81, 383, 131]; a room with a black wall and a white floor: [0, 0, 383, 127]; a gray square with a black background: [116, 0, 267, 79]; a gray shaped piece of paper: [0, 0, 121, 127]; a green block on a black background: [319, 103, 64, 100]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green block in a minecraft room; Dense Caption: green object on the right: [315, 96, 383, 206]; the basket is made of wicker: [86, 61, 183, 95]; white table top: [0, 72, 382, 211]; a box on a bed: [69, 16, 202, 126]; the walls are white: [47, 6, 356, 151]; the bed is white: [34, 100, 267, 210]; a black remote control: [352, 61, 383, 87]; the wall is white: [96, 1, 378, 79]; ; Region Captions: a white png of a white floor: [0, 81, 383, 131]; a room with a black wall and a white floor: [0, 0, 383, 127]; a gray square with a black background: [116, 0, 267, 79]; a gray shaped piece of paper: [0, 0, 121, 127]; a green block on a black background: [319, 103, 64, 100]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing on a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "square shaped ottoman with checkered print: [116, 52, 278, 114]; a light colored wooden trunk: [286, 91, 383, 211]; white bedspread on the bed: [26, 69, 328, 212]; a small lego piece: [185, 0, 221, 61]; wooden trunk with brown wood trim: [255, 75, 362, 155]; a red sign with a black arrow: [186, 14, 219, 42]; blue base of the lego piece: [192, 39, 211, 61]; the small white paper on the bed: [163, 55, 201, 68]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 80, 341, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 180]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 231, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[257, 80, 126, 133]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a white floor with a black background: [0, 80, 341, 132]; a black and white image of a lamp in a room: [0, 0, 383, 180]; a black and white image of a room with a lamp: [0, 0, 383, 97]; a silhouette of a man standing in front of a building: [0, 0, 231, 80]; a wooden block in minecraft: [257, 80, 126, 133]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing on a table; Dense Caption: square shaped ottoman with checkered print: [116, 52, 278, 114]; a light colored wooden trunk: [286, 91, 383, 211]; white bedspread on the bed: [26, 69, 328, 212]; a small lego piece: [185, 0, 221, 61]; wooden trunk with brown wood trim: [255, 75, 362, 155]; a red sign with a black arrow: [186, 14, 219, 42]; blue base of the lego piece: [192, 39, 211, 61]; the small white paper on the bed: [163, 55, 201, 68]; ; Region Captions: a white floor with a black background: [0, 80, 341, 132]; a black and white image of a lamp in a room: [0, 0, 383, 180]; a black and white image of a room with a lamp: [0, 0, 383, 97]; a silhouette of a man standing in front of a building: [0, 0, 231, 80]; a wooden block in minecraft: [257, 80, 126, 133]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a man standing on a bench\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white checkered bedspread: [0, 104, 162, 211]; the lego is holding a board: [19, 17, 80, 91]; brown wooden dresser: [149, 124, 381, 212]; the wall is white: [121, 4, 361, 124]; the multi colored object: [21, 33, 78, 71]; a bedroom: [34, 9, 359, 211]; two beds are next to each other: [0, 104, 382, 211]; yellow metal box on the bed: [192, 134, 319, 211]; brown wooden dresser: [147, 124, 231, 212]; the wall is white: [4, 8, 103, 110]; white table next to the bed: [24, 163, 169, 212]; yellow and blue box: [32, 19, 65, 45]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 165]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 111, 161, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[196, 138, 187, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 103, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[196, 138, 116, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft character standing in a room: [0, 0, 383, 165]; a black and white pixelated image of a minecraft bench: [0, 111, 161, 102]; a wooden block with a brown color: [196, 138, 187, 75]; a black and white image of a cross: [0, 0, 103, 116]; a wooden block on a black background: [196, 138, 116, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a man standing on a bench; Dense Caption: a black and white checkered bedspread: [0, 104, 162, 211]; the lego is holding a board: [19, 17, 80, 91]; brown wooden dresser: [149, 124, 381, 212]; the wall is white: [121, 4, 361, 124]; the multi colored object: [21, 33, 78, 71]; a bedroom: [34, 9, 359, 211]; two beds are next to each other: [0, 104, 382, 211]; yellow metal box on the bed: [192, 134, 319, 211]; brown wooden dresser: [147, 124, 231, 212]; the wall is white: [4, 8, 103, 110]; white table next to the bed: [24, 163, 169, 212]; yellow and blue box: [32, 19, 65, 45]; ; Region Captions: a minecraft character standing in a room: [0, 0, 383, 165]; a black and white pixelated image of a minecraft bench: [0, 111, 161, 102]; a wooden block with a brown color: [196, 138, 187, 75]; a black and white image of a cross: [0, 0, 103, 116]; a wooden block on a black background: [196, 138, 116, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a block of black and yellow blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "black and yellow walkway: [138, 1, 372, 197]; yellow section of the umbrella: [251, 98, 383, 187]; green triangle behind bear: [4, 0, 131, 51]; white table: [11, 60, 148, 210]; black and white checkered tie: [145, 2, 294, 102]; the keyboard is black: [170, 20, 272, 131]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[144, 4, 146, 159]\n",
      "process_ann took 0.00 seconds\n",
      "[273, 0, 110, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[273, 0, 110, 180]\n",
      "process_ann took 0.00 seconds\n",
      "[144, 5, 144, 95]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white cube: [0, 1, 383, 211]; a black block on a black background: [144, 4, 146, 159]; a black block with a black background: [273, 0, 110, 113]; a black block with a yellow arrow on it: [273, 0, 110, 180]; a black square tile on a black background: [144, 5, 144, 95]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a block of black and yellow blocks; Dense Caption: black and yellow walkway: [138, 1, 372, 197]; yellow section of the umbrella: [251, 98, 383, 187]; green triangle behind bear: [4, 0, 131, 51]; white table: [11, 60, 148, 210]; black and white checkered tie: [145, 2, 294, 102]; the keyboard is black: [170, 20, 272, 131]; ; Region Captions: a black and white image of a black and white cube: [0, 1, 383, 211]; a black block on a black background: [144, 4, 146, 159]; a black block with a black background: [273, 0, 110, 113]; a black block with a yellow arrow on it: [273, 0, 110, 180]; a black square tile on a black background: [144, 5, 144, 95]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a block of black and yellow blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "black and yellow necktie: [2, 0, 258, 209]; yellow section of a blue suitcase: [157, 72, 239, 177]; the keyboard is black: [340, 35, 383, 127]; green square on the right: [2, 21, 108, 71]; the table is white: [141, 29, 371, 212]; black and white neck of the vase: [82, 1, 252, 103]; the black and white checkered floor: [1, 42, 157, 208]; the black and white paper: [121, 22, 218, 124]; the black and white checkered fabric: [22, 80, 135, 183]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[132, 35, 251, 177]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 35, 155, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[84, 0, 167, 109]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 54, 168, 159]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 112, 168, 101]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a white stairway with a black background: [132, 35, 251, 177]; a black square tile on a black background: [0, 35, 155, 151]; a black block on a black background: [84, 0, 167, 109]; a black block with a black background: [0, 54, 168, 159]; a black block with a black background: [0, 112, 168, 101]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a block of black and yellow blocks in minecraft; Dense Caption: black and yellow necktie: [2, 0, 258, 209]; yellow section of a blue suitcase: [157, 72, 239, 177]; the keyboard is black: [340, 35, 383, 127]; green square on the right: [2, 21, 108, 71]; the table is white: [141, 29, 371, 212]; black and white neck of the vase: [82, 1, 252, 103]; the black and white checkered floor: [1, 42, 157, 208]; the black and white paper: [121, 22, 218, 124]; the black and white checkered fabric: [22, 80, 135, 183]; ; Region Captions: a white stairway with a black background: [132, 35, 251, 177]; a black square tile on a black background: [0, 35, 155, 151]; a black block on a black background: [84, 0, 167, 109]; a black block with a black background: [0, 54, 168, 159]; a black block with a black background: [0, 112, 168, 101]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a block of yellow and green blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the black and yellow object: [23, 0, 289, 182]; a black computer keyboard: [306, 0, 383, 79]; the yellow part of the kite: [60, 1, 255, 102]; green caution tape: [0, 6, 78, 87]; the bottom of the yellow suitcase: [118, 64, 219, 153]; the box is yellow: [166, 25, 232, 123]; a yellow section of the sign: [83, 7, 183, 111]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[45, 0, 221, 174]\n",
      "process_ann took 0.00 seconds\n",
      "[63, 0, 182, 107]\n",
      "process_ann took 0.00 seconds\n",
      "[45, 40, 189, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[309, 0, 74, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white image: [0, 2, 383, 210]; a yellow block with the word welcome: [45, 0, 221, 174]; a gold box with the words'golden box': [63, 0, 182, 107]; a black block on a white background: [45, 40, 189, 134]; a black and blue block with a blue logo: [309, 0, 74, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a block of yellow and green blocks in minecraft; Dense Caption: the black and yellow object: [23, 0, 289, 182]; a black computer keyboard: [306, 0, 383, 79]; the yellow part of the kite: [60, 1, 255, 102]; green caution tape: [0, 6, 78, 87]; the bottom of the yellow suitcase: [118, 64, 219, 153]; the box is yellow: [166, 25, 232, 123]; a yellow section of the sign: [83, 7, 183, 111]; ; Region Captions: a black and white image of a black and white image: [0, 2, 383, 210]; a yellow block with the word welcome: [45, 0, 221, 174]; a gold box with the words'golden box': [63, 0, 182, 107]; a black block on a white background: [45, 40, 189, 134]; a black and blue block with a blue logo: [309, 0, 74, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a yellow and black wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "black and yellow object: [0, 1, 158, 159]; a square shaped mat: [204, 0, 378, 53]; white table top: [0, 1, 382, 210]; a brown piece of furniture: [329, 15, 383, 111]; yellow section of a kite: [1, 0, 114, 89]; the snow is white in color: [200, 74, 303, 177]; the sheet is white in color: [164, 66, 337, 205]; yellow section of a black suitcase: [113, 23, 157, 102]; black and white checkerboard pattern: [56, 38, 133, 138]; the snow is white: [186, 115, 301, 202]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 15, 383, 197]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 152, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 46, 133, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 113, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[207, 0, 170, 50]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a white stairway with a black background: [0, 15, 383, 197]; a gold and black block with a yellow and black square: [0, 0, 152, 155]; a black block with a black background: [0, 46, 133, 110]; a gold triangle with a pixelated background: [0, 0, 113, 89]; a black and white patterned bag: [207, 0, 170, 50]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a yellow and black wall; Dense Caption: black and yellow object: [0, 1, 158, 159]; a square shaped mat: [204, 0, 378, 53]; white table top: [0, 1, 382, 210]; a brown piece of furniture: [329, 15, 383, 111]; yellow section of a kite: [1, 0, 114, 89]; the snow is white in color: [200, 74, 303, 177]; the sheet is white in color: [164, 66, 337, 205]; yellow section of a black suitcase: [113, 23, 157, 102]; black and white checkerboard pattern: [56, 38, 133, 138]; the snow is white: [186, 115, 301, 202]; ; Region Captions: a white stairway with a black background: [0, 15, 383, 197]; a gold and black block with a yellow and black square: [0, 0, 152, 155]; a black block with a black background: [0, 46, 133, 110]; a gold triangle with a pixelated background: [0, 0, 113, 89]; a black and white patterned bag: [207, 0, 170, 50]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a man running around\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown wooden box on white bed: [196, 73, 297, 161]; box is brown color: [109, 60, 217, 103]; the small black and yellow object: [0, 33, 49, 157]; some boxes are on the bed: [2, 21, 360, 209]; lego man holding a snowboard: [49, 23, 112, 95]; the boxes are made of wood: [52, 34, 286, 156]; yellow and blue tag: [51, 24, 94, 55]; a gray spot on the ground: [71, 98, 111, 119]; blue ribbon tied around orange ribbon: [58, 67, 112, 93]; red and white object: [53, 45, 95, 82]; the basket is brown: [75, 41, 236, 119]; the pillows are yellow and black: [0, 20, 115, 159]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 85, 355, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[198, 0, 185, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 380, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 196, 85]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a white png image of a stairway: [0, 85, 355, 128]; a black wall with a white wall: [2, 0, 381, 212]; a black and white image of a man on a cliff: [198, 0, 185, 212]; a black and white image of a man with a knife: [0, 0, 380, 85]; a silhouette of a man sitting on a chair: [0, 0, 196, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a man running around; Dense Caption: brown wooden box on white bed: [196, 73, 297, 161]; box is brown color: [109, 60, 217, 103]; the small black and yellow object: [0, 33, 49, 157]; some boxes are on the bed: [2, 21, 360, 209]; lego man holding a snowboard: [49, 23, 112, 95]; the boxes are made of wood: [52, 34, 286, 156]; yellow and blue tag: [51, 24, 94, 55]; a gray spot on the ground: [71, 98, 111, 119]; blue ribbon tied around orange ribbon: [58, 67, 112, 93]; red and white object: [53, 45, 95, 82]; the basket is brown: [75, 41, 236, 119]; the pillows are yellow and black: [0, 20, 115, 159]; ; Region Captions: a white png image of a stairway: [0, 85, 355, 128]; a black wall with a white wall: [2, 0, 381, 212]; a black and white image of a man on a cliff: [198, 0, 185, 212]; a black and white image of a man with a knife: [0, 0, 380, 85]; a silhouette of a man sitting on a chair: [0, 0, 196, 85]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden table and chairs\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown box on white surface: [75, 114, 239, 211]; a black and white checkered box: [0, 111, 92, 190]; white walls of room: [0, 2, 380, 210]; a white bed in the room: [2, 111, 335, 212]; a blue and red box: [0, 69, 17, 119]; the box is brown: [74, 121, 144, 189]; orange sticker on the wall: [0, 71, 14, 98]; white tablecloth on the table: [1, 161, 345, 212]; the box is brown: [107, 114, 210, 179]; the box is brown: [106, 123, 183, 206]; a brown wooden trunk: [156, 129, 235, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[20, 0, 363, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[76, 125, 156, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 162, 336, 51]\n",
      "process_ann took 0.00 seconds\n",
      "[156, 131, 76, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 162, 170, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.61 seconds\n",
      "finished...\n",
      "\n",
      "a black and gray wall with a black and gray wall: [20, 0, 363, 212]; a wooden block with a brown and white stripe: [76, 125, 156, 88]; a silver triangle with a black background: [0, 162, 336, 51]; a wooden block in minecraft: [156, 131, 76, 82]; a silver triangle with a black background: [0, 162, 170, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden table and chairs; Dense Caption: brown box on white surface: [75, 114, 239, 211]; a black and white checkered box: [0, 111, 92, 190]; white walls of room: [0, 2, 380, 210]; a white bed in the room: [2, 111, 335, 212]; a blue and red box: [0, 69, 17, 119]; the box is brown: [74, 121, 144, 189]; orange sticker on the wall: [0, 71, 14, 98]; white tablecloth on the table: [1, 161, 345, 212]; the box is brown: [107, 114, 210, 179]; the box is brown: [106, 123, 183, 206]; a brown wooden trunk: [156, 129, 235, 211]; ; Region Captions: a black and gray wall with a black and gray wall: [20, 0, 363, 212]; a wooden block with a brown and white stripe: [76, 125, 156, 88]; a silver triangle with a black background: [0, 162, 336, 51]; a wooden block in minecraft: [156, 131, 76, 82]; a silver triangle with a black background: [0, 162, 170, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a green square wall in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "green square on the photo: [5, 1, 381, 212]; white table cloth on the table: [0, 68, 92, 212]; the keyboard is black: [0, 45, 31, 73]; green section of a kite: [38, 40, 265, 213]; a black laptop computer: [0, 1, 31, 73]; white table under the green umbrella: [1, 2, 137, 211]; a green section of cloth: [103, 30, 184, 142]; white table cloth: [0, 78, 41, 210]; green wall in the background: [163, 57, 356, 208]; the wall is green: [47, 6, 264, 146]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[3, 0, 380, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 8, 91, 205]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 91, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[206, 1, 122, 55]\n",
      "process_ann took 0.00 seconds\n",
      "[155, 0, 174, 56]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.74 seconds\n",
      "finished...\n",
      "\n",
      "a green square on a black background: [3, 0, 380, 212]; a small white sled with a black background: [0, 8, 91, 205]; a white sand beach with a white sand dune: [0, 72, 91, 141]; a green square with the word arkansas: [206, 1, 122, 55]; a green logo with the word lsu: [155, 0, 174, 56]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a green square wall in minecraft; Dense Caption: green square on the photo: [5, 1, 381, 212]; white table cloth on the table: [0, 68, 92, 212]; the keyboard is black: [0, 45, 31, 73]; green section of a kite: [38, 40, 265, 213]; a black laptop computer: [0, 1, 31, 73]; white table under the green umbrella: [1, 2, 137, 211]; a green section of cloth: [103, 30, 184, 142]; white table cloth: [0, 78, 41, 210]; green wall in the background: [163, 57, 356, 208]; the wall is green: [47, 6, 264, 146]; ; Region Captions: a green square on a black background: [3, 0, 380, 212]; a small white sled with a black background: [0, 8, 91, 205]; a white sand beach with a white sand dune: [0, 72, 91, 141]; a green square with the word arkansas: [206, 1, 122, 55]; a green logo with the word lsu: [155, 0, 174, 56]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210413_200825 34\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white roof: [0, 73, 381, 212]; a person is walking: [174, 48, 222, 129]; a digital display: [107, 188, 275, 212]; the word right in the corner: [170, 33, 219, 47]; a red section of the roof: [271, 185, 359, 212]; a person in the air: [109, 24, 261, 186]; a toy train with red lights: [103, 157, 278, 212]; a brick wall: [311, 67, 380, 93]; a red light on a sign: [181, 192, 201, 212]; red letters on the building: [172, 154, 210, 173]; the sky is gray: [0, 1, 383, 99]; a red roof with a window: [101, 176, 359, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 80, 383, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 0, 254, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 132, 96]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing on a snowy hill: [0, 2, 383, 210]; a picture of a man with a gun in his hand: [0, 80, 383, 132]; a room with a sign on it: [0, 0, 383, 96]; a grey png image of a black and white picture: [129, 0, 254, 81]; a gray piece of paper with a black background: [0, 0, 132, 96]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a white roof: [0, 73, 381, 212]; a person is walking: [174, 48, 222, 129]; a digital display: [107, 188, 275, 212]; the word right in the corner: [170, 33, 219, 47]; a red section of the roof: [271, 185, 359, 212]; a person in the air: [109, 24, 261, 186]; a toy train with red lights: [103, 157, 278, 212]; a brick wall: [311, 67, 380, 93]; a red light on a sign: [181, 192, 201, 212]; red letters on the building: [172, 154, 210, 173]; the sky is gray: [0, 1, 383, 99]; a red roof with a window: [101, 176, 359, 212]; ; Region Captions: a silhouette of a man standing on a snowy hill: [0, 2, 383, 210]; a picture of a man with a gun in his hand: [0, 80, 383, 132]; a room with a sign on it: [0, 0, 383, 96]; a grey png image of a black and white picture: [129, 0, 254, 81]; a gray piece of paper with a black background: [0, 0, 132, 96]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "multicolored snowboard: [177, 47, 220, 122]; snow covering the ground: [35, 72, 356, 211]; a snowboarder on a snow covered hill: [81, 28, 280, 175]; a dark patterned fence in the distance: [309, 66, 383, 93]; the gray wall behind the hydrant: [0, 2, 383, 98]; object is on the ground: [166, 40, 239, 132]; blue and black base of hydrant: [185, 92, 205, 117]; the fire hydrant has black stripes: [187, 68, 214, 96]; a black square object in the background: [104, 64, 169, 84]; base of blue pole: [175, 106, 213, 123]; blue base of hydrant: [179, 90, 210, 121]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 80, 383, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 0, 254, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 132, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 73, 105, 24]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a person is standing on a snowy ground: [0, 80, 383, 132]; a silhouette of a man standing in a room: [0, 0, 383, 96]; a black and white picture of a gray wall: [129, 0, 254, 81]; a gray piece of paper with the words nebraska: [0, 0, 132, 96]; a black and white image of a tv screen: [0, 73, 105, 24]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: multicolored snowboard: [177, 47, 220, 122]; snow covering the ground: [35, 72, 356, 211]; a snowboarder on a snow covered hill: [81, 28, 280, 175]; a dark patterned fence in the distance: [309, 66, 383, 93]; the gray wall behind the hydrant: [0, 2, 383, 98]; object is on the ground: [166, 40, 239, 132]; blue and black base of hydrant: [185, 92, 205, 117]; the fire hydrant has black stripes: [187, 68, 214, 96]; a black square object in the background: [104, 64, 169, 84]; base of blue pole: [175, 106, 213, 123]; blue base of hydrant: [179, 90, 210, 121]; ; Region Captions: a person is standing on a snowy ground: [0, 80, 383, 132]; a silhouette of a man standing in a room: [0, 0, 383, 96]; a black and white picture of a gray wall: [129, 0, 254, 81]; a gray piece of paper with the words nebraska: [0, 0, 132, 96]; a black and white image of a tv screen: [0, 73, 105, 24]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with some blocks and a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [157, 68, 232, 111]; white sheets on the bed: [33, 74, 352, 211]; box is brown color: [61, 61, 164, 104]; the bed has a brown box: [47, 23, 294, 149]; two brown baskets on table: [49, 49, 241, 119]; white wall in the background: [0, 1, 137, 96]; the bed is white: [20, 108, 252, 210]; a box on the bed: [24, 29, 168, 126]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 91, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[1, 0, 382, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 0, 254, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 132, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[63, 68, 96, 34]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy mountain with a white snowy mountain: [0, 91, 383, 122]; a black and white image of a wall: [1, 0, 382, 143]; a gray wall with a black background: [129, 0, 254, 143]; a gray arrow with a white background: [0, 0, 132, 95]; a black block with a blue ring on it: [63, 68, 96, 34]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with some blocks and a table; Dense Caption: the box is brown: [157, 68, 232, 111]; white sheets on the bed: [33, 74, 352, 211]; box is brown color: [61, 61, 164, 104]; the bed has a brown box: [47, 23, 294, 149]; two brown baskets on table: [49, 49, 241, 119]; white wall in the background: [0, 1, 137, 96]; the bed is white: [20, 108, 252, 210]; a box on the bed: [24, 29, 168, 126]; ; Region Captions: a white snowy mountain with a white snowy mountain: [0, 91, 383, 122]; a black and white image of a wall: [1, 0, 382, 143]; a gray wall with a black background: [129, 0, 254, 143]; a gray arrow with a white background: [0, 0, 132, 95]; a black block with a blue ring on it: [63, 68, 96, 34]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a few blocks and a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the wooden box on the bed: [183, 35, 263, 83]; square shaped pillow: [93, 28, 191, 70]; white bed sheets: [0, 38, 382, 211]; a piece of cardboard with writing on it: [1, 151, 112, 211]; the boxes are made of wood: [75, 14, 273, 89]; the box is brown: [148, 11, 314, 118]; white wall in the background: [1, 1, 163, 63]; a square of wood: [195, 37, 234, 77]; the square brown suitcase: [214, 42, 260, 82]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 57, 383, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[159, 0, 224, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 158, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 156, 105, 57]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a white arrow with a black background: [0, 57, 383, 155]; a black and white image of a wall: [2, 0, 381, 115]; a black and gray wall with a black and gray wall: [159, 0, 224, 115]; a gray piece of paper with a black background: [0, 0, 158, 62]; a triangle with a black background: [0, 156, 105, 57]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a few blocks and a table; Dense Caption: the wooden box on the bed: [183, 35, 263, 83]; square shaped pillow: [93, 28, 191, 70]; white bed sheets: [0, 38, 382, 211]; a piece of cardboard with writing on it: [1, 151, 112, 211]; the boxes are made of wood: [75, 14, 273, 89]; the box is brown: [148, 11, 314, 118]; white wall in the background: [1, 1, 163, 63]; a square of wood: [195, 37, 234, 77]; the square brown suitcase: [214, 42, 260, 82]; ; Region Captions: a white arrow with a black background: [0, 57, 383, 155]; a black and white image of a wall: [2, 0, 381, 115]; a black and gray wall with a black and gray wall: [159, 0, 224, 115]; a gray piece of paper with a black background: [0, 0, 158, 62]; a triangle with a black background: [0, 156, 105, 57]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden chest\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [147, 55, 322, 136]; the table cloth is checkered: [0, 51, 140, 185]; white bed sheet on bed: [30, 75, 341, 213]; a light brown section of a suitcase: [195, 61, 254, 125]; a white lamp shade: [0, 0, 33, 59]; the wall is white: [33, 0, 341, 138]; the table is white: [169, 139, 297, 204]; the wall is white: [37, 2, 343, 59]; a black object on the bed: [2, 56, 61, 81]; the sky is dark: [164, 8, 287, 52]; a yellow post it note: [198, 61, 254, 79]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 95, 383, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[10, 1, 373, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 56, 139, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 62, 170, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[246, 67, 74, 65]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a floor: [0, 95, 383, 117]; a black and white image of a wall: [10, 1, 373, 117]; a black and white image of a minecraft block: [0, 56, 139, 125]; a wooden block with brown and white stripes: [150, 62, 170, 70]; a wooden block in minecraft: [246, 67, 74, 65]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden chest; Dense Caption: a brown wooden box: [147, 55, 322, 136]; the table cloth is checkered: [0, 51, 140, 185]; white bed sheet on bed: [30, 75, 341, 213]; a light brown section of a suitcase: [195, 61, 254, 125]; a white lamp shade: [0, 0, 33, 59]; the wall is white: [33, 0, 341, 138]; the table is white: [169, 139, 297, 204]; the wall is white: [37, 2, 343, 59]; a black object on the bed: [2, 56, 61, 81]; the sky is dark: [164, 8, 287, 52]; a yellow post it note: [198, 61, 254, 79]; ; Region Captions: a white and black image of a floor: [0, 95, 383, 117]; a black and white image of a wall: [10, 1, 373, 117]; a black and white image of a minecraft block: [0, 56, 139, 125]; a wooden block with brown and white stripes: [150, 62, 170, 70]; a wooden block in minecraft: [246, 67, 74, 65]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft table with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown and beige suitcase: [44, 141, 378, 212]; a tall gray building: [0, 133, 68, 212]; the sky is dark: [36, 4, 349, 152]; a white and green strip: [127, 148, 243, 212]; the sky is dark: [77, 81, 366, 208]; the sky is dark: [157, 84, 271, 142]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 201]\n",
      "process_ann took 0.00 seconds\n",
      "[49, 156, 334, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[236, 156, 147, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 151, 111, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[46, 147, 120, 66]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and gray wall with a black and gray wall: [0, 0, 383, 201]; a wooden plank with a wooden handle: [49, 156, 334, 57]; a wooden plank on a black background: [236, 156, 147, 57]; a wooden block on a black background: [129, 151, 111, 62]; a wooden table with a wooden top: [46, 147, 120, 66]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft table with different colored blocks; Dense Caption: brown and beige suitcase: [44, 141, 378, 212]; a tall gray building: [0, 133, 68, 212]; the sky is dark: [36, 4, 349, 152]; a white and green strip: [127, 148, 243, 212]; the sky is dark: [77, 81, 366, 208]; the sky is dark: [157, 84, 271, 142]; ; Region Captions: a black and gray wall with a black and gray wall: [0, 0, 383, 201]; a wooden plank with a wooden handle: [49, 156, 334, 57]; a wooden plank on a black background: [236, 156, 147, 57]; a wooden block on a black background: [129, 151, 111, 62]; a wooden table with a wooden top: [46, 147, 120, 66]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft table with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown and beige suitcase: [44, 141, 378, 212]; a tall gray building: [0, 133, 68, 212]; the sky is dark: [36, 4, 349, 152]; a white and green strip: [127, 148, 243, 212]; the sky is dark: [77, 81, 366, 208]; the sky is dark: [157, 84, 271, 142]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 201]\n",
      "process_ann took 0.00 seconds\n",
      "[49, 156, 334, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[236, 156, 147, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 151, 111, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[46, 147, 120, 66]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and gray wall with a black and gray wall: [0, 0, 383, 201]; a wooden plank with a wooden handle: [49, 156, 334, 57]; a wooden plank on a black background: [236, 156, 147, 57]; a wooden block on a black background: [129, 151, 111, 62]; a wooden table with a wooden top: [46, 147, 120, 66]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft table with different colored blocks; Dense Caption: brown and beige suitcase: [44, 141, 378, 212]; a tall gray building: [0, 133, 68, 212]; the sky is dark: [36, 4, 349, 152]; a white and green strip: [127, 148, 243, 212]; the sky is dark: [77, 81, 366, 208]; the sky is dark: [157, 84, 271, 142]; ; Region Captions: a black and gray wall with a black and gray wall: [0, 0, 383, 201]; a wooden plank with a wooden handle: [49, 156, 334, 57]; a wooden plank on a black background: [236, 156, 147, 57]; a wooden block on a black background: [129, 151, 111, 62]; a wooden table with a wooden top: [46, 147, 120, 66]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a table with a wooden top and a grey background\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown and white umbrella: [0, 134, 382, 211]; a white cloth seat: [130, 136, 299, 211]; the sky is dark: [36, 4, 346, 143]; the sky is clear: [22, 38, 304, 191]; a brown section of a roof: [2, 138, 143, 210]; the sky is clear: [149, 64, 262, 124]; the line is white: [188, 139, 231, 204]; a brown wooden table: [251, 134, 383, 208]; the sky is clear: [121, 73, 236, 130]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 178]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 139, 167, 74]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 140, 158, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[245, 139, 138, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[131, 202, 167, 11]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.52 seconds\n",
      "finished...\n",
      "\n",
      "a black and white room with a black floor: [0, 1, 383, 178]; a wooden board on a black background: [131, 139, 167, 74]; a wooden floor in minecraft: [0, 140, 158, 73]; a wooden table with a black background: [245, 139, 138, 73]; a wooden board with a wooden frame: [131, 202, 167, 11]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a table with a wooden top and a grey background; Dense Caption: brown and white umbrella: [0, 134, 382, 211]; a white cloth seat: [130, 136, 299, 211]; the sky is dark: [36, 4, 346, 143]; the sky is clear: [22, 38, 304, 191]; a brown section of a roof: [2, 138, 143, 210]; the sky is clear: [149, 64, 262, 124]; the line is white: [188, 139, 231, 204]; a brown wooden table: [251, 134, 383, 208]; the sky is clear: [121, 73, 236, 130]; ; Region Captions: a black and white room with a black floor: [0, 1, 383, 178]; a wooden board on a black background: [131, 139, 167, 74]; a wooden floor in minecraft: [0, 140, 158, 73]; a wooden table with a black background: [245, 139, 138, 73]; a wooden board with a wooden frame: [131, 202, 167, 11]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing next to a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is cardboard: [0, 61, 190, 160]; lego person carrying a surfboard: [294, 21, 378, 119]; the ground is white: [35, 45, 352, 210]; yellow and blue stripes: [317, 24, 377, 63]; red part of the kite: [300, 52, 365, 88]; a white and gold square: [78, 69, 150, 138]; the wall is gray: [32, 1, 349, 120]; blue base of umbrella: [303, 84, 340, 114]; shadow of the object: [292, 99, 344, 122]; blue and white base of lego sign: [301, 52, 350, 115]; a stack of black boxes: [356, 51, 383, 83]; a lego ice cream cone: [277, 37, 358, 130]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 73, 383, 139]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 353, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 69, 186, 89]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a stairway: [0, 73, 383, 139]; a black and white image of a small room: [0, 2, 383, 210]; a black and white image of a room: [0, 0, 383, 137]; a gray png image of a png file: [0, 0, 353, 95]; a block of wood in minecraft: [0, 69, 186, 89]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing next to a box; Dense Caption: the box is cardboard: [0, 61, 190, 160]; lego person carrying a surfboard: [294, 21, 378, 119]; the ground is white: [35, 45, 352, 210]; yellow and blue stripes: [317, 24, 377, 63]; red part of the kite: [300, 52, 365, 88]; a white and gold square: [78, 69, 150, 138]; the wall is gray: [32, 1, 349, 120]; blue base of umbrella: [303, 84, 340, 114]; shadow of the object: [292, 99, 344, 122]; blue and white base of lego sign: [301, 52, 350, 115]; a stack of black boxes: [356, 51, 383, 83]; a lego ice cream cone: [277, 37, 358, 130]; ; Region Captions: a black and white image of a stairway: [0, 73, 383, 139]; a black and white image of a small room: [0, 2, 383, 210]; a black and white image of a room: [0, 0, 383, 137]; a gray png image of a png file: [0, 0, 353, 95]; a block of wood in minecraft: [0, 69, 186, 89]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a blue light on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the keyboard of a laptop: [256, 10, 383, 163]; a bed in a room: [1, 2, 382, 210]; a clear plastic pen: [336, 18, 383, 52]; a black and white rug: [0, 0, 61, 28]; the snow is white: [11, 39, 242, 204]; the wall is white: [2, 0, 380, 51]; the snow is white in color: [69, 58, 179, 153]; the snow is white: [79, 85, 187, 178]; the snow is white in color: [98, 49, 203, 131]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 19, 383, 193]\n",
      "process_ann took 0.00 seconds\n",
      "[259, 15, 124, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[53, 0, 330, 47]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 58, 25]\n",
      "process_ann took 0.00 seconds\n",
      "[285, 60, 25, 8]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.51 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy surface with a black background: [0, 19, 383, 193]; a block of black and blue blocks: [259, 15, 124, 143]; a grey metal sheet with a black background: [53, 0, 330, 47]; a black leather wallet with a black pattern: [0, 0, 58, 25]; a black hat with a black hat: [285, 60, 25, 8]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a blue light on it; Dense Caption: the keyboard of a laptop: [256, 10, 383, 163]; a bed in a room: [1, 2, 382, 210]; a clear plastic pen: [336, 18, 383, 52]; a black and white rug: [0, 0, 61, 28]; the snow is white: [11, 39, 242, 204]; the wall is white: [2, 0, 380, 51]; the snow is white in color: [69, 58, 179, 153]; the snow is white: [79, 85, 187, 178]; the snow is white in color: [98, 49, 203, 131]; ; Region Captions: a white snowy surface with a black background: [0, 19, 383, 193]; a block of black and blue blocks: [259, 15, 124, 143]; a grey metal sheet with a black background: [53, 0, 330, 47]; a black leather wallet with a black pattern: [0, 0, 58, 25]; a black hat with a black hat: [285, 60, 25, 8]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a blue light on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the keyboard of a laptop: [256, 10, 383, 163]; a bed in a room: [1, 2, 382, 210]; a clear plastic pen: [336, 18, 383, 52]; a black and white rug: [0, 0, 61, 28]; the snow is white: [11, 39, 242, 204]; the wall is white: [2, 0, 380, 51]; the snow is white in color: [69, 58, 179, 153]; the snow is white: [79, 85, 187, 178]; the snow is white in color: [98, 49, 203, 131]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 19, 383, 193]\n",
      "process_ann took 0.00 seconds\n",
      "[259, 15, 124, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[53, 0, 330, 47]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 58, 25]\n",
      "process_ann took 0.00 seconds\n",
      "[285, 60, 25, 8]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.52 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy surface with a black background: [0, 19, 383, 193]; a block of black and blue blocks: [259, 15, 124, 143]; a grey metal sheet with a black background: [53, 0, 330, 47]; a black leather wallet with a black pattern: [0, 0, 58, 25]; a black hat with a black hat: [285, 60, 25, 8]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a blue light on it; Dense Caption: the keyboard of a laptop: [256, 10, 383, 163]; a bed in a room: [1, 2, 382, 210]; a clear plastic pen: [336, 18, 383, 52]; a black and white rug: [0, 0, 61, 28]; the snow is white: [11, 39, 242, 204]; the wall is white: [2, 0, 380, 51]; the snow is white in color: [69, 58, 179, 153]; the snow is white: [79, 85, 187, 178]; the snow is white in color: [98, 49, 203, 131]; ; Region Captions: a white snowy surface with a black background: [0, 19, 383, 193]; a block of black and blue blocks: [259, 15, 124, 143]; a grey metal sheet with a black background: [53, 0, 330, 47]; a black leather wallet with a black pattern: [0, 0, 58, 25]; a black hat with a black hat: [285, 60, 25, 8]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a person jumping over a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a square napkin holder: [229, 72, 309, 138]; white bedsheets: [34, 71, 345, 210]; a figure of a person: [97, 13, 142, 62]; the basket is brown: [0, 54, 119, 105]; the brown card board box: [126, 56, 193, 83]; a lego snowboarder: [36, 6, 339, 160]; a box on the table: [205, 55, 323, 157]; the wall is white: [25, 1, 358, 80]; a red coat on the person: [99, 28, 133, 49]; a yellow and blue umbrella: [105, 14, 130, 32]; a white wall: [0, 0, 41, 65]; blue pants on the figure: [102, 46, 135, 61]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 63, 383, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[19, 0, 364, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 34, 138, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 60, 118, 43]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 63, 383, 149]; a silhouette of a rocket in the sky: [0, 0, 383, 106]; a silhouette of a man standing in front of a building: [19, 0, 364, 76]; a black block with a black background: [0, 34, 138, 69]; a black block with a black background: [0, 60, 118, 43]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a person jumping over a box; Dense Caption: a square napkin holder: [229, 72, 309, 138]; white bedsheets: [34, 71, 345, 210]; a figure of a person: [97, 13, 142, 62]; the basket is brown: [0, 54, 119, 105]; the brown card board box: [126, 56, 193, 83]; a lego snowboarder: [36, 6, 339, 160]; a box on the table: [205, 55, 323, 157]; the wall is white: [25, 1, 358, 80]; a red coat on the person: [99, 28, 133, 49]; a yellow and blue umbrella: [105, 14, 130, 32]; a white wall: [0, 0, 41, 65]; blue pants on the figure: [102, 46, 135, 61]; ; Region Captions: a black and white image of a snowy area: [0, 63, 383, 149]; a silhouette of a rocket in the sky: [0, 0, 383, 106]; a silhouette of a man standing in front of a building: [19, 0, 364, 76]; a black block with a black background: [0, 34, 138, 69]; a black block with a black background: [0, 60, 118, 43]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a box and a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a square napkin holder: [229, 72, 309, 138]; white bedspread on the bed: [34, 71, 344, 210]; the basket is brown: [0, 55, 120, 105]; the square box on the bed: [126, 54, 194, 83]; a small lego figure: [85, 11, 123, 63]; a bed in a room: [37, 7, 339, 157]; a box on the table: [205, 55, 324, 157]; the wall is white: [36, 1, 353, 79]; a white pillow: [0, 0, 41, 65]; a yellow and blue tag: [88, 11, 111, 30]; red jacket on the blue pole: [91, 25, 111, 47]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 66, 383, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[19, 0, 364, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 60, 117, 43]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 40, 119, 63]\n",
      "process_ann took 0.00 seconds\n",
      "[233, 77, 73, 58]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.56 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 66, 383, 146]; a silhouette of a rocket with a black background: [19, 0, 364, 76]; a black block of bricks on a black background: [0, 60, 117, 43]; a black block with a black background: [0, 40, 119, 63]; a grey box with a white background: [233, 77, 73, 58]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a box and a box; Dense Caption: a square napkin holder: [229, 72, 309, 138]; white bedspread on the bed: [34, 71, 344, 210]; the basket is brown: [0, 55, 120, 105]; the square box on the bed: [126, 54, 194, 83]; a small lego figure: [85, 11, 123, 63]; a bed in a room: [37, 7, 339, 157]; a box on the table: [205, 55, 324, 157]; the wall is white: [36, 1, 353, 79]; a white pillow: [0, 0, 41, 65]; a yellow and blue tag: [88, 11, 111, 30]; red jacket on the blue pole: [91, 25, 111, 47]; ; Region Captions: a black and white image of a snowy area: [0, 66, 383, 146]; a silhouette of a rocket with a black background: [19, 0, 364, 76]; a black block of bricks on a black background: [0, 60, 117, 43]; a black block with a black background: [0, 40, 119, 63]; a grey box with a white background: [233, 77, 73, 58]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a white box and a white block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white and black book: [137, 84, 190, 135]; a white bed spread: [31, 75, 347, 212]; the chair is brown: [0, 73, 94, 116]; the basket is small: [213, 67, 288, 92]; the bed is made: [34, 47, 279, 172]; the box is white: [127, 76, 207, 147]; the wall is white: [30, 1, 275, 99]; a bed in the room: [175, 15, 330, 130]; a lamp on a table: [211, 1, 290, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 87, 383, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[252, 0, 131, 78]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 80, 88, 32]\n",
      "process_ann took 0.00 seconds\n",
      "[139, 88, 49, 46]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.56 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy mountain: [0, 87, 383, 125]; a black and white image of a wall: [0, 0, 383, 97]; a gray map of alabama: [252, 0, 131, 78]; a brown and white block of bricks: [0, 80, 88, 32]; a gray box with a white lid on it: [139, 88, 49, 46]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a white box and a white block; Dense Caption: a white and black book: [137, 84, 190, 135]; a white bed spread: [31, 75, 347, 212]; the chair is brown: [0, 73, 94, 116]; the basket is small: [213, 67, 288, 92]; the bed is made: [34, 47, 279, 172]; the box is white: [127, 76, 207, 147]; the wall is white: [30, 1, 275, 99]; a bed in the room: [175, 15, 330, 130]; a lamp on a table: [211, 1, 290, 92]; ; Region Captions: a black and white image of a snowy mountain: [0, 87, 383, 125]; a black and white image of a wall: [0, 0, 383, 97]; a gray map of alabama: [252, 0, 131, 78]; a brown and white block of bricks: [0, 80, 88, 32]; a gray box with a white lid on it: [139, 88, 49, 46]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a white box and some boxes\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the basket is on the floor: [170, 74, 222, 126]; the bed is made: [35, 56, 344, 209]; two brown square boxes: [46, 60, 132, 95]; the basket is small: [247, 52, 342, 83]; there are two pillows: [33, 27, 343, 145]; the wall is white: [28, 1, 334, 88]; a brown wicker basket: [0, 65, 35, 112]; the bed is white: [34, 121, 276, 210]; the box is white: [160, 67, 237, 136]; a lego house is on the side: [0, 23, 39, 114]; a colorful umbrella: [0, 24, 22, 72]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 73, 383, 139]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[285, 0, 98, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[173, 78, 46, 45]\n",
      "process_ann took 0.00 seconds\n",
      "[48, 65, 80, 28]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 73, 383, 139]; a 3d image of a room with a black wall: [0, 0, 383, 89]; a gray square with the word nasa: [285, 0, 98, 81]; a gray box with a white top: [173, 78, 46, 45]; a brown and white block of wood: [48, 65, 80, 28]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a white box and some boxes; Dense Caption: the basket is on the floor: [170, 74, 222, 126]; the bed is made: [35, 56, 344, 209]; two brown square boxes: [46, 60, 132, 95]; the basket is small: [247, 52, 342, 83]; there are two pillows: [33, 27, 343, 145]; the wall is white: [28, 1, 334, 88]; a brown wicker basket: [0, 65, 35, 112]; the bed is white: [34, 121, 276, 210]; the box is white: [160, 67, 237, 136]; a lego house is on the side: [0, 23, 39, 114]; a colorful umbrella: [0, 24, 22, 72]; ; Region Captions: a black and white image of a snowy area: [0, 73, 383, 139]; a 3d image of a room with a black wall: [0, 0, 383, 89]; a gray square with the word nasa: [285, 0, 98, 81]; a gray box with a white top: [173, 78, 46, 45]; a brown and white block of wood: [48, 65, 80, 28]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man standing next to a pile of blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white box on the floor: [189, 84, 263, 154]; the box is brown: [259, 66, 339, 104]; white tablecloth on the table: [0, 75, 382, 211]; small square shaped board: [185, 62, 265, 88]; lego figure on top of a cake: [245, 30, 270, 70]; the items are on the table: [147, 29, 325, 177]; the wall is white: [0, 2, 238, 84]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 80, 383, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 236, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[234, 0, 149, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[194, 89, 66, 62]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small black object: [0, 80, 383, 132]; a black and white image of a person standing in a room: [0, 0, 383, 112]; a gray piece of paper with a black background: [0, 0, 236, 84]; a silhouette of a man standing on a ledge: [234, 0, 149, 113]; a grey box with a white background: [194, 89, 66, 62]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man standing next to a pile of blocks; Dense Caption: a white box on the floor: [189, 84, 263, 154]; the box is brown: [259, 66, 339, 104]; white tablecloth on the table: [0, 75, 382, 211]; small square shaped board: [185, 62, 265, 88]; lego figure on top of a cake: [245, 30, 270, 70]; the items are on the table: [147, 29, 325, 177]; the wall is white: [0, 2, 238, 84]; ; Region Captions: a black and white image of a small black object: [0, 80, 383, 132]; a black and white image of a person standing in a room: [0, 0, 383, 112]; a gray piece of paper with a black background: [0, 0, 236, 84]; a silhouette of a man standing on a ledge: [234, 0, 149, 113]; a grey box with a white background: [194, 89, 66, 62]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft scene with a man standing next to a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white box: [201, 104, 333, 212]; the box is brown: [207, 71, 282, 106]; a brown wicker basket: [111, 67, 209, 103]; white bed sheets: [0, 79, 382, 211]; colorful figurine on top of a cake: [185, 34, 210, 76]; white paper on top of the box: [214, 104, 328, 163]; white wall in the background: [0, 1, 166, 103]; a small box on the bed: [121, 18, 334, 142]; a toy on the bed: [75, 22, 224, 128]; white blanket on the bed: [4, 104, 197, 209]; the sheet is white in color: [44, 108, 163, 186]; a bed in the room: [156, 50, 357, 213]; a lego figure on a table: [176, 28, 220, 88]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 92, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 92, 246, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[166, 0, 217, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 165, 103]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy mountain: [0, 92, 383, 120]; a white piece of paper on a black background: [0, 92, 246, 120]; a silhouette of a person standing on a ledge: [2, 0, 381, 118]; a silhouette of a man standing on a ledge: [166, 0, 217, 118]; a gray shaped png file with a white background: [0, 0, 165, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft scene with a man standing next to a box; Dense Caption: a white box: [201, 104, 333, 212]; the box is brown: [207, 71, 282, 106]; a brown wicker basket: [111, 67, 209, 103]; white bed sheets: [0, 79, 382, 211]; colorful figurine on top of a cake: [185, 34, 210, 76]; white paper on top of the box: [214, 104, 328, 163]; white wall in the background: [0, 1, 166, 103]; a small box on the bed: [121, 18, 334, 142]; a toy on the bed: [75, 22, 224, 128]; white blanket on the bed: [4, 104, 197, 209]; the sheet is white in color: [44, 108, 163, 186]; a bed in the room: [156, 50, 357, 213]; a lego figure on a table: [176, 28, 220, 88]; ; Region Captions: a black and white image of a snowy mountain: [0, 92, 383, 120]; a white piece of paper on a black background: [0, 92, 246, 120]; a silhouette of a person standing on a ledge: [2, 0, 381, 118]; a silhouette of a man standing on a ledge: [166, 0, 217, 118]; a gray shaped png file with a white background: [0, 0, 165, 103]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a square shaped box: [124, 66, 229, 106]; the box is brown: [233, 70, 311, 104]; white bedspread on the bed: [37, 80, 352, 210]; colorful lego man: [207, 34, 233, 76]; the items are on the bed: [111, 30, 329, 119]; a lego train on display: [54, 26, 326, 173]; a lego toy on a bed: [85, 32, 252, 142]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 92, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[173, 0, 210, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 173, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[127, 72, 98, 32]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy mountain with a black background: [0, 92, 383, 120]; a black and white image of a room with a white wall: [0, 0, 383, 116]; a silhouette of a man standing on a wall: [173, 0, 210, 106]; a gray shaped piece of paper: [0, 0, 173, 116]; a black cube with a black background: [127, 72, 98, 32]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: a square shaped box: [124, 66, 229, 106]; the box is brown: [233, 70, 311, 104]; white bedspread on the bed: [37, 80, 352, 210]; colorful lego man: [207, 34, 233, 76]; the items are on the bed: [111, 30, 329, 119]; a lego train on display: [54, 26, 326, 173]; a lego toy on a bed: [85, 32, 252, 142]; ; Region Captions: a white snowy mountain with a black background: [0, 92, 383, 120]; a black and white image of a room with a white wall: [0, 0, 383, 116]; a silhouette of a man standing on a wall: [173, 0, 210, 106]; a gray shaped piece of paper: [0, 0, 173, 116]; a black cube with a black background: [127, 72, 98, 32]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden box in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [0, 93, 188, 194]; white snow on the ground: [1, 131, 382, 212]; the sky is dark: [35, 3, 348, 146]; a book on the ground: [27, 38, 258, 205]; snow covered ground: [194, 139, 379, 210]; a brown section of a book: [105, 98, 184, 183]; sheet of plywood in sand: [23, 99, 127, 126]; the sky is grey in color: [220, 20, 340, 97]; a line of different color tiles: [19, 106, 119, 189]; the sky is cloudy: [220, 47, 340, 124]; the sky is overcast: [22, 5, 278, 96]; the corner of the book: [0, 100, 65, 192]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 137, 383, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 102, 181, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[20, 103, 104, 85]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a plane flying over a grey sky: [0, 1, 383, 143]; a black and white image of a mountain: [0, 1, 383, 99]; a white skateboard on a black surface: [0, 137, 383, 75]; a wooden block with a brown and white color: [0, 102, 181, 89]; a wooden block on a black background: [20, 103, 104, 85]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden box in a minecraft game; Dense Caption: a brown wooden box: [0, 93, 188, 194]; white snow on the ground: [1, 131, 382, 212]; the sky is dark: [35, 3, 348, 146]; a book on the ground: [27, 38, 258, 205]; snow covered ground: [194, 139, 379, 210]; a brown section of a book: [105, 98, 184, 183]; sheet of plywood in sand: [23, 99, 127, 126]; the sky is grey in color: [220, 20, 340, 97]; a line of different color tiles: [19, 106, 119, 189]; the sky is cloudy: [220, 47, 340, 124]; the sky is overcast: [22, 5, 278, 96]; the corner of the book: [0, 100, 65, 192]; ; Region Captions: a black and white image of a plane flying over a grey sky: [0, 1, 383, 143]; a black and white image of a mountain: [0, 1, 383, 99]; a white skateboard on a black surface: [0, 137, 383, 75]; a wooden block with a brown and white color: [0, 102, 181, 89]; a wooden block on a black background: [20, 103, 104, 85]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown and tan suitcase on the ground: [103, 100, 336, 193]; a checkered bedspread: [0, 102, 92, 212]; a line of yellow square boxes: [183, 106, 261, 190]; white tablecloth on the table: [6, 148, 382, 211]; the photo was taken in the daytime: [0, 7, 381, 209]; the sky is grey: [34, 3, 346, 113]; a line of squares in the middle of the book: [185, 106, 259, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 152]\n",
      "process_ann took 0.00 seconds\n",
      "[3, 108, 330, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[108, 108, 225, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[25, 152, 358, 61]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 109, 87, 104]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white cube: [0, 1, 383, 152]; a wooden block with a brown and white color: [3, 108, 330, 103]; a brown and white block of wood: [108, 108, 225, 83]; a silver metal letter l on a black background: [25, 152, 358, 61]; a black and white block of bricks: [0, 109, 87, 104]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: brown and tan suitcase on the ground: [103, 100, 336, 193]; a checkered bedspread: [0, 102, 92, 212]; a line of yellow square boxes: [183, 106, 261, 190]; white tablecloth on the table: [6, 148, 382, 211]; the photo was taken in the daytime: [0, 7, 381, 209]; the sky is grey: [34, 3, 346, 113]; a line of squares in the middle of the book: [185, 106, 259, 127]; ; Region Captions: a black and white image of a black and white cube: [0, 1, 383, 152]; a wooden block with a brown and white color: [3, 108, 330, 103]; a brown and white block of wood: [108, 108, 225, 83]; a silver metal letter l on a black background: [25, 152, 358, 61]; a black and white block of bricks: [0, 109, 87, 104]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown and tan box: [137, 86, 379, 188]; a black and white checkered bedspread: [0, 78, 123, 211]; a line of yellow square boxes: [206, 92, 293, 179]; the bed has a plaid bedspread: [26, 37, 354, 214]; the sky is overcast: [37, 2, 350, 89]; white table cloth on table: [26, 128, 377, 212]; the back of the chair: [137, 88, 211, 172]; the sky is clear: [144, 19, 273, 78]; the bed is made of wood: [220, 98, 279, 157]; the bed is made of wood: [126, 22, 369, 171]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[139, 92, 244, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[29, 95, 354, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[29, 133, 354, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 87, 121, 126]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a cloud: [0, 1, 383, 130]; a wooden block with brown and white stripes: [139, 92, 244, 96]; a black and white image of a square: [29, 95, 354, 118]; a silver triangle with a black background: [29, 133, 354, 80]; a black and white block with a black and white logo: [0, 87, 121, 126]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: brown and tan box: [137, 86, 379, 188]; a black and white checkered bedspread: [0, 78, 123, 211]; a line of yellow square boxes: [206, 92, 293, 179]; the bed has a plaid bedspread: [26, 37, 354, 214]; the sky is overcast: [37, 2, 350, 89]; white table cloth on table: [26, 128, 377, 212]; the back of the chair: [137, 88, 211, 172]; the sky is clear: [144, 19, 273, 78]; the bed is made of wood: [220, 98, 279, 157]; the bed is made of wood: [126, 22, 369, 171]; ; Region Captions: a black and white image of a building with a cloud: [0, 1, 383, 130]; a wooden block with brown and white stripes: [139, 92, 244, 96]; a black and white image of a square: [29, 95, 354, 118]; a silver triangle with a black background: [29, 133, 354, 80]; a black and white block with a black and white logo: [0, 87, 121, 126]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft screenshot of a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown building under a blue sky: [16, 127, 232, 211]; kite in the sky: [111, 0, 192, 39]; sky is dark and cloudy: [0, 1, 382, 210]; a line of different colored bricks: [103, 131, 175, 211]; the building is made of wood: [35, 70, 295, 214]; snow on the ground: [243, 144, 375, 211]; snow on the ground: [122, 148, 383, 212]; the snow is white in color: [282, 166, 348, 207]; kite in the sky: [98, 1, 208, 56]; a brown wood slat: [96, 141, 121, 213]; a yellow line of sunlight: [106, 131, 173, 151]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 194]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[19, 131, 209, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 152, 381, 61]\n",
      "process_ann took 0.00 seconds\n",
      "[136, 152, 247, 61]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man with a knife: [0, 0, 383, 194]; a black and white logo with the words ada: [0, 0, 383, 129]; a brown and white block of wood: [19, 131, 209, 82]; a white and black tv with a white screen: [2, 152, 381, 61]; a white tv screen with a black background: [136, 152, 247, 61]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft screenshot of a wooden box; Dense Caption: brown building under a blue sky: [16, 127, 232, 211]; kite in the sky: [111, 0, 192, 39]; sky is dark and cloudy: [0, 1, 382, 210]; a line of different colored bricks: [103, 131, 175, 211]; the building is made of wood: [35, 70, 295, 214]; snow on the ground: [243, 144, 375, 211]; snow on the ground: [122, 148, 383, 212]; the snow is white in color: [282, 166, 348, 207]; kite in the sky: [98, 1, 208, 56]; a brown wood slat: [96, 141, 121, 213]; a yellow line of sunlight: [106, 131, 173, 151]; ; Region Captions: a black and white image of a man with a knife: [0, 0, 383, 194]; a black and white logo with the words ada: [0, 0, 383, 129]; a brown and white block of wood: [19, 131, 209, 82]; a white and black tv with a white screen: [2, 152, 381, 61]; a white tv screen with a black background: [136, 152, 247, 61]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person sitting on a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large white box: [198, 121, 287, 211]; the box is brown: [19, 104, 131, 149]; white bedspread on the bed: [1, 106, 381, 211]; a small patterned ottoman: [261, 97, 368, 129]; colorful figurine on top of a cake: [210, 80, 252, 128]; a bedroom: [33, 5, 345, 197]; yellow top of lego house: [215, 82, 244, 108]; red material on the box: [213, 102, 239, 127]; a red toy on a bed: [166, 76, 314, 210]; the wall is white: [14, 3, 287, 114]; a light brown wooden box: [63, 108, 101, 143]; toy train on top of the cake: [227, 117, 254, 129]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 296, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 118, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 123, 232, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[245, 118, 138, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[297, 0, 86, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing in a field: [0, 0, 296, 141]; a silhouette of a man walking down a snowy path: [0, 118, 383, 94]; a small png image of a snowy path: [0, 123, 232, 89]; a white snowy mountain with a white sled: [245, 118, 138, 95]; a gray state with a white outline: [297, 0, 86, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person sitting on a box; Dense Caption: a large white box: [198, 121, 287, 211]; the box is brown: [19, 104, 131, 149]; white bedspread on the bed: [1, 106, 381, 211]; a small patterned ottoman: [261, 97, 368, 129]; colorful figurine on top of a cake: [210, 80, 252, 128]; a bedroom: [33, 5, 345, 197]; yellow top of lego house: [215, 82, 244, 108]; red material on the box: [213, 102, 239, 127]; a red toy on a bed: [166, 76, 314, 210]; the wall is white: [14, 3, 287, 114]; a light brown wooden box: [63, 108, 101, 143]; toy train on top of the cake: [227, 117, 254, 129]; ; Region Captions: a silhouette of a man standing in a field: [0, 0, 296, 141]; a silhouette of a man walking down a snowy path: [0, 118, 383, 94]; a small png image of a snowy path: [0, 123, 232, 89]; a white snowy mountain with a white sled: [245, 118, 138, 95]; a gray state with a white outline: [297, 0, 86, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is cardboard: [197, 122, 288, 211]; a lego figure on a platform: [218, 46, 275, 121]; the box is brown: [19, 104, 131, 149]; white bedspread on the bed: [1, 106, 381, 211]; a black square box: [264, 97, 368, 129]; a scene of a bedroom: [31, 9, 347, 204]; the legs of the lego figure: [229, 90, 271, 116]; a lego snowboarder: [180, 51, 316, 211]; a light brown brick: [63, 107, 102, 143]; yellow top of a lego a toy house: [234, 48, 266, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 298, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 118, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 125, 231, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[240, 119, 143, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[297, 0, 86, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing on a hill: [0, 0, 298, 141]; a black and white image of a mountain: [0, 118, 383, 94]; a snowy mountain road with a snowy path: [0, 125, 231, 87]; a white snowy mountain with a ridge: [240, 119, 143, 93]; a gray state with a white outline: [297, 0, 86, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is standing in a room; Dense Caption: the box is cardboard: [197, 122, 288, 211]; a lego figure on a platform: [218, 46, 275, 121]; the box is brown: [19, 104, 131, 149]; white bedspread on the bed: [1, 106, 381, 211]; a black square box: [264, 97, 368, 129]; a scene of a bedroom: [31, 9, 347, 204]; the legs of the lego figure: [229, 90, 271, 116]; a lego snowboarder: [180, 51, 316, 211]; a light brown brick: [63, 107, 102, 143]; yellow top of a lego a toy house: [234, 48, 266, 73]; ; Region Captions: a silhouette of a man standing on a hill: [0, 0, 298, 141]; a black and white image of a mountain: [0, 118, 383, 94]; a snowy mountain road with a snowy path: [0, 125, 231, 87]; a white snowy mountain with a ridge: [240, 119, 143, 93]; a gray state with a white outline: [297, 0, 86, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a small room with a black square in the middle\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a snowy hill that a man is standing on: [0, 129, 382, 212]; a snow covered ground: [34, 13, 347, 210]; a small bed with a black object on top: [169, 121, 230, 141]; object on the ground: [115, 147, 140, 160]; the object is in the background: [162, 113, 237, 147]; object in the snow: [109, 142, 146, 167]; a pole on the ground: [172, 1, 225, 140]; the sky is clear: [1, 3, 189, 126]; the snow is white: [178, 148, 290, 205]; the sky is clear: [207, 4, 378, 129]; a pole in the background: [184, 1, 213, 128]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 137, 383, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[200, 0, 183, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 196, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 129, 170, 21]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 127, 155, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a small white plane flying over a white field: [0, 137, 383, 75]; a gray wall with a black background: [200, 0, 183, 150]; a gray square on a black background: [0, 0, 196, 134]; a gray arrow with a black background: [0, 129, 170, 21]; a black and gray arrow with a black background: [228, 127, 155, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a small room with a black square in the middle; Dense Caption: a snowy hill that a man is standing on: [0, 129, 382, 212]; a snow covered ground: [34, 13, 347, 210]; a small bed with a black object on top: [169, 121, 230, 141]; object on the ground: [115, 147, 140, 160]; the object is in the background: [162, 113, 237, 147]; object in the snow: [109, 142, 146, 167]; a pole on the ground: [172, 1, 225, 140]; the sky is clear: [1, 3, 189, 126]; the snow is white: [178, 148, 290, 205]; the sky is clear: [207, 4, 378, 129]; a pole in the background: [184, 1, 213, 128]; ; Region Captions: a small white plane flying over a white field: [0, 137, 383, 75]; a gray wall with a black background: [200, 0, 183, 150]; a gray square on a black background: [0, 0, 196, 134]; a gray arrow with a black background: [0, 129, 170, 21]; a black and gray arrow with a black background: [228, 127, 155, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a small room with a black square in the middle\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a snowy hill that a man is standing on: [0, 129, 382, 212]; a snow covered ground: [34, 13, 347, 210]; a small bed with a black object on top: [169, 121, 230, 141]; object on the ground: [115, 147, 140, 160]; the object is in the background: [162, 113, 237, 147]; object in the snow: [109, 142, 146, 167]; a pole on the ground: [172, 1, 225, 140]; the sky is clear: [1, 3, 189, 126]; the snow is white: [178, 148, 290, 205]; the sky is clear: [207, 4, 378, 129]; a pole in the background: [184, 1, 213, 128]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 137, 383, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[200, 0, 183, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 196, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 129, 170, 21]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 127, 155, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a small white plane flying over a white field: [0, 137, 383, 75]; a gray wall with a black background: [200, 0, 183, 150]; a gray square on a black background: [0, 0, 196, 134]; a gray arrow with a black background: [0, 129, 170, 21]; a black and gray arrow with a black background: [228, 127, 155, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a small room with a black square in the middle; Dense Caption: a snowy hill that a man is standing on: [0, 129, 382, 212]; a snow covered ground: [34, 13, 347, 210]; a small bed with a black object on top: [169, 121, 230, 141]; object on the ground: [115, 147, 140, 160]; the object is in the background: [162, 113, 237, 147]; object in the snow: [109, 142, 146, 167]; a pole on the ground: [172, 1, 225, 140]; the sky is clear: [1, 3, 189, 126]; the snow is white: [178, 148, 290, 205]; the sky is clear: [207, 4, 378, 129]; a pole in the background: [184, 1, 213, 128]; ; Region Captions: a small white plane flying over a white field: [0, 137, 383, 75]; a gray wall with a black background: [200, 0, 183, 150]; a gray square on a black background: [0, 0, 196, 134]; a gray arrow with a black background: [0, 129, 170, 21]; a black and gray arrow with a black background: [228, 127, 155, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a few different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a square patterned ottoman: [0, 74, 93, 158]; a silver and yellow object: [270, 36, 382, 170]; the box is brown: [107, 74, 187, 107]; a blue decorative base: [199, 84, 250, 128]; white tablecloth on the table: [39, 77, 353, 212]; a brown piece of luggage: [196, 45, 258, 129]; the boxes are made of cardboard: [93, 28, 351, 177]; the chocolate cake on the blue cake: [200, 47, 254, 91]; legos on the floor: [247, 51, 270, 106]; the sky is grey: [37, 0, 352, 63]; a large square cardboard box: [271, 97, 375, 169]; the floor is white: [47, 117, 256, 211]; the boxes are brown: [19, 39, 251, 158]; the snow is white: [110, 140, 229, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 383, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[203, 40, 180, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[274, 40, 109, 127]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black and white background: [0, 1, 383, 211]; a minecraft map with a snowy path: [0, 91, 383, 121]; a silhouette of a city with a cloudy sky: [0, 0, 383, 101]; a yellow block with a yellow and white arrow: [203, 40, 180, 127]; a yellow and grey block on a black background: [274, 40, 109, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a few different colored blocks; Dense Caption: a square patterned ottoman: [0, 74, 93, 158]; a silver and yellow object: [270, 36, 382, 170]; the box is brown: [107, 74, 187, 107]; a blue decorative base: [199, 84, 250, 128]; white tablecloth on the table: [39, 77, 353, 212]; a brown piece of luggage: [196, 45, 258, 129]; the boxes are made of cardboard: [93, 28, 351, 177]; the chocolate cake on the blue cake: [200, 47, 254, 91]; legos on the floor: [247, 51, 270, 106]; the sky is grey: [37, 0, 352, 63]; a large square cardboard box: [271, 97, 375, 169]; the floor is white: [47, 117, 256, 211]; the boxes are brown: [19, 39, 251, 158]; the snow is white: [110, 140, 229, 208]; ; Region Captions: a black and white image of a room with a black and white background: [0, 1, 383, 211]; a minecraft map with a snowy path: [0, 91, 383, 121]; a silhouette of a city with a cloudy sky: [0, 0, 383, 101]; a yellow block with a yellow and white arrow: [203, 40, 180, 127]; a yellow and grey block on a black background: [274, 40, 109, 127]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a few different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large checkered tablecloth: [0, 74, 93, 158]; a silver and yellow object: [270, 36, 382, 170]; the box is brown: [106, 74, 187, 107]; a blue decorative base: [199, 85, 250, 128]; white bed sheet: [39, 77, 352, 212]; the stack of suitcases: [197, 46, 256, 129]; red white and blue cooler: [248, 53, 273, 101]; the boxes are made of cardboard: [91, 28, 351, 178]; the brown part of the cake: [200, 47, 254, 91]; the sky is grey: [37, 0, 353, 63]; a large square cardboard box: [271, 97, 375, 169]; the floor is white: [46, 117, 256, 211]; red sticker on the side of the box: [250, 67, 272, 85]; the snow is white: [102, 140, 220, 208]; the boxes are brown: [19, 39, 251, 158]; a small light brown pillow: [135, 76, 164, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 383, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[274, 40, 109, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[203, 40, 180, 127]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black and white background: [0, 1, 383, 211]; a black and white image of a snowy path: [0, 91, 383, 121]; a silhouette of a city with a cloudy sky: [0, 0, 383, 101]; a yellow and grey block on a black background: [274, 40, 109, 127]; a yellow and white block with a yellow and white block: [203, 40, 180, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a few different colored blocks; Dense Caption: a large checkered tablecloth: [0, 74, 93, 158]; a silver and yellow object: [270, 36, 382, 170]; the box is brown: [106, 74, 187, 107]; a blue decorative base: [199, 85, 250, 128]; white bed sheet: [39, 77, 352, 212]; the stack of suitcases: [197, 46, 256, 129]; red white and blue cooler: [248, 53, 273, 101]; the boxes are made of cardboard: [91, 28, 351, 178]; the brown part of the cake: [200, 47, 254, 91]; the sky is grey: [37, 0, 353, 63]; a large square cardboard box: [271, 97, 375, 169]; the floor is white: [46, 117, 256, 211]; red sticker on the side of the box: [250, 67, 272, 85]; the snow is white: [102, 140, 220, 208]; the boxes are brown: [19, 39, 251, 158]; a small light brown pillow: [135, 76, 164, 105]; ; Region Captions: a black and white image of a room with a black and white background: [0, 1, 383, 211]; a black and white image of a snowy path: [0, 91, 383, 121]; a silhouette of a city with a cloudy sky: [0, 0, 383, 101]; a yellow and grey block on a black background: [274, 40, 109, 127]; a yellow and white block with a yellow and white block: [203, 40, 180, 127]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a few people standing around\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a square patterned ottoman: [0, 74, 93, 158]; a silver and yellow object: [270, 35, 382, 170]; a blue decorative base: [199, 84, 250, 128]; the box is brown: [106, 74, 187, 107]; white tablecloth on the table: [39, 77, 352, 212]; a brown piece of luggage: [197, 46, 256, 129]; the boxes are made of cardboard: [89, 26, 352, 179]; the chocolate cake on the blue cake: [200, 47, 254, 91]; lego construction bucket: [247, 53, 271, 103]; a large square cardboard box: [271, 97, 374, 169]; the boxes are brown: [30, 38, 275, 164]; the sky is grey: [37, 0, 352, 62]; the floor is white: [47, 118, 255, 211]; red box on top of the stack: [250, 67, 271, 87]; the snow is white: [102, 140, 220, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 91, 383, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[203, 40, 180, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[275, 40, 108, 127]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.70 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with some black and white objects: [0, 1, 383, 211]; a minecraft map with a snowy path: [0, 91, 383, 121]; a silhouette of a city with a cloudy sky: [0, 0, 383, 101]; a yellow and white block in minecraft: [203, 40, 180, 127]; a yellow and grey block on a black background: [275, 40, 108, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a few people standing around; Dense Caption: a square patterned ottoman: [0, 74, 93, 158]; a silver and yellow object: [270, 35, 382, 170]; a blue decorative base: [199, 84, 250, 128]; the box is brown: [106, 74, 187, 107]; white tablecloth on the table: [39, 77, 352, 212]; a brown piece of luggage: [197, 46, 256, 129]; the boxes are made of cardboard: [89, 26, 352, 179]; the chocolate cake on the blue cake: [200, 47, 254, 91]; lego construction bucket: [247, 53, 271, 103]; a large square cardboard box: [271, 97, 374, 169]; the boxes are brown: [30, 38, 275, 164]; the sky is grey: [37, 0, 352, 62]; the floor is white: [47, 118, 255, 211]; red box on top of the stack: [250, 67, 271, 87]; the snow is white: [102, 140, 220, 208]; ; Region Captions: a black and white image of a room with some black and white objects: [0, 1, 383, 211]; a minecraft map with a snowy path: [0, 91, 383, 121]; a silhouette of a city with a cloudy sky: [0, 0, 383, 101]; a yellow and white block in minecraft: [203, 40, 180, 127]; a yellow and grey block on a black background: [275, 40, 108, 127]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a few people standing around\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a square patterned ottoman: [0, 74, 93, 158]; a silver and yellow object: [270, 35, 382, 170]; a blue decorative base: [199, 84, 250, 128]; the box is brown: [106, 74, 187, 107]; white tablecloth on the table: [39, 77, 352, 212]; a brown piece of luggage: [197, 46, 256, 129]; the boxes are made of cardboard: [89, 27, 352, 179]; red white and blue cooler: [248, 53, 271, 103]; the chocolate cake on the blue cake: [200, 47, 254, 91]; the sky is grey: [37, 0, 352, 63]; a large square cardboard box: [271, 97, 374, 169]; the boxes are brown: [30, 38, 276, 164]; the floor is white: [47, 118, 255, 211]; the snow is white: [102, 140, 220, 208]; red sticker on the side of the box: [250, 67, 271, 87]; a small light brown pillow: [135, 76, 164, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 92, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[203, 40, 180, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[275, 40, 108, 127]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with some black and white objects: [0, 1, 383, 211]; a black and white image of a snowy path: [0, 92, 383, 120]; a silhouette of a city with a cloudy sky: [0, 0, 383, 101]; a yellow and white block with a yellow and white block: [203, 40, 180, 127]; a yellow and grey block on a black background: [275, 40, 108, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a few people standing around; Dense Caption: a square patterned ottoman: [0, 74, 93, 158]; a silver and yellow object: [270, 35, 382, 170]; a blue decorative base: [199, 84, 250, 128]; the box is brown: [106, 74, 187, 107]; white tablecloth on the table: [39, 77, 352, 212]; a brown piece of luggage: [197, 46, 256, 129]; the boxes are made of cardboard: [89, 27, 352, 179]; red white and blue cooler: [248, 53, 271, 103]; the chocolate cake on the blue cake: [200, 47, 254, 91]; the sky is grey: [37, 0, 352, 63]; a large square cardboard box: [271, 97, 374, 169]; the boxes are brown: [30, 38, 276, 164]; the floor is white: [47, 118, 255, 211]; the snow is white: [102, 140, 220, 208]; red sticker on the side of the box: [250, 67, 271, 87]; a small light brown pillow: [135, 76, 164, 105]; ; Region Captions: a black and white image of a room with some black and white objects: [0, 1, 383, 211]; a black and white image of a snowy path: [0, 92, 383, 120]; a silhouette of a city with a cloudy sky: [0, 0, 383, 101]; a yellow and white block with a yellow and white block: [203, 40, 180, 127]; a yellow and grey block on a black background: [275, 40, 108, 127]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a white floor and a black wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [33, 94, 348, 211]; the bed is made: [20, 36, 267, 160]; the photo is black and white: [0, 2, 381, 210]; the basket is made of wood: [0, 87, 36, 120]; a small basket in the corner: [190, 82, 249, 102]; the walls are white: [1, 1, 381, 104]; the wall is white: [1, 2, 216, 92]; a hole in the snow: [141, 103, 163, 115]; the white wall behind the bed: [222, 1, 381, 100]; a small object on table: [183, 74, 255, 107]; a lamp on a bed: [191, 1, 248, 100]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 98, 383, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 220, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[221, 0, 162, 111]\n",
      "process_ann took 0.00 seconds\n",
      "[247, 89, 136, 23]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 93, 34, 25]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a small white snowy area with a black cat: [0, 98, 383, 114]; a gray teddy bear with a black background: [0, 0, 220, 105]; a gray shaped map of oklahoma: [221, 0, 162, 111]; a black and white image of a tv screen: [247, 89, 136, 23]; a stack of black bricks on a black background: [0, 93, 34, 25]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a white floor and a black wall; Dense Caption: the ground is covered in snow: [33, 94, 348, 211]; the bed is made: [20, 36, 267, 160]; the photo is black and white: [0, 2, 381, 210]; the basket is made of wood: [0, 87, 36, 120]; a small basket in the corner: [190, 82, 249, 102]; the walls are white: [1, 1, 381, 104]; the wall is white: [1, 2, 216, 92]; a hole in the snow: [141, 103, 163, 115]; the white wall behind the bed: [222, 1, 381, 100]; a small object on table: [183, 74, 255, 107]; a lamp on a bed: [191, 1, 248, 100]; ; Region Captions: a small white snowy area with a black cat: [0, 98, 383, 114]; a gray teddy bear with a black background: [0, 0, 220, 105]; a gray shaped map of oklahoma: [221, 0, 162, 111]; a black and white image of a tv screen: [247, 89, 136, 23]; a stack of black bricks on a black background: [0, 93, 34, 25]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and white gift box: [184, 43, 233, 118]; the two brown boxes: [98, 69, 176, 101]; the chair is made of wood: [245, 36, 341, 145]; white tablecloth on the table: [0, 72, 382, 211]; there are two chairs: [38, 28, 342, 172]; a brown wicker basket: [0, 70, 83, 145]; a teal blue and green decorative box: [186, 79, 231, 117]; yellow paper on the top of the cake: [252, 38, 339, 98]; the wall is white: [34, 1, 345, 93]; white base of the yellow and black sign: [247, 88, 326, 145]; the bed is white: [50, 124, 252, 210]; the white head of a toothbrush: [186, 44, 232, 83]; the snow is white: [103, 141, 220, 207]; two boxes are seen: [175, 31, 349, 153]; a black and white checkered object in the background: [328, 64, 383, 94]; a yellow square pillow: [126, 72, 153, 99]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 87, 383, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[249, 41, 89, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[253, 41, 85, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 75, 81, 68]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 87, 383, 125]; a silhouette of a city with a cloudy sky: [0, 0, 383, 118]; a yellow and white box on a black background: [249, 41, 89, 102]; a yellow block on a black background: [253, 41, 85, 56]; a black block with a black background: [0, 75, 81, 68]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with different colored blocks; Dense Caption: a blue and white gift box: [184, 43, 233, 118]; the two brown boxes: [98, 69, 176, 101]; the chair is made of wood: [245, 36, 341, 145]; white tablecloth on the table: [0, 72, 382, 211]; there are two chairs: [38, 28, 342, 172]; a brown wicker basket: [0, 70, 83, 145]; a teal blue and green decorative box: [186, 79, 231, 117]; yellow paper on the top of the cake: [252, 38, 339, 98]; the wall is white: [34, 1, 345, 93]; white base of the yellow and black sign: [247, 88, 326, 145]; the bed is white: [50, 124, 252, 210]; the white head of a toothbrush: [186, 44, 232, 83]; the snow is white: [103, 141, 220, 207]; two boxes are seen: [175, 31, 349, 153]; a black and white checkered object in the background: [328, 64, 383, 94]; a yellow square pillow: [126, 72, 153, 99]; ; Region Captions: a black and white image of a snowy area: [0, 87, 383, 125]; a silhouette of a city with a cloudy sky: [0, 0, 383, 118]; a yellow and white box on a black background: [249, 41, 89, 102]; a yellow block on a black background: [253, 41, 85, 56]; a black block with a black background: [0, 75, 81, 68]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a man standing next to some blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and white box: [176, 80, 224, 155]; legos on a bed: [35, 47, 337, 203]; the box is brown: [91, 101, 168, 135]; a yellow colored box: [241, 84, 316, 141]; a brown and white checkered ottoman: [0, 103, 73, 190]; a blue and white box: [178, 114, 222, 154]; white wooden base of the yellow and gray box: [240, 128, 310, 186]; legos on the floor: [205, 52, 334, 190]; a red and white box: [286, 52, 334, 99]; the table is white: [21, 109, 290, 212]; the white toothpaste on the toothbrush: [179, 82, 222, 120]; the wall is grey: [1, 1, 332, 124]; the box is yellow: [236, 81, 318, 187]; yellow and white square: [292, 51, 327, 80]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 129]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 116, 383, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[241, 88, 73, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[322, 0, 61, 99]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a city with a skyscraper: [0, 0, 383, 129]; a silhouette of a city with a black background: [0, 0, 383, 210]; a black and white image of a snowy mountain: [0, 116, 383, 96]; a yellow and grey box on a black background: [241, 88, 73, 97]; a gray paper with the word sacramento on it: [322, 0, 61, 99]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a man standing next to some blocks; Dense Caption: a blue and white box: [176, 80, 224, 155]; legos on a bed: [35, 47, 337, 203]; the box is brown: [91, 101, 168, 135]; a yellow colored box: [241, 84, 316, 141]; a brown and white checkered ottoman: [0, 103, 73, 190]; a blue and white box: [178, 114, 222, 154]; white wooden base of the yellow and gray box: [240, 128, 310, 186]; legos on the floor: [205, 52, 334, 190]; a red and white box: [286, 52, 334, 99]; the table is white: [21, 109, 290, 212]; the white toothpaste on the toothbrush: [179, 82, 222, 120]; the wall is grey: [1, 1, 332, 124]; the box is yellow: [236, 81, 318, 187]; yellow and white square: [292, 51, 327, 80]; ; Region Captions: a silhouette of a city with a skyscraper: [0, 0, 383, 129]; a silhouette of a city with a black background: [0, 0, 383, 210]; a black and white image of a snowy mountain: [0, 116, 383, 96]; a yellow and grey box on a black background: [241, 88, 73, 97]; a gray paper with the word sacramento on it: [322, 0, 61, 99]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a yellow and white minecraft room with a yellow wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a yellow and white object: [0, 0, 121, 210]; the basket is dark: [254, 17, 334, 42]; the photo was taken indoors: [1, 1, 382, 210]; the base of a lamp: [61, 1, 335, 43]; snow covering the ground: [68, 42, 304, 211]; the snow is white in color: [187, 60, 299, 153]; the basket is black: [62, 16, 122, 38]; yellow section of a caution sign: [1, 2, 79, 132]; the snow is white: [130, 36, 347, 161]; the snow is white: [196, 84, 309, 180]; the snow is white in color: [161, 51, 271, 129]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[71, 33, 312, 179]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 112, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[57, 0, 326, 54]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 93, 112, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 88, 144]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.52 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy surface with a black background: [71, 33, 312, 179]; a yellow and grey roof: [0, 0, 112, 212]; a grey shirt with a black background: [57, 0, 326, 54]; a gray piece of wood with a black background: [0, 93, 112, 120]; a yellow tiled roof on a black background: [0, 0, 88, 144]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a yellow and white minecraft room with a yellow wall; Dense Caption: a yellow and white object: [0, 0, 121, 210]; the basket is dark: [254, 17, 334, 42]; the photo was taken indoors: [1, 1, 382, 210]; the base of a lamp: [61, 1, 335, 43]; snow covering the ground: [68, 42, 304, 211]; the snow is white in color: [187, 60, 299, 153]; the basket is black: [62, 16, 122, 38]; yellow section of a caution sign: [1, 2, 79, 132]; the snow is white: [130, 36, 347, 161]; the snow is white: [196, 84, 309, 180]; the snow is white in color: [161, 51, 271, 129]; ; Region Captions: a white snowy surface with a black background: [71, 33, 312, 179]; a yellow and grey roof: [0, 0, 112, 212]; a grey shirt with a black background: [57, 0, 326, 54]; a gray piece of wood with a black background: [0, 93, 112, 120]; a yellow tiled roof on a black background: [0, 0, 88, 144]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210428_163559 36\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red couch and a red chair\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [28, 98, 356, 211]; red and yellow item: [0, 119, 75, 211]; the room is very clean: [38, 29, 348, 174]; the basket is brown: [133, 94, 180, 115]; the walls are white: [0, 1, 381, 116]; object on the bed: [166, 116, 217, 135]; a black and white checkered pillow: [306, 96, 383, 133]; the basket on the right: [34, 93, 132, 120]; the snow is white: [161, 140, 288, 205]; object on the bed: [157, 110, 225, 146]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 112, 381, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 88, 121]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 127, 66, 86]\n",
      "process_ann took 0.00 seconds\n",
      "[308, 101, 75, 30]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a black door: [0, 0, 383, 121]; a white shirt with a white background: [2, 112, 381, 101]; a gray piece of paper with a white border: [0, 0, 88, 121]; a red block with a yellow arrow on it: [0, 127, 66, 86]; a black stone wall with a black stone in the middle: [308, 101, 75, 30]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red couch and a red chair; Dense Caption: the ground is covered in snow: [28, 98, 356, 211]; red and yellow item: [0, 119, 75, 211]; the room is very clean: [38, 29, 348, 174]; the basket is brown: [133, 94, 180, 115]; the walls are white: [0, 1, 381, 116]; object on the bed: [166, 116, 217, 135]; a black and white checkered pillow: [306, 96, 383, 133]; the basket on the right: [34, 93, 132, 120]; the snow is white: [161, 140, 288, 205]; object on the bed: [157, 110, 225, 146]; ; Region Captions: a gray wall with a black door: [0, 0, 383, 121]; a white shirt with a white background: [2, 112, 381, 101]; a gray piece of paper with a white border: [0, 0, 88, 121]; a red block with a yellow arrow on it: [0, 127, 66, 86]; a black stone wall with a black stone in the middle: [308, 101, 75, 30]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red and white wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bedsheets are orange: [27, 98, 362, 211]; a red and yellow object: [0, 105, 69, 211]; the room is a bedroom: [38, 26, 348, 176]; two brown and tan baskets: [133, 94, 180, 115]; the wall is white: [0, 1, 380, 114]; a black square object with white dots: [306, 96, 382, 133]; object on the bed: [166, 116, 217, 136]; the basket on the right: [34, 93, 132, 120]; the snow is white in color: [171, 139, 296, 204]; object on the bed: [157, 110, 225, 145]; the snow is white: [138, 133, 259, 200]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 190]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[6, 112, 377, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 89, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[308, 101, 75, 30]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white image: [0, 0, 383, 190]; a black and white image of a wall: [0, 0, 383, 120]; a white piece of paper with a hole in it: [6, 112, 377, 101]; a gray paper clip with a white background: [0, 0, 89, 120]; a black stone wall with a black stone in the middle: [308, 101, 75, 30]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red and white wall; Dense Caption: the bedsheets are orange: [27, 98, 362, 211]; a red and yellow object: [0, 105, 69, 211]; the room is a bedroom: [38, 26, 348, 176]; two brown and tan baskets: [133, 94, 180, 115]; the wall is white: [0, 1, 380, 114]; a black square object with white dots: [306, 96, 382, 133]; object on the bed: [166, 116, 217, 136]; the basket on the right: [34, 93, 132, 120]; the snow is white in color: [171, 139, 296, 204]; object on the bed: [157, 110, 225, 145]; the snow is white: [138, 133, 259, 200]; ; Region Captions: a black and white image of a black and white image: [0, 0, 383, 190]; a black and white image of a wall: [0, 0, 383, 120]; a white piece of paper with a hole in it: [6, 112, 377, 101]; a gray paper clip with a white background: [0, 0, 89, 120]; a black stone wall with a black stone in the middle: [308, 101, 75, 30]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red and white wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [19, 98, 370, 211]; a yellow and red striped object: [0, 105, 71, 211]; the room is a bedroom: [38, 27, 348, 175]; two brown and tan baskets: [133, 94, 180, 115]; the wall is white: [0, 1, 380, 114]; a black square object with white dots: [306, 96, 382, 133]; object on the bed: [166, 116, 217, 136]; the basket is black: [34, 93, 132, 120]; the snow is white in color: [171, 139, 296, 204]; object on the bed: [157, 110, 225, 145]; the snow is white: [138, 133, 258, 200]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 183]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[6, 112, 377, 100]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 89, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[308, 101, 75, 30]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a black and white picture of a black and white picture: [0, 0, 383, 183]; a grey box with a black background: [0, 0, 383, 120]; a white png image of a white sheet: [6, 112, 377, 100]; a gray paper clip with a black background: [0, 0, 89, 120]; a black stone wall with a black stone in the middle: [308, 101, 75, 30]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red and white wall; Dense Caption: the ground is covered in snow: [19, 98, 370, 211]; a yellow and red striped object: [0, 105, 71, 211]; the room is a bedroom: [38, 27, 348, 175]; two brown and tan baskets: [133, 94, 180, 115]; the wall is white: [0, 1, 380, 114]; a black square object with white dots: [306, 96, 382, 133]; object on the bed: [166, 116, 217, 136]; the basket is black: [34, 93, 132, 120]; the snow is white in color: [171, 139, 296, 204]; object on the bed: [157, 110, 225, 145]; the snow is white: [138, 133, 258, 200]; ; Region Captions: a black and white picture of a black and white picture: [0, 0, 383, 183]; a grey box with a black background: [0, 0, 383, 120]; a white png image of a white sheet: [6, 112, 377, 100]; a gray paper clip with a black background: [0, 0, 89, 120]; a black stone wall with a black stone in the middle: [308, 101, 75, 30]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red and white wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [18, 98, 371, 211]; the room is a bedroom: [38, 27, 348, 175]; a yellow and red striped object: [0, 106, 71, 211]; two brown and tan baskets: [133, 94, 180, 115]; the wall is white: [0, 1, 380, 114]; a black square object with white dots: [306, 96, 382, 133]; object on the bed: [166, 116, 217, 136]; the basket on the right: [34, 93, 132, 120]; the snow is white in color: [171, 139, 296, 204]; object on the bed: [157, 110, 225, 146]; the snow is white: [138, 133, 258, 200]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 189]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[6, 112, 377, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 89, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 147, 66, 66]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white image: [0, 0, 383, 189]; a grey box with a black background: [0, 0, 383, 120]; a white piece of paper with a hole in it: [6, 112, 377, 101]; a gray paper clip with a black background: [0, 0, 89, 120]; a red and yellow block with a yellow border: [0, 147, 66, 66]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red and white wall; Dense Caption: the ground is covered in snow: [18, 98, 371, 211]; the room is a bedroom: [38, 27, 348, 175]; a yellow and red striped object: [0, 106, 71, 211]; two brown and tan baskets: [133, 94, 180, 115]; the wall is white: [0, 1, 380, 114]; a black square object with white dots: [306, 96, 382, 133]; object on the bed: [166, 116, 217, 136]; the basket on the right: [34, 93, 132, 120]; the snow is white in color: [171, 139, 296, 204]; object on the bed: [157, 110, 225, 146]; the snow is white: [138, 133, 258, 200]; ; Region Captions: a black and white image of a black and white image: [0, 0, 383, 189]; a grey box with a black background: [0, 0, 383, 120]; a white piece of paper with a hole in it: [6, 112, 377, 101]; a gray paper clip with a black background: [0, 0, 89, 120]; a red and yellow block with a yellow border: [0, 147, 66, 66]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a multicolored snow plow: [0, 66, 104, 211]; the snow is white: [37, 53, 350, 211]; a black and white object: [308, 95, 380, 132]; the wall is white: [80, 1, 380, 112]; the snow is white: [171, 137, 298, 205]; two brown and tan baskets: [133, 94, 180, 115]; object in the snow: [166, 116, 217, 136]; yellow and blue stripes: [0, 68, 91, 121]; blue square with white stripes: [27, 167, 89, 212]; a large blanket of snow: [98, 111, 379, 210]; a snowboarder on the snow: [8, 27, 215, 206]; object in the snow: [157, 109, 226, 146]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[84, 0, 299, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[83, 112, 300, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 87, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 86, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.81 seconds\n",
      "finished...\n",
      "\n",
      "a black and gray png image of a black and gray png image: [0, 0, 383, 211]; a gray square with a black background: [84, 0, 299, 114]; a white sandbox with a white door: [83, 112, 300, 101]; a grey t shirt with a white logo on it: [0, 0, 87, 113]; a grey t shirt with a white logo on it: [0, 0, 86, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a multicolored snow plow: [0, 66, 104, 211]; the snow is white: [37, 53, 350, 211]; a black and white object: [308, 95, 380, 132]; the wall is white: [80, 1, 380, 112]; the snow is white: [171, 137, 298, 205]; two brown and tan baskets: [133, 94, 180, 115]; object in the snow: [166, 116, 217, 136]; yellow and blue stripes: [0, 68, 91, 121]; blue square with white stripes: [27, 167, 89, 212]; a large blanket of snow: [98, 111, 379, 210]; a snowboarder on the snow: [8, 27, 215, 206]; object in the snow: [157, 109, 226, 146]; ; Region Captions: a black and gray png image of a black and gray png image: [0, 0, 383, 211]; a gray square with a black background: [84, 0, 299, 114]; a white sandbox with a white door: [83, 112, 300, 101]; a grey t shirt with a white logo on it: [0, 0, 87, 113]; a grey t shirt with a white logo on it: [0, 0, 86, 75]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a multicolored snow plow: [0, 66, 105, 211]; the snow is white: [37, 52, 349, 211]; a black square object with white and grey shapes: [305, 96, 383, 133]; the wall is white: [80, 1, 380, 113]; the snow is white: [171, 137, 298, 206]; two brown and tan baskets: [133, 94, 180, 115]; object in the snow: [166, 116, 217, 136]; yellow and blue stripes: [0, 68, 91, 120]; blue square with white stripes: [26, 167, 88, 212]; a large bed: [104, 113, 378, 210]; a snowboarder on the snow: [8, 28, 215, 207]; the chairs are brown: [84, 55, 362, 149]; two brown and black decorative objects: [88, 91, 181, 118]; object in the snow: [157, 109, 226, 147]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 159]\n",
      "process_ann took 0.00 seconds\n",
      "[84, 0, 299, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 112, 383, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 87, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 86, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white image: [0, 0, 383, 159]; a gray square with a black background: [84, 0, 299, 114]; a small white car driving down a snowy road: [0, 112, 383, 101]; a grey t shirt with a white logo on it: [0, 0, 87, 112]; a grey flag with a white background: [0, 0, 86, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a multicolored snow plow: [0, 66, 105, 211]; the snow is white: [37, 52, 349, 211]; a black square object with white and grey shapes: [305, 96, 383, 133]; the wall is white: [80, 1, 380, 113]; the snow is white: [171, 137, 298, 206]; two brown and tan baskets: [133, 94, 180, 115]; object in the snow: [166, 116, 217, 136]; yellow and blue stripes: [0, 68, 91, 120]; blue square with white stripes: [26, 167, 88, 212]; a large bed: [104, 113, 378, 210]; a snowboarder on the snow: [8, 28, 215, 207]; the chairs are brown: [84, 55, 362, 149]; two brown and black decorative objects: [88, 91, 181, 118]; object in the snow: [157, 109, 226, 147]; ; Region Captions: a black and white image of a black and white image: [0, 0, 383, 159]; a gray square with a black background: [84, 0, 299, 114]; a small white car driving down a snowy road: [0, 112, 383, 101]; a grey t shirt with a white logo on it: [0, 0, 87, 112]; a grey flag with a white background: [0, 0, 86, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a multi colored sign: [0, 65, 113, 211]; the snow is white: [36, 54, 349, 211]; a black woven basket: [305, 96, 383, 133]; the wall is white: [80, 1, 380, 113]; the snow is white: [163, 138, 289, 206]; two brown and tan baskets: [133, 94, 180, 115]; blue square with white stripes: [26, 167, 88, 212]; object in the snow: [166, 116, 217, 135]; yellow and blue stripes: [0, 68, 91, 121]; a snowy white floor: [105, 113, 378, 210]; a snowboarder on a snowboard: [7, 28, 215, 207]; the chairs are brown: [83, 55, 362, 149]; object in the snow: [157, 110, 226, 146]; two brown and tan objects: [88, 91, 181, 117]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 208]\n",
      "process_ann took 0.00 seconds\n",
      "[84, 0, 299, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 112, 383, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 87, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 86, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.78 seconds\n",
      "finished...\n",
      "\n",
      "a black and gray png image of a black and gray png image: [0, 0, 383, 208]; a gray square with a black background: [84, 0, 299, 114]; a person is walking down a snowy road: [0, 112, 383, 101]; a grey t shirt with a white logo on it: [0, 0, 87, 112]; a grey flag with a white background: [0, 0, 86, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a multi colored sign: [0, 65, 113, 211]; the snow is white: [36, 54, 349, 211]; a black woven basket: [305, 96, 383, 133]; the wall is white: [80, 1, 380, 113]; the snow is white: [163, 138, 289, 206]; two brown and tan baskets: [133, 94, 180, 115]; blue square with white stripes: [26, 167, 88, 212]; object in the snow: [166, 116, 217, 135]; yellow and blue stripes: [0, 68, 91, 121]; a snowy white floor: [105, 113, 378, 210]; a snowboarder on a snowboard: [7, 28, 215, 207]; the chairs are brown: [83, 55, 362, 149]; object in the snow: [157, 110, 226, 146]; two brown and tan objects: [88, 91, 181, 117]; ; Region Captions: a black and gray png image of a black and gray png image: [0, 0, 383, 208]; a gray square with a black background: [84, 0, 299, 114]; a person is walking down a snowy road: [0, 112, 383, 101]; a grey t shirt with a white logo on it: [0, 0, 87, 112]; a grey flag with a white background: [0, 0, 86, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a multi colored sign: [0, 66, 104, 211]; the snow is white: [37, 52, 350, 211]; a black and white object: [308, 95, 380, 132]; the wall is white: [80, 1, 380, 112]; the snow is white: [171, 137, 298, 205]; two brown and tan baskets: [133, 94, 180, 115]; object in the snow: [166, 116, 217, 135]; blue square with white stripes: [27, 167, 89, 212]; yellow and blue stripes: [0, 68, 91, 121]; a large bed: [97, 111, 379, 210]; a snowboarder on the snow: [8, 27, 216, 207]; object in the snow: [157, 109, 226, 147]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[84, 0, 299, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[5, 112, 378, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 87, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 86, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a gray box with a white arrow on it: [0, 0, 383, 160]; a gray square with a black background: [84, 0, 299, 114]; a picture of a car driving down a road: [5, 112, 378, 101]; a grey t shirt with a white logo on it: [0, 0, 87, 113]; a grey flag with a white background: [0, 0, 86, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a multi colored sign: [0, 66, 104, 211]; the snow is white: [37, 52, 350, 211]; a black and white object: [308, 95, 380, 132]; the wall is white: [80, 1, 380, 112]; the snow is white: [171, 137, 298, 205]; two brown and tan baskets: [133, 94, 180, 115]; object in the snow: [166, 116, 217, 135]; blue square with white stripes: [27, 167, 89, 212]; yellow and blue stripes: [0, 68, 91, 121]; a large bed: [97, 111, 379, 210]; a snowboarder on the snow: [8, 27, 216, 207]; object in the snow: [157, 109, 226, 147]; ; Region Captions: a gray box with a white arrow on it: [0, 0, 383, 160]; a gray square with a black background: [84, 0, 299, 114]; a picture of a car driving down a road: [5, 112, 378, 101]; a grey t shirt with a white logo on it: [0, 0, 87, 113]; a grey flag with a white background: [0, 0, 86, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the multi colored tiles: [0, 67, 97, 211]; the bed is made: [38, 43, 352, 212]; a black woven basket: [299, 97, 383, 133]; object on the ground: [161, 118, 212, 137]; the wall is white: [1, 0, 382, 114]; the box is brown: [128, 96, 175, 117]; the snow is white: [163, 143, 288, 208]; yellow and blue stripes: [0, 69, 82, 123]; a blue section of a book: [16, 171, 80, 212]; a white table: [87, 111, 379, 211]; a snowboarder on a snowboard: [8, 23, 219, 209]; object on the ground: [150, 108, 225, 151]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[77, 0, 306, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 114, 383, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 80, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 80, 77]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 73, 80, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a gray square with a black background: [77, 0, 306, 115]; a small white building with a door on it: [0, 114, 383, 99]; a grey and white t shirt with a white logo: [0, 0, 80, 120]; a grey flag with a white background: [0, 0, 80, 77]; a pixelated head with blue eyes: [0, 73, 80, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: the multi colored tiles: [0, 67, 97, 211]; the bed is made: [38, 43, 352, 212]; a black woven basket: [299, 97, 383, 133]; object on the ground: [161, 118, 212, 137]; the wall is white: [1, 0, 382, 114]; the box is brown: [128, 96, 175, 117]; the snow is white: [163, 143, 288, 208]; yellow and blue stripes: [0, 69, 82, 123]; a blue section of a book: [16, 171, 80, 212]; a white table: [87, 111, 379, 211]; a snowboarder on a snowboard: [8, 23, 219, 209]; object on the ground: [150, 108, 225, 151]; ; Region Captions: a gray square with a black background: [77, 0, 306, 115]; a small white building with a door on it: [0, 114, 383, 99]; a grey and white t shirt with a white logo: [0, 0, 80, 120]; a grey flag with a white background: [0, 0, 80, 77]; a pixelated head with blue eyes: [0, 73, 80, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego snowboard: [86, 63, 172, 198]; a white snowy ground: [0, 98, 381, 212]; shadow of the object: [101, 167, 168, 208]; the sign is red: [91, 98, 169, 151]; a lego snowboarder: [48, 14, 291, 207]; blue wooden base of umbrella: [116, 147, 154, 193]; yellow and blue square: [100, 65, 159, 107]; a brown box in the background: [193, 87, 238, 107]; a yellow plastic pole: [85, 137, 107, 186]; the wall is white: [0, 0, 381, 118]; a black rock in the snow: [223, 111, 279, 131]; two brown and yellow objects: [155, 82, 240, 109]; a small square building: [156, 86, 192, 106]; snow covering the ground: [195, 123, 371, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 104, 383, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[156, 0, 227, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 155, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 108, 122, 104]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a clock: [0, 0, 383, 118]; a man is standing on a snowy road: [0, 104, 383, 108]; a gray tv screen with a black background: [156, 0, 227, 115]; a gray wall with a white wall: [0, 0, 155, 117]; a person is standing on a snowy ground: [0, 108, 122, 104]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a lego snowboard: [86, 63, 172, 198]; a white snowy ground: [0, 98, 381, 212]; shadow of the object: [101, 167, 168, 208]; the sign is red: [91, 98, 169, 151]; a lego snowboarder: [48, 14, 291, 207]; blue wooden base of umbrella: [116, 147, 154, 193]; yellow and blue square: [100, 65, 159, 107]; a brown box in the background: [193, 87, 238, 107]; a yellow plastic pole: [85, 137, 107, 186]; the wall is white: [0, 0, 381, 118]; a black rock in the snow: [223, 111, 279, 131]; two brown and yellow objects: [155, 82, 240, 109]; a small square building: [156, 86, 192, 106]; snow covering the ground: [195, 123, 371, 208]; ; Region Captions: a black and white image of a building with a clock: [0, 0, 383, 118]; a man is standing on a snowy road: [0, 104, 383, 108]; a gray tv screen with a black background: [156, 0, 227, 115]; a gray wall with a white wall: [0, 0, 155, 117]; a person is standing on a snowy ground: [0, 108, 122, 104]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego snowboard: [88, 62, 172, 199]; a white snowy hill: [0, 98, 381, 212]; shadow of the object: [101, 167, 168, 208]; the square is red in color: [91, 99, 169, 151]; a person is enjoying their day: [48, 14, 290, 207]; blue wooden base: [116, 147, 154, 193]; yellow and blue square: [100, 65, 159, 107]; a yellow plastic pole: [87, 138, 109, 188]; a brown box in the background: [193, 87, 238, 107]; the wall is white: [0, 0, 381, 118]; a black rock in the snow: [223, 111, 279, 131]; two brown and yellow objects: [155, 82, 240, 109]; a small square building: [156, 86, 192, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 104, 383, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[156, 0, 227, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 155, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 108, 121, 104]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a clock: [0, 0, 383, 118]; a person is standing on a snowy ground: [0, 104, 383, 108]; a gray tv screen with a black background: [156, 0, 227, 115]; a gray wall with a white wall: [0, 0, 155, 117]; a small black cat standing on a white floor: [0, 108, 121, 104]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a lego snowboard: [88, 62, 172, 199]; a white snowy hill: [0, 98, 381, 212]; shadow of the object: [101, 167, 168, 208]; the square is red in color: [91, 99, 169, 151]; a person is enjoying their day: [48, 14, 290, 207]; blue wooden base: [116, 147, 154, 193]; yellow and blue square: [100, 65, 159, 107]; a yellow plastic pole: [87, 138, 109, 188]; a brown box in the background: [193, 87, 238, 107]; the wall is white: [0, 0, 381, 118]; a black rock in the snow: [223, 111, 279, 131]; two brown and yellow objects: [155, 82, 240, 109]; a small square building: [156, 86, 192, 106]; ; Region Captions: a black and white image of a building with a clock: [0, 0, 383, 118]; a person is standing on a snowy ground: [0, 104, 383, 108]; a gray tv screen with a black background: [156, 0, 227, 115]; a gray wall with a white wall: [0, 0, 155, 117]; a small black cat standing on a white floor: [0, 108, 121, 104]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a multi colored sign: [89, 62, 170, 198]; a white snowy hill: [0, 98, 381, 212]; shadow of the object: [101, 167, 168, 208]; the square is red in color: [92, 99, 167, 151]; a snowboarder on a snowboard: [47, 13, 292, 208]; yellow and blue square: [100, 65, 159, 107]; blue wooden base: [116, 147, 154, 193]; a yellow plastic cloth object: [90, 138, 111, 187]; a brown box in the background: [193, 87, 238, 107]; a black rock in the snow: [223, 111, 279, 131]; the wall is white: [0, 0, 381, 118]; two brown and yellow objects: [155, 82, 240, 109]; a small square building: [155, 86, 192, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 104, 383, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[156, 0, 227, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[126, 104, 257, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 155, 117]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a clock: [0, 0, 383, 118]; a person is standing on a snowy ground: [0, 104, 383, 108]; a gray tv screen with a black background: [156, 0, 227, 115]; a white piece of paper with a black background: [126, 104, 257, 108]; a grey t shirt with a white logo on it: [0, 0, 155, 117]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a multi colored sign: [89, 62, 170, 198]; a white snowy hill: [0, 98, 381, 212]; shadow of the object: [101, 167, 168, 208]; the square is red in color: [92, 99, 167, 151]; a snowboarder on a snowboard: [47, 13, 292, 208]; yellow and blue square: [100, 65, 159, 107]; blue wooden base: [116, 147, 154, 193]; a yellow plastic cloth object: [90, 138, 111, 187]; a brown box in the background: [193, 87, 238, 107]; a black rock in the snow: [223, 111, 279, 131]; the wall is white: [0, 0, 381, 118]; two brown and yellow objects: [155, 82, 240, 109]; a small square building: [155, 86, 192, 106]; ; Region Captions: a black and white image of a building with a clock: [0, 0, 383, 118]; a person is standing on a snowy ground: [0, 104, 383, 108]; a gray tv screen with a black background: [156, 0, 227, 115]; a white piece of paper with a black background: [126, 104, 257, 108]; a grey t shirt with a white logo on it: [0, 0, 155, 117]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red and white striped wall\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large bed: [34, 95, 348, 211]; the bed is made: [29, 38, 344, 170]; the box is brown: [80, 83, 138, 106]; the wall is white: [26, 0, 338, 105]; the basket is made of cloth: [252, 82, 366, 113]; a card with a number on it: [0, 92, 27, 186]; a hole in the snow: [122, 107, 177, 125]; the edge of a colorful flag: [0, 85, 46, 194]; a hole in the snow: [116, 101, 186, 133]; a black and white fence: [1, 83, 79, 116]; the basket is made of wicker: [242, 70, 374, 125]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 101, 383, 111]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 154]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 314, 100]\n",
      "process_ann took 0.00 seconds\n",
      "[258, 0, 125, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[305, 0, 78, 113]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a white png image of a white floor: [0, 101, 383, 111]; a black and white image of a black and white picture: [0, 0, 383, 154]; a black and gray square with a black background: [0, 0, 314, 100]; a black and white image of a map: [258, 0, 125, 113]; a gray map with the word nevada: [305, 0, 78, 113]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red and white striped wall; Dense Caption: a large bed: [34, 95, 348, 211]; the bed is made: [29, 38, 344, 170]; the box is brown: [80, 83, 138, 106]; the wall is white: [26, 0, 338, 105]; the basket is made of cloth: [252, 82, 366, 113]; a card with a number on it: [0, 92, 27, 186]; a hole in the snow: [122, 107, 177, 125]; the edge of a colorful flag: [0, 85, 46, 194]; a hole in the snow: [116, 101, 186, 133]; a black and white fence: [1, 83, 79, 116]; the basket is made of wicker: [242, 70, 374, 125]; ; Region Captions: a white png image of a white floor: [0, 101, 383, 111]; a black and white image of a black and white picture: [0, 0, 383, 154]; a black and gray square with a black background: [0, 0, 314, 100]; a black and white image of a map: [258, 0, 125, 113]; a gray map with the word nevada: [305, 0, 78, 113]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a bed and a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "lego person carrying a blue bag: [105, 81, 133, 129]; a brown and black snow covered trunk: [0, 96, 113, 143]; a black object: [157, 159, 289, 212]; two brown and tan suitcases: [124, 98, 191, 129]; a snowy white floor: [0, 118, 382, 211]; a bed in the middle of the room: [34, 38, 348, 212]; the grey wall behind the suitcase: [0, 1, 381, 134]; a brown box: [105, 81, 193, 131]; a lego figure on a platform: [96, 74, 139, 137]; blue base of a fire hydrant: [111, 110, 126, 127]; the red part of the hydrant: [108, 94, 131, 113]; yellow top of red plastic container: [107, 82, 129, 98]; the yellow luggage in the snow: [161, 102, 190, 129]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 195]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 125, 383, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 106, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 69, 104]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.52 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 0, 383, 195]; a black and white image of a building: [2, 0, 381, 136]; a black and white image of a small square: [0, 125, 383, 87]; a grey square with a black background: [0, 0, 106, 104]; a gray square with the word sand: [0, 0, 69, 104]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a bed and a table; Dense Caption: lego person carrying a blue bag: [105, 81, 133, 129]; a brown and black snow covered trunk: [0, 96, 113, 143]; a black object: [157, 159, 289, 212]; two brown and tan suitcases: [124, 98, 191, 129]; a snowy white floor: [0, 118, 382, 211]; a bed in the middle of the room: [34, 38, 348, 212]; the grey wall behind the suitcase: [0, 1, 381, 134]; a brown box: [105, 81, 193, 131]; a lego figure on a platform: [96, 74, 139, 137]; blue base of a fire hydrant: [111, 110, 126, 127]; the red part of the hydrant: [108, 94, 131, 113]; yellow top of red plastic container: [107, 82, 129, 98]; the yellow luggage in the snow: [161, 102, 190, 129]; ; Region Captions: a black and white image of a wall: [0, 0, 383, 195]; a black and white image of a building: [2, 0, 381, 136]; a black and white image of a small square: [0, 125, 383, 87]; a grey square with a black background: [0, 0, 106, 104]; a gray square with the word sand: [0, 0, 69, 104]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in front of a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "white box on white surface: [150, 118, 227, 202]; lego person standing next to a cake: [117, 80, 150, 136]; white tablecloth on the table: [0, 113, 382, 211]; a brown and black snow covered trunk: [0, 96, 123, 143]; the square brown basket: [142, 101, 190, 127]; a cake with a candle: [40, 48, 305, 210]; the wall is white: [75, 1, 363, 123]; legos on the floor: [116, 77, 192, 136]; red stripe on the hydrant: [119, 95, 144, 118]; red and blue lego: [124, 96, 144, 134]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[6, 0, 377, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 122, 383, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 253, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[215, 128, 168, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[102, 128, 281, 84]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man standing in front of a wall: [6, 0, 377, 136]; a black and white image of a man in a black shirt: [0, 122, 383, 90]; a black and white image of a person walking down a snowy path: [0, 121, 253, 91]; a white wall with a white arrow on it: [215, 128, 168, 84]; a white wall with a white sheet of paper: [102, 128, 281, 84]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in front of a box; Dense Caption: white box on white surface: [150, 118, 227, 202]; lego person standing next to a cake: [117, 80, 150, 136]; white tablecloth on the table: [0, 113, 382, 211]; a brown and black snow covered trunk: [0, 96, 123, 143]; the square brown basket: [142, 101, 190, 127]; a cake with a candle: [40, 48, 305, 210]; the wall is white: [75, 1, 363, 123]; legos on the floor: [116, 77, 192, 136]; red stripe on the hydrant: [119, 95, 144, 118]; red and blue lego: [124, 96, 144, 134]; ; Region Captions: a black and white image of a man standing in front of a wall: [6, 0, 377, 136]; a black and white image of a man in a black shirt: [0, 122, 383, 90]; a black and white image of a person walking down a snowy path: [0, 121, 253, 91]; a white wall with a white arrow on it: [215, 128, 168, 84]; a white wall with a white sheet of paper: [102, 128, 281, 84]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a white block and a man\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white gift box: [203, 42, 268, 108]; white tablecloth on the table: [0, 13, 382, 210]; the large square object: [0, 47, 67, 133]; a hanging red white and blue banner: [43, 0, 123, 71]; small square object at top of bed: [174, 17, 242, 43]; shadow of object on ground: [72, 73, 119, 98]; a wooden bench: [0, 0, 129, 138]; the snow is white: [136, 26, 338, 179]; red figure on a yellow diamond: [48, 6, 106, 50]; the basket is made of paper: [172, 20, 288, 130]; a lego snowboard and a snowboard: [23, 2, 279, 140]; the blue and black paper: [52, 40, 115, 72]; the snow is white: [62, 104, 257, 208]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 36, 383, 176]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 191, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[194, 0, 189, 39]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 50, 109, 81]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small room: [0, 36, 383, 176]; a shadow of a man standing in a room: [0, 0, 383, 83]; a silhouette of a man standing on a cliff: [0, 0, 191, 83]; a black and white image of a black and white tv: [194, 0, 189, 39]; a wooden block in minecraft: [0, 50, 109, 81]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a white block and a man; Dense Caption: a white gift box: [203, 42, 268, 108]; white tablecloth on the table: [0, 13, 382, 210]; the large square object: [0, 47, 67, 133]; a hanging red white and blue banner: [43, 0, 123, 71]; small square object at top of bed: [174, 17, 242, 43]; shadow of object on ground: [72, 73, 119, 98]; a wooden bench: [0, 0, 129, 138]; the snow is white: [136, 26, 338, 179]; red figure on a yellow diamond: [48, 6, 106, 50]; the basket is made of paper: [172, 20, 288, 130]; a lego snowboard and a snowboard: [23, 2, 279, 140]; the blue and black paper: [52, 40, 115, 72]; the snow is white: [62, 104, 257, 208]; ; Region Captions: a black and white image of a small room: [0, 36, 383, 176]; a shadow of a man standing in a room: [0, 0, 383, 83]; a silhouette of a man standing on a cliff: [0, 0, 191, 83]; a black and white image of a black and white tv: [194, 0, 189, 39]; a wooden block in minecraft: [0, 50, 109, 81]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing next to some blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white towel: [228, 62, 343, 162]; wooden box on the table: [4, 51, 127, 129]; the bed is made: [36, 35, 343, 211]; lego person is holding a board: [191, 16, 232, 93]; a black box with white dots: [256, 37, 359, 71]; the table is wooden: [24, 13, 249, 135]; yellow top of red fire hydrant: [199, 19, 228, 48]; blue base of fire hydrant: [199, 65, 220, 89]; the yellow part of the pillow: [68, 54, 126, 106]; a bed with a book: [118, 10, 349, 168]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 62, 383, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[232, 66, 111, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 59, 124, 66]\n",
      "process_ann took 0.00 seconds\n",
      "[287, 0, 96, 64]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small room: [0, 62, 383, 150]; a black and white image of a room with a black wall: [0, 0, 383, 85]; a white and black block on a black background: [232, 66, 111, 94]; a block of bricks in minecraft: [0, 59, 124, 66]; a gray square with a black background: [287, 0, 96, 64]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing next to some blocks; Dense Caption: a black and white towel: [228, 62, 343, 162]; wooden box on the table: [4, 51, 127, 129]; the bed is made: [36, 35, 343, 211]; lego person is holding a board: [191, 16, 232, 93]; a black box with white dots: [256, 37, 359, 71]; the table is wooden: [24, 13, 249, 135]; yellow top of red fire hydrant: [199, 19, 228, 48]; blue base of fire hydrant: [199, 65, 220, 89]; the yellow part of the pillow: [68, 54, 126, 106]; a bed with a book: [118, 10, 349, 168]; ; Region Captions: a black and white image of a small room: [0, 62, 383, 150]; a black and white image of a room with a black wall: [0, 0, 383, 85]; a white and black block on a black background: [232, 66, 111, 94]; a block of bricks in minecraft: [0, 59, 124, 66]; a gray square with a black background: [287, 0, 96, 64]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man standing in front of a room with blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white towel: [228, 62, 343, 162]; wooden box on the table: [4, 51, 127, 129]; lego person is holding a red and yellow item: [191, 16, 233, 93]; the bed is made: [36, 35, 342, 211]; a black box with white dots: [256, 37, 359, 71]; the table is wooden: [25, 14, 250, 135]; yellow top of red fire hydrant: [199, 19, 228, 48]; blue base of fire hydrant: [198, 65, 220, 90]; a light brown wooden block: [67, 54, 126, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 62, 383, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[232, 66, 111, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 59, 124, 66]\n",
      "process_ann took 0.00 seconds\n",
      "[287, 0, 96, 64]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small room: [0, 62, 383, 150]; a black and white image of a building: [0, 0, 383, 85]; a white and black block on a black background: [232, 66, 111, 94]; a block of bricks in minecraft: [0, 59, 124, 66]; a gray teddy bear with a black background: [287, 0, 96, 64]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man standing in front of a room with blocks; Dense Caption: a black and white towel: [228, 62, 343, 162]; wooden box on the table: [4, 51, 127, 129]; lego person is holding a red and yellow item: [191, 16, 233, 93]; the bed is made: [36, 35, 342, 211]; a black box with white dots: [256, 37, 359, 71]; the table is wooden: [25, 14, 250, 135]; yellow top of red fire hydrant: [199, 19, 228, 48]; blue base of fire hydrant: [198, 65, 220, 90]; a light brown wooden block: [67, 54, 126, 106]; ; Region Captions: a black and white image of a small room: [0, 62, 383, 150]; a black and white image of a building: [0, 0, 383, 85]; a white and black block on a black background: [232, 66, 111, 94]; a block of bricks in minecraft: [0, 59, 124, 66]; a gray teddy bear with a black background: [287, 0, 96, 64]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing next to some blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white checkered box: [226, 60, 345, 164]; the bed is made: [33, 49, 340, 211]; wooden box on table: [8, 50, 127, 124]; a black box with white dots: [256, 37, 359, 71]; the wall is white: [33, 1, 339, 100]; red and black tape measure: [0, 50, 39, 112]; blue felt on the table: [0, 106, 34, 158]; the table is white: [70, 114, 240, 209]; a green square on the box: [67, 54, 126, 107]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 62, 383, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[232, 66, 111, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[288, 0, 95, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[332, 63, 51, 71]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a skateboard: [0, 62, 383, 150]; a 3d image of a room with a black wall: [0, 0, 383, 85]; a white and black block on a black background: [232, 66, 111, 94]; a gray square with a white background: [288, 0, 95, 64]; a piece of paper with a white border: [332, 63, 51, 71]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing next to some blocks; Dense Caption: a black and white checkered box: [226, 60, 345, 164]; the bed is made: [33, 49, 340, 211]; wooden box on table: [8, 50, 127, 124]; a black box with white dots: [256, 37, 359, 71]; the wall is white: [33, 1, 339, 100]; red and black tape measure: [0, 50, 39, 112]; blue felt on the table: [0, 106, 34, 158]; the table is white: [70, 114, 240, 209]; a green square on the box: [67, 54, 126, 107]; ; Region Captions: a black and white image of a skateboard: [0, 62, 383, 150]; a 3d image of a room with a black wall: [0, 0, 383, 85]; a white and black block on a black background: [232, 66, 111, 94]; a gray square with a white background: [288, 0, 95, 64]; a piece of paper with a white border: [332, 63, 51, 71]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is standing in front of a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white book: [228, 62, 343, 162]; a red and yellow object: [1, 144, 179, 212]; a black box on the bed: [256, 37, 359, 70]; a gold colored church steeple: [158, 122, 206, 207]; a yellow and gray box: [0, 1, 98, 186]; small wooden box: [79, 54, 127, 105]; the bed is made: [53, 42, 347, 210]; the sign is yellow and red: [1, 0, 188, 210]; blue triangle with cross: [41, 3, 84, 102]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[84, 62, 299, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[61, 0, 322, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[61, 0, 233, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 94, 184]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 149, 176, 64]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a sandbox: [84, 62, 299, 150]; a gray wall with a black background: [61, 0, 322, 85]; a gray square with a black background: [61, 0, 233, 91]; a pixelated image of a blue and brown building: [0, 0, 94, 184]; a red and white striped hat: [0, 149, 176, 64]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is standing in front of a room; Dense Caption: a black and white book: [228, 62, 343, 162]; a red and yellow object: [1, 144, 179, 212]; a black box on the bed: [256, 37, 359, 70]; a gold colored church steeple: [158, 122, 206, 207]; a yellow and gray box: [0, 1, 98, 186]; small wooden box: [79, 54, 127, 105]; the bed is made: [53, 42, 347, 210]; the sign is yellow and red: [1, 0, 188, 210]; blue triangle with cross: [41, 3, 84, 102]; ; Region Captions: a black and white image of a sandbox: [84, 62, 299, 150]; a gray wall with a black background: [61, 0, 322, 85]; a gray square with a black background: [61, 0, 233, 91]; a pixelated image of a blue and brown building: [0, 0, 94, 184]; a red and white striped hat: [0, 149, 176, 64]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft scene with a man standing next to a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white and black book: [218, 60, 320, 145]; the box is brown: [4, 49, 128, 125]; white tablecloth on the table: [0, 53, 381, 211]; the flag is red blue and yellow: [300, 0, 382, 71]; the boxes are made of cardboard: [32, 4, 335, 164]; yellow and red stripes: [301, 0, 383, 35]; a box on a table: [149, 34, 338, 181]; a lego snowboard: [218, 2, 382, 141]; a black box of tissue: [253, 38, 317, 66]; the wall is white: [17, 1, 276, 108]; a blue stripe on a flag: [309, 30, 354, 68]; black part of the cake: [257, 57, 324, 121]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 61, 383, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 57, 124, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 63, 99, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[21, 60, 65, 50]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.48 seconds\n",
      "finished...\n",
      "\n",
      "a black cat standing on a white floor: [0, 61, 383, 151]; a black and white image of a wall: [0, 0, 383, 82]; a block of bricks in minecraft: [0, 57, 124, 62]; a block of black and white blocks: [222, 63, 99, 80]; a wooden block on a black background: [21, 60, 65, 50]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft scene with a man standing next to a block; Dense Caption: a white and black book: [218, 60, 320, 145]; the box is brown: [4, 49, 128, 125]; white tablecloth on the table: [0, 53, 381, 211]; the flag is red blue and yellow: [300, 0, 382, 71]; the boxes are made of cardboard: [32, 4, 335, 164]; yellow and red stripes: [301, 0, 383, 35]; a box on a table: [149, 34, 338, 181]; a lego snowboard: [218, 2, 382, 141]; a black box of tissue: [253, 38, 317, 66]; the wall is white: [17, 1, 276, 108]; a blue stripe on a flag: [309, 30, 354, 68]; black part of the cake: [257, 57, 324, 121]; ; Region Captions: a black cat standing on a white floor: [0, 61, 383, 151]; a black and white image of a wall: [0, 0, 383, 82]; a block of bricks in minecraft: [0, 57, 124, 62]; a block of black and white blocks: [222, 63, 99, 80]; a wooden block on a black background: [21, 60, 65, 50]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is jumping over a block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the white cake: [217, 64, 308, 145]; the box is brown: [3, 49, 128, 125]; white tablecloth on the table: [0, 52, 381, 211]; red and white striped sign: [297, 0, 379, 54]; a lego snowboard and a snowboard: [32, 3, 336, 160]; a lego snowboard: [269, 0, 381, 83]; blue blocks on the end of the umbrella: [283, 44, 354, 81]; a lego snowboard on a table: [202, 16, 346, 156]; the black box behind the umbrella: [252, 35, 309, 64]; the bench is empty: [132, 49, 344, 195]; blue object on the ground: [281, 44, 321, 75]; shadow of the bench: [290, 101, 329, 128]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 61, 383, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 57, 124, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 68, 83, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[21, 60, 65, 50]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft sandbox: [0, 61, 383, 151]; a black and white image of a wall: [0, 0, 383, 82]; a block of bricks in minecraft: [0, 57, 124, 62]; a white block on a black background: [222, 68, 83, 75]; a wooden block on a black background: [21, 60, 65, 50]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is jumping over a block in minecraft; Dense Caption: the white cake: [217, 64, 308, 145]; the box is brown: [3, 49, 128, 125]; white tablecloth on the table: [0, 52, 381, 211]; red and white striped sign: [297, 0, 379, 54]; a lego snowboard and a snowboard: [32, 3, 336, 160]; a lego snowboard: [269, 0, 381, 83]; blue blocks on the end of the umbrella: [283, 44, 354, 81]; a lego snowboard on a table: [202, 16, 346, 156]; the black box behind the umbrella: [252, 35, 309, 64]; the bench is empty: [132, 49, 344, 195]; blue object on the ground: [281, 44, 321, 75]; shadow of the bench: [290, 101, 329, 128]; ; Region Captions: a black and white image of a minecraft sandbox: [0, 61, 383, 151]; a black and white image of a wall: [0, 0, 383, 82]; a block of bricks in minecraft: [0, 57, 124, 62]; a white block on a black background: [222, 68, 83, 75]; a wooden block on a black background: [21, 60, 65, 50]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing next to a block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white checkered box: [217, 7, 347, 146]; a lego person is holding a stack of luggage: [106, 12, 166, 120]; a lego set up on a bed: [34, 8, 343, 206]; wooden panel with dark brown stripes: [4, 49, 125, 125]; the red part of the lego: [110, 44, 159, 88]; blue pants on the person: [128, 79, 158, 115]; shadow of a blue object: [122, 98, 169, 122]; yellow top of the lego set: [110, 13, 156, 49]; the floor is white: [43, 129, 301, 211]; the top of the bench: [251, 9, 341, 74]; the boxes are made of wood: [0, 12, 168, 131]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 61, 383, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 12, 119, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 57, 123, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 68, 99, 75]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person in a room: [0, 61, 383, 151]; a black and white image of a building: [0, 0, 383, 76]; a white and black chair with a black and white background: [222, 12, 119, 131]; a brown and brown pillow with a brown and brown background: [0, 57, 123, 62]; a white block with black and white stripes: [222, 68, 99, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing next to a block in minecraft; Dense Caption: a black and white checkered box: [217, 7, 347, 146]; a lego person is holding a stack of luggage: [106, 12, 166, 120]; a lego set up on a bed: [34, 8, 343, 206]; wooden panel with dark brown stripes: [4, 49, 125, 125]; the red part of the lego: [110, 44, 159, 88]; blue pants on the person: [128, 79, 158, 115]; shadow of a blue object: [122, 98, 169, 122]; yellow top of the lego set: [110, 13, 156, 49]; the floor is white: [43, 129, 301, 211]; the top of the bench: [251, 9, 341, 74]; the boxes are made of wood: [0, 12, 168, 131]; ; Region Captions: a black and white image of a person in a room: [0, 61, 383, 151]; a black and white image of a building: [0, 0, 383, 76]; a white and black chair with a black and white background: [222, 12, 119, 131]; a brown and brown pillow with a brown and brown background: [0, 57, 123, 62]; a white block with black and white stripes: [222, 68, 99, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white checkered box: [218, 7, 347, 146]; the box is brown: [3, 49, 128, 125]; lego person is holding a skateboard: [181, 20, 223, 86]; the room is a bedroom: [34, 7, 342, 207]; red square on the pole: [187, 38, 221, 65]; blue base of lego: [193, 62, 213, 84]; the floor is white: [51, 124, 324, 211]; little yellow toy house: [193, 21, 218, 46]; the top of the bench: [251, 8, 342, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 61, 383, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 341, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 12, 119, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 57, 124, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 68, 97, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small black and white building: [0, 61, 383, 151]; a silhouette of a man standing on a hill: [0, 0, 341, 82]; a white and black chair with a black and white background: [222, 12, 119, 131]; a block of bricks in minecraft: [0, 57, 124, 62]; a block of white blocks on a black background: [222, 68, 97, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a minecraft room; Dense Caption: a black and white checkered box: [218, 7, 347, 146]; the box is brown: [3, 49, 128, 125]; lego person is holding a skateboard: [181, 20, 223, 86]; the room is a bedroom: [34, 7, 342, 207]; red square on the pole: [187, 38, 221, 65]; blue base of lego: [193, 62, 213, 84]; the floor is white: [51, 124, 324, 211]; little yellow toy house: [193, 21, 218, 46]; the top of the bench: [251, 8, 342, 74]; ; Region Captions: a black and white image of a small black and white building: [0, 61, 383, 151]; a silhouette of a man standing on a hill: [0, 0, 341, 82]; a white and black chair with a black and white background: [222, 12, 119, 131]; a block of bricks in minecraft: [0, 57, 124, 62]; a block of white blocks on a black background: [222, 68, 97, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man standing in a room with some blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white checkered box: [218, 7, 347, 146]; the box is brown: [3, 49, 128, 125]; a lego with a skateboard: [180, 21, 223, 86]; the area is well lit: [34, 7, 342, 207]; red part of the lego: [187, 38, 221, 65]; the floor is white: [51, 124, 323, 211]; blue base of lego: [194, 62, 213, 83]; yellow top of lego house: [193, 21, 218, 46]; the top of the bench: [251, 9, 342, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 61, 383, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 341, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 12, 119, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 57, 124, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[222, 68, 97, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small black and white object: [0, 61, 383, 151]; a silhouette of a man standing on a hill: [0, 0, 341, 82]; a white and black chair with a black and white background: [222, 12, 119, 131]; a block of bricks in minecraft: [0, 57, 124, 62]; a block of white blocks on a black background: [222, 68, 97, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man standing in a room with some blocks; Dense Caption: a black and white checkered box: [218, 7, 347, 146]; the box is brown: [3, 49, 128, 125]; a lego with a skateboard: [180, 21, 223, 86]; the area is well lit: [34, 7, 342, 207]; red part of the lego: [187, 38, 221, 65]; the floor is white: [51, 124, 323, 211]; blue base of lego: [194, 62, 213, 83]; yellow top of lego house: [193, 21, 218, 46]; the top of the bench: [251, 9, 342, 74]; ; Region Captions: a black and white image of a small black and white object: [0, 61, 383, 151]; a silhouette of a man standing on a hill: [0, 0, 341, 82]; a white and black chair with a black and white background: [222, 12, 119, 131]; a block of bricks in minecraft: [0, 57, 124, 62]; a block of white blocks on a black background: [222, 68, 97, 75]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a white and black cube on a white surface\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "an umbrella is in the photo: [0, 1, 382, 201]; black edge of wing: [22, 80, 335, 204]; black panel on the side of the plane: [128, 115, 336, 192]; the line is white: [189, 41, 299, 129]; the wing of the plane: [103, 5, 372, 133]; the wing of a plane: [0, 4, 127, 156]; a reflection of the right side of a plane wing: [1, 95, 161, 177]; the windows are square: [1, 19, 92, 109]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 116, 383, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 33, 383, 179]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 102, 342, 86]\n",
      "process_ann took 0.00 seconds\n",
      "[134, 123, 208, 65]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 22, 129, 98]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.78 seconds\n",
      "finished...\n",
      "\n",
      "a black and white triangle with a black background: [0, 116, 383, 96]; a black and white png image of a black and white png: [0, 33, 383, 179]; a black and white square on a black background: [0, 102, 342, 86]; a black square on a black background: [134, 123, 208, 65]; a white triangle with a black background: [0, 22, 129, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a white and black cube on a white surface; Dense Caption: an umbrella is in the photo: [0, 1, 382, 201]; black edge of wing: [22, 80, 335, 204]; black panel on the side of the plane: [128, 115, 336, 192]; the line is white: [189, 41, 299, 129]; the wing of the plane: [103, 5, 372, 133]; the wing of a plane: [0, 4, 127, 156]; a reflection of the right side of a plane wing: [1, 95, 161, 177]; the windows are square: [1, 19, 92, 109]; ; Region Captions: a black and white triangle with a black background: [0, 116, 383, 96]; a black and white png image of a black and white png: [0, 33, 383, 179]; a black and white square on a black background: [0, 102, 342, 86]; a black square on a black background: [134, 123, 208, 65]; a white triangle with a black background: [0, 22, 129, 98]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a block of white and black blocks in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the plane is white: [0, 1, 381, 210]; black square on the bottom of the plane: [115, 156, 327, 211]; the wing of a plane: [0, 0, 39, 44]; a white line on the plane: [30, 4, 244, 176]; the wing of a plane: [0, 43, 132, 212]; a flap on the left side: [1, 152, 148, 211]; black square on the bottom of the plane: [66, 119, 328, 211]; the wall is white in color: [172, 46, 280, 145]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[119, 161, 209, 52]\n",
      "process_ann took 0.00 seconds\n",
      "[1, 156, 326, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 66, 114, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 155, 149, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 132, 383, 81]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.56 seconds\n",
      "finished...\n",
      "\n",
      "a black square on a black background: [119, 161, 209, 52]; a black square with a black background: [1, 156, 326, 57]; a white triangle with a black background: [0, 66, 114, 93]; a gray square with a black background: [0, 155, 149, 57]; a white and silver arrow pointing to the right: [0, 132, 383, 81]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a block of white and black blocks in minecraft; Dense Caption: the plane is white: [0, 1, 381, 210]; black square on the bottom of the plane: [115, 156, 327, 211]; the wing of a plane: [0, 0, 39, 44]; a white line on the plane: [30, 4, 244, 176]; the wing of a plane: [0, 43, 132, 212]; a flap on the left side: [1, 152, 148, 211]; black square on the bottom of the plane: [66, 119, 328, 211]; the wall is white in color: [172, 46, 280, 145]; ; Region Captions: a black square on a black background: [119, 161, 209, 52]; a black square with a black background: [1, 156, 326, 57]; a white triangle with a black background: [0, 66, 114, 93]; a gray square with a black background: [0, 155, 149, 57]; a white and silver arrow pointing to the right: [0, 132, 383, 81]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a white and black block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "white ceiling tiles: [0, 1, 381, 210]; the blue and red object: [0, 0, 47, 88]; black panel on the floor: [0, 117, 367, 211]; black square on the bottom of the umbrella: [128, 144, 349, 211]; blue material on the table: [0, 34, 40, 82]; red and yellow stripes: [0, 0, 33, 41]; the shadow of the plane: [109, 63, 357, 210]; the wall is white in color: [189, 40, 301, 133]; the wall is tiled: [99, 8, 364, 158]; the right wing of a plane: [1, 121, 160, 206]; the wall is white in color: [181, 70, 289, 152]; a piece of wood on the table: [29, 0, 71, 34]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[133, 149, 215, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 144, 383, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 54, 129, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 128, 347, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 128, 155, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.52 seconds\n",
      "finished...\n",
      "\n",
      "a black square on a black background: [133, 149, 215, 64]; a pair of triangles with a black background: [0, 144, 383, 69]; a white triangle on a black background: [0, 54, 129, 93]; a square of white paper on a black background: [0, 128, 347, 73]; a gray square on a black background: [0, 128, 155, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a white and black block in minecraft; Dense Caption: white ceiling tiles: [0, 1, 381, 210]; the blue and red object: [0, 0, 47, 88]; black panel on the floor: [0, 117, 367, 211]; black square on the bottom of the umbrella: [128, 144, 349, 211]; blue material on the table: [0, 34, 40, 82]; red and yellow stripes: [0, 0, 33, 41]; the shadow of the plane: [109, 63, 357, 210]; the wall is white in color: [189, 40, 301, 133]; the wall is tiled: [99, 8, 364, 158]; the right wing of a plane: [1, 121, 160, 206]; the wall is white in color: [181, 70, 289, 152]; a piece of wood on the table: [29, 0, 71, 34]; ; Region Captions: a black square on a black background: [133, 149, 215, 64]; a pair of triangles with a black background: [0, 144, 383, 69]; a white triangle on a black background: [0, 54, 129, 93]; a square of white paper on a black background: [0, 128, 347, 73]; a gray square on a black background: [0, 128, 155, 73]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a white and black block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "white ceiling tiles: [0, 1, 381, 210]; black panel on the floor: [1, 117, 367, 211]; the blue and red object: [0, 0, 48, 88]; black square on the bottom of the umbrella: [128, 144, 349, 211]; blue mat on the floor: [0, 36, 40, 82]; red and yellow stripes: [0, 0, 37, 41]; the shadow of the plane: [109, 65, 357, 210]; the wall is white in color: [189, 40, 301, 133]; the wall is tiled: [101, 8, 363, 157]; the right wing of a plane: [1, 121, 160, 206]; the wall is white in color: [182, 70, 289, 152]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[133, 149, 215, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 144, 383, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 54, 129, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 128, 347, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 128, 155, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.52 seconds\n",
      "finished...\n",
      "\n",
      "a black square on a black background: [133, 149, 215, 64]; a pair of triangles with a black background: [0, 144, 383, 69]; a white triangle on a black background: [0, 54, 129, 93]; a square of white paper on a black background: [0, 128, 347, 73]; a gray square on a black background: [0, 128, 155, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a white and black block in minecraft; Dense Caption: white ceiling tiles: [0, 1, 381, 210]; black panel on the floor: [1, 117, 367, 211]; the blue and red object: [0, 0, 48, 88]; black square on the bottom of the umbrella: [128, 144, 349, 211]; blue mat on the floor: [0, 36, 40, 82]; red and yellow stripes: [0, 0, 37, 41]; the shadow of the plane: [109, 65, 357, 210]; the wall is white in color: [189, 40, 301, 133]; the wall is tiled: [101, 8, 363, 157]; the right wing of a plane: [1, 121, 160, 206]; the wall is white in color: [182, 70, 289, 152]; ; Region Captions: a black square on a black background: [133, 149, 215, 64]; a pair of triangles with a black background: [0, 144, 383, 69]; a white triangle on a black background: [0, 54, 129, 93]; a square of white paper on a black background: [0, 128, 347, 73]; a gray square on a black background: [0, 128, 155, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a lot of boxes\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white box: [267, 100, 382, 211]; the box is brown: [170, 45, 262, 92]; lego person is holding a surfboard: [103, 13, 163, 112]; red paper wrapped around pole: [108, 42, 156, 80]; a bedroom: [1, 6, 381, 208]; a black basket: [17, 39, 170, 99]; blue base of a stop sign: [123, 75, 153, 107]; a lego train on display: [29, 12, 246, 176]; yellow birthday cake topper: [111, 15, 152, 46]; a yellow square pillow: [219, 51, 260, 92]; the base of the lego figure: [119, 93, 162, 114]; white blanket on the bed: [20, 78, 270, 209]; the boxes are made of cardboard: [78, 5, 313, 111]; the snow is white: [70, 124, 196, 200]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 383, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[105, 0, 278, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[297, 104, 86, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 111, 83]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 2, 383, 210]; a white and black png image of a snowy area: [0, 72, 383, 140]; a black and white image of a building: [105, 0, 278, 101]; a white and gray checkered cloth: [297, 104, 86, 98]; a grey arrow with the word arrow on it: [0, 0, 111, 83]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a lot of boxes; Dense Caption: a white box: [267, 100, 382, 211]; the box is brown: [170, 45, 262, 92]; lego person is holding a surfboard: [103, 13, 163, 112]; red paper wrapped around pole: [108, 42, 156, 80]; a bedroom: [1, 6, 381, 208]; a black basket: [17, 39, 170, 99]; blue base of a stop sign: [123, 75, 153, 107]; a lego train on display: [29, 12, 246, 176]; yellow birthday cake topper: [111, 15, 152, 46]; a yellow square pillow: [219, 51, 260, 92]; the base of the lego figure: [119, 93, 162, 114]; white blanket on the bed: [20, 78, 270, 209]; the boxes are made of cardboard: [78, 5, 313, 111]; the snow is white: [70, 124, 196, 200]; ; Region Captions: a black and white image of a snowy area: [0, 2, 383, 210]; a white and black png image of a snowy area: [0, 72, 383, 140]; a black and white image of a building: [105, 0, 278, 101]; a white and gray checkered cloth: [297, 104, 86, 98]; a grey arrow with the word arrow on it: [0, 0, 111, 83]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white box: [267, 100, 382, 211]; the box is brown: [170, 45, 262, 92]; yellow and blue card with a p on it: [56, 10, 116, 56]; lego man looking at toy train: [17, 11, 170, 134]; red square of an umbrella: [66, 49, 114, 99]; the black basket on the table: [16, 40, 170, 99]; a display of toys: [1, 7, 381, 208]; the boxes are made of cardboard: [48, 3, 319, 121]; shadow of a snowboarder: [79, 107, 134, 137]; red and blue flag: [64, 48, 123, 133]; blue square on box: [86, 16, 105, 47]; blue wooden table leg: [87, 93, 118, 130]; a yellow square pillow: [219, 51, 260, 92]; white carpet on floor: [20, 69, 281, 211]; gold colored clasp on top of a brown umbrella: [108, 70, 150, 98]; gold colored metal chain: [132, 71, 149, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 72, 383, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[104, 0, 279, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[297, 108, 86, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 107, 82]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small room: [0, 2, 383, 210]; a black and white image of a t shirt: [0, 72, 383, 140]; a black and white image of a wall: [104, 0, 279, 101]; a white square tile on a black background: [297, 108, 86, 94]; a black and white image of a sand castle: [0, 0, 107, 82]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a white box: [267, 100, 382, 211]; the box is brown: [170, 45, 262, 92]; yellow and blue card with a p on it: [56, 10, 116, 56]; lego man looking at toy train: [17, 11, 170, 134]; red square of an umbrella: [66, 49, 114, 99]; the black basket on the table: [16, 40, 170, 99]; a display of toys: [1, 7, 381, 208]; the boxes are made of cardboard: [48, 3, 319, 121]; shadow of a snowboarder: [79, 107, 134, 137]; red and blue flag: [64, 48, 123, 133]; blue square on box: [86, 16, 105, 47]; blue wooden table leg: [87, 93, 118, 130]; a yellow square pillow: [219, 51, 260, 92]; white carpet on floor: [20, 69, 281, 211]; gold colored clasp on top of a brown umbrella: [108, 70, 150, 98]; gold colored metal chain: [132, 71, 149, 98]; ; Region Captions: a black and white image of a small room: [0, 2, 383, 210]; a black and white image of a t shirt: [0, 72, 383, 140]; a black and white image of a wall: [104, 0, 279, 101]; a white square tile on a black background: [297, 108, 86, 94]; a black and white image of a sand castle: [0, 0, 107, 82]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a white box with tape on it: [267, 100, 382, 211]; the box is brown: [169, 45, 262, 93]; a lego piece holding the cake: [5, 14, 81, 110]; a bed in a bedroom: [0, 8, 382, 208]; a square patterned box: [63, 42, 169, 99]; yellow and blue square: [6, 16, 61, 50]; red part of the cake: [7, 42, 80, 82]; a yellow square pillow: [218, 51, 260, 92]; the boxes are made of cardboard: [14, 22, 265, 123]; the wall is white: [59, 3, 331, 105]; a stack of small boxes: [4, 15, 169, 109]; white snow on the ground: [12, 105, 259, 209]; blue box on the floor: [39, 76, 76, 108]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 72, 383, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[104, 0, 279, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[297, 108, 86, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 111, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[47, 46, 145, 56]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.71 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a snowy area: [0, 72, 383, 140]; a black and white image of a wall: [104, 0, 279, 101]; a white square tile on a black background: [297, 108, 86, 94]; a grey and white teddy bear with a black hat: [0, 0, 111, 83]; a black block with a black background: [47, 46, 145, 56]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: a white box with tape on it: [267, 100, 382, 211]; the box is brown: [169, 45, 262, 93]; a lego piece holding the cake: [5, 14, 81, 110]; a bed in a bedroom: [0, 8, 382, 208]; a square patterned box: [63, 42, 169, 99]; yellow and blue square: [6, 16, 61, 50]; red part of the cake: [7, 42, 80, 82]; a yellow square pillow: [218, 51, 260, 92]; the boxes are made of cardboard: [14, 22, 265, 123]; the wall is white: [59, 3, 331, 105]; a stack of small boxes: [4, 15, 169, 109]; white snow on the ground: [12, 105, 259, 209]; blue box on the floor: [39, 76, 76, 108]; ; Region Captions: a white and black image of a snowy area: [0, 72, 383, 140]; a black and white image of a wall: [104, 0, 279, 101]; a white square tile on a black background: [297, 108, 86, 94]; a grey and white teddy bear with a black hat: [0, 0, 111, 83]; a black block with a black background: [47, 46, 145, 56]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person is standing in a room with a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a pile of boxes: [117, 1, 270, 129]; a checkered table cloth: [0, 57, 114, 160]; snow covering the ground: [32, 89, 337, 212]; snowboarder is jumping over: [144, 125, 205, 166]; red white and blue flag: [136, 0, 198, 116]; wooden box holding the clock: [114, 62, 267, 128]; a blue piece of paper: [155, 69, 188, 113]; a snow covered area: [0, 2, 381, 208]; red part of the plane: [137, 0, 192, 65]; brown and white striped signs: [180, 45, 240, 87]; a yellow cross on the top of a building: [210, 46, 239, 87]; a brown wooden trunk: [114, 63, 159, 117]; the white part of the cake: [206, 66, 266, 128]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 98, 383, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[186, 0, 197, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 153, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 228, 96]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black hole in a white floor: [0, 98, 383, 114]; a silhouette of a man standing on a ladder: [0, 0, 383, 117]; a gray png image of a tiger: [186, 0, 197, 117]; a gray speech bubble with a black background: [0, 0, 153, 96]; a gray speech bubble with a black background: [0, 0, 228, 96]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person is standing in a room with a box; Dense Caption: a pile of boxes: [117, 1, 270, 129]; a checkered table cloth: [0, 57, 114, 160]; snow covering the ground: [32, 89, 337, 212]; snowboarder is jumping over: [144, 125, 205, 166]; red white and blue flag: [136, 0, 198, 116]; wooden box holding the clock: [114, 62, 267, 128]; a blue piece of paper: [155, 69, 188, 113]; a snow covered area: [0, 2, 381, 208]; red part of the plane: [137, 0, 192, 65]; brown and white striped signs: [180, 45, 240, 87]; a yellow cross on the top of a building: [210, 46, 239, 87]; a brown wooden trunk: [114, 63, 159, 117]; the white part of the cake: [206, 66, 266, 128]; ; Region Captions: a black hole in a white floor: [0, 98, 383, 114]; a silhouette of a man standing on a ladder: [0, 0, 383, 117]; a gray png image of a tiger: [186, 0, 197, 117]; a gray speech bubble with a black background: [0, 0, 153, 96]; a gray speech bubble with a black background: [0, 0, 228, 96]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing on a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black square object: [180, 55, 293, 169]; the box is brown: [201, 16, 272, 47]; the brown wicker basket: [64, 11, 192, 59]; a white box of tissue: [310, 14, 382, 90]; white bedsheets on a bed: [0, 3, 382, 210]; red and blue cup: [131, 0, 152, 26]; a person standing on the cake: [126, 0, 165, 29]; yellow and red jacket: [131, 0, 166, 8]; white bed sheets: [31, 48, 220, 204]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 40, 383, 172]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "[189, 61, 99, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[121, 0, 262, 44]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 123, 74]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black square in the middle of a white floor: [0, 40, 383, 172]; a black and white image of a man in a black shirt: [0, 0, 383, 74]; a black block on a white background: [189, 61, 99, 101]; a black and white image of a city with a skyscraper: [121, 0, 262, 44]; a grey shaped piece of paper: [0, 0, 123, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing on a block; Dense Caption: a black square object: [180, 55, 293, 169]; the box is brown: [201, 16, 272, 47]; the brown wicker basket: [64, 11, 192, 59]; a white box of tissue: [310, 14, 382, 90]; white bedsheets on a bed: [0, 3, 382, 210]; red and blue cup: [131, 0, 152, 26]; a person standing on the cake: [126, 0, 165, 29]; yellow and red jacket: [131, 0, 166, 8]; white bed sheets: [31, 48, 220, 204]; ; Region Captions: a black square in the middle of a white floor: [0, 40, 383, 172]; a black and white image of a man in a black shirt: [0, 0, 383, 74]; a black block on a white background: [189, 61, 99, 101]; a black and white image of a city with a skyscraper: [121, 0, 262, 44]; a grey shaped piece of paper: [0, 0, 123, 74]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large square black book: [132, 40, 227, 136]; square shaped fabric: [4, 2, 138, 61]; the square box on the table: [153, 5, 226, 37]; the bed is made: [0, 7, 383, 209]; a black and white checkered box: [267, 0, 383, 78]; a black box on the table: [102, 25, 260, 168]; blue cup on the table: [38, 0, 66, 17]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 33, 383, 179]\n",
      "process_ann took 0.00 seconds\n",
      "[134, 45, 90, 87]\n",
      "process_ann took 0.00 seconds\n",
      "[271, 0, 112, 74]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 9, 138, 50]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 328, 31]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft block: [0, 33, 383, 179]; a black block on a black background: [134, 45, 90, 87]; a black and white block with a white and black background: [271, 0, 112, 74]; a black block with a black square on it: [0, 9, 138, 50]; a black and white image of a city: [0, 0, 328, 31]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a large square black book: [132, 40, 227, 136]; square shaped fabric: [4, 2, 138, 61]; the square box on the table: [153, 5, 226, 37]; the bed is made: [0, 7, 383, 209]; a black and white checkered box: [267, 0, 383, 78]; a black box on the table: [102, 25, 260, 168]; blue cup on the table: [38, 0, 66, 17]; ; Region Captions: a black and white image of a minecraft block: [0, 33, 383, 179]; a black block on a black background: [134, 45, 90, 87]; a black and white block with a white and black background: [271, 0, 112, 74]; a black block with a black square on it: [0, 9, 138, 50]; a black and white image of a city: [0, 0, 328, 31]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a few different colored blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [35, 111, 350, 212]; a small black trash can: [183, 117, 222, 150]; the basket is brown: [233, 109, 286, 133]; two small square black and white objects: [278, 89, 362, 164]; the room is a bedroom: [40, 1, 354, 203]; black and white objects: [162, 89, 368, 165]; a black square box: [160, 108, 232, 129]; the chairs are black: [163, 105, 230, 154]; the table is white: [69, 145, 175, 205]; a small square block of stone: [278, 119, 314, 155]; a white box on top of the black object: [311, 90, 359, 128]; the snow is white: [107, 150, 215, 206]; the snow is white: [180, 157, 283, 208]; white snow covering the ground: [19, 143, 249, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 127, 383, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 193, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[196, 0, 187, 139]\n",
      "process_ann took 0.00 seconds\n",
      "[280, 122, 77, 40]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 0, 383, 141]; a minecraft png of a snowy path: [0, 127, 383, 85]; a gray square with a black background: [0, 0, 193, 142]; a black and white image of a man with a hat: [196, 0, 187, 139]; a black and grey striped wall: [280, 122, 77, 40]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a few different colored blocks; Dense Caption: the ground is covered in snow: [35, 111, 350, 212]; a small black trash can: [183, 117, 222, 150]; the basket is brown: [233, 109, 286, 133]; two small square black and white objects: [278, 89, 362, 164]; the room is a bedroom: [40, 1, 354, 203]; black and white objects: [162, 89, 368, 165]; a black square box: [160, 108, 232, 129]; the chairs are black: [163, 105, 230, 154]; the table is white: [69, 145, 175, 205]; a small square block of stone: [278, 119, 314, 155]; a white box on top of the black object: [311, 90, 359, 128]; the snow is white: [107, 150, 215, 206]; the snow is white: [180, 157, 283, 208]; white snow covering the ground: [19, 143, 249, 211]; ; Region Captions: a black and white image of a wall: [0, 0, 383, 141]; a minecraft png of a snowy path: [0, 127, 383, 85]; a gray square with a black background: [0, 0, 193, 142]; a black and white image of a man with a hat: [196, 0, 187, 139]; a black and grey striped wall: [280, 122, 77, 40]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210428_164645 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a bed and a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is white: [34, 136, 352, 211]; a dark colored basket: [245, 124, 350, 154]; the room is the bedroom: [37, 2, 343, 190]; a gray square object: [278, 160, 333, 185]; a brown wooden headboard: [355, 131, 383, 157]; a brown object in the snow: [269, 153, 341, 194]; a small basket on the table: [0, 128, 47, 165]; the sky is white: [12, 3, 270, 121]; the snow is white in color: [93, 154, 213, 207]; the sky is white: [76, 46, 191, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 286, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 144, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[248, 129, 99, 23]\n",
      "process_ann took 0.00 seconds\n",
      "[290, 116, 93, 33]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 133, 44, 30]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a gray square with a white background: [0, 0, 286, 150]; a white sandbox with a small white object on it: [0, 144, 383, 68]; a black block of bricks on a black background: [248, 129, 99, 23]; a black and gray gun with a black handle: [290, 116, 93, 33]; a black speaker with a black cover: [0, 133, 44, 30]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a bed and a table; Dense Caption: the bed is white: [34, 136, 352, 211]; a dark colored basket: [245, 124, 350, 154]; the room is the bedroom: [37, 2, 343, 190]; a gray square object: [278, 160, 333, 185]; a brown wooden headboard: [355, 131, 383, 157]; a brown object in the snow: [269, 153, 341, 194]; a small basket on the table: [0, 128, 47, 165]; the sky is white: [12, 3, 270, 121]; the snow is white in color: [93, 154, 213, 207]; the sky is white: [76, 46, 191, 122]; ; Region Captions: a gray square with a white background: [0, 0, 286, 150]; a white sandbox with a small white object on it: [0, 144, 383, 68]; a black block of bricks on a black background: [248, 129, 99, 23]; a black and gray gun with a black handle: [290, 116, 93, 33]; a black speaker with a black cover: [0, 133, 44, 30]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a bed and a table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is white: [34, 136, 352, 211]; a dark patterned bed edge: [245, 124, 350, 154]; the room is the bedroom: [37, 2, 343, 190]; a gray square object: [278, 160, 333, 185]; a brown wooden night stand: [355, 131, 383, 157]; a gray spot on the ground: [269, 153, 341, 194]; a small basket on the table: [0, 128, 47, 165]; the sky is white: [12, 3, 270, 121]; the snow is white in color: [93, 154, 213, 207]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 286, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 144, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[248, 129, 99, 23]\n",
      "process_ann took 0.00 seconds\n",
      "[289, 116, 94, 33]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 133, 44, 30]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a gray square with a white background: [0, 0, 286, 150]; a white sandbox with a small white object: [0, 144, 383, 68]; a black block of bricks on a black background: [248, 129, 99, 23]; a black and gray tv with a black screen: [289, 116, 94, 33]; a black speaker with a black cover: [0, 133, 44, 30]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a bed and a table; Dense Caption: the bed is white: [34, 136, 352, 211]; a dark patterned bed edge: [245, 124, 350, 154]; the room is the bedroom: [37, 2, 343, 190]; a gray square object: [278, 160, 333, 185]; a brown wooden night stand: [355, 131, 383, 157]; a gray spot on the ground: [269, 153, 341, 194]; a small basket on the table: [0, 128, 47, 165]; the sky is white: [12, 3, 270, 121]; the snow is white in color: [93, 154, 213, 207]; ; Region Captions: a gray square with a white background: [0, 0, 286, 150]; a white sandbox with a small white object: [0, 144, 383, 68]; a black block of bricks on a black background: [248, 129, 99, 23]; a black and gray tv with a black screen: [289, 116, 94, 33]; a black speaker with a black cover: [0, 133, 44, 30]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft screenshot of a room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego with red jacket: [337, 111, 375, 166]; snow covering the ground: [34, 134, 352, 211]; the wall is white: [31, 1, 285, 141]; the photo is black and white: [36, 20, 343, 209]; a dark patterned table: [246, 125, 344, 154]; a small gray spot on the ground: [278, 161, 332, 185]; red and white stripes: [341, 125, 374, 148]; a brick wall: [0, 128, 47, 165]; the snow is white: [92, 157, 213, 209]; blue base of an orange cone: [344, 142, 366, 165]; a brown object in the snow: [260, 149, 337, 197]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 287, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 144, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[248, 129, 97, 23]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 133, 44, 30]\n",
      "process_ann took 0.00 seconds\n",
      "[345, 129, 19, 35]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a gray square with a white background: [0, 0, 287, 150]; a small white object is sitting on a white surface: [0, 144, 383, 68]; a black block of wood on a black background: [248, 129, 97, 23]; a black speaker with a black cover: [0, 133, 44, 30]; a red and blue striped bag: [345, 129, 19, 35]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft screenshot of a room with a person standing in it; Dense Caption: a lego with red jacket: [337, 111, 375, 166]; snow covering the ground: [34, 134, 352, 211]; the wall is white: [31, 1, 285, 141]; the photo is black and white: [36, 20, 343, 209]; a dark patterned table: [246, 125, 344, 154]; a small gray spot on the ground: [278, 161, 332, 185]; red and white stripes: [341, 125, 374, 148]; a brick wall: [0, 128, 47, 165]; the snow is white: [92, 157, 213, 209]; blue base of an orange cone: [344, 142, 366, 165]; a brown object in the snow: [260, 149, 337, 197]; ; Region Captions: a gray square with a white background: [0, 0, 287, 150]; a small white object is sitting on a white surface: [0, 144, 383, 68]; a black block of wood on a black background: [248, 129, 97, 23]; a black speaker with a black cover: [0, 133, 44, 30]; a red and blue striped bag: [345, 129, 19, 35]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "snow covering the ground: [35, 132, 352, 211]; red and yellow item on the ground: [314, 111, 356, 167]; the wall is white: [4, 1, 287, 147]; the photo is black and white: [36, 18, 339, 209]; a small grate in the snow: [279, 161, 332, 185]; a brick wall: [247, 125, 320, 153]; a brick wall: [0, 128, 47, 165]; a brown wooden box: [355, 131, 383, 157]; blue base of the orange cone: [321, 143, 345, 167]; red cloth on the fire hydrant: [316, 125, 354, 148]; a lego house in the snow: [297, 103, 363, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 287, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 144, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[248, 129, 74, 23]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 133, 44, 30]\n",
      "process_ann took 0.00 seconds\n",
      "[357, 134, 26, 23]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.56 seconds\n",
      "finished...\n",
      "\n",
      "a gray square with a white background: [0, 0, 287, 150]; a person is standing on a snowy surface: [0, 144, 383, 68]; a black block of bricks on a black background: [248, 129, 74, 23]; a black speaker with a black cover: [0, 133, 44, 30]; a wooden table with a paper on it: [357, 134, 26, 23]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: snow covering the ground: [35, 132, 352, 211]; red and yellow item on the ground: [314, 111, 356, 167]; the wall is white: [4, 1, 287, 147]; the photo is black and white: [36, 18, 339, 209]; a small grate in the snow: [279, 161, 332, 185]; a brick wall: [247, 125, 320, 153]; a brick wall: [0, 128, 47, 165]; a brown wooden box: [355, 131, 383, 157]; blue base of the orange cone: [321, 143, 345, 167]; red cloth on the fire hydrant: [316, 125, 354, 148]; a lego house in the snow: [297, 103, 363, 179]; ; Region Captions: a gray square with a white background: [0, 0, 287, 150]; a person is standing on a snowy surface: [0, 144, 383, 68]; a black block of bricks on a black background: [248, 129, 74, 23]; a black speaker with a black cover: [0, 133, 44, 30]; a wooden table with a paper on it: [357, 134, 26, 23]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a door\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego person with a red jacket: [324, 110, 359, 162]; white bedspread on the bed: [35, 133, 352, 211]; the wall is white: [31, 1, 285, 141]; the photo is black and white: [36, 19, 342, 209]; the black box in the background: [246, 125, 332, 153]; a gray square object: [278, 161, 332, 185]; a lego figure on a snow covered wall: [306, 102, 365, 174]; a brown wooden box: [356, 131, 383, 158]; the red clothes hanging on the pole: [325, 124, 357, 144]; blue pants on a person: [332, 140, 353, 160]; a brick wall: [0, 128, 47, 165]; the snow is white: [92, 157, 213, 209]; a yellow top of a lego chair: [327, 112, 355, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 286, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 144, 383, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[248, 129, 86, 23]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 133, 44, 30]\n",
      "process_ann took 0.00 seconds\n",
      "[357, 134, 26, 22]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.56 seconds\n",
      "finished...\n",
      "\n",
      "a gray square with a white background: [0, 0, 286, 150]; a small white object is flying in the air: [0, 144, 383, 68]; a black block of bricks on a black background: [248, 129, 86, 23]; a black speaker with a black cover: [0, 133, 44, 30]; a wooden table with a black background: [357, 134, 26, 22]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a door; Dense Caption: a lego person with a red jacket: [324, 110, 359, 162]; white bedspread on the bed: [35, 133, 352, 211]; the wall is white: [31, 1, 285, 141]; the photo is black and white: [36, 19, 342, 209]; the black box in the background: [246, 125, 332, 153]; a gray square object: [278, 161, 332, 185]; a lego figure on a snow covered wall: [306, 102, 365, 174]; a brown wooden box: [356, 131, 383, 158]; the red clothes hanging on the pole: [325, 124, 357, 144]; blue pants on a person: [332, 140, 353, 160]; a brick wall: [0, 128, 47, 165]; the snow is white: [92, 157, 213, 209]; a yellow top of a lego chair: [327, 112, 355, 127]; ; Region Captions: a gray square with a white background: [0, 0, 286, 150]; a small white object is flying in the air: [0, 144, 383, 68]; a black block of bricks on a black background: [248, 129, 86, 23]; a black speaker with a black cover: [0, 133, 44, 30]; a wooden table with a black background: [357, 134, 26, 22]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a bed\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the small wooden box on the ground: [158, 92, 241, 126]; a lego ice cream cone: [27, 54, 146, 205]; shadow of the object: [42, 170, 124, 211]; snow covering the ground: [1, 111, 382, 211]; red stripe on the pole: [34, 93, 128, 159]; blue square on yellow box: [74, 60, 97, 97]; blue base of umbrella: [56, 150, 108, 203]; yellow and blue sign: [31, 57, 107, 106]; the bench is empty: [27, 44, 264, 207]; snow on the ground: [181, 142, 304, 208]; the grey sky: [0, 1, 381, 128]; white snow covering the ground: [152, 130, 372, 210]; snow covering the ground: [227, 141, 352, 209]; a black and white checkered table cloth: [0, 98, 36, 154]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 117, 383, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 66, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 146, 65]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man with a hat on his head: [0, 0, 383, 126]; a black and white image of a small black and white cat: [0, 2, 383, 210]; a person is standing on a snowy surface: [0, 117, 383, 95]; a gray tv stand with a black screen: [0, 0, 66, 98]; a black and white image of a minecraft block: [0, 94, 146, 65]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a bed; Dense Caption: the small wooden box on the ground: [158, 92, 241, 126]; a lego ice cream cone: [27, 54, 146, 205]; shadow of the object: [42, 170, 124, 211]; snow covering the ground: [1, 111, 382, 211]; red stripe on the pole: [34, 93, 128, 159]; blue square on yellow box: [74, 60, 97, 97]; blue base of umbrella: [56, 150, 108, 203]; yellow and blue sign: [31, 57, 107, 106]; the bench is empty: [27, 44, 264, 207]; snow on the ground: [181, 142, 304, 208]; the grey sky: [0, 1, 381, 128]; white snow covering the ground: [152, 130, 372, 210]; snow covering the ground: [227, 141, 352, 209]; a black and white checkered table cloth: [0, 98, 36, 154]; ; Region Captions: a silhouette of a man with a hat on his head: [0, 0, 383, 126]; a black and white image of a small black and white cat: [0, 2, 383, 210]; a person is standing on a snowy surface: [0, 117, 383, 95]; a gray tv stand with a black screen: [0, 0, 66, 98]; a black and white image of a minecraft block: [0, 94, 146, 65]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a desk\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the wood box on the right: [158, 92, 242, 126]; a lego ice cream cone: [27, 54, 146, 205]; shadow of the object: [43, 170, 124, 211]; snow covering the ground: [1, 110, 382, 211]; blue base of the umbrella: [57, 150, 108, 203]; black stripes on pole: [34, 92, 131, 158]; yellow and blue sign: [31, 57, 107, 107]; blue square on yellow box: [74, 60, 97, 97]; the bench is empty: [27, 44, 264, 208]; snow on the ground: [181, 142, 304, 208]; the sky is grey: [1, 1, 381, 128]; white snow covering the ground: [152, 130, 371, 210]; snow covering the ground: [228, 141, 352, 209]; a black and white checkered table cloth: [0, 97, 37, 155]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 139]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 2, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 117, 383, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[34, 60, 91, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 67, 98]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man in a city: [0, 0, 383, 139]; a black and white image of a chair: [0, 2, 383, 211]; a person is standing on a snowy surface: [0, 117, 383, 95]; a minecraft character with a red shirt and blue pants: [34, 60, 91, 142]; a gray piece of metal with a small hole in it: [0, 0, 67, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a desk; Dense Caption: the wood box on the right: [158, 92, 242, 126]; a lego ice cream cone: [27, 54, 146, 205]; shadow of the object: [43, 170, 124, 211]; snow covering the ground: [1, 110, 382, 211]; blue base of the umbrella: [57, 150, 108, 203]; black stripes on pole: [34, 92, 131, 158]; yellow and blue sign: [31, 57, 107, 107]; blue square on yellow box: [74, 60, 97, 97]; the bench is empty: [27, 44, 264, 208]; snow on the ground: [181, 142, 304, 208]; the sky is grey: [1, 1, 381, 128]; white snow covering the ground: [152, 130, 371, 210]; snow covering the ground: [228, 141, 352, 209]; a black and white checkered table cloth: [0, 97, 37, 155]; ; Region Captions: a black and white image of a man in a city: [0, 0, 383, 139]; a black and white image of a chair: [0, 2, 383, 211]; a person is standing on a snowy surface: [0, 117, 383, 95]; a minecraft character with a red shirt and blue pants: [34, 60, 91, 142]; a gray piece of metal with a small hole in it: [0, 0, 67, 98]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is running in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego snowboard: [110, 46, 237, 207]; a large woven basket: [0, 89, 148, 160]; snow covering the ground: [0, 115, 383, 211]; shadow of the person: [137, 173, 209, 211]; the sign is yellow: [146, 51, 214, 110]; the wooden crate behind the umbrella: [196, 93, 242, 128]; the wall is white: [59, 3, 326, 156]; a red part of a snowboard: [115, 92, 191, 167]; a lego snowboard and snowboard: [5, 50, 285, 209]; blue plastic on the end of the umbrella: [132, 139, 224, 204]; snow covered ground: [241, 126, 379, 210]; a blue diamond on the traffic sign: [162, 63, 194, 99]; a red part of the umbrella: [153, 114, 189, 163]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 122, 383, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[140, 122, 243, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 126, 204, 86]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 146, 64]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black cat: [0, 0, 383, 126]; a black and white image of a person standing on a snowy surface: [0, 122, 383, 90]; a white snowy mountain with a white snowy mountain: [140, 122, 243, 91]; a silhouette of a man with a hat on: [0, 126, 204, 86]; a black block with a blue light in it: [0, 94, 146, 64]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is running in a room; Dense Caption: a lego snowboard: [110, 46, 237, 207]; a large woven basket: [0, 89, 148, 160]; snow covering the ground: [0, 115, 383, 211]; shadow of the person: [137, 173, 209, 211]; the sign is yellow: [146, 51, 214, 110]; the wooden crate behind the umbrella: [196, 93, 242, 128]; the wall is white: [59, 3, 326, 156]; a red part of a snowboard: [115, 92, 191, 167]; a lego snowboard and snowboard: [5, 50, 285, 209]; blue plastic on the end of the umbrella: [132, 139, 224, 204]; snow covered ground: [241, 126, 379, 210]; a blue diamond on the traffic sign: [162, 63, 194, 99]; a red part of the umbrella: [153, 114, 189, 163]; ; Region Captions: a black and white image of a room with a black cat: [0, 0, 383, 126]; a black and white image of a person standing on a snowy surface: [0, 122, 383, 90]; a white snowy mountain with a white snowy mountain: [140, 122, 243, 91]; a silhouette of a man with a hat on: [0, 126, 204, 86]; a black block with a blue light in it: [0, 94, 146, 64]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue block and a blue block in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the suitcase is blue: [139, 106, 208, 179]; the square patterned ottoman: [0, 89, 148, 161]; the two brown boxes: [156, 92, 243, 128]; white tablecloth on the table: [0, 113, 382, 211]; a bed in the room: [38, 49, 304, 205]; the wall is white: [44, 1, 347, 150]; the yellow part of the headboard: [210, 94, 242, 128]; two brown and blue suitcases: [134, 86, 245, 184]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 146, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 71, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 109, 61, 67]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 0, 383, 126]; a black and white image of a small black and white object: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 146, 64]; a grey square with a black background: [0, 0, 71, 98]; a blue block on a black background: [143, 109, 61, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue block and a blue block in a minecraft room; Dense Caption: the suitcase is blue: [139, 106, 208, 179]; the square patterned ottoman: [0, 89, 148, 161]; the two brown boxes: [156, 92, 243, 128]; white tablecloth on the table: [0, 113, 382, 211]; a bed in the room: [38, 49, 304, 205]; the wall is white: [44, 1, 347, 150]; the yellow part of the headboard: [210, 94, 242, 128]; two brown and blue suitcases: [134, 86, 245, 184]; ; Region Captions: a black and white image of a wall: [0, 0, 383, 126]; a black and white image of a small black and white object: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 146, 64]; a grey square with a black background: [0, 0, 71, 98]; a blue block on a black background: [143, 109, 61, 67]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the suitcase is blue: [139, 106, 207, 179]; a large bricked box: [0, 88, 148, 161]; a lego figure on a platform: [212, 66, 261, 145]; the items are on the bed: [28, 68, 324, 210]; a lego piece sitting on a bed: [133, 50, 281, 173]; a suitcase on the floor: [25, 6, 285, 180]; a round base of a vase: [215, 130, 255, 148]; a wooden box on a table: [157, 67, 263, 142]; orange piece of tape on the hydrant: [213, 85, 258, 119]; the box is brown: [156, 91, 227, 126]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 146, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 71, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 109, 61, 67]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man with a hat: [0, 0, 383, 126]; a black and white image of a person in a black and white shirt: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 146, 64]; a gray square with a black background: [0, 0, 71, 98]; a blue block on a black background: [143, 109, 61, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is standing in a room; Dense Caption: the suitcase is blue: [139, 106, 207, 179]; a large bricked box: [0, 88, 148, 161]; a lego figure on a platform: [212, 66, 261, 145]; the items are on the bed: [28, 68, 324, 210]; a lego piece sitting on a bed: [133, 50, 281, 173]; a suitcase on the floor: [25, 6, 285, 180]; a round base of a vase: [215, 130, 255, 148]; a wooden box on a table: [157, 67, 263, 142]; orange piece of tape on the hydrant: [213, 85, 258, 119]; the box is brown: [156, 91, 227, 126]; ; Region Captions: a black and white image of a man with a hat: [0, 0, 383, 126]; a black and white image of a person in a black and white shirt: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 146, 64]; a gray square with a black background: [0, 0, 71, 98]; a blue block on a black background: [143, 109, 61, 67]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a blue box and a blue chair\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the suitcase is blue: [139, 106, 208, 179]; a large bricked box: [1, 89, 149, 161]; the square brown suitcase: [156, 92, 243, 127]; a lego figure holding a board: [267, 66, 307, 132]; a bed in a room: [31, 42, 339, 204]; white tablecloth on the table: [0, 112, 382, 211]; red clothes on the lego person: [270, 83, 303, 111]; the yellow luggage in the middle: [210, 94, 242, 128]; black cord coming from the head of the cake: [268, 64, 282, 86]; the wall is white: [45, 1, 362, 128]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 146, 64]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 71, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 109, 61, 67]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.56 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 0, 383, 126]; a black and white image of a snowy area: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 146, 64]; a gray square with a black background: [0, 0, 71, 98]; a blue block on a black background: [143, 109, 61, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a blue box and a blue chair; Dense Caption: the suitcase is blue: [139, 106, 208, 179]; a large bricked box: [1, 89, 149, 161]; the square brown suitcase: [156, 92, 243, 127]; a lego figure holding a board: [267, 66, 307, 132]; a bed in a room: [31, 42, 339, 204]; white tablecloth on the table: [0, 112, 382, 211]; red clothes on the lego person: [270, 83, 303, 111]; the yellow luggage in the middle: [210, 94, 242, 128]; black cord coming from the head of the cake: [268, 64, 282, 86]; the wall is white: [45, 1, 362, 128]; ; Region Captions: a black and white image of a wall: [0, 0, 383, 126]; a black and white image of a snowy area: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 146, 64]; a gray square with a black background: [0, 0, 71, 98]; a blue block on a black background: [143, 109, 61, 67]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a blue and white table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the suitcase is blue: [135, 106, 204, 179]; a large woven basket: [0, 89, 144, 162]; the two brown boxes: [152, 92, 238, 127]; a lego with red clothes: [266, 68, 298, 128]; white tablecloth on the table: [0, 114, 382, 212]; a bed in the room: [34, 44, 337, 204]; red cloth on the fire hydrant: [269, 86, 294, 108]; top of hydrant is yellow and blue: [270, 69, 296, 89]; the square wood headboard: [206, 94, 238, 128]; the walls are white: [30, 1, 371, 126]; white tablecloth on the table: [216, 130, 371, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 0, 381, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 142, 66]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 65, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[138, 109, 62, 67]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing in front of a building: [2, 0, 381, 125]; a black and white image of a skier in the snow: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 142, 66]; a grey square with a black background: [0, 0, 65, 98]; a blue block on a black background: [138, 109, 62, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a blue and white table; Dense Caption: the suitcase is blue: [135, 106, 204, 179]; a large woven basket: [0, 89, 144, 162]; the two brown boxes: [152, 92, 238, 127]; a lego with red clothes: [266, 68, 298, 128]; white tablecloth on the table: [0, 114, 382, 212]; a bed in the room: [34, 44, 337, 204]; red cloth on the fire hydrant: [269, 86, 294, 108]; top of hydrant is yellow and blue: [270, 69, 296, 89]; the square wood headboard: [206, 94, 238, 128]; the walls are white: [30, 1, 371, 126]; white tablecloth on the table: [216, 130, 371, 211]; ; Region Captions: a silhouette of a man standing in front of a building: [2, 0, 381, 125]; a black and white image of a skier in the snow: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 142, 66]; a grey square with a black background: [0, 0, 65, 98]; a blue block on a black background: [138, 109, 62, 67]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a blue and white table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the suitcase is blue: [135, 106, 204, 179]; a large woven basket: [0, 89, 144, 162]; the two brown boxes: [152, 92, 238, 127]; a lego with many colors: [266, 68, 298, 128]; white tablecloth on the table: [0, 114, 382, 212]; a bed in the room: [33, 44, 338, 204]; red part of the lego: [269, 86, 294, 108]; a small box: [206, 94, 238, 127]; top of hydrant is yellow and blue: [270, 69, 296, 89]; the walls are white: [28, 1, 372, 126]; white tablecloth on the table: [216, 130, 371, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 0, 381, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 142, 66]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 65, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[138, 109, 62, 67]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing in front of a building: [2, 0, 381, 125]; a black and white image of a skateboarder: [0, 121, 383, 91]; a black block with a blue block on it: [0, 94, 142, 66]; a grey square with a black background: [0, 0, 65, 98]; a blue block on a black background: [138, 109, 62, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a blue and white table; Dense Caption: the suitcase is blue: [135, 106, 204, 179]; a large woven basket: [0, 89, 144, 162]; the two brown boxes: [152, 92, 238, 127]; a lego with many colors: [266, 68, 298, 128]; white tablecloth on the table: [0, 114, 382, 212]; a bed in the room: [33, 44, 338, 204]; red part of the lego: [269, 86, 294, 108]; a small box: [206, 94, 238, 127]; top of hydrant is yellow and blue: [270, 69, 296, 89]; the walls are white: [28, 1, 372, 126]; white tablecloth on the table: [216, 130, 371, 211]; ; Region Captions: a silhouette of a man standing in front of a building: [2, 0, 381, 125]; a black and white image of a skateboarder: [0, 121, 383, 91]; a black block with a blue block on it: [0, 94, 142, 66]; a grey square with a black background: [0, 0, 65, 98]; a blue block on a black background: [138, 109, 62, 67]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a blue and white table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the suitcase is blue: [135, 106, 204, 179]; a large woven basket: [0, 89, 144, 162]; the two brown boxes: [152, 92, 238, 127]; a lego person is standing: [266, 68, 297, 128]; white tablecloth on the table: [0, 114, 382, 212]; a bed in the room: [34, 43, 338, 204]; red part of hydrant: [269, 86, 294, 108]; the square wood headboard: [206, 94, 238, 128]; top of hydrant is yellow and blue: [270, 69, 296, 89]; the walls are white: [29, 1, 371, 126]; white tablecloth on the table: [216, 130, 371, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 0, 381, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 142, 66]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 65, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[138, 109, 62, 67]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing in front of a building: [2, 0, 381, 125]; a black and white image of a skateboarder: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 142, 66]; a grey square with a black background: [0, 0, 65, 98]; a blue block on a black background: [138, 109, 62, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a blue and white table; Dense Caption: the suitcase is blue: [135, 106, 204, 179]; a large woven basket: [0, 89, 144, 162]; the two brown boxes: [152, 92, 238, 127]; a lego person is standing: [266, 68, 297, 128]; white tablecloth on the table: [0, 114, 382, 212]; a bed in the room: [34, 43, 338, 204]; red part of hydrant: [269, 86, 294, 108]; the square wood headboard: [206, 94, 238, 128]; top of hydrant is yellow and blue: [270, 69, 296, 89]; the walls are white: [29, 1, 371, 126]; white tablecloth on the table: [216, 130, 371, 211]; ; Region Captions: a silhouette of a man standing in front of a building: [2, 0, 381, 125]; a black and white image of a skateboarder: [0, 121, 383, 91]; a block of black blocks on a black background: [0, 94, 142, 66]; a grey square with a black background: [0, 0, 65, 98]; a blue block on a black background: [138, 109, 62, 67]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a square blue suitcase: [136, 106, 204, 178]; a large woven basket: [0, 87, 144, 163]; a lego house and a toy on a bed: [36, 28, 306, 207]; white tablecloth on the table: [0, 113, 382, 212]; lego red and blue chair: [193, 45, 265, 122]; a circle in the middle of the room: [209, 131, 253, 156]; red and white umbrella: [209, 69, 263, 105]; yellow and blue square: [213, 47, 250, 77]; lego house on a platform: [144, 30, 283, 156]; the boxes are brown: [152, 92, 241, 127]; black and white striped pole: [190, 68, 214, 89]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[6, 0, 377, 125]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 94, 142, 66]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 65, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[139, 109, 61, 67]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.77 seconds\n",
      "finished...\n",
      "\n",
      "a shadow of a man and a woman standing in front of a wall: [6, 0, 377, 125]; a black and white image of a small black object: [0, 121, 383, 91]; a black block with a blue block on it: [0, 94, 142, 66]; a grey square with a black background: [0, 0, 65, 98]; a blue block on a black background: [139, 109, 61, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is standing in a room; Dense Caption: a square blue suitcase: [136, 106, 204, 178]; a large woven basket: [0, 87, 144, 163]; a lego house and a toy on a bed: [36, 28, 306, 207]; white tablecloth on the table: [0, 113, 382, 212]; lego red and blue chair: [193, 45, 265, 122]; a circle in the middle of the room: [209, 131, 253, 156]; red and white umbrella: [209, 69, 263, 105]; yellow and blue square: [213, 47, 250, 77]; lego house on a platform: [144, 30, 283, 156]; the boxes are brown: [152, 92, 241, 127]; black and white striped pole: [190, 68, 214, 89]; ; Region Captions: a shadow of a man and a woman standing in front of a wall: [6, 0, 377, 125]; a black and white image of a small black object: [0, 121, 383, 91]; a black block with a blue block on it: [0, 94, 142, 66]; a grey square with a black background: [0, 0, 65, 98]; a blue block on a black background: [139, 109, 61, 67]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a table with wooden blocks on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown and beige suitcase: [97, 127, 363, 212]; a tall building: [0, 149, 40, 212]; the sky is dark: [37, 21, 352, 177]; the building is made of wood: [273, 127, 383, 212]; the building is made of wood: [110, 57, 371, 209]; the sky is dark: [147, 74, 263, 129]; the sky is clear: [94, 73, 210, 130]; rows of slats in the wood: [120, 140, 242, 209]; the sky is overcast: [20, 13, 280, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0.0, 0.0, 383.0, 212.0]\n",
      "process_ann took 0.00 seconds\n",
      "[91.0, 132.0, 292.0, 81.0]\n",
      "process_ann took 0.00 seconds\n",
      "[276.0, 132.0, 107.0, 81.0]\n",
      "process_ann took 0.00 seconds\n",
      "[276.0, 132.0, 107.0, 39.0]\n",
      "process_ann took 0.00 seconds\n",
      "[0.0, 153.0, 38.0, 60.0]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black cat: [0.0, 0.0, 383.0, 212.0]; a wooden block with two colors: [91.0, 132.0, 292.0, 81.0]; a wooden table with a wooden top: [276.0, 132.0, 107.0, 81.0]; a wooden plank on a black background: [276.0, 132.0, 107.0, 39.0]; a black block on a black background: [0.0, 153.0, 38.0, 60.0]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a table with wooden blocks on it; Dense Caption: brown and beige suitcase: [97, 127, 363, 212]; a tall building: [0, 149, 40, 212]; the sky is dark: [37, 21, 352, 177]; the building is made of wood: [273, 127, 383, 212]; the building is made of wood: [110, 57, 371, 209]; the sky is dark: [147, 74, 263, 129]; the sky is clear: [94, 73, 210, 130]; rows of slats in the wood: [120, 140, 242, 209]; the sky is overcast: [20, 13, 280, 122]; ; Region Captions: a black and white image of a room with a black cat: [0.0, 0.0, 383.0, 212.0]; a wooden block with two colors: [91.0, 132.0, 292.0, 81.0]; a wooden table with a wooden top: [276.0, 132.0, 107.0, 81.0]; a wooden plank on a black background: [276.0, 132.0, 107.0, 39.0]; a black block on a black background: [0.0, 153.0, 38.0, 60.0]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a blue and red block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue umbrella: [236, 0, 381, 92]; a large woven basket: [0, 0, 158, 97]; white snow on the ground: [0, 1, 382, 210]; the snow is white: [56, 68, 330, 209]; a bed of snow: [12, 1, 366, 111]; a blue bench in the snow: [151, 0, 370, 165]; shadow of an umbrella handle: [332, 53, 370, 80]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 153, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[242, 0, 141, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[188, 0, 66, 10]\n",
      "process_ann took 0.00 seconds\n",
      "[188, 0, 37, 10]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a white floor: [0, 1, 383, 211]; a black and white block of ice: [0, 0, 153, 92]; a blue block with a black background: [242, 0, 141, 88]; a dark brown background with a black cat: [188, 0, 66, 10]; a black and white image of a black and white image: [188, 0, 37, 10]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a blue and red block; Dense Caption: a blue umbrella: [236, 0, 381, 92]; a large woven basket: [0, 0, 158, 97]; white snow on the ground: [0, 1, 382, 210]; the snow is white: [56, 68, 330, 209]; a bed of snow: [12, 1, 366, 111]; a blue bench in the snow: [151, 0, 370, 165]; shadow of an umbrella handle: [332, 53, 370, 80]; ; Region Captions: a black and white image of a room with a white floor: [0, 1, 383, 211]; a black and white block of ice: [0, 0, 153, 92]; a blue block with a black background: [242, 0, 141, 88]; a dark brown background with a black cat: [188, 0, 66, 10]; a black and white image of a black and white image: [188, 0, 37, 10]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft table with two wooden blocks on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the roof of the building: [67, 136, 382, 212]; black and white checkerboard pattern on cloth: [0, 127, 70, 212]; the sky is dark: [40, 10, 351, 146]; shadow on the bench: [164, 142, 195, 212]; the sun is setting: [42, 68, 341, 212]; the sky is grey: [38, 1, 350, 78]; shadow on the ground: [142, 144, 253, 210]; the sky is clear: [164, 72, 285, 132]; the sky is clear: [164, 44, 285, 113]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 204]\n",
      "process_ann took 0.00 seconds\n",
      "[70, 142, 313, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 45]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 133, 69, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 106, 42, 28]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.70 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a cloud: [0, 1, 383, 204]; a wooden floor with brown stripes: [70, 142, 313, 71]; a black and white image of a city with a cloudy sky: [0, 1, 383, 45]; a black and white square block: [0, 133, 69, 80]; a black and gray hat with a tan lining: [0, 106, 42, 28]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft table with two wooden blocks on it; Dense Caption: the roof of the building: [67, 136, 382, 212]; black and white checkerboard pattern on cloth: [0, 127, 70, 212]; the sky is dark: [40, 10, 351, 146]; shadow on the bench: [164, 142, 195, 212]; the sun is setting: [42, 68, 341, 212]; the sky is grey: [38, 1, 350, 78]; shadow on the ground: [142, 144, 253, 210]; the sky is clear: [164, 72, 285, 132]; the sky is clear: [164, 44, 285, 113]; ; Region Captions: a black and white image of a cloud: [0, 1, 383, 204]; a wooden floor with brown stripes: [70, 142, 313, 71]; a black and white image of a city with a cloudy sky: [0, 1, 383, 45]; a black and white square block: [0, 133, 69, 80]; a black and gray hat with a tan lining: [0, 106, 42, 28]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with some blocks and a blue block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a checkered blanket: [143, 99, 315, 212]; blue book on the white bed: [74, 62, 136, 118]; the box is brown: [154, 54, 231, 99]; the room is a bedroom: [0, 19, 381, 210]; square basket behind the table: [57, 47, 163, 91]; a lamp shade on the lamp: [0, 18, 41, 114]; a black basket on the bed: [53, 38, 169, 124]; white sheet on bed: [2, 114, 134, 211]; the wall is white: [100, 3, 329, 119]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 202]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 77, 383, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 77, 239, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[147, 102, 166, 111]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black cat: [0, 0, 383, 134]; a black and white image of a room with a black wall: [0, 0, 383, 202]; a 3d image of a building with a black background: [0, 77, 383, 135]; a white and black image of a snowy mountain: [0, 77, 239, 135]; a block of gray blocks on a black background: [147, 102, 166, 111]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with some blocks and a blue block; Dense Caption: a checkered blanket: [143, 99, 315, 212]; blue book on the white bed: [74, 62, 136, 118]; the box is brown: [154, 54, 231, 99]; the room is a bedroom: [0, 19, 381, 210]; square basket behind the table: [57, 47, 163, 91]; a lamp shade on the lamp: [0, 18, 41, 114]; a black basket on the bed: [53, 38, 169, 124]; white sheet on bed: [2, 114, 134, 211]; the wall is white: [100, 3, 329, 119]; ; Region Captions: a black and white image of a room with a black cat: [0, 0, 383, 134]; a black and white image of a room with a black wall: [0, 0, 383, 202]; a 3d image of a building with a black background: [0, 77, 383, 135]; a white and black image of a snowy mountain: [0, 77, 239, 135]; a block of gray blocks on a black background: [147, 102, 166, 111]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person in a minecraft game is standing in front of some blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a black and white foot rest: [145, 99, 315, 212]; lego multicolored toy: [53, 7, 153, 155]; the box is brown: [155, 54, 230, 99]; a pillow on the bed: [0, 24, 41, 114]; a lego toy set: [39, 10, 326, 213]; red and yellow sign: [55, 53, 141, 123]; top of the cake is yellow: [63, 8, 136, 73]; blue wooden legs of the umbrella: [86, 100, 149, 151]; a lego toy on display: [39, 2, 227, 169]; blue wooden post: [115, 101, 148, 149]; shadow of umbrella on the ground: [86, 130, 150, 170]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 134]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 77, 383, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[148, 102, 165, 111]\n",
      "process_ann took 0.00 seconds\n",
      "[211, 95, 172, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 126, 77]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black cat: [0, 0, 383, 134]; a person standing in a room with a black background: [0, 77, 383, 135]; a block of gray blocks on a black background: [148, 102, 165, 111]; a white sheet of paper with a black background: [211, 95, 172, 118]; a black and white image of a tiger: [0, 0, 126, 77]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person in a minecraft game is standing in front of some blocks; Dense Caption: a black and white foot rest: [145, 99, 315, 212]; lego multicolored toy: [53, 7, 153, 155]; the box is brown: [155, 54, 230, 99]; a pillow on the bed: [0, 24, 41, 114]; a lego toy set: [39, 10, 326, 213]; red and yellow sign: [55, 53, 141, 123]; top of the cake is yellow: [63, 8, 136, 73]; blue wooden legs of the umbrella: [86, 100, 149, 151]; a lego toy on display: [39, 2, 227, 169]; blue wooden post: [115, 101, 148, 149]; shadow of umbrella on the ground: [86, 130, 150, 170]; ; Region Captions: a black and white image of a room with a black cat: [0, 0, 383, 134]; a person standing in a room with a black background: [0, 77, 383, 135]; a block of gray blocks on a black background: [148, 102, 165, 111]; a white sheet of paper with a black background: [211, 95, 172, 118]; a black and white image of a tiger: [0, 0, 126, 77]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with orange and blue colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the object is orange: [117, 1, 371, 211]; a blue plastic box: [80, 58, 136, 110]; a black and white rug: [0, 19, 46, 109]; small black box behind the blue suitcase: [61, 43, 144, 84]; white and black diamond pattern on box: [147, 123, 256, 211]; the table is wooden: [113, 88, 330, 211]; the floor is white: [5, 117, 110, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[65, 0, 307, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 71, 383, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 70, 167, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[258, 0, 113, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[285, 26, 98, 187]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a block of orange and grey: [65, 0, 307, 212]; a black and white image of a hallway: [0, 71, 383, 141]; a white png of a snowy path: [0, 70, 167, 142]; a carrot shaped pixel art: [258, 0, 113, 212]; a white table with a black background: [285, 26, 98, 187]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with orange and blue colors; Dense Caption: the object is orange: [117, 1, 371, 211]; a blue plastic box: [80, 58, 136, 110]; a black and white rug: [0, 19, 46, 109]; small black box behind the blue suitcase: [61, 43, 144, 84]; white and black diamond pattern on box: [147, 123, 256, 211]; the table is wooden: [113, 88, 330, 211]; the floor is white: [5, 117, 110, 209]; ; Region Captions: a block of orange and grey: [65, 0, 307, 212]; a black and white image of a hallway: [0, 71, 383, 141]; a white png of a snowy path: [0, 70, 167, 142]; a carrot shaped pixel art: [258, 0, 113, 212]; a white table with a black background: [285, 26, 98, 187]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with orange and blue colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large piece of artwork: [68, 1, 255, 199]; a blue plastic box: [12, 54, 100, 114]; the orange part of the sculpture: [103, 0, 253, 122]; black and white checkered box: [125, 90, 240, 196]; a snow covered area: [0, 13, 380, 208]; red and yellow box: [58, 17, 102, 65]; yellow top of red plastic container: [60, 17, 93, 45]; a stack of plastic trays: [1, 40, 68, 90]; a stack of black boxes: [0, 26, 106, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 71, 383, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[107, 0, 141, 194]\n",
      "process_ann took 0.00 seconds\n",
      "[107, 0, 141, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[127, 91, 109, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[239, 59, 144, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white object: [0, 71, 383, 141]; a minecraft block with an orange and black color: [107, 0, 141, 194]; a minecraft block with the word orange: [107, 0, 141, 122]; a black and grey square block: [127, 91, 109, 104]; a gray piece of wood with a black background: [239, 59, 144, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with orange and blue colors; Dense Caption: a large piece of artwork: [68, 1, 255, 199]; a blue plastic box: [12, 54, 100, 114]; the orange part of the sculpture: [103, 0, 253, 122]; black and white checkered box: [125, 90, 240, 196]; a snow covered area: [0, 13, 380, 208]; red and yellow box: [58, 17, 102, 65]; yellow top of red plastic container: [60, 17, 93, 45]; a stack of plastic trays: [1, 40, 68, 90]; a stack of black boxes: [0, 26, 106, 92]; ; Region Captions: a black and white image of a black and white object: [0, 71, 383, 141]; a minecraft block with an orange and black color: [107, 0, 141, 194]; a minecraft block with the word orange: [107, 0, 141, 122]; a black and grey square block: [127, 91, 109, 104]; a gray piece of wood with a black background: [239, 59, 144, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with orange and blue blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large blue and orange cone: [106, 1, 358, 202]; a blue plastic box: [63, 24, 130, 82]; a black remote control: [25, 7, 118, 57]; a roof shaped like a pyramid: [0, 26, 28, 81]; the stripe is orange: [166, 2, 344, 126]; a line of orange paper: [201, 49, 300, 139]; black and white checkered design: [178, 87, 288, 200]; snow on the ground: [3, 93, 127, 211]; black and blue suitcase: [20, 3, 131, 88]; blue and white checkered design: [154, 3, 204, 148]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 41, 383, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[115, 0, 241, 198]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 41, 254, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[176, 0, 180, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[254, 77, 129, 135]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a mountain: [0, 41, 383, 171]; a minecraft block with orange and grey squares: [115, 0, 241, 198]; a white snowy surface with a white sand: [0, 41, 254, 171]; a block of orange bricks: [176, 0, 180, 128]; a sheet of silver paper on a black background: [254, 77, 129, 135]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with orange and blue blocks; Dense Caption: a large blue and orange cone: [106, 1, 358, 202]; a blue plastic box: [63, 24, 130, 82]; a black remote control: [25, 7, 118, 57]; a roof shaped like a pyramid: [0, 26, 28, 81]; the stripe is orange: [166, 2, 344, 126]; a line of orange paper: [201, 49, 300, 139]; black and white checkered design: [178, 87, 288, 200]; snow on the ground: [3, 93, 127, 211]; black and blue suitcase: [20, 3, 131, 88]; blue and white checkered design: [154, 3, 204, 148]; ; Region Captions: a black and white image of a mountain: [0, 41, 383, 171]; a minecraft block with orange and grey squares: [115, 0, 241, 198]; a white snowy surface with a white sand: [0, 41, 254, 171]; a block of orange bricks: [176, 0, 180, 128]; a sheet of silver paper on a black background: [254, 77, 129, 135]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man standing in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown and tan striped box: [143, 111, 282, 211]; a grey and white checkered bedspread: [0, 39, 189, 175]; white railing on the bed: [47, 48, 136, 90]; red blue and yellow colors: [0, 5, 59, 66]; blue square on umbrella: [2, 59, 61, 99]; a bed in a room: [1, 2, 282, 209]; white sheet on bed: [0, 126, 170, 212]; a pillow on a bed: [0, 6, 162, 124]; the wall is white: [204, 9, 363, 171]; a small wire rack: [3, 41, 139, 103]; the flag is red blue and yellow: [0, 2, 75, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 43, 186, 127]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 132, 167, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[149, 115, 132, 98]\n",
      "process_ann took 0.00 seconds\n",
      "[3, 0, 147, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[13, 0, 137, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.52 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft block with a window in it: [0, 43, 186, 127]; a silver triangle with a black background: [0, 132, 167, 81]; a wooden floor in minecraft: [149, 115, 132, 98]; a grey square with a black background: [3, 0, 147, 71]; a grey piece of paper with a white background: [13, 0, 137, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man standing in a minecraft room; Dense Caption: a brown and tan striped box: [143, 111, 282, 211]; a grey and white checkered bedspread: [0, 39, 189, 175]; white railing on the bed: [47, 48, 136, 90]; red blue and yellow colors: [0, 5, 59, 66]; blue square on umbrella: [2, 59, 61, 99]; a bed in a room: [1, 2, 282, 209]; white sheet on bed: [0, 126, 170, 212]; a pillow on a bed: [0, 6, 162, 124]; the wall is white: [204, 9, 363, 171]; a small wire rack: [3, 41, 139, 103]; the flag is red blue and yellow: [0, 2, 75, 105]; ; Region Captions: a minecraft block with a window in it: [0, 43, 186, 127]; a silver triangle with a black background: [0, 132, 167, 81]; a wooden floor in minecraft: [149, 115, 132, 98]; a grey square with a black background: [3, 0, 147, 71]; a grey piece of paper with a white background: [13, 0, 137, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing in front of a minecraft block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the corner of a blue and orange striped wall: [0, 1, 207, 210]; a blue box on the floor: [270, 74, 381, 156]; lego woman in blue pants: [215, 22, 275, 131]; a wooden chair: [274, 24, 348, 93]; blue square on the wall: [56, 1, 207, 129]; red part of the object: [216, 54, 275, 101]; legos on the floor: [213, 22, 381, 157]; shadow of the object: [214, 110, 263, 136]; gray square tile on the floor: [1, 131, 116, 211]; a yellow gift box: [225, 23, 268, 67]; the floor is white: [141, 59, 369, 211]; blue post it note on the base of the cake: [224, 92, 256, 130]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[108, 60, 275, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[55, 0, 216, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[55, 0, 150, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 91, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[206, 0, 177, 82]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a man is standing in a hallway with a black suit: [108, 60, 275, 153]; a blue block with a red arrow on it: [55, 0, 216, 131]; blue pixel block: [55, 0, 150, 131]; a brown tiled roof in minecraft: [0, 0, 91, 143]; a silhouette of a city with a tall building: [206, 0, 177, 82]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing in front of a minecraft block; Dense Caption: the corner of a blue and orange striped wall: [0, 1, 207, 210]; a blue box on the floor: [270, 74, 381, 156]; lego woman in blue pants: [215, 22, 275, 131]; a wooden chair: [274, 24, 348, 93]; blue square on the wall: [56, 1, 207, 129]; red part of the object: [216, 54, 275, 101]; legos on the floor: [213, 22, 381, 157]; shadow of the object: [214, 110, 263, 136]; gray square tile on the floor: [1, 131, 116, 211]; a yellow gift box: [225, 23, 268, 67]; the floor is white: [141, 59, 369, 211]; blue post it note on the base of the cake: [224, 92, 256, 130]; ; Region Captions: a man is standing in a hallway with a black suit: [108, 60, 275, 153]; a blue block with a red arrow on it: [55, 0, 216, 131]; blue pixel block: [55, 0, 150, 131]; a brown tiled roof in minecraft: [0, 0, 91, 143]; a silhouette of a city with a tall building: [206, 0, 177, 82]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210428_165333 14\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character walking in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego piece holding the snow: [67, 4, 169, 154]; the ground is covered in snow: [0, 52, 382, 211]; yellow and blue square: [71, 5, 144, 60]; blue base of the umbrella: [106, 105, 151, 148]; the back wall is white: [31, 0, 343, 61]; shadow of the object: [97, 125, 166, 166]; a brown box in the background: [264, 42, 373, 71]; a lego snowboarder: [48, 4, 348, 175]; black stripes on the pole: [78, 53, 161, 109]; a black square fence: [0, 45, 77, 73]; the snowboard is red: [50, 58, 193, 196]; two brown objects in the snow: [260, 58, 375, 95]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 61, 383, 151]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 47, 371, 30]\n",
      "process_ann took 0.00 seconds\n",
      "[73, 8, 69, 53]\n",
      "process_ann took 0.00 seconds\n",
      "[317, 0, 66, 65]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft character walking on a snowy surface: [0, 61, 383, 151]; a black and white image of a city: [0, 0, 383, 60]; two black and white png files: [0, 47, 371, 30]; a brown and blue striped box: [73, 8, 69, 53]; a black and white picture of a black and white picture: [317, 0, 66, 65]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character walking in a room; Dense Caption: a lego piece holding the snow: [67, 4, 169, 154]; the ground is covered in snow: [0, 52, 382, 211]; yellow and blue square: [71, 5, 144, 60]; blue base of the umbrella: [106, 105, 151, 148]; the back wall is white: [31, 0, 343, 61]; shadow of the object: [97, 125, 166, 166]; a brown box in the background: [264, 42, 373, 71]; a lego snowboarder: [48, 4, 348, 175]; black stripes on the pole: [78, 53, 161, 109]; a black square fence: [0, 45, 77, 73]; the snowboard is red: [50, 58, 193, 196]; two brown objects in the snow: [260, 58, 375, 95]; ; Region Captions: a minecraft character walking on a snowy surface: [0, 61, 383, 151]; a black and white image of a city: [0, 0, 383, 60]; two black and white png files: [0, 47, 371, 30]; a brown and blue striped box: [73, 8, 69, 53]; a black and white picture of a black and white picture: [317, 0, 66, 65]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego snowboarder: [46, 20, 162, 180]; snow covering the ground: [40, 70, 349, 212]; shadow of the snowboarder: [75, 143, 146, 187]; blue wooden table leg: [87, 125, 130, 174]; red stripe on the pole: [49, 68, 125, 141]; the basket is made of wood: [252, 58, 365, 89]; a snowboarder on a snowboard: [33, 6, 244, 206]; the wall is white: [6, 0, 335, 81]; a green and black street light: [125, 99, 158, 140]; brown square in the snow: [248, 78, 372, 115]; yellow and blue square: [58, 22, 129, 84]; the black and yellow design on the blue and yellow portion of the larger umbrella: [99, 98, 162, 143]; a brown wooden chair: [359, 66, 383, 96]; a black and white snow covered fence: [4, 60, 66, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 79, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[306, 0, 77, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 64, 362, 27]\n",
      "process_ann took 0.00 seconds\n",
      "[60, 25, 64, 58]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a person walking down a street in a minecraft world: [0, 79, 383, 133]; a black and white image of a building: [0, 0, 383, 84]; a gray teddy bear with a black background: [306, 0, 77, 84]; two black and white star wars ships: [0, 64, 362, 27]; a head with a blue and yellow hat: [60, 25, 64, 58]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a lego snowboarder: [46, 20, 162, 180]; snow covering the ground: [40, 70, 349, 212]; shadow of the snowboarder: [75, 143, 146, 187]; blue wooden table leg: [87, 125, 130, 174]; red stripe on the pole: [49, 68, 125, 141]; the basket is made of wood: [252, 58, 365, 89]; a snowboarder on a snowboard: [33, 6, 244, 206]; the wall is white: [6, 0, 335, 81]; a green and black street light: [125, 99, 158, 140]; brown square in the snow: [248, 78, 372, 115]; yellow and blue square: [58, 22, 129, 84]; the black and yellow design on the blue and yellow portion of the larger umbrella: [99, 98, 162, 143]; a brown wooden chair: [359, 66, 383, 96]; a black and white snow covered fence: [4, 60, 66, 94]; ; Region Captions: a person walking down a street in a minecraft world: [0, 79, 383, 133]; a black and white image of a building: [0, 0, 383, 84]; a gray teddy bear with a black background: [306, 0, 77, 84]; two black and white star wars ships: [0, 64, 362, 27]; a head with a blue and yellow hat: [60, 25, 64, 58]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a few blocks on the floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is made: [33, 96, 347, 211]; the basket is made of plastic: [145, 83, 218, 107]; a brown wicker basket: [215, 85, 275, 114]; a bed in a room: [34, 28, 318, 189]; two brown squares on the bed: [130, 104, 216, 122]; the wall is white: [0, 1, 186, 103]; the bed has a brown headboard: [121, 64, 329, 136]; two brown pillows on the bed: [139, 76, 278, 118]; brown square on white bedspread: [185, 107, 214, 120]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 102, 383, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 187, 109]\n",
      "process_ann took 0.00 seconds\n",
      "[189, 0, 194, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 145, 20]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy surface with a black background: [0, 102, 383, 110]; a black and white image of a wall: [0, 0, 383, 128]; a gray state with a white background: [0, 0, 187, 109]; a gray silhouette of a state with a black background: [189, 0, 194, 128]; a gray rectangle with a black background: [0, 90, 145, 20]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a few blocks on the floor; Dense Caption: the bed is made: [33, 96, 347, 211]; the basket is made of plastic: [145, 83, 218, 107]; a brown wicker basket: [215, 85, 275, 114]; a bed in a room: [34, 28, 318, 189]; two brown squares on the bed: [130, 104, 216, 122]; the wall is white: [0, 1, 186, 103]; the bed has a brown headboard: [121, 64, 329, 136]; two brown pillows on the bed: [139, 76, 278, 118]; brown square on white bedspread: [185, 107, 214, 120]; ; Region Captions: a white snowy surface with a black background: [0, 102, 383, 110]; a black and white image of a wall: [0, 0, 383, 128]; a gray state with a white background: [0, 0, 187, 109]; a gray silhouette of a state with a black background: [189, 0, 194, 128]; a gray rectangle with a black background: [0, 90, 145, 20]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing on a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large bed: [33, 97, 347, 211]; lego man in red shirt: [156, 57, 176, 88]; the black object on the top of the table: [146, 84, 217, 107]; the brown box on the side of the bed: [215, 85, 274, 113]; the items are on the table: [112, 52, 302, 130]; the room is a bedroom: [0, 4, 380, 209]; two brown squares on the ground: [130, 104, 216, 122]; a cake with a candle: [55, 36, 319, 174]; small lego with a toy: [143, 54, 218, 107]; the wall is white: [0, 1, 182, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 102, 383, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[189, 0, 194, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 187, 109]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 145, 20]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a white snowy surface with a black background: [0, 102, 383, 110]; a person standing in a room with a wall: [0, 0, 383, 128]; a gray silhouette of a state with a black background: [189, 0, 194, 128]; a gray wall with a white board on it: [0, 0, 187, 109]; a gray rectangle with a black background: [0, 90, 145, 20]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing on a block; Dense Caption: a large bed: [33, 97, 347, 211]; lego man in red shirt: [156, 57, 176, 88]; the black object on the top of the table: [146, 84, 217, 107]; the brown box on the side of the bed: [215, 85, 274, 113]; the items are on the table: [112, 52, 302, 130]; the room is a bedroom: [0, 4, 380, 209]; two brown squares on the ground: [130, 104, 216, 122]; a cake with a candle: [55, 36, 319, 174]; small lego with a toy: [143, 54, 218, 107]; the wall is white: [0, 1, 182, 103]; ; Region Captions: a white snowy surface with a black background: [0, 102, 383, 110]; a person standing in a room with a wall: [0, 0, 383, 128]; a gray silhouette of a state with a black background: [189, 0, 194, 128]; a gray wall with a white board on it: [0, 0, 187, 109]; a gray rectangle with a black background: [0, 90, 145, 20]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large bed: [32, 97, 348, 211]; the brown square box: [215, 86, 275, 113]; the boxes are made of cardboard: [93, 66, 308, 132]; a black square box: [147, 83, 218, 107]; person wearing blue pants: [126, 67, 154, 121]; red jacket on person: [133, 82, 149, 103]; a bedroom: [1, 4, 380, 209]; yellow and blue cap: [129, 69, 149, 87]; person standing in the snow: [117, 62, 165, 131]; a person wearing blue pants: [132, 79, 149, 119]; blue pants on a child: [133, 100, 147, 118]; the boxes are brown: [137, 77, 278, 115]; brown square in the middle of the white bed: [185, 107, 215, 120]; the wall is white: [0, 1, 184, 102]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 102, 383, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[189, 0, 194, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 187, 109]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 134, 20]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a small white pixelated image of a snowy hill: [0, 102, 383, 110]; a black and white image of a room with a wall: [0, 0, 383, 128]; a gray silhouette of a state with a black background: [189, 0, 194, 128]; a gray square with a black background: [0, 0, 187, 109]; a gray t shirt with a black background: [0, 90, 134, 20]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a large bed: [32, 97, 348, 211]; the brown square box: [215, 86, 275, 113]; the boxes are made of cardboard: [93, 66, 308, 132]; a black square box: [147, 83, 218, 107]; person wearing blue pants: [126, 67, 154, 121]; red jacket on person: [133, 82, 149, 103]; a bedroom: [1, 4, 380, 209]; yellow and blue cap: [129, 69, 149, 87]; person standing in the snow: [117, 62, 165, 131]; a person wearing blue pants: [132, 79, 149, 119]; blue pants on a child: [133, 100, 147, 118]; the boxes are brown: [137, 77, 278, 115]; brown square in the middle of the white bed: [185, 107, 215, 120]; the wall is white: [0, 1, 184, 102]; ; Region Captions: a small white pixelated image of a snowy hill: [0, 102, 383, 110]; a black and white image of a room with a wall: [0, 0, 383, 128]; a gray silhouette of a state with a black background: [189, 0, 194, 128]; a gray square with a black background: [0, 0, 187, 109]; a gray t shirt with a black background: [0, 90, 134, 20]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the brown box on the right: [202, 76, 282, 115]; the ground is covered in snow: [38, 80, 350, 212]; the boxes are made of wood: [76, 49, 278, 135]; red square on pole: [154, 72, 182, 106]; lego man is holding a skateboard: [142, 48, 203, 133]; a yellow and blue tag: [150, 51, 182, 78]; a green sticker on a suitcase: [186, 85, 201, 104]; red and blue flags: [149, 51, 184, 106]; the black basket on the ground: [109, 72, 208, 106]; blue base of the lego piece: [155, 101, 174, 129]; white wall in the background: [0, 1, 164, 104]; the snow is white: [24, 113, 255, 211]; a bedroom: [0, 4, 379, 203]; red and blue post: [151, 65, 183, 130]; the signs shadow on the ground: [76, 103, 206, 138]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 97, 383, 115]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 128]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 257, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 165, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[204, 81, 74, 32]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a small pixelated image of a snowy area: [0, 97, 383, 115]; a black and white image of a room with a wall: [0, 0, 383, 128]; a black and white image of a wall: [0, 0, 257, 105]; a gray shaped object with a black background: [0, 0, 165, 105]; a stack of bricks in a dark background: [204, 81, 74, 32]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: the brown box on the right: [202, 76, 282, 115]; the ground is covered in snow: [38, 80, 350, 212]; the boxes are made of wood: [76, 49, 278, 135]; red square on pole: [154, 72, 182, 106]; lego man is holding a skateboard: [142, 48, 203, 133]; a yellow and blue tag: [150, 51, 182, 78]; a green sticker on a suitcase: [186, 85, 201, 104]; red and blue flags: [149, 51, 184, 106]; the black basket on the ground: [109, 72, 208, 106]; blue base of the lego piece: [155, 101, 174, 129]; white wall in the background: [0, 1, 164, 104]; the snow is white: [24, 113, 255, 211]; a bedroom: [0, 4, 379, 203]; red and blue post: [151, 65, 183, 130]; the signs shadow on the ground: [76, 103, 206, 138]; ; Region Captions: a small pixelated image of a snowy area: [0, 97, 383, 115]; a black and white image of a room with a wall: [0, 0, 383, 128]; a black and white image of a wall: [0, 0, 257, 105]; a gray shaped object with a black background: [0, 0, 165, 105]; a stack of bricks in a dark background: [204, 81, 74, 32]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden floor and a wooden table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [177, 64, 287, 128]; box is brown color: [62, 57, 186, 110]; the bed is made: [29, 65, 349, 213]; a brown card board box: [85, 118, 158, 163]; the bed has many pillows: [36, 18, 313, 163]; a white wall: [0, 0, 149, 95]; the sheet is white in color: [174, 143, 294, 208]; the box is brown: [147, 46, 306, 153]; brown objects in the snow: [0, 105, 165, 183]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 89, 383, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[142, 0, 241, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 145, 93]\n",
      "process_ann took 0.00 seconds\n",
      "[180, 69, 104, 56]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.74 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a snowy mountain: [0, 89, 383, 123]; a black and white image of a room with a hole in the wall: [0, 0, 383, 146]; a gray gun with a hole in it: [142, 0, 241, 146]; a grey square with the word'm' on it: [0, 0, 145, 93]; a wooden block on a black background: [180, 69, 104, 56]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden floor and a wooden table; Dense Caption: a brown wooden box: [177, 64, 287, 128]; box is brown color: [62, 57, 186, 110]; the bed is made: [29, 65, 349, 213]; a brown card board box: [85, 118, 158, 163]; the bed has many pillows: [36, 18, 313, 163]; a white wall: [0, 0, 149, 95]; the sheet is white in color: [174, 143, 294, 208]; the box is brown: [147, 46, 306, 153]; brown objects in the snow: [0, 105, 165, 183]; ; Region Captions: a white and black image of a snowy mountain: [0, 89, 383, 123]; a black and white image of a room with a hole in the wall: [0, 0, 383, 146]; a gray gun with a hole in it: [142, 0, 241, 146]; a grey square with the word'm' on it: [0, 0, 145, 93]; a wooden block on a black background: [180, 69, 104, 56]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft screenshot showing a yellow block and a yellow block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "yellow object in the forefront: [152, 80, 243, 175]; white tablecloth on the table: [0, 59, 382, 211]; the black colored box: [216, 69, 271, 124]; red white and blue toy: [270, 35, 313, 105]; a black box with white dots: [308, 62, 383, 124]; a brown basket in the corner: [81, 52, 149, 74]; a brown cardboard box: [295, 134, 383, 199]; the suitcase is yellow: [118, 57, 286, 191]; a table with many different items: [59, 9, 353, 182]; red part of the lego: [276, 56, 303, 83]; white wall in the background: [0, 0, 128, 78]; a yellow and blue tag: [278, 37, 313, 61]; white snow covering the ground: [5, 78, 136, 207]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 70, 383, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[117, 0, 266, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 122, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[155, 85, 86, 88]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.56 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 70, 383, 142]; a black and white image of a city: [0, 0, 383, 85]; a black and white image of a building: [117, 0, 266, 85]; a gray square with a black background: [0, 0, 122, 75]; a yellow block on a black background: [155, 85, 86, 88]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft screenshot showing a yellow block and a yellow block; Dense Caption: yellow object in the forefront: [152, 80, 243, 175]; white tablecloth on the table: [0, 59, 382, 211]; the black colored box: [216, 69, 271, 124]; red white and blue toy: [270, 35, 313, 105]; a black box with white dots: [308, 62, 383, 124]; a brown basket in the corner: [81, 52, 149, 74]; a brown cardboard box: [295, 134, 383, 199]; the suitcase is yellow: [118, 57, 286, 191]; a table with many different items: [59, 9, 353, 182]; red part of the lego: [276, 56, 303, 83]; white wall in the background: [0, 0, 128, 78]; a yellow and blue tag: [278, 37, 313, 61]; white snow covering the ground: [5, 78, 136, 207]; ; Region Captions: a black and white image of a snowy area: [0, 70, 383, 142]; a black and white image of a city: [0, 0, 383, 85]; a black and white image of a building: [117, 0, 266, 85]; a gray square with a black background: [0, 0, 122, 75]; a yellow block on a black background: [155, 85, 86, 88]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two wooden blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown and beige suitcase: [57, 125, 381, 212]; a black and white checkered tablecloth: [0, 115, 80, 211]; a bed in front of a cloudy sky: [42, 40, 351, 209]; the sky is dark: [37, 15, 351, 138]; a line on a table: [226, 132, 251, 214]; a line on the bench: [235, 133, 265, 214]; the sky is dark: [155, 68, 274, 123]; the line is yellow: [193, 133, 233, 201]; a line on the bench: [212, 136, 244, 210]; the bench is brown: [171, 132, 272, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0.0, 0.0, 383.0, 177.0]\n",
      "process_ann took 0.00 seconds\n",
      "[63.0, 130.0, 320.0, 83.0]\n",
      "process_ann took 0.00 seconds\n",
      "[0.0, 123.0, 77.0, 90.0]\n",
      "process_ann took 0.00 seconds\n",
      "[11.0, 185.0, 54.0, 28.0]\n",
      "process_ann took 0.00 seconds\n",
      "[220.0, 136.0, 19.0, 30.0]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0.0, 0.0, 383.0, 177.0]; a wooden block with a wooden texture: [63.0, 130.0, 320.0, 83.0]; a black and white block of a block: [0.0, 123.0, 77.0, 90.0]; a black triangle with a white triangle on it: [11.0, 185.0, 54.0, 28.0]; a tan hat on a black background: [220.0, 136.0, 19.0, 30.0]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two wooden blocks; Dense Caption: brown and beige suitcase: [57, 125, 381, 212]; a black and white checkered tablecloth: [0, 115, 80, 211]; a bed in front of a cloudy sky: [42, 40, 351, 209]; the sky is dark: [37, 15, 351, 138]; a line on a table: [226, 132, 251, 214]; a line on the bench: [235, 133, 265, 214]; the sky is dark: [155, 68, 274, 123]; the line is yellow: [193, 133, 233, 201]; a line on the bench: [212, 136, 244, 210]; the bench is brown: [171, 132, 272, 210]; ; Region Captions: a black and white image of a wall: [0.0, 0.0, 383.0, 177.0]; a wooden block with a wooden texture: [63.0, 130.0, 320.0, 83.0]; a black and white block of a block: [0.0, 123.0, 77.0, 90.0]; a black triangle with a white triangle on it: [11.0, 185.0, 54.0, 28.0]; a tan hat on a black background: [220.0, 136.0, 19.0, 30.0]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing on a wooden platform with a knife\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [56, 124, 382, 212]; a pile of legos: [1, 1, 143, 161]; a place to sleep: [41, 20, 346, 211]; black and white checkered table cloth: [0, 118, 65, 211]; blue and white section of umbrella: [53, 86, 116, 154]; red and white stripes: [3, 8, 139, 91]; a white blue and yellow sign: [23, 0, 116, 36]; brown and white wooden bench: [228, 134, 256, 213]; the sky is cloudy: [177, 64, 291, 125]; black and white checkered design on umbrella: [0, 38, 28, 69]; the sky is overcast: [154, 12, 371, 124]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 177]\n",
      "process_ann took 0.00 seconds\n",
      "[63, 130, 320, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 123, 65, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[63, 148, 75, 65]\n",
      "process_ann took 0.00 seconds\n",
      "[55, 88, 59, 54]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man standing in a room: [0, 0, 383, 177]; a wooden block with a wooden texture: [63, 130, 320, 83]; a black and white block of minecraft: [0, 123, 65, 90]; a wooden block with a wooden texture: [63, 148, 75, 65]; a blue square on a black background: [55, 88, 59, 54]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing on a wooden platform with a knife; Dense Caption: a brown wooden box: [56, 124, 382, 212]; a pile of legos: [1, 1, 143, 161]; a place to sleep: [41, 20, 346, 211]; black and white checkered table cloth: [0, 118, 65, 211]; blue and white section of umbrella: [53, 86, 116, 154]; red and white stripes: [3, 8, 139, 91]; a white blue and yellow sign: [23, 0, 116, 36]; brown and white wooden bench: [228, 134, 256, 213]; the sky is cloudy: [177, 64, 291, 125]; black and white checkered design on umbrella: [0, 38, 28, 69]; the sky is overcast: [154, 12, 371, 124]; ; Region Captions: a silhouette of a man standing in a room: [0, 0, 383, 177]; a wooden block with a wooden texture: [63, 130, 320, 83]; a black and white block of minecraft: [0, 123, 65, 90]; a wooden block with a wooden texture: [63, 148, 75, 65]; a blue square on a black background: [55, 88, 59, 54]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a yellow and red block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "square shaped dark fabric: [213, 67, 380, 129]; the chair is yellow and black: [102, 34, 176, 136]; yellow square box: [2, 96, 119, 212]; the floor is white: [38, 58, 347, 212]; a brown card: [171, 140, 254, 201]; red table behind yellow cake: [4, 68, 61, 110]; a green angel statue: [43, 47, 80, 81]; the wall is white: [33, 0, 344, 91]; yellow and black cardboard boxes: [1, 34, 160, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 81, 383, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[17, 0, 321, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 100, 116, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[215, 72, 168, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[103, 39, 68, 95]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a building: [0, 81, 383, 131]; a black and white image of a building with a sign: [17, 0, 321, 88]; a yellow block on a black background: [0, 100, 116, 113]; a black and blue textured minecraft box: [215, 72, 168, 56]; a yellow and black block on a white background: [103, 39, 68, 95]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a yellow and red block; Dense Caption: square shaped dark fabric: [213, 67, 380, 129]; the chair is yellow and black: [102, 34, 176, 136]; yellow square box: [2, 96, 119, 212]; the floor is white: [38, 58, 347, 212]; a brown card: [171, 140, 254, 201]; red table behind yellow cake: [4, 68, 61, 110]; a green angel statue: [43, 47, 80, 81]; the wall is white: [33, 0, 344, 91]; yellow and black cardboard boxes: [1, 34, 160, 210]; ; Region Captions: a white and black image of a building: [0, 81, 383, 131]; a black and white image of a building with a sign: [17, 0, 321, 88]; a yellow block on a black background: [0, 100, 116, 113]; a black and blue textured minecraft box: [215, 72, 168, 56]; a yellow and black block on a white background: [103, 39, 68, 95]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "dark box with light pattern: [105, 74, 236, 132]; brown square in the white snow: [153, 153, 255, 211]; a black and yellow object: [0, 16, 81, 211]; brown wooden box: [236, 80, 383, 173]; red white and blue gift: [250, 76, 310, 142]; lego man is holding a kite: [242, 47, 335, 145]; a bed in a bedroom: [0, 4, 382, 209]; a green and black x: [302, 51, 343, 84]; the floor is white: [61, 88, 381, 211]; blue cloth on table: [252, 105, 280, 142]; a yellow and blue paper bag: [251, 49, 294, 81]; a toy on the bed: [171, 34, 353, 177]; black square tiles on the table: [0, 111, 79, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[68, 106, 315, 106]\n",
      "process_ann took 0.00 seconds\n",
      "[183, 0, 200, 100]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 182, 107]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 20, 77, 192]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a man is standing in front of a wall: [0, 0, 383, 118]; a white and black image of a stairway: [68, 106, 315, 106]; a silhouette of a man standing in front of a wall: [183, 0, 200, 100]; a grey shaped object with a black background: [0, 0, 182, 107]; a yellow and black block on a black background: [0, 20, 77, 192]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: dark box with light pattern: [105, 74, 236, 132]; brown square in the white snow: [153, 153, 255, 211]; a black and yellow object: [0, 16, 81, 211]; brown wooden box: [236, 80, 383, 173]; red white and blue gift: [250, 76, 310, 142]; lego man is holding a kite: [242, 47, 335, 145]; a bed in a bedroom: [0, 4, 382, 209]; a green and black x: [302, 51, 343, 84]; the floor is white: [61, 88, 381, 211]; blue cloth on table: [252, 105, 280, 142]; a yellow and blue paper bag: [251, 49, 294, 81]; a toy on the bed: [171, 34, 353, 177]; black square tiles on the table: [0, 111, 79, 211]; ; Region Captions: a man is standing in front of a wall: [0, 0, 383, 118]; a white and black image of a stairway: [68, 106, 315, 106]; a silhouette of a man standing in front of a wall: [183, 0, 200, 100]; a grey shaped object with a black background: [0, 0, 182, 107]; a yellow and black block on a black background: [0, 20, 77, 192]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego piece holding the cake: [70, 0, 162, 134]; wooden box on the ground: [162, 33, 328, 124]; the large brown object: [32, 144, 183, 210]; blue square on umbrella: [109, 82, 153, 127]; a snowboarder on a snowboard: [28, 0, 293, 159]; the floor is white: [35, 74, 346, 211]; brown and white checkered cloth: [0, 23, 167, 132]; a green and black checkered pattern: [144, 58, 175, 98]; shadow of a child: [103, 103, 164, 137]; yellow and blue stripes: [77, 0, 146, 41]; red paper with black writing: [73, 28, 149, 97]; the umbrella has black and brown squares: [118, 55, 179, 101]; black and white checkered table cloth: [0, 33, 75, 114]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 88, 383, 124]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 118]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 0, 240, 117]\n",
      "process_ann took 0.00 seconds\n",
      "[164, 40, 160, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 32, 163, 96]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person walking on a snowy path: [0, 88, 383, 124]; a black and white image of a wall: [0, 0, 383, 118]; a black and gray png image of a tv: [143, 0, 240, 117]; a wooden block in minecraft: [164, 40, 160, 82]; a black and blue block with a blue light: [0, 32, 163, 96]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a lego piece holding the cake: [70, 0, 162, 134]; wooden box on the ground: [162, 33, 328, 124]; the large brown object: [32, 144, 183, 210]; blue square on umbrella: [109, 82, 153, 127]; a snowboarder on a snowboard: [28, 0, 293, 159]; the floor is white: [35, 74, 346, 211]; brown and white checkered cloth: [0, 23, 167, 132]; a green and black checkered pattern: [144, 58, 175, 98]; shadow of a child: [103, 103, 164, 137]; yellow and blue stripes: [77, 0, 146, 41]; red paper with black writing: [73, 28, 149, 97]; the umbrella has black and brown squares: [118, 55, 179, 101]; black and white checkered table cloth: [0, 33, 75, 114]; ; Region Captions: a black and white image of a person walking on a snowy path: [0, 88, 383, 124]; a black and white image of a wall: [0, 0, 383, 118]; a black and gray png image of a tv: [143, 0, 240, 117]; a wooden block in minecraft: [164, 40, 160, 82]; a black and blue block with a blue light: [0, 32, 163, 96]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a yellow, blue, and black block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "yellow black and blue boxes: [160, 11, 272, 150]; yellow square tiles on the wall: [33, 83, 161, 208]; a black and white checkered object: [331, 72, 382, 162]; a table with a book: [2, 15, 382, 209]; black square on the yellow and black cup: [181, 81, 261, 148]; a small basket on the floor: [126, 48, 164, 68]; yellow section of the clock: [182, 13, 270, 91]; the tip of a ski: [236, 187, 298, 211]; the white wall next to the bed: [1, 0, 163, 70]; blue section of the cake: [161, 23, 185, 79]; the left side of the blue and yellow box: [160, 22, 188, 126]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 65, 383, 147]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[163, 0, 220, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[162, 15, 107, 131]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building: [0, 2, 383, 210]; a black and white image of a building: [0, 65, 383, 147]; a 3d model of a door with a door: [0, 0, 383, 94]; a gray shaped object with a white background: [163, 0, 220, 94]; a yellow, blue and black square block: [162, 15, 107, 131]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a yellow, blue, and black block in minecraft; Dense Caption: yellow black and blue boxes: [160, 11, 272, 150]; yellow square tiles on the wall: [33, 83, 161, 208]; a black and white checkered object: [331, 72, 382, 162]; a table with a book: [2, 15, 382, 209]; black square on the yellow and black cup: [181, 81, 261, 148]; a small basket on the floor: [126, 48, 164, 68]; yellow section of the clock: [182, 13, 270, 91]; the tip of a ski: [236, 187, 298, 211]; the white wall next to the bed: [1, 0, 163, 70]; blue section of the cake: [161, 23, 185, 79]; the left side of the blue and yellow box: [160, 22, 188, 126]; ; Region Captions: a black and white image of a building: [0, 2, 383, 210]; a black and white image of a building: [0, 65, 383, 147]; a 3d model of a door with a door: [0, 0, 383, 94]; a gray shaped object with a white background: [163, 0, 220, 94]; a yellow, blue and black square block: [162, 15, 107, 131]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210428_165855 19\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character with a sword and a knife\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large amount of snow: [0, 71, 382, 212]; a lego ice cream truck: [169, 20, 255, 184]; a shadow on the ground: [179, 145, 243, 186]; a black and white sign with yellow and white: [142, 92, 186, 126]; a multicolored striped box: [181, 71, 251, 138]; the basket is woven: [110, 58, 179, 79]; the top of the lego box: [183, 21, 249, 75]; snowboard on the ground: [101, 14, 284, 197]; a black rock on the side of the hill: [353, 62, 383, 91]; blue and red stripes on the pole: [194, 119, 230, 173]; white wall in the background: [0, 1, 147, 92]; green and white stripes: [203, 76, 226, 140]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 72, 383, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[139, 0, 244, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 142, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[186, 23, 62, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a person is standing on a snowy hill: [0, 72, 383, 140]; a black and white image of a room with a door: [0, 0, 383, 90]; a black and gray png image of a png: [139, 0, 244, 80]; a gray shaped object on a black background: [0, 0, 142, 90]; a small brown and blue box with a blue roof: [186, 23, 62, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character with a sword and a knife; Dense Caption: a large amount of snow: [0, 71, 382, 212]; a lego ice cream truck: [169, 20, 255, 184]; a shadow on the ground: [179, 145, 243, 186]; a black and white sign with yellow and white: [142, 92, 186, 126]; a multicolored striped box: [181, 71, 251, 138]; the basket is woven: [110, 58, 179, 79]; the top of the lego box: [183, 21, 249, 75]; snowboard on the ground: [101, 14, 284, 197]; a black rock on the side of the hill: [353, 62, 383, 91]; blue and red stripes on the pole: [194, 119, 230, 173]; white wall in the background: [0, 1, 147, 92]; green and white stripes: [203, 76, 226, 140]; ; Region Captions: a person is standing on a snowy hill: [0, 72, 383, 140]; a black and white image of a room with a door: [0, 0, 383, 90]; a black and gray png image of a png: [139, 0, 244, 80]; a gray shaped object on a black background: [0, 0, 142, 90]; a small brown and blue box with a blue roof: [186, 23, 62, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character with a sword\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego snowboard: [168, 22, 261, 182]; a white table: [0, 70, 382, 211]; shadow of the parking meter: [178, 143, 248, 187]; a snow covered tree branch: [146, 90, 189, 123]; the basket is brown: [110, 58, 179, 79]; snowboard on the ground: [104, 15, 299, 196]; the top of the cake is orange: [186, 23, 258, 76]; red section of the object: [226, 71, 256, 135]; stripes on the pole: [188, 72, 257, 140]; green and white stripes: [203, 76, 231, 140]; blue and red toy: [196, 120, 235, 173]; a black and white checkered pillow: [353, 62, 383, 91]; white wall in the background: [0, 1, 145, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 76, 383, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[140, 0, 243, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 80]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 143, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 66, 111, 25]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.73 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a person riding a bike: [0, 76, 383, 136]; a black and white image of a building with a black and white background: [140, 0, 243, 80]; a silhouette of a city with tall buildings: [2, 0, 381, 80]; a gray shaped piece of paper: [0, 0, 143, 90]; a gray slat with a black background: [0, 66, 111, 25]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character with a sword; Dense Caption: a lego snowboard: [168, 22, 261, 182]; a white table: [0, 70, 382, 211]; shadow of the parking meter: [178, 143, 248, 187]; a snow covered tree branch: [146, 90, 189, 123]; the basket is brown: [110, 58, 179, 79]; snowboard on the ground: [104, 15, 299, 196]; the top of the cake is orange: [186, 23, 258, 76]; red section of the object: [226, 71, 256, 135]; stripes on the pole: [188, 72, 257, 140]; green and white stripes: [203, 76, 231, 140]; blue and red toy: [196, 120, 235, 173]; a black and white checkered pillow: [353, 62, 383, 91]; white wall in the background: [0, 1, 145, 92]; ; Region Captions: a silhouette of a person riding a bike: [0, 76, 383, 136]; a black and white image of a building with a black and white background: [140, 0, 243, 80]; a silhouette of a city with tall buildings: [2, 0, 381, 80]; a gray shaped piece of paper: [0, 0, 143, 90]; a gray slat with a black background: [0, 66, 111, 25]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [34, 92, 350, 212]; a person walking through the snow: [128, 71, 154, 109]; shadow of the snowboarder: [99, 107, 187, 132]; the room is a bedroom: [0, 3, 381, 209]; the black basket on the table: [39, 83, 134, 109]; a black square object with white dots: [315, 85, 383, 120]; a brown wooden box: [147, 85, 187, 103]; the wall is white: [78, 1, 367, 99]; a bed in the room: [35, 18, 329, 149]; blue snow pants: [136, 93, 149, 107]; a lego person is on the snow: [101, 64, 182, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 102, 383, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 92, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[41, 88, 139, 20]\n",
      "process_ann took 0.00 seconds\n",
      "[41, 88, 95, 20]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a small white object is sitting on a snowy surface: [0, 102, 383, 110]; a man is standing in a room with a black background: [0, 0, 383, 112]; a gray shaped piece of paper: [0, 0, 92, 113]; a black block with a black arrow on it: [41, 88, 139, 20]; a black and white patterned bag with a black handle: [41, 88, 95, 20]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a box; Dense Caption: the ground is covered in snow: [34, 92, 350, 212]; a person walking through the snow: [128, 71, 154, 109]; shadow of the snowboarder: [99, 107, 187, 132]; the room is a bedroom: [0, 3, 381, 209]; the black basket on the table: [39, 83, 134, 109]; a black square object with white dots: [315, 85, 383, 120]; a brown wooden box: [147, 85, 187, 103]; the wall is white: [78, 1, 367, 99]; a bed in the room: [35, 18, 329, 149]; blue snow pants: [136, 93, 149, 107]; a lego person is on the snow: [101, 64, 182, 127]; ; Region Captions: a small white object is sitting on a snowy surface: [0, 102, 383, 110]; a man is standing in a room with a black background: [0, 0, 383, 112]; a gray shaped piece of paper: [0, 0, 92, 113]; a black block with a black arrow on it: [41, 88, 139, 20]; a black and white patterned bag with a black handle: [41, 88, 95, 20]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a person standing in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is made: [34, 92, 350, 212]; red yellow and blue lego item: [142, 72, 161, 105]; the basket is made of plastic: [39, 83, 138, 109]; shadow of object on bed: [97, 105, 187, 134]; the room is a bedroom: [0, 3, 381, 210]; a black and white pillow: [315, 85, 383, 120]; the wall is white: [59, 0, 361, 101]; a bed in the room: [36, 20, 328, 146]; red yellow and blue toy on a bed: [140, 73, 188, 105]; a toy on the bed: [129, 65, 194, 114]; the basket is brown: [156, 86, 187, 103]; a small object on the bed: [44, 50, 231, 154]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 96, 383, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 112]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 92, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[41, 88, 96, 20]\n",
      "process_ann took 0.00 seconds\n",
      "[317, 90, 66, 28]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.58 seconds\n",
      "finished...\n",
      "\n",
      "a small white object on a snowy surface: [0, 96, 383, 116]; a man is flying in the air above a building: [0, 0, 383, 112]; a gray shaped piece of paper: [0, 0, 92, 113]; a black and white striped bag with a black handle: [41, 88, 96, 20]; a black leather wallet with a black leather strap: [317, 90, 66, 28]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a person standing in it; Dense Caption: the bed is made: [34, 92, 350, 212]; red yellow and blue lego item: [142, 72, 161, 105]; the basket is made of plastic: [39, 83, 138, 109]; shadow of object on bed: [97, 105, 187, 134]; the room is a bedroom: [0, 3, 381, 210]; a black and white pillow: [315, 85, 383, 120]; the wall is white: [59, 0, 361, 101]; a bed in the room: [36, 20, 328, 146]; red yellow and blue toy on a bed: [140, 73, 188, 105]; a toy on the bed: [129, 65, 194, 114]; the basket is brown: [156, 86, 187, 103]; a small object on the bed: [44, 50, 231, 154]; ; Region Captions: a small white object on a snowy surface: [0, 96, 383, 116]; a man is flying in the air above a building: [0, 0, 383, 112]; a gray shaped piece of paper: [0, 0, 92, 113]; a black and white striped bag with a black handle: [41, 88, 96, 20]; a black leather wallet with a black leather strap: [317, 90, 66, 28]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "wooden box is brown: [105, 27, 215, 95]; yellow object in front of the cat: [0, 86, 150, 211]; a blue and yellow flag: [54, 1, 126, 96]; a white table top: [0, 14, 382, 209]; a gray circle on the ground: [79, 76, 126, 99]; black and white rug on the floor: [0, 20, 85, 88]; red ribbon on the pole: [64, 20, 117, 63]; blue plastic base of umbrella: [84, 59, 113, 93]; the chain is metallic: [105, 1, 127, 30]; the wooden box is brown: [48, 1, 224, 105]; the carpet is black and white: [0, 6, 130, 104]; the bed is white: [159, 104, 361, 209]; a toy on the floor: [17, 0, 227, 185]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 62, 383, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 126]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 29, 147, 184]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 89, 147, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[107, 31, 105, 62]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person walking down a hallway: [0, 62, 383, 150]; a black and white image of a wall with a light on it: [0, 0, 383, 126]; a yellow block with the word gold: [0, 29, 147, 184]; a yellow block on a black background: [0, 89, 147, 123]; a wooden block with a wooden block on top: [107, 31, 105, 62]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: wooden box is brown: [105, 27, 215, 95]; yellow object in front of the cat: [0, 86, 150, 211]; a blue and yellow flag: [54, 1, 126, 96]; a white table top: [0, 14, 382, 209]; a gray circle on the ground: [79, 76, 126, 99]; black and white rug on the floor: [0, 20, 85, 88]; red ribbon on the pole: [64, 20, 117, 63]; blue plastic base of umbrella: [84, 59, 113, 93]; the chain is metallic: [105, 1, 127, 30]; the wooden box is brown: [48, 1, 224, 105]; the carpet is black and white: [0, 6, 130, 104]; the bed is white: [159, 104, 361, 209]; a toy on the floor: [17, 0, 227, 185]; ; Region Captions: a black and white image of a person walking down a hallway: [0, 62, 383, 150]; a black and white image of a wall with a light on it: [0, 0, 383, 126]; a yellow block with the word gold: [0, 29, 147, 184]; a yellow block on a black background: [0, 89, 147, 123]; a wooden block with a wooden block on top: [107, 31, 105, 62]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in front of a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "square shaped dark box: [129, 53, 262, 106]; a large wooden box: [236, 69, 382, 211]; a lego is standing on a table: [0, 38, 64, 198]; red square of fabric: [0, 62, 62, 143]; the floor is white: [32, 58, 339, 213]; yellow paper on the table: [0, 188, 81, 212]; shadow of the umbrella: [47, 111, 123, 148]; a white wall in the background: [1, 1, 237, 78]; blue square on top of cake: [0, 132, 54, 192]; the remote is black: [95, 27, 286, 110]; the stickers on the top of the suitcase: [162, 55, 223, 71]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 79, 316, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 231, 79]\n",
      "process_ann took 0.00 seconds\n",
      "[240, 77, 143, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[230, 0, 153, 105]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.59 seconds\n",
      "finished...\n",
      "\n",
      "a white wall with a black door: [0, 0, 383, 104]; a white floor with a small table and a chair: [0, 79, 316, 133]; a gray square with a black background: [0, 0, 231, 79]; a wooden plank on a black background: [240, 77, 143, 135]; a gray wall with a black door: [230, 0, 153, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in front of a room; Dense Caption: square shaped dark box: [129, 53, 262, 106]; a large wooden box: [236, 69, 382, 211]; a lego is standing on a table: [0, 38, 64, 198]; red square of fabric: [0, 62, 62, 143]; the floor is white: [32, 58, 339, 213]; yellow paper on the table: [0, 188, 81, 212]; shadow of the umbrella: [47, 111, 123, 148]; a white wall in the background: [1, 1, 237, 78]; blue square on top of cake: [0, 132, 54, 192]; the remote is black: [95, 27, 286, 110]; the stickers on the top of the suitcase: [162, 55, 223, 71]; ; Region Captions: a white wall with a black door: [0, 0, 383, 104]; a white floor with a small table and a chair: [0, 79, 316, 133]; a gray square with a black background: [0, 0, 231, 79]; a wooden plank on a black background: [240, 77, 143, 135]; a gray wall with a black door: [230, 0, 153, 105]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a person standing next to a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and yellow towel: [105, 84, 238, 204]; a brown wooden box: [256, 71, 361, 136]; white bedspread on the bed: [0, 72, 381, 210]; a wooden chair: [68, 42, 130, 126]; a small wicker basket: [186, 63, 277, 96]; a yellow square on a cake: [163, 87, 223, 104]; a blue box on the floor: [106, 86, 172, 151]; a black bag on the bed: [50, 26, 159, 150]; a wooden bed frame: [70, 25, 349, 161]; a black object on the ground: [67, 84, 85, 107]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 82, 383, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 256, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[255, 0, 128, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[140, 102, 93, 100]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person riding a skateboard: [0, 82, 383, 130]; a black and white image of a room with a chair: [0, 0, 383, 153]; a gray building with a black sky: [0, 0, 256, 82]; a gun with a black handle: [255, 0, 128, 153]; a blue block in minecraft: [140, 102, 93, 100]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a person standing next to a block; Dense Caption: a blue and yellow towel: [105, 84, 238, 204]; a brown wooden box: [256, 71, 361, 136]; white bedspread on the bed: [0, 72, 381, 210]; a wooden chair: [68, 42, 130, 126]; a small wicker basket: [186, 63, 277, 96]; a yellow square on a cake: [163, 87, 223, 104]; a blue box on the floor: [106, 86, 172, 151]; a black bag on the bed: [50, 26, 159, 150]; a wooden bed frame: [70, 25, 349, 161]; a black object on the ground: [67, 84, 85, 107]; ; Region Captions: a black and white image of a person riding a skateboard: [0, 82, 383, 130]; a black and white image of a room with a chair: [0, 0, 383, 153]; a gray building with a black sky: [0, 0, 256, 82]; a gun with a black handle: [255, 0, 128, 153]; a blue block in minecraft: [140, 102, 93, 100]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a person standing next to a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and yellow box: [106, 84, 238, 204]; a brown wooden box: [256, 71, 361, 136]; white bedspread on the bed: [0, 72, 381, 210]; a black stuffed animal: [68, 43, 129, 126]; a stack of black boxes: [186, 63, 277, 96]; a black suitcase: [47, 30, 147, 148]; a yellow square on a cake: [163, 87, 223, 104]; a bed in a room: [69, 23, 349, 162]; a blue box on the floor: [106, 86, 172, 151]; a black camera: [68, 83, 87, 107]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 82, 383, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 256, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[255, 0, 128, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[140, 102, 93, 100]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a man is standing on a snowy hill: [0, 82, 383, 130]; a black and white image of a room with a chair: [0, 0, 383, 153]; a gray shaver with a black background: [0, 0, 256, 82]; a gun with a black handle: [255, 0, 128, 153]; a blue block in minecraft: [140, 102, 93, 100]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a person standing next to a block; Dense Caption: a blue and yellow box: [106, 84, 238, 204]; a brown wooden box: [256, 71, 361, 136]; white bedspread on the bed: [0, 72, 381, 210]; a black stuffed animal: [68, 43, 129, 126]; a stack of black boxes: [186, 63, 277, 96]; a black suitcase: [47, 30, 147, 148]; a yellow square on a cake: [163, 87, 223, 104]; a bed in a room: [69, 23, 349, 162]; a blue box on the floor: [106, 86, 172, 151]; a black camera: [68, 83, 87, 107]; ; Region Captions: a man is standing on a snowy hill: [0, 82, 383, 130]; a black and white image of a room with a chair: [0, 0, 383, 153]; a gray shaver with a black background: [0, 0, 256, 82]; a gun with a black handle: [255, 0, 128, 153]; a blue block in minecraft: [140, 102, 93, 100]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a blue block and a blue block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and yellow towel: [106, 84, 238, 204]; a brown wooden box: [256, 71, 361, 136]; white bedspread on the bed: [0, 73, 381, 210]; a small wooden chair: [79, 43, 130, 126]; a small wicker basket: [186, 63, 277, 96]; a yellow square on a cake: [163, 87, 223, 104]; a blue box on the table: [106, 86, 172, 151]; a black bag on the floor: [52, 26, 160, 149]; a bed in a room: [66, 23, 349, 174]; a small wicker basket: [0, 63, 34, 87]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 82, 383, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 256, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[255, 0, 128, 153]\n",
      "process_ann took 0.00 seconds\n",
      "[140, 102, 93, 100]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person walking down a snowy path: [0, 82, 383, 130]; a room with a black and white background: [0, 0, 383, 153]; a silhouette of a building with a black background: [0, 0, 256, 82]; a gun with a black handle: [255, 0, 128, 153]; a blue block in minecraft: [140, 102, 93, 100]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a blue block and a blue block; Dense Caption: a blue and yellow towel: [106, 84, 238, 204]; a brown wooden box: [256, 71, 361, 136]; white bedspread on the bed: [0, 73, 381, 210]; a small wooden chair: [79, 43, 130, 126]; a small wicker basket: [186, 63, 277, 96]; a yellow square on a cake: [163, 87, 223, 104]; a blue box on the table: [106, 86, 172, 151]; a black bag on the floor: [52, 26, 160, 149]; a bed in a room: [66, 23, 349, 174]; a small wicker basket: [0, 63, 34, 87]; ; Region Captions: a black and white image of a person walking down a snowy path: [0, 82, 383, 130]; a room with a black and white background: [0, 0, 383, 153]; a silhouette of a building with a black background: [0, 0, 256, 82]; a gun with a black handle: [255, 0, 128, 153]; a blue block in minecraft: [140, 102, 93, 100]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft table with blue and yellow blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and yellow towel: [90, 81, 227, 199]; the wooden box on the bed: [244, 68, 338, 127]; white bedspread on the bed: [0, 74, 381, 211]; the object is black: [102, 39, 146, 89]; the box is made of cardboard: [175, 60, 262, 91]; a lego with a suitcase: [63, 24, 250, 203]; a yellow square on a cake: [152, 84, 211, 101]; a blue paper back on a table: [90, 84, 159, 150]; the wall is white: [0, 1, 257, 81]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 79, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 242, 78]\n",
      "process_ann took 0.00 seconds\n",
      "[241, 0, 142, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[92, 87, 130, 108]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a skateboarder: [0, 79, 383, 133]; a black and white image of a room with a chair: [0, 0, 383, 155]; a black and white image of a city with a skyscraper: [0, 0, 242, 78]; a gun with a black background: [241, 0, 142, 155]; a blue and yellow block in minecraft: [92, 87, 130, 108]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft table with blue and yellow blocks; Dense Caption: a blue and yellow towel: [90, 81, 227, 199]; the wooden box on the bed: [244, 68, 338, 127]; white bedspread on the bed: [0, 74, 381, 211]; the object is black: [102, 39, 146, 89]; the box is made of cardboard: [175, 60, 262, 91]; a lego with a suitcase: [63, 24, 250, 203]; a yellow square on a cake: [152, 84, 211, 101]; a blue paper back on a table: [90, 84, 159, 150]; the wall is white: [0, 1, 257, 81]; ; Region Captions: a black and white image of a skateboarder: [0, 79, 383, 133]; a black and white image of a room with a chair: [0, 0, 383, 155]; a black and white image of a city with a skyscraper: [0, 0, 242, 78]; a gun with a black background: [241, 0, 142, 155]; a blue and yellow block in minecraft: [92, 87, 130, 108]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is standing in a room with blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "brown wooden box on white table: [305, 75, 382, 172]; a blue and yellow box: [95, 72, 223, 183]; the floor is white: [38, 40, 350, 212]; a red white and blue toy on a table: [26, 30, 109, 160]; a black square box: [228, 60, 348, 101]; a toy cow on a cake: [70, 98, 115, 129]; a white wall: [87, 0, 349, 80]; blue square on umbrella: [60, 116, 98, 157]; yellow square box: [154, 79, 219, 146]; shadow of a cake on the table: [49, 132, 112, 167]; a red piece of paper: [26, 69, 103, 124]; a small cardboard box: [43, 31, 100, 81]; a lego piece: [25, 32, 225, 181]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 66, 383, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[99, 0, 247, 77]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 105, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[107, 90, 85, 89]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.69 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a person standing in a room: [0, 66, 383, 146]; a black and white image of a room with a window: [0, 0, 383, 88]; a grey paper with the words i am a sailor: [99, 0, 247, 77]; a gray paper clip with a black background: [0, 0, 105, 75]; a blue block on a black background: [107, 90, 85, 89]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is standing in a room with blocks; Dense Caption: brown wooden box on white table: [305, 75, 382, 172]; a blue and yellow box: [95, 72, 223, 183]; the floor is white: [38, 40, 350, 212]; a red white and blue toy on a table: [26, 30, 109, 160]; a black square box: [228, 60, 348, 101]; a toy cow on a cake: [70, 98, 115, 129]; a white wall: [87, 0, 349, 80]; blue square on umbrella: [60, 116, 98, 157]; yellow square box: [154, 79, 219, 146]; shadow of a cake on the table: [49, 132, 112, 167]; a red piece of paper: [26, 69, 103, 124]; a small cardboard box: [43, 31, 100, 81]; a lego piece: [25, 32, 225, 181]; ; Region Captions: a black and white image of a person standing in a room: [0, 66, 383, 146]; a black and white image of a room with a window: [0, 0, 383, 88]; a grey paper with the words i am a sailor: [99, 0, 247, 77]; a gray paper clip with a black background: [0, 0, 105, 75]; a blue block on a black background: [107, 90, 85, 89]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing on a blue and yellow block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue box on the table: [117, 115, 236, 212]; the basket is made of cloth: [266, 84, 383, 139]; a blue and yellow box: [102, 57, 278, 212]; white tablecloth on the table: [0, 86, 383, 211]; yellow section of the cooler: [181, 107, 262, 197]; a green box on the table: [143, 54, 216, 120]; multi colored lego piece: [153, 1, 206, 57]; the back of the lego piece: [138, 55, 237, 181]; white bedspread: [1, 94, 119, 211]; white wall in the background: [0, 0, 139, 95]; the lego is blue: [140, 0, 218, 118]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 93, 383, 119]\n",
      "process_ann took 0.00 seconds\n",
      "[137, 0, 246, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[121, 59, 139, 153]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 0, 383, 101]; a black and white image of a minecraft map: [0, 2, 383, 210]; a person standing in a dark room: [0, 93, 383, 119]; a black and gray picture of a bottle: [137, 0, 246, 101]; a blue and yellow block in minecraft: [121, 59, 139, 153]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing on a blue and yellow block; Dense Caption: a blue box on the table: [117, 115, 236, 212]; the basket is made of cloth: [266, 84, 383, 139]; a blue and yellow box: [102, 57, 278, 212]; white tablecloth on the table: [0, 86, 383, 211]; yellow section of the cooler: [181, 107, 262, 197]; a green box on the table: [143, 54, 216, 120]; multi colored lego piece: [153, 1, 206, 57]; the back of the lego piece: [138, 55, 237, 181]; white bedspread: [1, 94, 119, 211]; white wall in the background: [0, 0, 139, 95]; the lego is blue: [140, 0, 218, 118]; ; Region Captions: a black and white image of a wall: [0, 0, 383, 101]; a black and white image of a minecraft map: [0, 2, 383, 210]; a person standing in a dark room: [0, 93, 383, 119]; a black and gray picture of a bottle: [137, 0, 246, 101]; a blue and yellow block in minecraft: [121, 59, 139, 153]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a yellow and blue floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "wooden box on the bed: [186, 31, 292, 103]; the basket is made of plastic: [87, 21, 200, 69]; blue and yellow bedspread: [10, 45, 243, 212]; a table with a white tablecloth: [3, 0, 377, 210]; yellow square on a blue and yellow cover: [16, 67, 170, 139]; a green and blue pillow: [0, 1, 58, 137]; the basket is on the bed: [37, 4, 206, 103]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[44, 52, 339, 161]\n",
      "process_ann took 0.00 seconds\n",
      "[147, 62, 236, 150]\n",
      "process_ann took 0.00 seconds\n",
      "[18, 0, 365, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 2, 239, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 105, 239, 107]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.54 seconds\n",
      "finished...\n",
      "\n",
      "a white stairway with a white railing: [44, 52, 339, 161]; a white arrow with a white background: [147, 62, 236, 150]; a room with a black wall and a lamp: [18, 0, 365, 142]; a blue square on a black background: [0, 2, 239, 210]; a blue tiled floor in minecraft: [0, 105, 239, 107]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a yellow and blue floor; Dense Caption: wooden box on the bed: [186, 31, 292, 103]; the basket is made of plastic: [87, 21, 200, 69]; blue and yellow bedspread: [10, 45, 243, 212]; a table with a white tablecloth: [3, 0, 377, 210]; yellow square on a blue and yellow cover: [16, 67, 170, 139]; a green and blue pillow: [0, 1, 58, 137]; the basket is on the bed: [37, 4, 206, 103]; ; Region Captions: a white stairway with a white railing: [44, 52, 339, 161]; a white arrow with a white background: [147, 62, 236, 150]; a room with a black wall and a lamp: [18, 0, 365, 142]; a blue square on a black background: [0, 2, 239, 210]; a blue tiled floor in minecraft: [0, 105, 239, 107]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a blue block in the middle\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue bag in the middle: [141, 63, 253, 174]; square pattern on square: [129, 31, 325, 100]; a large wooden box: [277, 66, 382, 212]; white table top: [0, 43, 381, 210]; a brown piece of paper: [20, 109, 122, 164]; the stickers on the mattress: [179, 34, 259, 51]; a checkered table cloth: [116, 21, 332, 179]; a brown piece of paper: [10, 93, 130, 186]; a sticker on the bed: [164, 28, 271, 63]; the wall is white: [1, 1, 381, 67]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 57, 342, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 269, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[283, 72, 100, 141]\n",
      "process_ann took 0.00 seconds\n",
      "[148, 69, 100, 98]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a minecraft floor: [0, 57, 342, 155]; a black and white image of a room with a black wall: [0, 0, 383, 74]; a grey png file with a black background: [0, 0, 269, 57]; a wooden plank on a black background: [283, 72, 100, 141]; a blue block with a blue background: [148, 69, 100, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a blue block in the middle; Dense Caption: a blue bag in the middle: [141, 63, 253, 174]; square pattern on square: [129, 31, 325, 100]; a large wooden box: [277, 66, 382, 212]; white table top: [0, 43, 381, 210]; a brown piece of paper: [20, 109, 122, 164]; the stickers on the mattress: [179, 34, 259, 51]; a checkered table cloth: [116, 21, 332, 179]; a brown piece of paper: [10, 93, 130, 186]; a sticker on the bed: [164, 28, 271, 63]; the wall is white: [1, 1, 381, 67]; ; Region Captions: a black and white image of a minecraft floor: [0, 57, 342, 155]; a black and white image of a room with a black wall: [0, 0, 383, 74]; a grey png file with a black background: [0, 0, 269, 57]; a wooden plank on a black background: [283, 72, 100, 141]; a blue block with a blue background: [148, 69, 100, 98]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue and white minecraft block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue colored box: [132, 69, 254, 200]; the room is a bedroom: [1, 8, 382, 209]; a black and white checkered box: [279, 48, 383, 191]; a green and black box: [0, 1, 77, 201]; a brown wicker basket: [115, 24, 175, 48]; the wall is white: [112, 1, 345, 81]; the green portion of the umbrella: [0, 0, 46, 98]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 43, 364, 169]\n",
      "process_ann took 0.00 seconds\n",
      "[14, 0, 369, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[155, 0, 228, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 74, 116, 124]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 71, 194]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a door: [0, 43, 364, 169]; a gray wall with a black door: [14, 0, 369, 75]; a grey box with a white arrow on it: [155, 0, 228, 75]; a blue block in minecraft: [135, 74, 116, 124]; a blue pixelated image of a minecraft ice block: [0, 1, 71, 194]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue and white minecraft block; Dense Caption: a blue colored box: [132, 69, 254, 200]; the room is a bedroom: [1, 8, 382, 209]; a black and white checkered box: [279, 48, 383, 191]; a green and black box: [0, 1, 77, 201]; a brown wicker basket: [115, 24, 175, 48]; the wall is white: [112, 1, 345, 81]; the green portion of the umbrella: [0, 0, 46, 98]; ; Region Captions: a white and black image of a door: [0, 43, 364, 169]; a gray wall with a black door: [14, 0, 369, 75]; a grey box with a white arrow on it: [155, 0, 228, 75]; a blue block in minecraft: [135, 74, 116, 124]; a blue pixelated image of a minecraft ice block: [0, 1, 71, 194]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person is standing next to a bunch of blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "table is cover with blue tablecloth: [0, 16, 382, 209]; a blue and green box: [240, 99, 382, 211]; lego red blue and yellow plush toy: [0, 18, 99, 158]; the pillows are blue and yellow: [100, 21, 284, 141]; yellow throw pillow on floor: [101, 68, 171, 141]; the table is covered by a white tablecloth: [38, 92, 354, 211]; a blue and green striped box: [24, 158, 200, 212]; shadow of umbrella on floor: [32, 126, 103, 166]; the backrest of the empty chair: [204, 23, 283, 133]; the top of the lego house: [0, 20, 72, 114]; a black and white checkered floor: [68, 50, 112, 75]; blue square on a cake: [166, 77, 206, 124]; blue and red striped box: [37, 106, 87, 155]; black and white stripes: [0, 57, 51, 113]; the wall is white: [15, 0, 244, 65]; blue colored wooden bench: [145, 25, 208, 130]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 63, 383, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[243, 103, 140, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 238, 65]\n",
      "process_ann took 0.00 seconds\n",
      "[149, 26, 131, 106]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man standing in a room: [0, 63, 383, 149]; a silhouette of a city with a black background: [0, 0, 383, 69]; a blue block in minecraft: [243, 103, 140, 110]; a black and white image of a building: [2, 0, 238, 65]; a yellow and blue block in minecraft: [149, 26, 131, 106]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person is standing next to a bunch of blocks; Dense Caption: table is cover with blue tablecloth: [0, 16, 382, 209]; a blue and green box: [240, 99, 382, 211]; lego red blue and yellow plush toy: [0, 18, 99, 158]; the pillows are blue and yellow: [100, 21, 284, 141]; yellow throw pillow on floor: [101, 68, 171, 141]; the table is covered by a white tablecloth: [38, 92, 354, 211]; a blue and green striped box: [24, 158, 200, 212]; shadow of umbrella on floor: [32, 126, 103, 166]; the backrest of the empty chair: [204, 23, 283, 133]; the top of the lego house: [0, 20, 72, 114]; a black and white checkered floor: [68, 50, 112, 75]; blue square on a cake: [166, 77, 206, 124]; blue and red striped box: [37, 106, 87, 155]; black and white stripes: [0, 57, 51, 113]; the wall is white: [15, 0, 244, 65]; blue colored wooden bench: [145, 25, 208, 130]; ; Region Captions: a black and white image of a man standing in a room: [0, 63, 383, 149]; a silhouette of a city with a black background: [0, 0, 383, 69]; a blue block in minecraft: [243, 103, 140, 110]; a black and white image of a building: [2, 0, 238, 65]; a yellow and blue block in minecraft: [149, 26, 131, 106]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with blue and yellow blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "blue and yellow box next to blue and yellow fabric: [99, 21, 283, 141]; lego ice cream colored table: [0, 25, 381, 212]; a blue and green box: [240, 99, 382, 211]; the basket is brown: [19, 49, 112, 81]; a blue and green striped box: [24, 157, 200, 212]; yellow and blue square: [100, 69, 171, 141]; the backrest of the seat: [204, 23, 283, 133]; the chair is blue and yellow: [53, 23, 213, 172]; the table is covered by a white tablecloth: [40, 103, 357, 211]; blue square on the small green box: [166, 77, 206, 124]; blue and green square boxes: [144, 26, 208, 131]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 63, 383, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 66, 260, 146]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[243, 103, 140, 110]\n",
      "process_ann took 0.00 seconds\n",
      "[84, 103, 299, 109]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.55 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a w: [0, 63, 383, 149]; a white and black image of a skeleton: [0, 66, 260, 146]; a black silhouette of a person in a room: [0, 0, 383, 95]; a blue block in minecraft: [243, 103, 140, 110]; a blue block in minecraft: [84, 103, 299, 109]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with blue and yellow blocks; Dense Caption: blue and yellow box next to blue and yellow fabric: [99, 21, 283, 141]; lego ice cream colored table: [0, 25, 381, 212]; a blue and green box: [240, 99, 382, 211]; the basket is brown: [19, 49, 112, 81]; a blue and green striped box: [24, 157, 200, 212]; yellow and blue square: [100, 69, 171, 141]; the backrest of the seat: [204, 23, 283, 133]; the chair is blue and yellow: [53, 23, 213, 172]; the table is covered by a white tablecloth: [40, 103, 357, 211]; blue square on the small green box: [166, 77, 206, 124]; blue and green square boxes: [144, 26, 208, 131]; ; Region Captions: a white and black image of a w: [0, 63, 383, 149]; a white and black image of a skeleton: [0, 66, 260, 146]; a black silhouette of a person in a room: [0, 0, 383, 95]; a blue block in minecraft: [243, 103, 140, 110]; a blue block in minecraft: [84, 103, 299, 109]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is sitting on a wooden table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden box: [1, 117, 319, 211]; a stack of boxes: [297, 58, 382, 212]; the sky is clear: [17, 7, 276, 186]; blue square on the umbrella: [310, 153, 367, 211]; black stripes on the flag: [299, 90, 335, 149]; a wall on the side of a building: [90, 39, 362, 210]; yellow and blue stripes: [309, 59, 382, 111]; blue and white stripes: [314, 74, 360, 95]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 382, 208]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 374, 116]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 124, 317, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 154, 171, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[304, 62, 79, 64]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a lamp: [0, 0, 382, 208]; a gray arrow with the word 'fall': [0, 0, 374, 116]; a wooden plank with a wooden texture: [0, 124, 317, 89]; a wooden plank with a wooden texture: [0, 154, 171, 59]; a minecraft head with a blue eye: [304, 62, 79, 64]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is sitting on a wooden table; Dense Caption: a large wooden box: [1, 117, 319, 211]; a stack of boxes: [297, 58, 382, 212]; the sky is clear: [17, 7, 276, 186]; blue square on the umbrella: [310, 153, 367, 211]; black stripes on the flag: [299, 90, 335, 149]; a wall on the side of a building: [90, 39, 362, 210]; yellow and blue stripes: [309, 59, 382, 111]; blue and white stripes: [314, 74, 360, 95]; ; Region Captions: a black and white image of a room with a lamp: [0, 0, 382, 208]; a gray arrow with the word 'fall': [0, 0, 374, 116]; a wooden plank with a wooden texture: [0, 124, 317, 89]; a wooden plank with a wooden texture: [0, 154, 171, 59]; a minecraft head with a blue eye: [304, 62, 79, 64]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a man is standing on a blue and yellow block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and green striped pillow: [172, 136, 381, 212]; white tablecloth on table: [0, 71, 382, 210]; yellow square on the right: [66, 93, 148, 167]; a blue and yellow gift bag: [48, 7, 301, 175]; a blue square pillow: [237, 97, 322, 153]; a brown wicker basket: [286, 69, 360, 92]; a blue colored box: [172, 51, 221, 134]; a yellow and blue tag: [160, 5, 195, 42]; red square of a flag: [163, 28, 187, 69]; a red and blue flag: [159, 17, 193, 112]; the chair is yellow: [39, 71, 168, 177]; white wall in the background: [1, 1, 159, 93]; blue square on the back of the cake: [108, 50, 171, 141]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 81, 383, 131]\n",
      "process_ann took 0.00 seconds\n",
      "[156, 0, 198, 81]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 157, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[173, 138, 210, 75]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.52 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a man with a knife: [0, 0, 383, 97]; a black and white image of a city: [0, 81, 383, 131]; a black and white image of a trophy: [156, 0, 198, 81]; a gray piece of paper with a black background: [0, 0, 157, 92]; a blue square with a black background: [173, 138, 210, 75]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a man is standing on a blue and yellow block; Dense Caption: a blue and green striped pillow: [172, 136, 381, 212]; white tablecloth on table: [0, 71, 382, 210]; yellow square on the right: [66, 93, 148, 167]; a blue and yellow gift bag: [48, 7, 301, 175]; a blue square pillow: [237, 97, 322, 153]; a brown wicker basket: [286, 69, 360, 92]; a blue colored box: [172, 51, 221, 134]; a yellow and blue tag: [160, 5, 195, 42]; red square of a flag: [163, 28, 187, 69]; a red and blue flag: [159, 17, 193, 112]; the chair is yellow: [39, 71, 168, 177]; white wall in the background: [1, 1, 159, 93]; blue square on the back of the cake: [108, 50, 171, 141]; ; Region Captions: a silhouette of a man with a knife: [0, 0, 383, 97]; a black and white image of a city: [0, 81, 383, 131]; a black and white image of a trophy: [156, 0, 198, 81]; a gray piece of paper with a black background: [0, 0, 157, 92]; a blue square with a black background: [173, 138, 210, 75]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210428_170427 23\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is standing next to another person\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a toy train with lights: [106, 176, 275, 211]; a row of stop signs: [1, 1, 241, 211]; the sign is red: [9, 65, 142, 210]; a green building: [249, 153, 382, 212]; the green and white box on the right: [162, 50, 250, 176]; yellow traffic sign with black writing: [2, 1, 224, 83]; a black object on the ground: [208, 22, 263, 48]; red and white lights: [102, 172, 277, 195]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 43, 383, 169]\n",
      "process_ann took 0.00 seconds\n",
      "[202, 43, 181, 156]\n",
      "process_ann took 0.00 seconds\n",
      "[109, 43, 274, 157]\n",
      "process_ann took 0.00 seconds\n",
      "[10, 65, 125, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[211, 0, 172, 59]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a white and black image of a man with a knife: [0, 43, 383, 169]; a white sled with a white sled: [202, 43, 181, 156]; a white teddy bear with a white hat: [109, 43, 274, 157]; a red book with a black background: [10, 65, 125, 142]; a white sheet of paper with the word'save': [211, 0, 172, 59]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is standing next to another person; Dense Caption: a toy train with lights: [106, 176, 275, 211]; a row of stop signs: [1, 1, 241, 211]; the sign is red: [9, 65, 142, 210]; a green building: [249, 153, 382, 212]; the green and white box on the right: [162, 50, 250, 176]; yellow traffic sign with black writing: [2, 1, 224, 83]; a black object on the ground: [208, 22, 263, 48]; red and white lights: [102, 172, 277, 195]; ; Region Captions: a white and black image of a man with a knife: [0, 43, 383, 169]; a white sled with a white sled: [202, 43, 181, 156]; a white teddy bear with a white hat: [109, 43, 274, 157]; a red book with a black background: [10, 65, 125, 142]; a white sheet of paper with the word'save': [211, 0, 172, 59]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a man jumping on the snow\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and red striped object: [230, 0, 279, 21]; a snowy white field: [0, 1, 382, 211]; the snowboarder is casting a shadow: [232, 20, 264, 36]; the snow is white: [37, 38, 262, 194]; the object in the background is brown: [282, 0, 382, 19]; snowboarder doing a trick: [216, 0, 289, 45]; the snow is white: [128, 59, 343, 203]; the snow is white: [101, 71, 204, 156]; snow covering the ground: [90, 44, 196, 129]; shadow of the snowboarder: [227, 14, 271, 42]; the snow is white: [156, 50, 256, 128]; the snow is white: [182, 74, 287, 156]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 18]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 164, 18]\n",
      "process_ann took 0.00 seconds\n",
      "[233, 0, 150, 17]\n",
      "process_ann took 0.00 seconds\n",
      "[284, 0, 99, 17]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.65 seconds\n",
      "finished...\n",
      "\n",
      "a snowy area with a black cat on it: [0, 2, 383, 210]; a black and white picture of a man with a hat: [0, 0, 383, 18]; a black and white image of a triangle: [0, 0, 164, 18]; a wooden door with a red light on it: [233, 0, 150, 17]; a brown wooden plank on a black background: [284, 0, 99, 17]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a man jumping on the snow; Dense Caption: a blue and red striped object: [230, 0, 279, 21]; a snowy white field: [0, 1, 382, 211]; the snowboarder is casting a shadow: [232, 20, 264, 36]; the snow is white: [37, 38, 262, 194]; the object in the background is brown: [282, 0, 382, 19]; snowboarder doing a trick: [216, 0, 289, 45]; the snow is white: [128, 59, 343, 203]; the snow is white: [101, 71, 204, 156]; snow covering the ground: [90, 44, 196, 129]; shadow of the snowboarder: [227, 14, 271, 42]; the snow is white: [156, 50, 256, 128]; the snow is white: [182, 74, 287, 156]; ; Region Captions: a snowy area with a black cat on it: [0, 2, 383, 210]; a black and white picture of a man with a hat: [0, 0, 383, 18]; a black and white image of a triangle: [0, 0, 164, 18]; a wooden door with a red light on it: [233, 0, 150, 17]; a brown wooden plank on a black background: [284, 0, 99, 17]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft map with a blue pole in the snow\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a snowy white field: [0, 1, 382, 211]; blue post on the sidewalk: [158, 0, 180, 22]; the basket is brown: [281, 0, 383, 19]; snow is white and smooth: [36, 42, 266, 196]; a blue and red fire hydrant: [152, 0, 186, 27]; snow covering the ground: [153, 56, 260, 138]; snow covering the ground: [192, 55, 296, 139]; snow covering the ground: [174, 41, 277, 118]; snow is white and smooth: [128, 57, 343, 204]; base of the hydrant: [157, 14, 183, 25]; snow on the ground: [172, 72, 279, 157]; the snow is white: [101, 73, 204, 155]; snow covering the ground: [145, 81, 250, 166]; a bush on the hill: [199, 0, 275, 8]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 18]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 154, 18]\n",
      "process_ann took 0.00 seconds\n",
      "[209, 0, 174, 17]\n",
      "process_ann took 0.00 seconds\n",
      "[283, 0, 100, 17]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.66 seconds\n",
      "finished...\n",
      "\n",
      "a snowy field with a tree in the middle: [0, 1, 383, 211]; a black and white picture of a man with a hat: [0, 0, 383, 18]; a black and white image of a black and white image: [0, 0, 154, 18]; a wooden door with a black background: [209, 0, 174, 17]; a wooden plank on a black background: [283, 0, 100, 17]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft map with a blue pole in the snow; Dense Caption: a snowy white field: [0, 1, 382, 211]; blue post on the sidewalk: [158, 0, 180, 22]; the basket is brown: [281, 0, 383, 19]; snow is white and smooth: [36, 42, 266, 196]; a blue and red fire hydrant: [152, 0, 186, 27]; snow covering the ground: [153, 56, 260, 138]; snow covering the ground: [192, 55, 296, 139]; snow covering the ground: [174, 41, 277, 118]; snow is white and smooth: [128, 57, 343, 204]; base of the hydrant: [157, 14, 183, 25]; snow on the ground: [172, 72, 279, 157]; the snow is white: [101, 73, 204, 155]; snow covering the ground: [145, 81, 250, 166]; a bush on the hill: [199, 0, 275, 8]; ; Region Captions: a snowy field with a tree in the middle: [0, 1, 383, 211]; a black and white picture of a man with a hat: [0, 0, 383, 18]; a black and white image of a black and white image: [0, 0, 154, 18]; a wooden door with a black background: [209, 0, 174, 17]; a wooden plank on a black background: [283, 0, 100, 17]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two wooden blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden box: [41, 71, 277, 160]; white snow on the ground: [33, 113, 352, 212]; a square shaped object: [0, 70, 56, 143]; the sky is dark: [0, 1, 381, 135]; a line on a bench: [175, 80, 212, 144]; the keyboard is brown: [3, 46, 310, 207]; the sky is cloudy: [40, 3, 341, 78]; the box is made of cardboard: [110, 81, 250, 147]; a line of rivets in the wood: [109, 79, 156, 139]; the sky is cloudy: [103, 29, 237, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 121, 383, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[45, 80, 227, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 78, 52, 61]\n",
      "process_ann took 0.00 seconds\n",
      "[45, 81, 68, 58]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.51 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a mountain: [0, 1, 383, 133]; a white and black image of a floor: [0, 121, 383, 91]; a stack of wooden blocks on a black background: [45, 80, 227, 73]; a black and white textured block: [0, 78, 52, 61]; a wooden block with a brown background: [45, 81, 68, 58]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two wooden blocks; Dense Caption: a large wooden box: [41, 71, 277, 160]; white snow on the ground: [33, 113, 352, 212]; a square shaped object: [0, 70, 56, 143]; the sky is dark: [0, 1, 381, 135]; a line on a bench: [175, 80, 212, 144]; the keyboard is brown: [3, 46, 310, 207]; the sky is cloudy: [40, 3, 341, 78]; the box is made of cardboard: [110, 81, 250, 147]; a line of rivets in the wood: [109, 79, 156, 139]; the sky is cloudy: [103, 29, 237, 74]; ; Region Captions: a black and white image of a mountain: [0, 1, 383, 133]; a white and black image of a floor: [0, 121, 383, 91]; a stack of wooden blocks on a black background: [45, 80, 227, 73]; a black and white textured block: [0, 78, 52, 61]; a wooden block with a brown background: [45, 81, 68, 58]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden table and chairs\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [96, 116, 235, 168]; white blanket on the bed: [0, 146, 383, 211]; a box on the table: [0, 111, 97, 182]; the wall is white: [39, 1, 355, 157]; white window frame: [0, 0, 21, 119]; the box is brown: [37, 98, 243, 188]; white bedspread on bed: [242, 154, 362, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[12, 0, 371, 162]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 147, 383, 65]\n",
      "process_ann took 0.00 seconds\n",
      "[98, 121, 133, 45]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 119, 95, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 15, 118]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.78 seconds\n",
      "finished...\n",
      "\n",
      "a black and gray png image of a black and gray png image: [12, 0, 371, 162]; a white png image of a white png: [0, 147, 383, 65]; a stack of brown blocks on a black background: [98, 121, 133, 45]; a black and white block of stone: [0, 119, 95, 59]; a grey teddy bear is standing on a black background: [0, 0, 15, 118]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden table and chairs; Dense Caption: the box is brown: [96, 116, 235, 168]; white blanket on the bed: [0, 146, 383, 211]; a box on the table: [0, 111, 97, 182]; the wall is white: [39, 1, 355, 157]; white window frame: [0, 0, 21, 119]; the box is brown: [37, 98, 243, 188]; white bedspread on bed: [242, 154, 362, 210]; ; Region Captions: a black and gray png image of a black and gray png image: [12, 0, 371, 162]; a white png image of a white png: [0, 147, 383, 65]; a stack of brown blocks on a black background: [98, 121, 133, 45]; a black and white block of stone: [0, 119, 95, 59]; a grey teddy bear is standing on a black background: [0, 0, 15, 118]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in front of a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown box: [255, 76, 382, 134]; square shaped fabric: [174, 70, 261, 103]; white bedspread on the bed: [38, 88, 351, 210]; lego person holding a yellow bucket: [139, 55, 170, 111]; red shirt on the toothbrush: [147, 71, 164, 92]; a lego person is holding a bucket: [145, 62, 164, 107]; a bedroom: [52, 13, 348, 164]; yellow and blue cap: [142, 57, 165, 76]; a green toy: [164, 74, 177, 93]; the wall is white: [0, 1, 381, 100]; two wooden baskets: [158, 59, 371, 141]; blue plastic cup: [147, 89, 161, 107]; lego person looking at wall: [129, 49, 180, 118]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 92, 383, 120]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 227, 97]\n",
      "process_ann took 0.00 seconds\n",
      "[227, 0, 156, 91]\n",
      "process_ann took 0.00 seconds\n",
      "[230, 0, 153, 62]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a white floor with a black cat on it: [0, 92, 383, 120]; a person standing in a room with a wall: [0, 0, 383, 97]; a man is standing on a gray background: [0, 0, 227, 97]; a gray t shirt with a black background: [227, 0, 156, 91]; a gray hat with a black hat: [230, 0, 153, 62]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in front of a room; Dense Caption: a brown box: [255, 76, 382, 134]; square shaped fabric: [174, 70, 261, 103]; white bedspread on the bed: [38, 88, 351, 210]; lego person holding a yellow bucket: [139, 55, 170, 111]; red shirt on the toothbrush: [147, 71, 164, 92]; a lego person is holding a bucket: [145, 62, 164, 107]; a bedroom: [52, 13, 348, 164]; yellow and blue cap: [142, 57, 165, 76]; a green toy: [164, 74, 177, 93]; the wall is white: [0, 1, 381, 100]; two wooden baskets: [158, 59, 371, 141]; blue plastic cup: [147, 89, 161, 107]; lego person looking at wall: [129, 49, 180, 118]; ; Region Captions: a white floor with a black cat on it: [0, 92, 383, 120]; a person standing in a room with a wall: [0, 0, 383, 97]; a man is standing on a gray background: [0, 0, 227, 97]; a gray t shirt with a black background: [227, 0, 156, 91]; a gray hat with a black hat: [230, 0, 153, 62]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in front of a box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "square shaped cloth: [147, 22, 262, 80]; a lego figure: [235, 1, 337, 119]; white table top: [0, 38, 382, 211]; blue x on the brown wooden bench: [308, 45, 338, 89]; red and black stripes: [255, 27, 307, 83]; shadow of the object: [235, 89, 288, 118]; blue plastic base of the umbrella: [249, 66, 281, 110]; wooden box is brown: [297, 35, 383, 115]; a lego snowboard: [155, 0, 350, 142]; yellow and blue sign: [262, 0, 325, 34]; blue diamond on a yellow sign: [276, 0, 303, 28]; the snow is white: [39, 97, 254, 208]; white wall in the background: [1, 1, 228, 65]; a red and blue umbrella: [233, 17, 289, 119]; the basket is brown: [123, 6, 294, 90]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 54, 383, 158]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 224, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[298, 40, 85, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[149, 27, 148, 64]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a 3d image of a white floor with a black object: [0, 54, 383, 158]; a black and white image of a room with a black cat: [0, 0, 383, 62]; a grey png file with a black background: [0, 0, 224, 62]; a minecraft png of a wooden plank: [298, 40, 85, 76]; a black block with a blue square on it: [149, 27, 148, 64]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in front of a box; Dense Caption: square shaped cloth: [147, 22, 262, 80]; a lego figure: [235, 1, 337, 119]; white table top: [0, 38, 382, 211]; blue x on the brown wooden bench: [308, 45, 338, 89]; red and black stripes: [255, 27, 307, 83]; shadow of the object: [235, 89, 288, 118]; blue plastic base of the umbrella: [249, 66, 281, 110]; wooden box is brown: [297, 35, 383, 115]; a lego snowboard: [155, 0, 350, 142]; yellow and blue sign: [262, 0, 325, 34]; blue diamond on a yellow sign: [276, 0, 303, 28]; the snow is white: [39, 97, 254, 208]; white wall in the background: [1, 1, 228, 65]; a red and blue umbrella: [233, 17, 289, 119]; the basket is brown: [123, 6, 294, 90]; ; Region Captions: a 3d image of a white floor with a black object: [0, 54, 383, 158]; a black and white image of a room with a black cat: [0, 0, 383, 62]; a grey png file with a black background: [0, 0, 224, 62]; a minecraft png of a wooden plank: [298, 40, 85, 76]; a black block with a blue square on it: [149, 27, 148, 64]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden table and a wooden chair\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is brown: [138, 85, 372, 185]; white bedding on the bed: [29, 105, 348, 212]; a bed in a room: [0, 10, 382, 205]; the blanket is checkered: [0, 79, 138, 187]; white pillow on bed: [0, 0, 56, 93]; the wall is white: [41, 1, 353, 89]; the wall is white: [93, 30, 367, 147]; the bed is white: [69, 154, 168, 209]; the mattress is big in size: [220, 101, 305, 163]; a white wall: [185, 48, 317, 91]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 157]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 122, 383, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[140, 93, 241, 89]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 87, 135, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 51, 88]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a 3d model of a wall with a black background: [0, 0, 383, 157]; a white triangle with a black background: [0, 122, 383, 90]; a wooden block in minecraft: [140, 93, 241, 89]; a black and white image of a block of ice: [0, 87, 135, 96]; a gray shaped object on a black background: [0, 0, 51, 88]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden table and a wooden chair; Dense Caption: the box is brown: [138, 85, 372, 185]; white bedding on the bed: [29, 105, 348, 212]; a bed in a room: [0, 10, 382, 205]; the blanket is checkered: [0, 79, 138, 187]; white pillow on bed: [0, 0, 56, 93]; the wall is white: [41, 1, 353, 89]; the wall is white: [93, 30, 367, 147]; the bed is white: [69, 154, 168, 209]; the mattress is big in size: [220, 101, 305, 163]; a white wall: [185, 48, 317, 91]; ; Region Captions: a 3d model of a wall with a black background: [0, 0, 383, 157]; a white triangle with a black background: [0, 122, 383, 90]; a wooden block in minecraft: [140, 93, 241, 89]; a black and white image of a block of ice: [0, 87, 135, 96]; a gray shaped object on a black background: [0, 0, 51, 88]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft window with a light shining through it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the sign is yellow: [140, 54, 356, 213]; the building is tall: [19, 1, 382, 211]; a white wall: [0, 0, 146, 211]; the building has a window: [168, 134, 265, 210]; the light is yellow: [176, 81, 303, 205]; the building is made of bricks: [56, 50, 203, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 146, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[190, 77, 102, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[162, 142, 91, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[141, 177, 81, 36]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a black and white tv: [0, 0, 383, 212]; a grey triangle with a black background: [0, 0, 146, 212]; a brown and white pixelated blanket: [190, 77, 102, 94]; a brown and white square pattern on a black background: [162, 142, 91, 71]; a black and white triangle with a black and white pattern: [141, 177, 81, 36]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft window with a light shining through it; Dense Caption: the sign is yellow: [140, 54, 356, 213]; the building is tall: [19, 1, 382, 211]; a white wall: [0, 0, 146, 211]; the building has a window: [168, 134, 265, 210]; the light is yellow: [176, 81, 303, 205]; the building is made of bricks: [56, 50, 203, 210]; ; Region Captions: a black and white image of a black and white tv: [0, 0, 383, 212]; a grey triangle with a black background: [0, 0, 146, 212]; a brown and white pixelated blanket: [190, 77, 102, 94]; a brown and white square pattern on a black background: [162, 142, 91, 71]; a black and white triangle with a black and white pattern: [141, 177, 81, 36]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a white floor and some blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a bed in a room: [1, 32, 338, 211]; the keyboard is black: [1, 125, 166, 212]; a small box on the side of the bed: [265, 39, 336, 69]; the bed is made of sheets: [141, 61, 323, 206]; the bed is made: [25, 33, 274, 153]; the snow is white in color: [149, 71, 263, 158]; the wall is white: [33, 0, 341, 78]; the snow is white: [142, 97, 241, 182]; a small basket on the bed: [134, 30, 181, 48]; the snow is white in color: [102, 65, 209, 140]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 45, 331, 167]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 352, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[330, 0, 53, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 129, 165, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[156, 0, 197, 51]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a white arrow with a white background: [0, 45, 331, 167]; a gray wall with a door in the middle: [0, 0, 352, 59]; a grey metal box with a white arrow on it: [330, 0, 53, 212]; a black and white triangle with a black background: [0, 129, 165, 84]; a grey png file with a black background: [156, 0, 197, 51]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a white floor and some blocks; Dense Caption: a bed in a room: [1, 32, 338, 211]; the keyboard is black: [1, 125, 166, 212]; a small box on the side of the bed: [265, 39, 336, 69]; the bed is made of sheets: [141, 61, 323, 206]; the bed is made: [25, 33, 274, 153]; the snow is white in color: [149, 71, 263, 158]; the wall is white: [33, 0, 341, 78]; the snow is white: [142, 97, 241, 182]; a small basket on the bed: [134, 30, 181, 48]; the snow is white in color: [102, 65, 209, 140]; ; Region Captions: a white arrow with a white background: [0, 45, 331, 167]; a gray wall with a door in the middle: [0, 0, 352, 59]; a grey metal box with a white arrow on it: [330, 0, 53, 212]; a black and white triangle with a black background: [0, 129, 165, 84]; a grey png file with a black background: [156, 0, 197, 51]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden table with a wooden top\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bench is made of wood: [24, 100, 324, 211]; the sky is grey: [36, 3, 342, 114]; the sky is blue: [0, 2, 381, 212]; a line on a sign: [182, 104, 225, 198]; a piece of white paper: [324, 130, 382, 211]; a line of squares on the bench: [116, 106, 221, 200]; a line of slats of a bench: [215, 99, 294, 193]; the sky is clear: [263, 126, 382, 212]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 104, 329, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[162, 129, 221, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[6, 186, 317, 27]\n",
      "process_ann took 0.00 seconds\n",
      "[117, 186, 205, 26]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.71 seconds\n",
      "finished...\n",
      "\n",
      "a grey and black image of a sandbox: [0, 1, 383, 132]; a wooden floor with brown stripes: [0, 104, 329, 108]; a skateboarder is riding a skateboard on a black surface: [162, 129, 221, 84]; a wooden sword with a black background: [6, 186, 317, 27]; a brown wooden plank on a black background: [117, 186, 205, 26]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden table with a wooden top; Dense Caption: the bench is made of wood: [24, 100, 324, 211]; the sky is grey: [36, 3, 342, 114]; the sky is blue: [0, 2, 381, 212]; a line on a sign: [182, 104, 225, 198]; a piece of white paper: [324, 130, 382, 211]; a line of squares on the bench: [116, 106, 221, 200]; a line of slats of a bench: [215, 99, 294, 193]; the sky is clear: [263, 126, 382, 212]; ; Region Captions: a grey and black image of a sandbox: [0, 1, 383, 132]; a wooden floor with brown stripes: [0, 104, 329, 108]; a skateboarder is riding a skateboard on a black surface: [162, 129, 221, 84]; a wooden sword with a black background: [6, 186, 317, 27]; a brown wooden plank on a black background: [117, 186, 205, 26]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person is standing next to a block of wood\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and white box: [79, 82, 192, 199]; a brown box: [205, 54, 359, 148]; white table cloth on the table: [0, 58, 381, 210]; legos on the floor: [119, 31, 218, 88]; lego man is holding a surfboard: [161, 31, 197, 87]; the top of the box is blue: [85, 85, 185, 122]; the boxes are brown: [84, 23, 357, 168]; red and blue candle: [165, 47, 187, 86]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 73, 383, 139]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 156]\n",
      "process_ann took 0.00 seconds\n",
      "[194, 0, 189, 157]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 190, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 381, 77]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building: [0, 73, 383, 139]; a black and white image of a room with a chair: [0, 0, 383, 156]; a gray png image of a gun: [194, 0, 189, 157]; a black and white image of a man with a hat: [0, 0, 190, 76]; a black and white image of a png file: [0, 0, 381, 77]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person is standing next to a block of wood; Dense Caption: a blue and white box: [79, 82, 192, 199]; a brown box: [205, 54, 359, 148]; white table cloth on the table: [0, 58, 381, 210]; legos on the floor: [119, 31, 218, 88]; lego man is holding a surfboard: [161, 31, 197, 87]; the top of the box is blue: [85, 85, 185, 122]; the boxes are brown: [84, 23, 357, 168]; red and blue candle: [165, 47, 187, 86]; ; Region Captions: a black and white image of a building: [0, 73, 383, 139]; a black and white image of a room with a chair: [0, 0, 383, 156]; a gray png image of a gun: [194, 0, 189, 157]; a black and white image of a man with a hat: [0, 0, 190, 76]; a black and white image of a png file: [0, 0, 381, 77]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a person standing next to a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and white box: [18, 111, 161, 211]; a brown wicker basket: [170, 81, 301, 165]; square shaped ottoman: [79, 77, 182, 118]; small lego figure on top of the tv: [89, 38, 124, 87]; white table cloth on table: [0, 83, 382, 211]; a bed in the room: [36, 14, 331, 200]; a lego figure on a bed: [55, 33, 189, 153]; the red jacket the person is wearing: [92, 52, 121, 72]; blue pants on the figurine: [100, 69, 118, 85]; a blue and green table: [25, 42, 197, 207]; lego figure standing on top of the tv: [78, 32, 135, 95]; yellow top of red fire hydrant: [96, 39, 118, 58]; blue square on top of a box: [33, 113, 150, 161]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 186]\n",
      "process_ann took 0.00 seconds\n",
      "[154, 0, 229, 186]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 104, 383, 108]\n",
      "process_ann took 0.00 seconds\n",
      "[137, 109, 246, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 155, 107]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a person is standing in a room with a wall: [0, 0, 383, 186]; a black and gray wall with a black and gray wall: [154, 0, 229, 186]; a white and black image of a slender man: [0, 104, 383, 108]; a silver arrow with a white arrowhead: [137, 109, 246, 104]; a silhouette of a man standing in front of a wall: [0, 0, 155, 107]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a person standing next to a block; Dense Caption: a blue and white box: [18, 111, 161, 211]; a brown wicker basket: [170, 81, 301, 165]; square shaped ottoman: [79, 77, 182, 118]; small lego figure on top of the tv: [89, 38, 124, 87]; white table cloth on table: [0, 83, 382, 211]; a bed in the room: [36, 14, 331, 200]; a lego figure on a bed: [55, 33, 189, 153]; the red jacket the person is wearing: [92, 52, 121, 72]; blue pants on the figurine: [100, 69, 118, 85]; a blue and green table: [25, 42, 197, 207]; lego figure standing on top of the tv: [78, 32, 135, 95]; yellow top of red fire hydrant: [96, 39, 118, 58]; blue square on top of a box: [33, 113, 150, 161]; ; Region Captions: a person is standing in a room with a wall: [0, 0, 383, 186]; a black and gray wall with a black and gray wall: [154, 0, 229, 186]; a white and black image of a slender man: [0, 104, 383, 108]; a silver arrow with a white arrowhead: [137, 109, 246, 104]; a silhouette of a man standing in front of a wall: [0, 0, 155, 107]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden table and a lamp\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden trunk: [130, 80, 279, 210]; square shaped dark box: [14, 76, 155, 132]; a bed in the room: [46, 45, 288, 213]; the bed has a checkered bedspread: [14, 56, 189, 156]; a red blue and yellow flag: [0, 33, 15, 89]; red and yellow stripes: [0, 34, 14, 64]; the bench is made of wood: [175, 115, 222, 168]; the bed is white: [2, 127, 150, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[2, 0, 381, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[130, 0, 253, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 109, 298, 103]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 109, 203, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 133, 108]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [2, 0, 381, 212]; a black and white image of a wall: [130, 0, 253, 212]; a white iceberg with a black background: [0, 109, 298, 103]; a white snowy surface with a white snow: [0, 109, 203, 104]; a grey teddy bear with a black background: [0, 0, 133, 108]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden table and a lamp; Dense Caption: a large wooden trunk: [130, 80, 279, 210]; square shaped dark box: [14, 76, 155, 132]; a bed in the room: [46, 45, 288, 213]; the bed has a checkered bedspread: [14, 56, 189, 156]; a red blue and yellow flag: [0, 33, 15, 89]; red and yellow stripes: [0, 34, 14, 64]; the bench is made of wood: [175, 115, 222, 168]; the bed is white: [2, 127, 150, 211]; ; Region Captions: a black and white image of a wall: [2, 0, 381, 212]; a black and white image of a wall: [130, 0, 253, 212]; a white iceberg with a black background: [0, 109, 298, 103]; a white snowy surface with a white snow: [0, 109, 203, 104]; a grey teddy bear with a black background: [0, 0, 133, 108]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with wooden blocks and a wooden table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden box: [17, 101, 260, 211]; a checkered bedspread: [0, 91, 63, 157]; a bed in the room: [26, 26, 311, 213]; a brown box: [108, 130, 257, 211]; white sheets on the bed: [0, 151, 70, 212]; the top of the mattress: [60, 112, 161, 170]; the table is made of wood: [28, 106, 143, 211]; the table is made of wood: [70, 117, 188, 205]; the wall is white: [125, 17, 340, 134]; a bed in the room: [0, 92, 70, 210]; the wall is white: [140, 30, 363, 211]; white wall in the background: [0, 1, 26, 98]; the table is made of wood: [167, 147, 224, 199]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[18, 109, 238, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 152, 68, 61]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 97, 61, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 21, 96]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a 3d model of a room with a wall: [0, 0, 383, 212]; a block of wood with the word wood: [18, 109, 238, 104]; a grey sheet of paper on a black surface: [0, 152, 68, 61]; a black and grey striped table: [0, 97, 61, 59]; a black and white image of a tv screen: [0, 0, 21, 96]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with wooden blocks and a wooden table; Dense Caption: a large wooden box: [17, 101, 260, 211]; a checkered bedspread: [0, 91, 63, 157]; a bed in the room: [26, 26, 311, 213]; a brown box: [108, 130, 257, 211]; white sheets on the bed: [0, 151, 70, 212]; the top of the mattress: [60, 112, 161, 170]; the table is made of wood: [28, 106, 143, 211]; the table is made of wood: [70, 117, 188, 205]; the wall is white: [125, 17, 340, 134]; a bed in the room: [0, 92, 70, 210]; the wall is white: [140, 30, 363, 211]; white wall in the background: [0, 1, 26, 98]; the table is made of wood: [167, 147, 224, 199]; ; Region Captions: a 3d model of a room with a wall: [0, 0, 383, 212]; a block of wood with the word wood: [18, 109, 238, 104]; a grey sheet of paper on a black surface: [0, 152, 68, 61]; a black and grey striped table: [0, 97, 61, 59]; a black and white image of a tv screen: [0, 0, 21, 96]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with wooden blocks and a wooden table\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden box: [17, 101, 260, 211]; a checkered bedspread: [0, 91, 63, 157]; a bed in the room: [26, 26, 311, 213]; a brown box: [108, 130, 257, 211]; white sheets on the bed: [0, 151, 70, 212]; the top of the mattress: [60, 112, 161, 170]; the table is made of wood: [28, 106, 143, 211]; the table is made of wood: [70, 117, 188, 205]; the wall is white: [125, 17, 340, 134]; a bed in the room: [0, 92, 70, 210]; the wall is white: [140, 30, 363, 211]; white wall in the background: [0, 1, 26, 98]; the table is made of wood: [167, 147, 224, 199]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[18, 109, 238, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 152, 68, 61]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 97, 61, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 21, 96]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a 3d model of a room with a wall: [0, 0, 383, 212]; a block of wood with the word wood: [18, 109, 238, 104]; a grey sheet of paper on a black surface: [0, 152, 68, 61]; a black and grey striped table: [0, 97, 61, 59]; a black and white image of a tv screen: [0, 0, 21, 96]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with wooden blocks and a wooden table; Dense Caption: a large wooden box: [17, 101, 260, 211]; a checkered bedspread: [0, 91, 63, 157]; a bed in the room: [26, 26, 311, 213]; a brown box: [108, 130, 257, 211]; white sheets on the bed: [0, 151, 70, 212]; the top of the mattress: [60, 112, 161, 170]; the table is made of wood: [28, 106, 143, 211]; the table is made of wood: [70, 117, 188, 205]; the wall is white: [125, 17, 340, 134]; a bed in the room: [0, 92, 70, 210]; the wall is white: [140, 30, 363, 211]; white wall in the background: [0, 1, 26, 98]; the table is made of wood: [167, 147, 224, 199]; ; Region Captions: a 3d model of a room with a wall: [0, 0, 383, 212]; a block of wood with the word wood: [18, 109, 238, 104]; a grey sheet of paper on a black surface: [0, 152, 68, 61]; a black and grey striped table: [0, 97, 61, 59]; a black and white image of a tv screen: [0, 0, 21, 96]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is standing on a block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a wooden box: [181, 51, 325, 164]; a blue and green box: [0, 85, 112, 213]; the basket is square: [92, 40, 202, 85]; white table cloth on the table: [0, 41, 381, 211]; a red white and blue cup: [212, 0, 283, 71]; a blue stripe on the post: [221, 32, 256, 71]; a table with a basket: [95, 5, 326, 183]; the basket is made of wicker: [78, 23, 215, 99]; a multicolored jacket: [225, 0, 285, 36]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 2, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 68, 383, 145]\n",
      "process_ann took 0.00 seconds\n",
      "[183, 0, 200, 208]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 89, 108, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 181, 70]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.71 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a hallway: [0, 2, 383, 210]; a white png image of a slender metal pole: [0, 68, 383, 145]; a man is standing on a ledge with a sword: [183, 0, 200, 208]; a blue block in minecraft: [0, 89, 108, 123]; a grey teddy bear with a black background: [0, 0, 181, 70]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is standing on a block; Dense Caption: a wooden box: [181, 51, 325, 164]; a blue and green box: [0, 85, 112, 213]; the basket is square: [92, 40, 202, 85]; white table cloth on the table: [0, 41, 381, 211]; a red white and blue cup: [212, 0, 283, 71]; a blue stripe on the post: [221, 32, 256, 71]; a table with a basket: [95, 5, 326, 183]; the basket is made of wicker: [78, 23, 215, 99]; a multicolored jacket: [225, 0, 285, 36]; ; Region Captions: a black and white image of a hallway: [0, 2, 383, 210]; a white png image of a slender metal pole: [0, 68, 383, 145]; a man is standing on a ledge with a sword: [183, 0, 200, 208]; a blue block in minecraft: [0, 89, 108, 123]; a grey teddy bear with a black background: [0, 0, 181, 70]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a red and blue block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red and blue stack of luggage: [121, 25, 277, 189]; white table top: [0, 3, 381, 210]; a brown wooden dresser: [335, 65, 383, 212]; the black and white rug on the floor: [267, 14, 382, 85]; yellow and blue tag: [238, 12, 282, 51]; a red section of a pole: [172, 154, 304, 212]; blue bottom of the lego: [146, 108, 241, 181]; the word the on the front of the book: [282, 17, 355, 44]; a basket on the table: [36, 0, 117, 22]; tag on the red suitcase: [236, 11, 283, 95]; red section of the object: [139, 29, 248, 125]; tag on the suitcase: [241, 59, 267, 96]; the snow is white: [4, 29, 124, 206]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 13, 351, 199]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 13, 239, 199]\n",
      "process_ann took 0.00 seconds\n",
      "[174, 32, 177, 181]\n",
      "process_ann took 0.00 seconds\n",
      "[221, 69, 130, 144]\n",
      "process_ann took 0.00 seconds\n",
      "[132, 34, 119, 120]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a white shirt with a white hat on it: [0, 13, 351, 199]; a small white snowy area with a black background: [0, 13, 239, 199]; a silhouette of a man holding a piece of paper: [174, 32, 177, 181]; a piece of paper with a hole in it: [221, 69, 130, 144]; red block - minecraft: [132, 34, 119, 120]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a red and blue block in minecraft; Dense Caption: a red and blue stack of luggage: [121, 25, 277, 189]; white table top: [0, 3, 381, 210]; a brown wooden dresser: [335, 65, 383, 212]; the black and white rug on the floor: [267, 14, 382, 85]; yellow and blue tag: [238, 12, 282, 51]; a red section of a pole: [172, 154, 304, 212]; blue bottom of the lego: [146, 108, 241, 181]; the word the on the front of the book: [282, 17, 355, 44]; a basket on the table: [36, 0, 117, 22]; tag on the red suitcase: [236, 11, 283, 95]; red section of the object: [139, 29, 248, 125]; tag on the suitcase: [241, 59, 267, 96]; the snow is white: [4, 29, 124, 206]; ; Region Captions: a white shirt with a white hat on it: [0, 13, 351, 199]; a small white snowy area with a black background: [0, 13, 239, 199]; a silhouette of a man holding a piece of paper: [174, 32, 177, 181]; a piece of paper with a hole in it: [221, 69, 130, 144]; red block - minecraft: [132, 34, 119, 120]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a wooden floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown and orange box: [130, 87, 309, 212]; the box is made of cardboard: [59, 72, 184, 120]; white wall behind bed: [0, 1, 381, 210]; white bedspread on the bed: [0, 95, 144, 211]; the keyboard is black: [43, 54, 184, 143]; a white wall: [0, 1, 174, 99]; a bed in the room: [14, 66, 272, 212]; the table is brown: [147, 125, 257, 209]; a bed: [107, 72, 180, 214]; a white wall behind the bench: [182, 11, 376, 210]; the logo on the laptop: [106, 74, 160, 89]; a brown wooden dresser drawer: [144, 88, 235, 134]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[174, 0, 209, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[2, 0, 381, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 173, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 99, 149, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 99, 292, 113]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.53 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [174, 0, 209, 212]; a black and white image of a wall: [2, 0, 381, 212]; a gray arrow with a white background: [0, 0, 173, 99]; a white sheet of paper on a black background: [0, 99, 149, 114]; a white piece of paper with a black background: [0, 99, 292, 113]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a wooden floor; Dense Caption: a brown and orange box: [130, 87, 309, 212]; the box is made of cardboard: [59, 72, 184, 120]; white wall behind bed: [0, 1, 381, 210]; white bedspread on the bed: [0, 95, 144, 211]; the keyboard is black: [43, 54, 184, 143]; a white wall: [0, 1, 174, 99]; a bed in the room: [14, 66, 272, 212]; the table is brown: [147, 125, 257, 209]; a bed: [107, 72, 180, 214]; a white wall behind the bench: [182, 11, 376, 210]; the logo on the laptop: [106, 74, 160, 89]; a brown wooden dresser drawer: [144, 88, 235, 134]; ; Region Captions: a black and white image of a wall: [174, 0, 209, 212]; a black and white image of a wall: [2, 0, 381, 212]; a gray arrow with a white background: [0, 0, 173, 99]; a white sheet of paper on a black background: [0, 99, 149, 114]; a white piece of paper with a black background: [0, 99, 292, 113]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden table with a wooden floor in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the keyboard is black: [102, 112, 367, 212]; the sky is grey: [37, 9, 351, 185]; shadow on the ground: [125, 150, 265, 212]; the sky is clear: [156, 63, 273, 127]; the sky is clear: [176, 114, 289, 177]; the line is black: [233, 137, 381, 211]; a kite flying in the sky: [28, 53, 274, 209]; shadow on the bench: [184, 145, 280, 211]; the sky is clear: [140, 88, 249, 150]; shadow on the bench: [145, 157, 165, 211]; the sky is grey: [35, 2, 346, 77]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[106, 129, 277, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[200, 153, 59, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[174, 157, 37, 56]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a 3d model of a wall with a black background: [0, 1, 383, 211]; a black and white image of a cloudy sky: [0, 1, 383, 75]; a wooden floor in minecraft: [106, 129, 277, 84]; a wooden sword with a brown handle: [200, 153, 59, 60]; a wooden sword with a brown handle: [174, 157, 37, 56]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden table with a wooden floor in minecraft; Dense Caption: the keyboard is black: [102, 112, 367, 212]; the sky is grey: [37, 9, 351, 185]; shadow on the ground: [125, 150, 265, 212]; the sky is clear: [156, 63, 273, 127]; the sky is clear: [176, 114, 289, 177]; the line is black: [233, 137, 381, 211]; a kite flying in the sky: [28, 53, 274, 209]; shadow on the bench: [184, 145, 280, 211]; the sky is clear: [140, 88, 249, 150]; shadow on the bench: [145, 157, 165, 211]; the sky is grey: [35, 2, 346, 77]; ; Region Captions: a 3d model of a wall with a black background: [0, 1, 383, 211]; a black and white image of a cloudy sky: [0, 1, 383, 75]; a wooden floor in minecraft: [106, 129, 277, 84]; a wooden sword with a brown handle: [200, 153, 59, 60]; a wooden sword with a brown handle: [174, 157, 37, 56]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden table with a wooden floor in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the keyboard is black: [102, 112, 367, 212]; the sky is grey: [37, 9, 351, 185]; shadow on the ground: [125, 150, 265, 212]; the sky is clear: [156, 63, 273, 127]; the sky is clear: [176, 114, 289, 177]; the line is black: [233, 137, 381, 211]; a kite flying in the sky: [28, 53, 274, 209]; shadow on the bench: [184, 145, 280, 211]; the sky is clear: [140, 88, 249, 150]; shadow on the bench: [145, 157, 165, 211]; the sky is grey: [35, 2, 346, 77]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 75]\n",
      "process_ann took 0.00 seconds\n",
      "[106, 129, 277, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[200, 153, 59, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[174, 157, 37, 56]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a 3d model of a wall with a black background: [0, 1, 383, 211]; a black and white image of a cloudy sky: [0, 1, 383, 75]; a wooden floor in minecraft: [106, 129, 277, 84]; a wooden sword with a brown handle: [200, 153, 59, 60]; a wooden sword with a brown handle: [174, 157, 37, 56]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden table with a wooden floor in minecraft; Dense Caption: the keyboard is black: [102, 112, 367, 212]; the sky is grey: [37, 9, 351, 185]; shadow on the ground: [125, 150, 265, 212]; the sky is clear: [156, 63, 273, 127]; the sky is clear: [176, 114, 289, 177]; the line is black: [233, 137, 381, 211]; a kite flying in the sky: [28, 53, 274, 209]; shadow on the bench: [184, 145, 280, 211]; the sky is clear: [140, 88, 249, 150]; shadow on the bench: [145, 157, 165, 211]; the sky is grey: [35, 2, 346, 77]; ; Region Captions: a 3d model of a wall with a black background: [0, 1, 383, 211]; a black and white image of a cloudy sky: [0, 1, 383, 75]; a wooden floor in minecraft: [106, 129, 277, 84]; a wooden sword with a brown handle: [200, 153, 59, 60]; a wooden sword with a brown handle: [174, 157, 37, 56]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft game with a red block and a blue block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue box on the bed: [159, 84, 200, 122]; a brown wooden stand: [1, 95, 104, 212]; white bedspread on the bed: [44, 51, 380, 211]; a red cloth wrapped around the cake: [136, 111, 203, 189]; lego person is holding a surfboard: [210, 56, 245, 115]; the basket is made of plastic: [87, 51, 149, 78]; red fabric on table: [119, 75, 213, 195]; the bed is made: [77, 16, 281, 161]; a white wall: [78, 0, 274, 62]; yellow top of a fire hydrant: [218, 57, 243, 78]; the suitcase is blue: [152, 66, 234, 163]; red square pillow: [125, 80, 162, 119]; a green power cord: [208, 74, 223, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[84, 60, 299, 152]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 92, 161]\n",
      "process_ann took 0.00 seconds\n",
      "[81, 0, 187, 63]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 99, 101, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[264, 0, 119, 72]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a minecraft map with a man standing on a snowy ground: [84, 60, 299, 152]; a gray piece of paper with a black background: [0, 0, 92, 161]; a grey box with a black background: [81, 0, 187, 63]; a wooden block in minecraft: [0, 99, 101, 114]; a gray t shirt with a black background: [264, 0, 119, 72]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft game with a red block and a blue block; Dense Caption: a blue box on the bed: [159, 84, 200, 122]; a brown wooden stand: [1, 95, 104, 212]; white bedspread on the bed: [44, 51, 380, 211]; a red cloth wrapped around the cake: [136, 111, 203, 189]; lego person is holding a surfboard: [210, 56, 245, 115]; the basket is made of plastic: [87, 51, 149, 78]; red fabric on table: [119, 75, 213, 195]; the bed is made: [77, 16, 281, 161]; a white wall: [78, 0, 274, 62]; yellow top of a fire hydrant: [218, 57, 243, 78]; the suitcase is blue: [152, 66, 234, 163]; red square pillow: [125, 80, 162, 119]; a green power cord: [208, 74, 223, 92]; ; Region Captions: a minecraft map with a man standing on a snowy ground: [84, 60, 299, 152]; a gray piece of paper with a black background: [0, 0, 92, 161]; a grey box with a black background: [81, 0, 187, 63]; a wooden block in minecraft: [0, 99, 101, 114]; a gray t shirt with a black background: [264, 0, 119, 72]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft window with a fire in it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a small square tile: [57, 62, 236, 185]; the window is square: [118, 74, 203, 122]; a black and white photo: [2, 1, 252, 211]; pan of pizza in oven: [143, 95, 196, 119]; the white wall next to the vase: [234, 3, 370, 209]; a brown wood grain: [169, 201, 233, 212]; pan used to cook pizza: [158, 100, 194, 117]; a white wall: [0, 1, 238, 83]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 236, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 352, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 78, 227, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[59, 68, 173, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[121, 80, 78, 39]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a gray png file with a black background: [0, 0, 236, 84]; a gray png file with a black background: [0, 0, 352, 84]; a white sheet of paper with a black background: [0, 78, 227, 135]; a window in a minecraft block: [59, 68, 173, 113]; a set of four tiles with gold and black: [121, 80, 78, 39]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft window with a fire in it; Dense Caption: a small square tile: [57, 62, 236, 185]; the window is square: [118, 74, 203, 122]; a black and white photo: [2, 1, 252, 211]; pan of pizza in oven: [143, 95, 196, 119]; the white wall next to the vase: [234, 3, 370, 209]; a brown wood grain: [169, 201, 233, 212]; pan used to cook pizza: [158, 100, 194, 117]; a white wall: [0, 1, 238, 83]; ; Region Captions: a gray png file with a black background: [0, 0, 236, 84]; a gray png file with a black background: [0, 0, 352, 84]; a white sheet of paper with a black background: [0, 78, 227, 135]; a window in a minecraft block: [59, 68, 173, 113]; a set of four tiles with gold and black: [121, 80, 78, 39]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210428_171107 34\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a small square in a room with a black background\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a bed in the room: [33, 110, 350, 211]; a black decorative box: [192, 99, 277, 125]; a bed in the room: [127, 49, 332, 188]; small piece of wood on the bed: [180, 112, 199, 132]; the room is a bedroom: [0, 2, 381, 209]; a black bowl on a table: [170, 20, 320, 155]; a brown star on the bed: [173, 107, 205, 138]; the basket is on the bed: [180, 88, 284, 135]; the wall is white: [2, 3, 218, 112]; a lamp on a table: [187, 2, 279, 126]; the wall is white: [231, 1, 381, 132]; the snow is white: [97, 140, 206, 203]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 118, 383, 94]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 230, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[233, 0, 150, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[276, 105, 107, 29]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.75 seconds\n",
      "finished...\n",
      "\n",
      "a corner of a room with a wall: [0, 0, 383, 133]; a white png of a person walking on a snowy surface: [0, 118, 383, 94]; a gray square with a black background: [0, 0, 230, 132]; a gray state with a black background: [233, 0, 150, 133]; a gray curved wall with a black background: [276, 105, 107, 29]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a small square in a room with a black background; Dense Caption: a bed in the room: [33, 110, 350, 211]; a black decorative box: [192, 99, 277, 125]; a bed in the room: [127, 49, 332, 188]; small piece of wood on the bed: [180, 112, 199, 132]; the room is a bedroom: [0, 2, 381, 209]; a black bowl on a table: [170, 20, 320, 155]; a brown star on the bed: [173, 107, 205, 138]; the basket is on the bed: [180, 88, 284, 135]; the wall is white: [2, 3, 218, 112]; a lamp on a table: [187, 2, 279, 126]; the wall is white: [231, 1, 381, 132]; the snow is white: [97, 140, 206, 203]; ; Region Captions: a corner of a room with a wall: [0, 0, 383, 133]; a white png of a person walking on a snowy surface: [0, 118, 383, 94]; a gray square with a black background: [0, 0, 230, 132]; a gray state with a black background: [233, 0, 150, 133]; a gray curved wall with a black background: [276, 105, 107, 29]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a small square in a room with a black background\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the bed is made: [32, 112, 351, 211]; the basket is made of wicker: [189, 103, 271, 129]; the room is a bedroom: [0, 2, 382, 209]; a bed in the room: [140, 9, 326, 178]; a lamp on a table: [186, 1, 272, 129]; the wall is white: [1, 2, 218, 117]; the wall is white: [228, 1, 381, 132]; the bed is white: [46, 138, 167, 204]; the clock is small: [178, 88, 279, 136]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 122, 383, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 227, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 0, 155, 137]\n",
      "process_ann took 0.00 seconds\n",
      "[189, 106, 81, 22]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a corner and a door: [0, 0, 383, 137]; a white sand beach with a black background: [0, 122, 383, 90]; a gray png file with a black background: [0, 0, 227, 136]; a gray map of arizona with a black background: [228, 0, 155, 137]; a black block with a black background: [189, 106, 81, 22]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a small square in a room with a black background; Dense Caption: the bed is made: [32, 112, 351, 211]; the basket is made of wicker: [189, 103, 271, 129]; the room is a bedroom: [0, 2, 382, 209]; a bed in the room: [140, 9, 326, 178]; a lamp on a table: [186, 1, 272, 129]; the wall is white: [1, 2, 218, 117]; the wall is white: [228, 1, 381, 132]; the bed is white: [46, 138, 167, 204]; the clock is small: [178, 88, 279, 136]; ; Region Captions: a gray wall with a corner and a door: [0, 0, 383, 137]; a white sand beach with a black background: [0, 122, 383, 90]; a gray png file with a black background: [0, 0, 227, 136]; a gray map of arizona with a black background: [228, 0, 155, 137]; a black block with a black background: [189, 106, 81, 22]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the basket is made of woven material: [128, 62, 227, 100]; the snow is white: [35, 51, 342, 210]; the box is brown: [232, 68, 307, 100]; yellow and blue sign: [29, 40, 77, 79]; a red white and blue flag: [41, 70, 94, 151]; red square on post: [45, 71, 88, 116]; shadow of the object: [41, 127, 101, 156]; a red blue and yellow flag: [26, 38, 101, 154]; blue post it attached to stop sign: [55, 111, 84, 148]; a black and white striped sign: [81, 86, 121, 109]; a lego snowboard and a snowboard: [31, 28, 288, 160]; a gray square piece of paper: [283, 109, 336, 134]; two brown objects in the snow: [230, 92, 337, 137]; blue square on yellow sign: [42, 43, 62, 71]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 89, 383, 123]\n",
      "process_ann took 0.00 seconds\n",
      "[177, 0, 206, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 176, 107]\n",
      "process_ann took 0.00 seconds\n",
      "[129, 69, 95, 29]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.71 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy area: [0, 89, 383, 123]; a black and white image of a black and white image: [177, 0, 206, 104]; a black and white image of a wall: [0, 0, 383, 105]; a black and white image of a man standing in a dark room: [0, 0, 176, 107]; a black cube with a black background: [129, 69, 95, 29]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is standing in a room; Dense Caption: the basket is made of woven material: [128, 62, 227, 100]; the snow is white: [35, 51, 342, 210]; the box is brown: [232, 68, 307, 100]; yellow and blue sign: [29, 40, 77, 79]; a red white and blue flag: [41, 70, 94, 151]; red square on post: [45, 71, 88, 116]; shadow of the object: [41, 127, 101, 156]; a red blue and yellow flag: [26, 38, 101, 154]; blue post it attached to stop sign: [55, 111, 84, 148]; a black and white striped sign: [81, 86, 121, 109]; a lego snowboard and a snowboard: [31, 28, 288, 160]; a gray square piece of paper: [283, 109, 336, 134]; two brown objects in the snow: [230, 92, 337, 137]; blue square on yellow sign: [42, 43, 62, 71]; ; Region Captions: a black and white image of a snowy area: [0, 89, 383, 123]; a black and white image of a black and white image: [177, 0, 206, 104]; a black and white image of a wall: [0, 0, 383, 105]; a black and white image of a man standing in a dark room: [0, 0, 176, 107]; a black cube with a black background: [129, 69, 95, 29]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden texture\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black book: [0, 80, 30, 203]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a black and white image: [0, 90, 383, 122]; a black and white image of a man with a knife: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden texture; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black book: [0, 80, 30, 203]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a black and white image: [0, 90, 383, 122]; a black and white image of a man with a knife: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black and white checkered tablecloth: [0, 80, 30, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black box with a black handle: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black and white checkered tablecloth: [0, 80, 30, 209]; ; Region Captions: a black box with a black handle: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a sandbox: [0, 139, 383, 73]; a black and white image of a small black box: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; ; Region Captions: a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a sandbox: [0, 139, 383, 73]; a black and white image of a small black box: [0, 90, 383, 122]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; corner of black and white checkered tablecloth: [0, 80, 30, 209]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a man is standing in front of a black wall: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; corner of black and white checkered tablecloth: [0, 80, 30, 209]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a man is standing in front of a black wall: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; corner of black book: [0, 80, 30, 204]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a knife: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden box; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; corner of black book: [0, 80, 30, 204]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a knife: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 74]\n",
      "process_ann took 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboarder: [0, 90, 383, 122]; a silver and white png image of a pylon: [0, 139, 383, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboarder: [0, 90, 383, 122]; a silver and white png image of a pylon: [0, 139, 383, 74]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a silver and white png image of a pylon: [0, 139, 383, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a silver and white png image of a pylon: [0, 139, 383, 74]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden texture\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 211]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black book: [0, 80, 30, 203]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a table and chairs: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a sword: [0, 139, 383, 73]; a black and white image of a black and white image: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden texture; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 211]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black book: [0, 80, 30, 203]; ; Region Captions: a black and white image of a table and chairs: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a sword: [0, 139, 383, 73]; a black and white image of a black and white image: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black book in the foreground: [0, 167, 14, 209]; corner of black and white checkered tablecloth: [0, 80, 30, 207]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a man is standing in front of a black wall: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden box; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black book in the foreground: [0, 167, 14, 209]; corner of black and white checkered tablecloth: [0, 80, 30, 207]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a man is standing in front of a black wall: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [282, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.62 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a sandbox: [0, 139, 383, 73]; a black and white image of a small black box: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [282, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; ; Region Captions: a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a sandbox: [0, 139, 383, 73]; a black and white image of a small black box: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black book in the foreground: [0, 171, 14, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a knife: [0, 90, 383, 122]; a white and silver building with a black background: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black book in the foreground: [0, 171, 14, 211]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a knife: [0, 90, 383, 122]; a white and silver building with a black background: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden texture\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; black and white checkered tablecloth: [0, 79, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black box: [0, 162, 14, 204]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a black and white image: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden texture; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; black and white checkered tablecloth: [0, 79, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black box: [0, 162, 14, 204]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a black and white image: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [1, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [282, 141, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.71 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a silver and white png image of a sand castle: [0, 139, 383, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [1, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [282, 141, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a silver and white png image of a sand castle: [0, 139, 383, 74]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboard: [0, 90, 383, 122]; a silver and white png image of a pylon: [0, 139, 383, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboard: [0, 90, 383, 122]; a silver and white png image of a pylon: [0, 139, 383, 74]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 211]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 79, 24, 158]; the sky is grey: [39, 3, 345, 88]; corner of black book: [0, 80, 30, 207]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 211]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 79, 24, 158]; the sky is grey: [39, 3, 345, 88]; corner of black book: [0, 80, 30, 207]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 79, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black and white checkered tablecloth: [0, 80, 30, 205]; a black book in the floor: [0, 166, 14, 207]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 86, 278, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 86, 278, 96]; a man is standing on a black background: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden box; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 79, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black and white checkered tablecloth: [0, 80, 30, 205]; a black book in the floor: [0, 166, 14, 207]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 86, 278, 96]; a man is standing on a black background: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a small black and white object: [0, 90, 383, 122]; a black and white image of a sand castle: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a small black and white object: [0, 90, 383, 122]; a black and white image of a sand castle: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a building: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboard: [0, 90, 383, 122]; a silver and white png image of a building: [0, 139, 383, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a building: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboard: [0, 90, 383, 122]; a silver and white png image of a building: [0, 139, 383, 74]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 79, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black box: [0, 162, 14, 204]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a black and white image: [0, 90, 383, 122]; a man is riding a skateboard on a black background: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden box; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 79, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black box: [0, 162, 14, 204]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a black and white image: [0, 90, 383, 122]; a man is riding a skateboard on a black background: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboarder: [0, 90, 383, 122]; a silver and white png image of a building: [0, 139, 383, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboarder: [0, 90, 383, 122]; a silver and white png image of a building: [0, 139, 383, 74]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [282, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a white and silver png image of a pylon: [0, 139, 383, 74]; a black and white image of a small black box: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [282, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; ; Region Captions: a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a white and silver png image of a pylon: [0, 139, 383, 74]; a black and white image of a small black box: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; corner of black and white checkered tablecloth: [0, 80, 30, 208]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black piece of plastic: [0, 167, 14, 209]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a sword: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden box; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; corner of black and white checkered tablecloth: [0, 80, 30, 208]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; a black piece of plastic: [0, 167, 14, 209]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a sword: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black and white checkered tablecloth: [0, 80, 30, 204]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden box; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black and white checkered tablecloth: [0, 80, 30, 204]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a building: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a white and silver png image of a metal plate: [0, 139, 383, 74]; a black and white image of a man with a knife: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a building: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a white and silver png image of a metal plate: [0, 139, 383, 74]; a black and white image of a man with a knife: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 74]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a black and white image of a metal plate: [0, 139, 383, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the corner of a checkered tablecloth: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a table: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; a black and white image of a metal plate: [0, 139, 383, 74]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden texture\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 211]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black book: [0, 80, 30, 204]; a black piece of paper: [0, 163, 15, 205]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboard: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden texture; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 211]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; corner of black book: [0, 80, 30, 204]; a black piece of paper: [0, 163, 15, 205]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a skateboard: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a sword: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a man with a sword: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [282, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a table in a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a small black and white object: [0, 90, 383, 122]; a black and white image of a sandbox: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a brown wooden box: [15, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 80, 23, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [282, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 192, 179]; ; Region Captions: a black and white image of a table in a room: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a small black and white object: [0, 90, 383, 122]; a black and white image of a sandbox: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden texture\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 79, 24, 158]; the sky is grey: [38, 3, 345, 88]; corner of black and white checkered tablecloth: [0, 80, 30, 209]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black box with a black handle: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a man is standing in front of a black wall: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden texture; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 134, 382, 212]; the sky is grey: [0, 1, 381, 142]; the black and white checkered design on the right: [0, 79, 24, 158]; the sky is grey: [38, 3, 345, 88]; corner of black and white checkered tablecloth: [0, 80, 30, 209]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black box with a black handle: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a man is standing in front of a black wall: [0, 139, 383, 73]; a black and white image of a man in a black shirt: [0, 90, 383, 122]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a wooden box\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 211]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[4, 87, 278, 95]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 90, 383, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 139, 383, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a small black and white box: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a wooden box; Dense Caption: a brown wooden box: [14, 79, 286, 189]; white tablecloth on the table: [0, 135, 382, 211]; the sky is grey: [0, 1, 381, 142]; a black and white checkered blanket: [0, 80, 24, 158]; the sky is grey: [38, 3, 345, 88]; white counter top: [283, 142, 378, 210]; rows of horizontal lines on the bench: [97, 85, 193, 179]; ; Region Captions: a black and white image of a room with a black chair: [0, 1, 383, 211]; a black and white image of a building with a cloud: [0, 1, 383, 138]; a block of wood in minecraft: [4, 87, 278, 95]; a black and white image of a small black and white box: [0, 90, 383, 122]; a man is standing on a black background: [0, 139, 383, 73]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a room with a bed and a couch\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large bed: [0, 121, 382, 211]; a small square box: [164, 109, 238, 133]; the room is a bedroom: [31, 28, 345, 208]; the chair is brown: [241, 110, 302, 136]; the walls are white: [0, 1, 382, 143]; the snow is white: [171, 146, 275, 204]; two small brown squares: [242, 129, 314, 153]; a brown object in the snow: [276, 136, 315, 154]; the snow is white: [67, 143, 181, 204]; the chair is brown: [235, 103, 313, 148]; a bed in the room: [155, 52, 348, 151]; the wall is white: [1, 2, 197, 125]; the chairs are brown: [157, 93, 328, 146]; the chair is in the corner: [148, 98, 244, 142]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 144]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 128, 383, 84]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 198, 143]\n",
      "process_ann took 0.00 seconds\n",
      "[200, 0, 183, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 117, 164, 28]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.56 seconds\n",
      "finished...\n",
      "\n",
      "a gray wall with a corner and a door: [0, 0, 383, 144]; a snowy mountain with a black background: [0, 128, 383, 84]; a gray t shirt with a white logo: [0, 1, 198, 143]; a gray tv screen with a black background: [200, 0, 183, 140]; a gray arrow with a black background: [0, 117, 164, 28]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a room with a bed and a couch; Dense Caption: a large bed: [0, 121, 382, 211]; a small square box: [164, 109, 238, 133]; the room is a bedroom: [31, 28, 345, 208]; the chair is brown: [241, 110, 302, 136]; the walls are white: [0, 1, 382, 143]; the snow is white: [171, 146, 275, 204]; two small brown squares: [242, 129, 314, 153]; a brown object in the snow: [276, 136, 315, 154]; the snow is white: [67, 143, 181, 204]; the chair is brown: [235, 103, 313, 148]; a bed in the room: [155, 52, 348, 151]; the wall is white: [1, 2, 197, 125]; the chairs are brown: [157, 93, 328, 146]; the chair is in the corner: [148, 98, 244, 142]; ; Region Captions: a gray wall with a corner and a door: [0, 0, 383, 144]; a snowy mountain with a black background: [0, 128, 383, 84]; a gray t shirt with a white logo: [0, 1, 198, 143]; a gray tv screen with a black background: [200, 0, 183, 140]; a gray arrow with a black background: [0, 117, 164, 28]; \n",
      "NEW GAME ../Frames_60/main_logs/172_31_25_15_20210428_172012 43\n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft player standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "yellow and red striped umbrella: [1, 1, 228, 210]; the brown and red square box: [262, 1, 357, 35]; blue section of the umbrella: [96, 160, 189, 212]; a basket in the background: [190, 0, 264, 25]; yellow section of the umbrella: [1, 1, 196, 121]; white snow on the ground: [235, 38, 375, 206]; yellow stripe on umbrella: [31, 13, 159, 92]; green ribbon on umbrella: [180, 112, 199, 130]; two brown boxes: [191, 0, 361, 39]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 21, 383, 191]\n",
      "process_ann took 0.00 seconds\n",
      "[177, 21, 206, 191]\n",
      "process_ann took 0.00 seconds\n",
      "[49, 82, 128, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 153, 105, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[99, 165, 81, 48]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a person walking on a snowy surface: [0, 21, 383, 191]; a white sand beach with a white sand: [177, 21, 206, 191]; red squares - minecraft: [49, 82, 128, 99]; a white airplane with a white wing: [0, 153, 105, 60]; a blue square on a black background: [99, 165, 81, 48]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft player standing in a room; Dense Caption: yellow and red striped umbrella: [1, 1, 228, 210]; the brown and red square box: [262, 1, 357, 35]; blue section of the umbrella: [96, 160, 189, 212]; a basket in the background: [190, 0, 264, 25]; yellow section of the umbrella: [1, 1, 196, 121]; white snow on the ground: [235, 38, 375, 206]; yellow stripe on umbrella: [31, 13, 159, 92]; green ribbon on umbrella: [180, 112, 199, 130]; two brown boxes: [191, 0, 361, 39]; ; Region Captions: a person walking on a snowy surface: [0, 21, 383, 191]; a white sand beach with a white sand: [177, 21, 206, 191]; red squares - minecraft: [49, 82, 128, 99]; a white airplane with a white wing: [0, 153, 105, 60]; a blue square on a black background: [99, 165, 81, 48]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a snowy area\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a person in a red jacket: [287, 0, 366, 67]; a snowy white slope: [0, 7, 382, 210]; a brick wall: [3, 0, 65, 39]; the snow is white: [48, 47, 295, 204]; shadow of the person: [283, 48, 329, 69]; the sign is red: [294, 0, 363, 38]; blue base of the umbrella: [294, 32, 330, 63]; the snowboard is red: [42, 1, 351, 78]; a brown wooden baseboard: [361, 1, 383, 31]; yellow stripes on the flag: [292, 14, 310, 38]; the snow is white in color: [97, 53, 209, 139]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 15, 383, 197]\n",
      "process_ann took 0.00 seconds\n",
      "[58, 0, 203, 19]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 65, 36]\n",
      "process_ann took 0.00 seconds\n",
      "[296, 0, 65, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[260, 0, 47, 22]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.49 seconds\n",
      "finished...\n",
      "\n",
      "a small white square with a black background: [0, 15, 383, 197]; a gray metal plate on a black background: [58, 0, 203, 19]; a black keyboard with a black cover: [0, 0, 65, 36]; a red and blue pixelated bird: [296, 0, 65, 62]; a black square with a black background: [260, 0, 47, 22]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a snowy area; Dense Caption: a person in a red jacket: [287, 0, 366, 67]; a snowy white slope: [0, 7, 382, 210]; a brick wall: [3, 0, 65, 39]; the snow is white: [48, 47, 295, 204]; shadow of the person: [283, 48, 329, 69]; the sign is red: [294, 0, 363, 38]; blue base of the umbrella: [294, 32, 330, 63]; the snowboard is red: [42, 1, 351, 78]; a brown wooden baseboard: [361, 1, 383, 31]; yellow stripes on the flag: [292, 14, 310, 38]; the snow is white in color: [97, 53, 209, 139]; ; Region Captions: a small white square with a black background: [0, 15, 383, 197]; a gray metal plate on a black background: [58, 0, 203, 19]; a black keyboard with a black cover: [0, 0, 65, 36]; a red and blue pixelated bird: [296, 0, 65, 62]; a black square with a black background: [260, 0, 47, 22]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego figure on a snowboard: [210, 17, 251, 91]; snow covering the ground: [36, 56, 349, 210]; the snowboarder is brown and red: [252, 40, 329, 67]; a lego snowboarder: [41, 5, 344, 160]; blue stripe on the hydrant: [217, 64, 237, 87]; the wall is white: [1, 1, 220, 69]; the snowboard has a brown and tan pattern: [185, 31, 334, 72]; the base of the hydrant: [210, 79, 243, 91]; the red part of the hydrant: [212, 39, 248, 67]; snowboarder on the ground: [192, 14, 271, 113]; lego ice cream cone and snowboard: [174, 15, 328, 100]; blue base of the hydrant: [212, 61, 242, 91]; a yellow top of a toy dumpster: [220, 20, 243, 46]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 55, 383, 157]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 217, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[220, 0, 163, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 43, 180, 25]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a man walking on a snowy field: [0, 55, 383, 157]; a black and white image of a room with a lamp: [0, 0, 383, 70]; a grey paper clip with a black background: [0, 0, 217, 68]; a black and gray png image of a gun: [220, 0, 163, 71]; a gray arrow with a black background: [0, 43, 180, 25]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a lego figure on a snowboard: [210, 17, 251, 91]; snow covering the ground: [36, 56, 349, 210]; the snowboarder is brown and red: [252, 40, 329, 67]; a lego snowboarder: [41, 5, 344, 160]; blue stripe on the hydrant: [217, 64, 237, 87]; the wall is white: [1, 1, 220, 69]; the snowboard has a brown and tan pattern: [185, 31, 334, 72]; the base of the hydrant: [210, 79, 243, 91]; the red part of the hydrant: [212, 39, 248, 67]; snowboarder on the ground: [192, 14, 271, 113]; lego ice cream cone and snowboard: [174, 15, 328, 100]; blue base of the hydrant: [212, 61, 242, 91]; a yellow top of a toy dumpster: [220, 20, 243, 46]; ; Region Captions: a man walking on a snowy field: [0, 55, 383, 157]; a black and white image of a room with a lamp: [0, 0, 383, 70]; a grey paper clip with a black background: [0, 0, 217, 68]; a black and gray png image of a gun: [220, 0, 163, 71]; a gray arrow with a black background: [0, 43, 180, 25]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a red shirt\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "snow covering the ground: [36, 56, 349, 210]; red and yellow item on snow: [210, 18, 250, 90]; the snowboarder is brown and red: [252, 40, 329, 67]; a lego snowboarder: [41, 5, 344, 160]; blue base of the hydrant: [217, 64, 237, 87]; the wall is white: [1, 1, 220, 69]; the snowboard has a brown and tan pattern: [184, 31, 334, 71]; the red part of the hydrant: [212, 39, 248, 66]; the base of the hydrant: [210, 79, 243, 91]; snowboarder on the snow: [191, 13, 265, 106]; lego ice cream truck: [174, 15, 331, 99]; blue base of the hydrant: [210, 62, 244, 92]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 55, 383, 157]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 217, 68]\n",
      "process_ann took 0.00 seconds\n",
      "[219, 0, 164, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 43, 180, 25]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a man walking on a snowy field: [0, 55, 383, 157]; a black and white image of a room with a lamp: [0, 0, 383, 70]; a grey paper clip with a black background: [0, 0, 217, 68]; a black and gray png image of a gun: [219, 0, 164, 71]; a gray arrow with a black background: [0, 43, 180, 25]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a red shirt; Dense Caption: snow covering the ground: [36, 56, 349, 210]; red and yellow item on snow: [210, 18, 250, 90]; the snowboarder is brown and red: [252, 40, 329, 67]; a lego snowboarder: [41, 5, 344, 160]; blue base of the hydrant: [217, 64, 237, 87]; the wall is white: [1, 1, 220, 69]; the snowboard has a brown and tan pattern: [184, 31, 334, 71]; the red part of the hydrant: [212, 39, 248, 66]; the base of the hydrant: [210, 79, 243, 91]; snowboarder on the snow: [191, 13, 265, 106]; lego ice cream truck: [174, 15, 331, 99]; blue base of the hydrant: [210, 62, 244, 92]; ; Region Captions: a man walking on a snowy field: [0, 55, 383, 157]; a black and white image of a room with a lamp: [0, 0, 383, 70]; a grey paper clip with a black background: [0, 0, 217, 68]; a black and gray png image of a gun: [219, 0, 164, 71]; a gray arrow with a black background: [0, 43, 180, 25]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "lego person carrying a snowboard: [95, 16, 165, 114]; a white snowy hill: [0, 54, 381, 211]; the orange part of the board: [107, 45, 158, 82]; a brown and red striped box: [198, 44, 268, 72]; small yellow box with blue stripes: [107, 19, 147, 56]; blue base of a fire hydrant: [122, 79, 152, 108]; a lego snowboarder: [35, 7, 287, 189]; yellow strap on the side of the snowboard: [97, 64, 115, 90]; shadow of the object: [117, 95, 162, 115]; lego ice cream cone and snowboard: [75, 19, 276, 106]; a toy on the snow: [62, 10, 204, 160]; a black square object: [151, 42, 200, 67]; the snow is white: [46, 110, 334, 211]; gray wall in background: [0, 2, 381, 87]; the block is brown: [149, 40, 269, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 63, 383, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[166, 0, 217, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 164, 72]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 49, 107, 24]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a person walking on a snowy field: [0, 63, 383, 149]; a black and white image of a person in a room: [0, 0, 383, 82]; a black and white image of a giraffe: [166, 0, 217, 82]; a man is standing in front of a wall: [0, 0, 164, 72]; a grey and white striped wall: [0, 49, 107, 24]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: lego person carrying a snowboard: [95, 16, 165, 114]; a white snowy hill: [0, 54, 381, 211]; the orange part of the board: [107, 45, 158, 82]; a brown and red striped box: [198, 44, 268, 72]; small yellow box with blue stripes: [107, 19, 147, 56]; blue base of a fire hydrant: [122, 79, 152, 108]; a lego snowboarder: [35, 7, 287, 189]; yellow strap on the side of the snowboard: [97, 64, 115, 90]; shadow of the object: [117, 95, 162, 115]; lego ice cream cone and snowboard: [75, 19, 276, 106]; a toy on the snow: [62, 10, 204, 160]; a black square object: [151, 42, 200, 67]; the snow is white: [46, 110, 334, 211]; gray wall in background: [0, 2, 381, 87]; the block is brown: [149, 40, 269, 73]; ; Region Captions: a person walking on a snowy field: [0, 63, 383, 149]; a black and white image of a person in a room: [0, 0, 383, 82]; a black and white image of a giraffe: [166, 0, 217, 82]; a man is standing in front of a wall: [0, 0, 164, 72]; a grey and white striped wall: [0, 49, 107, 24]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a lego ice cream truck: [95, 16, 165, 113]; a white snowy hill: [0, 54, 381, 211]; the orange part of the board: [106, 45, 158, 82]; a brown and red striped box: [198, 44, 268, 72]; blue base of a fire hydrant: [122, 79, 152, 108]; small yellow box with blue stripes: [107, 19, 147, 55]; a lego snowboarder: [37, 8, 285, 188]; shadow of the object: [117, 95, 162, 115]; yellow strap on the luggage: [97, 66, 115, 92]; lego ice cream cone and snowboard: [76, 18, 277, 107]; a black square object: [151, 42, 200, 67]; a toy on the snow: [62, 11, 204, 160]; the snow is white: [46, 110, 335, 211]; gray wall in background: [0, 2, 381, 87]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 63, 383, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[166, 0, 217, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 164, 72]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 49, 107, 24]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a person walking on a snowy field: [0, 63, 383, 149]; a black and white image of a person in a room: [0, 0, 383, 82]; a black and white image of a giraffe: [166, 0, 217, 82]; a man is standing in front of a wall: [0, 0, 164, 72]; a grey and white striped wall: [0, 49, 107, 24]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a lego ice cream truck: [95, 16, 165, 113]; a white snowy hill: [0, 54, 381, 211]; the orange part of the board: [106, 45, 158, 82]; a brown and red striped box: [198, 44, 268, 72]; blue base of a fire hydrant: [122, 79, 152, 108]; small yellow box with blue stripes: [107, 19, 147, 55]; a lego snowboarder: [37, 8, 285, 188]; shadow of the object: [117, 95, 162, 115]; yellow strap on the luggage: [97, 66, 115, 92]; lego ice cream cone and snowboard: [76, 18, 277, 107]; a black square object: [151, 42, 200, 67]; a toy on the snow: [62, 11, 204, 160]; the snow is white: [46, 110, 335, 211]; gray wall in background: [0, 2, 381, 87]; ; Region Captions: a person walking on a snowy field: [0, 63, 383, 149]; a black and white image of a person in a room: [0, 0, 383, 82]; a black and white image of a giraffe: [166, 0, 217, 82]; a man is standing in front of a wall: [0, 0, 164, 72]; a grey and white striped wall: [0, 49, 107, 24]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a room with a lot of boxes\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the ground is covered in snow: [33, 64, 348, 209]; the basket is made of plastic: [120, 40, 201, 68]; the lego is holding a kite: [199, 25, 270, 76]; person wearing a pair of gloves: [212, 27, 248, 75]; red shirt on the person: [220, 41, 237, 59]; a yellow and blue flag: [220, 27, 241, 47]; a man with a snowboard: [74, 15, 306, 86]; the brown basket: [200, 46, 268, 72]; a stuffed bird on the box: [236, 42, 250, 55]; person in red and blue snow suit: [218, 40, 238, 74]; blue pants on a person: [218, 56, 234, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 63, 383, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 82]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 164, 72]\n",
      "process_ann took 0.00 seconds\n",
      "[170, 0, 213, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 49, 123, 24]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.63 seconds\n",
      "finished...\n",
      "\n",
      "a white sand field with a black background: [0, 63, 383, 149]; a black and white image of a room with a chair: [0, 0, 383, 82]; a gray piece of paper with a black background: [0, 0, 164, 72]; a silhouette of a mountain with a black background: [170, 0, 213, 57]; a gray rectangle with a black background: [0, 49, 123, 24]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in a room with a lot of boxes; Dense Caption: the ground is covered in snow: [33, 64, 348, 209]; the basket is made of plastic: [120, 40, 201, 68]; the lego is holding a kite: [199, 25, 270, 76]; person wearing a pair of gloves: [212, 27, 248, 75]; red shirt on the person: [220, 41, 237, 59]; a yellow and blue flag: [220, 27, 241, 47]; a man with a snowboard: [74, 15, 306, 86]; the brown basket: [200, 46, 268, 72]; a stuffed bird on the box: [236, 42, 250, 55]; person in red and blue snow suit: [218, 40, 238, 74]; blue pants on a person: [218, 56, 234, 73]; ; Region Captions: a white sand field with a black background: [0, 63, 383, 149]; a black and white image of a room with a chair: [0, 0, 383, 82]; a gray piece of paper with a black background: [0, 0, 164, 72]; a silhouette of a mountain with a black background: [170, 0, 213, 57]; a gray rectangle with a black background: [0, 49, 123, 24]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft screenshot of a wooden shelf\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the boxes are made of cardboard: [4, 85, 308, 212]; empty room in the background: [0, 2, 379, 210]; a line of yellow tiles: [142, 119, 296, 211]; yellow and black checkered table cloth: [2, 120, 47, 161]; red and orange box: [16, 98, 142, 208]; the sky is clear: [125, 22, 330, 102]; white tablecloth on the table: [0, 150, 93, 212]; a black and white checkered mattress: [0, 85, 58, 131]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[76, 113, 217, 100]\n",
      "process_ann took 0.00 seconds\n",
      "[37, 103, 103, 101]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 153, 92, 60]\n",
      "process_ann took 0.00 seconds\n",
      "[12, 102, 89, 26]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.71 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a skeleton in a cave: [0, 0, 383, 212]; a block of wood with a wooden texture: [76, 113, 217, 100]; a wooden table with a wooden top: [37, 103, 103, 101]; a black and white image of a tiger: [0, 153, 92, 60]; a wooden bench with a wooden top: [12, 102, 89, 26]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft screenshot of a wooden shelf; Dense Caption: the boxes are made of cardboard: [4, 85, 308, 212]; empty room in the background: [0, 2, 379, 210]; a line of yellow tiles: [142, 119, 296, 211]; yellow and black checkered table cloth: [2, 120, 47, 161]; red and orange box: [16, 98, 142, 208]; the sky is clear: [125, 22, 330, 102]; white tablecloth on the table: [0, 150, 93, 212]; a black and white checkered mattress: [0, 85, 58, 131]; ; Region Captions: a black and white image of a skeleton in a cave: [0, 0, 383, 212]; a block of wood with a wooden texture: [76, 113, 217, 100]; a wooden table with a wooden top: [37, 103, 103, 101]; a black and white image of a tiger: [0, 153, 92, 60]; a wooden bench with a wooden top: [12, 102, 89, 26]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with wooden blocks on the floor\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the box is cardboard: [17, 96, 296, 211]; empty room in the background: [0, 2, 379, 210]; a black and white checkered mattress: [0, 84, 59, 154]; a line of yellow tiles: [143, 119, 296, 211]; the box is made of cardboard: [11, 98, 142, 208]; white sheets on the bed: [0, 146, 93, 212]; the wall is white: [125, 22, 330, 102]; the wall is white: [64, 16, 342, 143]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[13, 102, 280, 111]\n",
      "process_ann took 0.00 seconds\n",
      "[37, 106, 103, 99]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 148, 92, 65]\n",
      "process_ann took 0.00 seconds\n",
      "[12, 102, 86, 76]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.71 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a skeleton in a cave: [0, 0, 383, 212]; a block of wood in minecraft: [13, 102, 280, 111]; a wooden table with a black background: [37, 106, 103, 99]; a silver teddy bear sitting on a black surface: [0, 148, 92, 65]; a wooden block with a black background: [12, 102, 86, 76]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with wooden blocks on the floor; Dense Caption: the box is cardboard: [17, 96, 296, 211]; empty room in the background: [0, 2, 379, 210]; a black and white checkered mattress: [0, 84, 59, 154]; a line of yellow tiles: [143, 119, 296, 211]; the box is made of cardboard: [11, 98, 142, 208]; white sheets on the bed: [0, 146, 93, 212]; the wall is white: [125, 22, 330, 102]; the wall is white: [64, 16, 342, 143]; ; Region Captions: a black and white image of a skeleton in a cave: [0, 0, 383, 212]; a block of wood in minecraft: [13, 102, 280, 111]; a wooden table with a black background: [37, 106, 103, 99]; a silver teddy bear sitting on a black surface: [0, 148, 92, 65]; a wooden block with a black background: [12, 102, 86, 76]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a brown cardboard box: [330, 72, 382, 213]; a lego piece holding the snowboard: [242, 2, 351, 141]; white bedspread on the bed: [1, 46, 368, 211]; yellow and blue cardboard box: [268, 3, 344, 55]; yellow fire hydrant picture: [261, 83, 281, 120]; shadow of the snowboarder: [245, 116, 308, 150]; white bedsheet: [17, 65, 227, 209]; a small basket in the corner: [46, 35, 118, 57]; the snow is white in color: [58, 85, 173, 182]; blue and yellow hydrant: [255, 84, 304, 138]; two blue squares on the ribbon: [282, 57, 310, 81]; blue and white square: [274, 18, 315, 39]; red square of cardboard: [251, 46, 340, 102]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 53, 352, 159]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 62]\n",
      "process_ann took 0.00 seconds\n",
      "[334, 75, 49, 138]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 95, 56]\n",
      "process_ann took 0.00 seconds\n",
      "[220, 48, 163, 59]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a small white square with a black hole in it: [0, 53, 352, 159]; a silhouette of a building with a tall building in the background: [0, 0, 383, 62]; a brown and brown wooden block: [334, 75, 49, 138]; a gray square with a black background: [0, 0, 95, 56]; a black and white image of a stone wall: [220, 48, 163, 59]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a brown cardboard box: [330, 72, 382, 213]; a lego piece holding the snowboard: [242, 2, 351, 141]; white bedspread on the bed: [1, 46, 368, 211]; yellow and blue cardboard box: [268, 3, 344, 55]; yellow fire hydrant picture: [261, 83, 281, 120]; shadow of the snowboarder: [245, 116, 308, 150]; white bedsheet: [17, 65, 227, 209]; a small basket in the corner: [46, 35, 118, 57]; the snow is white in color: [58, 85, 173, 182]; blue and yellow hydrant: [255, 84, 304, 138]; two blue squares on the ribbon: [282, 57, 310, 81]; blue and white square: [274, 18, 315, 39]; red square of cardboard: [251, 46, 340, 102]; ; Region Captions: a small white square with a black hole in it: [0, 53, 352, 159]; a silhouette of a building with a tall building in the background: [0, 0, 383, 62]; a brown and brown wooden block: [334, 75, 49, 138]; a gray square with a black background: [0, 0, 95, 56]; a black and white image of a stone wall: [220, 48, 163, 59]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors of wood\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "an orange and white building: [7, 96, 251, 211]; a keyboard and a book: [28, 16, 329, 213]; red and orange building: [0, 95, 96, 211]; the sky is dark: [120, 18, 333, 96]; the sky is dark: [22, 14, 268, 102]; the line is black: [59, 103, 163, 173]; the sky is dark: [112, 36, 230, 96]; a white counter top: [244, 186, 381, 212]; red brick on side of building: [0, 132, 35, 211]; orange boarder of a surfboard: [1, 95, 91, 139]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 210]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 99, 248, 113]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 102, 95, 111]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 189, 379, 24]\n",
      "process_ann took 0.00 seconds\n",
      "[246, 189, 133, 24]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.72 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall with a black and white wall: [0, 1, 383, 210]; a block of wood in minecraft: [0, 99, 248, 113]; a wooden table with a wooden top: [0, 102, 95, 111]; a black and white image of a sailboat: [0, 189, 379, 24]; a gray triangle with a black background: [246, 189, 133, 24]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors of wood; Dense Caption: an orange and white building: [7, 96, 251, 211]; a keyboard and a book: [28, 16, 329, 213]; red and orange building: [0, 95, 96, 211]; the sky is dark: [120, 18, 333, 96]; the sky is dark: [22, 14, 268, 102]; the line is black: [59, 103, 163, 173]; the sky is dark: [112, 36, 230, 96]; a white counter top: [244, 186, 381, 212]; red brick on side of building: [0, 132, 35, 211]; orange boarder of a surfboard: [1, 95, 91, 139]; ; Region Captions: a black and white image of a wall with a black and white wall: [0, 1, 383, 210]; a block of wood in minecraft: [0, 99, 248, 113]; a wooden table with a wooden top: [0, 102, 95, 111]; a black and white image of a sailboat: [0, 189, 379, 24]; a gray triangle with a black background: [246, 189, 133, 24]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden table with different colors on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the building is made of wood: [0, 110, 247, 211]; a keyboard and mouse: [16, 37, 277, 210]; red section of a dock: [0, 113, 86, 156]; the sky is dark: [20, 29, 270, 128]; the sky is dark: [96, 55, 209, 112]; the line is black: [44, 118, 147, 185]; the right slat of the bench: [99, 125, 237, 194]; the sky is dark: [144, 54, 252, 113]; row of five drawers: [1, 164, 93, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 117, 244, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 119, 84, 33]\n",
      "process_ann took 0.00 seconds\n",
      "[201, 131, 15, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[180, 195, 19, 18]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.70 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 1, 383, 211]; a block of wood with different colors: [0, 117, 244, 96]; a wooden floor with a brown color: [0, 119, 84, 33]; a wooden staircase with a wooden floor: [201, 131, 15, 59]; a small brown teddy bear is standing on a black background: [180, 195, 19, 18]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden table with different colors on it; Dense Caption: the building is made of wood: [0, 110, 247, 211]; a keyboard and mouse: [16, 37, 277, 210]; red section of a dock: [0, 113, 86, 156]; the sky is dark: [20, 29, 270, 128]; the sky is dark: [96, 55, 209, 112]; the line is black: [44, 118, 147, 185]; the right slat of the bench: [99, 125, 237, 194]; the sky is dark: [144, 54, 252, 113]; row of five drawers: [1, 164, 93, 211]; ; Region Captions: a black and white image of a wall: [0, 1, 383, 211]; a block of wood with different colors: [0, 117, 244, 96]; a wooden floor with a brown color: [0, 119, 84, 33]; a wooden staircase with a wooden floor: [201, 131, 15, 59]; a small brown teddy bear is standing on a black background: [180, 195, 19, 18]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden table with different colors on it\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the building is made of wood: [0, 110, 247, 211]; a keyboard and mouse: [16, 37, 277, 210]; red section of a dock: [0, 113, 86, 156]; the sky is dark: [20, 29, 270, 128]; the sky is dark: [96, 55, 209, 112]; the line is black: [44, 118, 147, 185]; the right slat of the bench: [99, 125, 237, 194]; the sky is dark: [144, 54, 252, 113]; row of five drawers: [1, 164, 93, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 117, 244, 96]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 119, 84, 33]\n",
      "process_ann took 0.00 seconds\n",
      "[201, 131, 15, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[180, 195, 19, 18]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.71 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a wall: [0, 1, 383, 211]; a block of wood with different colors: [0, 117, 244, 96]; a wooden floor with a brown color: [0, 119, 84, 33]; a wooden staircase with a wooden floor: [201, 131, 15, 59]; a small brown teddy bear is standing on a black background: [180, 195, 19, 18]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden table with different colors on it; Dense Caption: the building is made of wood: [0, 110, 247, 211]; a keyboard and mouse: [16, 37, 277, 210]; red section of a dock: [0, 113, 86, 156]; the sky is dark: [20, 29, 270, 128]; the sky is dark: [96, 55, 209, 112]; the line is black: [44, 118, 147, 185]; the right slat of the bench: [99, 125, 237, 194]; the sky is dark: [144, 54, 252, 113]; row of five drawers: [1, 164, 93, 211]; ; Region Captions: a black and white image of a wall: [0, 1, 383, 211]; a block of wood with different colors: [0, 117, 244, 96]; a wooden floor with a brown color: [0, 119, 84, 33]; a wooden staircase with a wooden floor: [201, 131, 15, 59]; a small brown teddy bear is standing on a black background: [180, 195, 19, 18]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "orange and brown storage units: [141, 115, 381, 211]; a black and white checkered tablecloth: [0, 99, 126, 212]; the sky is dark: [38, 11, 351, 146]; the sky is overcast: [29, 64, 355, 211]; a line on a table: [244, 136, 268, 213]; red section of the bench: [250, 123, 382, 211]; the sky is grey: [36, 2, 350, 83]; the sky is dark: [162, 48, 288, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 120, 240, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 109, 123, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 120, 121, 93]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.53 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a speech bubble: [0, 0, 383, 171]; a block of wood in minecraft: [143, 120, 240, 92]; a man is standing on a black background: [0, 0, 383, 57]; a black and white square block: [0, 109, 123, 104]; a wooden box in minecraft: [143, 120, 121, 93]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: orange and brown storage units: [141, 115, 381, 211]; a black and white checkered tablecloth: [0, 99, 126, 212]; the sky is dark: [38, 11, 351, 146]; the sky is overcast: [29, 64, 355, 211]; a line on a table: [244, 136, 268, 213]; red section of the bench: [250, 123, 382, 211]; the sky is grey: [36, 2, 350, 83]; the sky is dark: [162, 48, 288, 105]; ; Region Captions: a black and white image of a speech bubble: [0, 0, 383, 171]; a block of wood in minecraft: [143, 120, 240, 92]; a man is standing on a black background: [0, 0, 383, 57]; a black and white square block: [0, 109, 123, 104]; a wooden box in minecraft: [143, 120, 121, 93]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "orange and brown storage units: [141, 115, 381, 211]; a black and white checkered tablecloth: [0, 99, 126, 212]; the sky is dark: [38, 11, 351, 146]; the sky is overcast: [29, 64, 355, 211]; a line on a table: [244, 136, 268, 213]; red section of the bench: [250, 123, 382, 211]; the sky is grey: [36, 2, 350, 83]; the sky is dark: [162, 48, 288, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 120, 240, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 109, 123, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 120, 121, 93]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.53 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a speech bubble: [0, 0, 383, 171]; a block of wood in minecraft: [143, 120, 240, 92]; a man is standing on a black background: [0, 0, 383, 57]; a black and white square block: [0, 109, 123, 104]; a wooden box in minecraft: [143, 120, 121, 93]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: orange and brown storage units: [141, 115, 381, 211]; a black and white checkered tablecloth: [0, 99, 126, 212]; the sky is dark: [38, 11, 351, 146]; the sky is overcast: [29, 64, 355, 211]; a line on a table: [244, 136, 268, 213]; red section of the bench: [250, 123, 382, 211]; the sky is grey: [36, 2, 350, 83]; the sky is dark: [162, 48, 288, 105]; ; Region Captions: a black and white image of a speech bubble: [0, 0, 383, 171]; a block of wood in minecraft: [143, 120, 240, 92]; a man is standing on a black background: [0, 0, 383, 57]; a black and white square block: [0, 109, 123, 104]; a wooden box in minecraft: [143, 120, 121, 93]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with two different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "orange and brown storage units: [141, 115, 381, 211]; a black and white checkered tablecloth: [0, 99, 126, 212]; the sky is dark: [38, 11, 351, 146]; the sky is overcast: [29, 64, 355, 211]; a line on a table: [244, 136, 268, 213]; red section of the bench: [250, 123, 382, 211]; the sky is grey: [36, 2, 350, 83]; the sky is dark: [162, 48, 288, 105]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 171]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 120, 240, 92]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 109, 123, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 120, 121, 93]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.53 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a speech bubble: [0, 0, 383, 171]; a block of wood in minecraft: [143, 120, 240, 92]; a man is standing on a black background: [0, 0, 383, 57]; a black and white square block: [0, 109, 123, 104]; a wooden box in minecraft: [143, 120, 121, 93]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with two different colors; Dense Caption: orange and brown storage units: [141, 115, 381, 211]; a black and white checkered tablecloth: [0, 99, 126, 212]; the sky is dark: [38, 11, 351, 146]; the sky is overcast: [29, 64, 355, 211]; a line on a table: [244, 136, 268, 213]; red section of the bench: [250, 123, 382, 211]; the sky is grey: [36, 2, 350, 83]; the sky is dark: [162, 48, 288, 105]; ; Region Captions: a black and white image of a speech bubble: [0, 0, 383, 171]; a block of wood in minecraft: [143, 120, 240, 92]; a man is standing on a black background: [0, 0, 383, 57]; a black and white square block: [0, 109, 123, 104]; a wooden box in minecraft: [143, 120, 121, 93]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a box on the snow: [51, 57, 237, 131]; white snow on the ground: [37, 92, 349, 212]; a red square piece of cloth: [348, 79, 383, 176]; a square shaped building: [0, 54, 64, 119]; the photo was taken in the daytime: [1, 6, 378, 200]; the sky is dark: [39, 9, 301, 124]; red square on the bench: [88, 61, 147, 116]; line of black marks on box: [131, 67, 181, 122]; the sky is dark: [31, 4, 306, 69]; the snow is white: [23, 129, 248, 211]; a brown wooden slat: [177, 65, 235, 128]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 98, 383, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 119]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 60, 62, 57]\n",
      "process_ann took 0.00 seconds\n",
      "[90, 65, 56, 51]\n",
      "process_ann took 0.00 seconds\n",
      "[351, 81, 32, 94]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a white floor with a black background: [0, 98, 383, 114]; a black and white image of a man standing on a hill: [0, 1, 383, 119]; a black and white pixelated image of a minecraft block: [0, 60, 62, 57]; a wooden block on a black background: [90, 65, 56, 51]; red and yellow rug: [351, 81, 32, 94]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: a box on the snow: [51, 57, 237, 131]; white snow on the ground: [37, 92, 349, 212]; a red square piece of cloth: [348, 79, 383, 176]; a square shaped building: [0, 54, 64, 119]; the photo was taken in the daytime: [1, 6, 378, 200]; the sky is dark: [39, 9, 301, 124]; red square on the bench: [88, 61, 147, 116]; line of black marks on box: [131, 67, 181, 122]; the sky is dark: [31, 4, 306, 69]; the snow is white: [23, 129, 248, 211]; a brown wooden slat: [177, 65, 235, 128]; ; Region Captions: a white floor with a black background: [0, 98, 383, 114]; a black and white image of a man standing on a hill: [0, 1, 383, 119]; a black and white pixelated image of a minecraft block: [0, 60, 62, 57]; a wooden block on a black background: [90, 65, 56, 51]; red and yellow rug: [351, 81, 32, 94]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden table with a wooden top\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden structure: [2, 133, 261, 211]; sky is dark and cloudy: [0, 2, 380, 210]; orange sheet on the bed: [0, 139, 52, 169]; the sky is dark: [16, 34, 278, 174]; a white table top: [259, 184, 382, 212]; the line is white: [136, 139, 180, 213]; a line on the bench: [101, 139, 138, 213]; the sky is dark: [35, 11, 298, 125]; orange sheet on the bed: [0, 134, 58, 188]; red section of the wing: [4, 141, 34, 166]; a white and orange parachute: [21, 100, 350, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 198]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 137, 259, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[259, 189, 124, 24]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 143, 50, 24]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 139, 15, 50]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man with a hat: [0, 0, 383, 198]; a wooden plank on a black background: [0, 137, 259, 76]; a grey and white striped shirt: [259, 189, 124, 24]; a wooden floor with a brown color: [0, 143, 50, 24]; a wooden ladder with a wooden base: [150, 139, 15, 50]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden table with a wooden top; Dense Caption: a large wooden structure: [2, 133, 261, 211]; sky is dark and cloudy: [0, 2, 380, 210]; orange sheet on the bed: [0, 139, 52, 169]; the sky is dark: [16, 34, 278, 174]; a white table top: [259, 184, 382, 212]; the line is white: [136, 139, 180, 213]; a line on the bench: [101, 139, 138, 213]; the sky is dark: [35, 11, 298, 125]; orange sheet on the bed: [0, 134, 58, 188]; red section of the wing: [4, 141, 34, 166]; a white and orange parachute: [21, 100, 350, 210]; ; Region Captions: a black and white image of a man with a hat: [0, 0, 383, 198]; a wooden plank on a black background: [0, 137, 259, 76]; a grey and white striped shirt: [259, 189, 124, 24]; a wooden floor with a brown color: [0, 143, 50, 24]; a wooden ladder with a wooden base: [150, 139, 15, 50]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden table with a wooden top\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden structure: [2, 133, 261, 211]; sky is dark and cloudy: [0, 2, 380, 210]; orange sheet on the bed: [0, 139, 52, 169]; the sky is dark: [16, 34, 278, 174]; a white table top: [259, 184, 382, 212]; the line is white: [136, 139, 180, 213]; a line on the bench: [101, 139, 138, 213]; the sky is dark: [35, 11, 298, 125]; orange sheet on the bed: [0, 134, 58, 188]; red section of the wing: [4, 141, 34, 166]; a white and orange parachute: [21, 100, 350, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 198]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 137, 259, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[259, 189, 124, 24]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 143, 50, 24]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 139, 15, 50]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man with a hat: [0, 0, 383, 198]; a wooden plank on a black background: [0, 137, 259, 76]; a grey and white striped shirt: [259, 189, 124, 24]; a wooden floor with a brown color: [0, 143, 50, 24]; a wooden ladder with a wooden base: [150, 139, 15, 50]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden table with a wooden top; Dense Caption: a large wooden structure: [2, 133, 261, 211]; sky is dark and cloudy: [0, 2, 380, 210]; orange sheet on the bed: [0, 139, 52, 169]; the sky is dark: [16, 34, 278, 174]; a white table top: [259, 184, 382, 212]; the line is white: [136, 139, 180, 213]; a line on the bench: [101, 139, 138, 213]; the sky is dark: [35, 11, 298, 125]; orange sheet on the bed: [0, 134, 58, 188]; red section of the wing: [4, 141, 34, 166]; a white and orange parachute: [21, 100, 350, 210]; ; Region Captions: a black and white image of a man with a hat: [0, 0, 383, 198]; a wooden plank on a black background: [0, 137, 259, 76]; a grey and white striped shirt: [259, 189, 124, 24]; a wooden floor with a brown color: [0, 143, 50, 24]; a wooden ladder with a wooden base: [150, 139, 15, 50]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a wooden table with a wooden top\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a large wooden structure: [2, 133, 261, 211]; sky is dark and cloudy: [0, 2, 380, 210]; orange sheet on the bed: [0, 139, 52, 169]; the sky is dark: [16, 34, 278, 174]; a white table top: [259, 184, 382, 212]; the line is white: [136, 139, 180, 213]; a line on the bench: [101, 139, 138, 213]; the sky is dark: [35, 11, 298, 125]; orange sheet on the bed: [0, 134, 58, 188]; red section of the wing: [4, 141, 34, 166]; a white and orange parachute: [21, 100, 350, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 198]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 137, 259, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[259, 189, 124, 24]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 143, 50, 24]\n",
      "process_ann took 0.00 seconds\n",
      "[150, 139, 15, 50]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a man with a hat: [0, 0, 383, 198]; a wooden plank on a black background: [0, 137, 259, 76]; a grey and white striped shirt: [259, 189, 124, 24]; a wooden floor with a brown color: [0, 143, 50, 24]; a wooden ladder with a wooden base: [150, 139, 15, 50]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a wooden table with a wooden top; Dense Caption: a large wooden structure: [2, 133, 261, 211]; sky is dark and cloudy: [0, 2, 380, 210]; orange sheet on the bed: [0, 139, 52, 169]; the sky is dark: [16, 34, 278, 174]; a white table top: [259, 184, 382, 212]; the line is white: [136, 139, 180, 213]; a line on the bench: [101, 139, 138, 213]; the sky is dark: [35, 11, 298, 125]; orange sheet on the bed: [0, 134, 58, 188]; red section of the wing: [4, 141, 34, 166]; a white and orange parachute: [21, 100, 350, 210]; ; Region Captions: a black and white image of a man with a hat: [0, 0, 383, 198]; a wooden plank on a black background: [0, 137, 259, 76]; a grey and white striped shirt: [259, 189, 124, 24]; a wooden floor with a brown color: [0, 143, 50, 24]; a wooden ladder with a wooden base: [150, 139, 15, 50]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a red, yellow and blue color\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "yellow and blue post: [115, 18, 197, 150]; red white and yellow object: [0, 4, 101, 161]; white snow covering the ground: [34, 69, 353, 212]; blue base of a clock: [127, 89, 193, 146]; the boxes are yellow and red: [0, 7, 198, 164]; red box on the white table: [0, 85, 99, 161]; a black box on the floor: [311, 54, 382, 77]; yellow square of the clock: [118, 22, 191, 92]; a yellow diamond shaped sign: [63, 20, 99, 52]; yellow section of the kite: [0, 19, 90, 99]; a vent in the wall: [88, 58, 127, 85]; the wall is white: [86, 0, 368, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 70, 383, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 71]\n",
      "process_ann took 0.00 seconds\n",
      "[118, 24, 72, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 21, 87, 77]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 85, 96, 73]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.60 seconds\n",
      "finished...\n",
      "\n",
      "a small white building with a black door: [0, 70, 383, 142]; a black and white image of a building: [0, 0, 383, 71]; a blue and yellow square with a yellow and blue border: [118, 24, 72, 122]; a gold block with a pixelated design: [0, 21, 87, 77]; a red square block on a black background: [0, 85, 96, 73]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a red, yellow and blue color; Dense Caption: yellow and blue post: [115, 18, 197, 150]; red white and yellow object: [0, 4, 101, 161]; white snow covering the ground: [34, 69, 353, 212]; blue base of a clock: [127, 89, 193, 146]; the boxes are yellow and red: [0, 7, 198, 164]; red box on the white table: [0, 85, 99, 161]; a black box on the floor: [311, 54, 382, 77]; yellow square of the clock: [118, 22, 191, 92]; a yellow diamond shaped sign: [63, 20, 99, 52]; yellow section of the kite: [0, 19, 90, 99]; a vent in the wall: [88, 58, 127, 85]; the wall is white: [86, 0, 368, 73]; ; Region Captions: a small white building with a black door: [0, 70, 383, 142]; a black and white image of a building: [0, 0, 383, 71]; a blue and yellow square with a yellow and blue border: [118, 24, 72, 122]; a gold block with a pixelated design: [0, 21, 87, 77]; a red square block on a black background: [0, 85, 96, 73]; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with a red and yellow color\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "red box in the corner: [0, 146, 43, 212]; small square shaped ottoman: [170, 101, 254, 132]; a red yellow and blue box: [42, 42, 180, 206]; blue base of a yellow box: [92, 130, 173, 205]; the floor is white: [1, 116, 382, 211]; yellow section of the clock: [92, 73, 171, 140]; the red base of the snowboard: [50, 122, 95, 172]; lego set up for a birthday party: [40, 36, 356, 211]; yellow section of the cake: [49, 81, 93, 127]; white table top: [190, 131, 368, 211]; the wall is white: [198, 1, 381, 127]; red and yellow box: [47, 48, 129, 172]; a colorful box on top of the cake: [87, 47, 128, 82]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 0, 383, 156]\n",
      "process_ann took 0.00 seconds\n",
      "[31, 123, 352, 90]\n",
      "process_ann took 0.00 seconds\n",
      "[201, 0, 182, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 199, 157]\n",
      "process_ann took 0.00 seconds\n",
      "[93, 76, 77, 127]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a silhouette of a building with a clock on it: [0, 0, 383, 156]; a white iceberg with a black background: [31, 123, 352, 90]; a gray state with a white background: [201, 0, 182, 130]; a silhouette of a man standing on a hill: [0, 0, 199, 157]; a blue and yellow box with a blue and yellow stripe: [93, 76, 77, 127]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with a red and yellow color; Dense Caption: red box in the corner: [0, 146, 43, 212]; small square shaped ottoman: [170, 101, 254, 132]; a red yellow and blue box: [42, 42, 180, 206]; blue base of a yellow box: [92, 130, 173, 205]; the floor is white: [1, 116, 382, 211]; yellow section of the clock: [92, 73, 171, 140]; the red base of the snowboard: [50, 122, 95, 172]; lego set up for a birthday party: [40, 36, 356, 211]; yellow section of the cake: [49, 81, 93, 127]; white table top: [190, 131, 368, 211]; the wall is white: [198, 1, 381, 127]; red and yellow box: [47, 48, 129, 172]; a colorful box on top of the cake: [87, 47, 128, 82]; ; Region Captions: a silhouette of a building with a clock on it: [0, 0, 383, 156]; a white iceberg with a black background: [31, 123, 352, 90]; a gray state with a white background: [201, 0, 182, 130]; a silhouette of a man standing on a hill: [0, 0, 199, 157]; a blue and yellow box with a blue and yellow stripe: [93, 76, 77, 127]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft block with different colors\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "orange and brown tower: [134, 104, 380, 211]; black and white checkered umbrella: [1, 96, 110, 212]; the sky is grey: [36, 3, 353, 128]; a person is on a bed: [69, 23, 358, 210]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 164]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 108, 248, 104]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 108, 136, 105]\n",
      "process_ann took 0.00 seconds\n",
      "[243, 110, 140, 102]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 1, 383, 31]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.71 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a cloudy sky: [0, 1, 383, 164]; a block of wood in minecraft: [135, 108, 248, 104]; a wooden box in minecraft: [135, 108, 136, 105]; a wooden plank on a black background: [243, 110, 140, 102]; a city with a black background and a cloud: [0, 1, 383, 31]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft block with different colors; Dense Caption: orange and brown tower: [134, 104, 380, 211]; black and white checkered umbrella: [1, 96, 110, 212]; the sky is grey: [36, 3, 353, 128]; a person is on a bed: [69, 23, 358, 210]; ; Region Captions: a black and white image of a building with a cloudy sky: [0, 1, 383, 164]; a block of wood in minecraft: [135, 108, 248, 104]; a wooden box in minecraft: [135, 108, 136, 105]; a wooden plank on a black background: [243, 110, 140, 102]; a city with a black background and a cloud: [0, 1, 383, 31]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a red, blue, and yellow block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a blue and red striped box: [117, 1, 326, 156]; a blue and yellow lego snowboard: [1, 1, 381, 209]; the square is red: [144, 80, 239, 153]; red and yellow object: [42, 0, 135, 95]; blue square on the end of the kite: [130, 0, 254, 85]; yellow part of the sign: [44, 0, 128, 49]; red section of a caution cone: [65, 42, 135, 95]; a black object on the side of the bed: [337, 18, 383, 44]; a blue section of the snowboard: [229, 55, 324, 149]; snowboard is red and yellow: [37, 1, 252, 177]; the tie is blue: [146, 3, 258, 145]; black writing on the tag: [161, 88, 222, 142]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 37, 383, 175]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[132, 0, 119, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[144, 59, 179, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 59, 95, 88]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.53 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a small square: [0, 37, 383, 175]; a black and white image of a door: [0, 0, 383, 114]; a blue square block on a black background: [132, 0, 119, 85]; a blue block with a black background: [144, 59, 179, 88]; a blue block with a square shape: [228, 59, 95, 88]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a red, blue, and yellow block in minecraft; Dense Caption: a blue and red striped box: [117, 1, 326, 156]; a blue and yellow lego snowboard: [1, 1, 381, 209]; the square is red: [144, 80, 239, 153]; red and yellow object: [42, 0, 135, 95]; blue square on the end of the kite: [130, 0, 254, 85]; yellow part of the sign: [44, 0, 128, 49]; red section of a caution cone: [65, 42, 135, 95]; a black object on the side of the bed: [337, 18, 383, 44]; a blue section of the snowboard: [229, 55, 324, 149]; snowboard is red and yellow: [37, 1, 252, 177]; the tie is blue: [146, 3, 258, 145]; black writing on the tag: [161, 88, 222, 142]; ; Region Captions: a black and white image of a small square: [0, 37, 383, 175]; a black and white image of a door: [0, 0, 383, 114]; a blue square block on a black background: [132, 0, 119, 85]; a blue block with a black background: [144, 59, 179, 88]; a blue block with a square shape: [228, 59, 95, 88]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a red, blue and yellow block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "snow covering the ground: [64, 1, 329, 160]; the square is red: [144, 80, 239, 153]; yellow and red cone: [42, 0, 135, 95]; white table with item: [1, 24, 381, 209]; yellow part of the parking meter: [44, 0, 128, 49]; red section of the object: [65, 42, 135, 95]; blue vase on the table: [130, 0, 253, 85]; a blue section of the snowboard: [229, 55, 324, 149]; a black object on the side of the bed: [337, 18, 383, 44]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 37, 383, 175]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 114]\n",
      "process_ann took 0.00 seconds\n",
      "[132, 0, 118, 85]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 59, 95, 88]\n",
      "process_ann took 0.00 seconds\n",
      "[143, 59, 180, 88]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a square: [0, 37, 383, 175]; a black and white image of a room with a window: [0, 0, 383, 114]; a blue square block on a black background: [132, 0, 118, 85]; a blue block with a square shape: [228, 59, 95, 88]; a blue block with a blue background: [143, 59, 180, 88]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a red, blue and yellow block in minecraft; Dense Caption: snow covering the ground: [64, 1, 329, 160]; the square is red: [144, 80, 239, 153]; yellow and red cone: [42, 0, 135, 95]; white table with item: [1, 24, 381, 209]; yellow part of the parking meter: [44, 0, 128, 49]; red section of the object: [65, 42, 135, 95]; blue vase on the table: [130, 0, 253, 85]; a blue section of the snowboard: [229, 55, 324, 149]; a black object on the side of the bed: [337, 18, 383, 44]; ; Region Captions: a black and white image of a square: [0, 37, 383, 175]; a black and white image of a room with a window: [0, 0, 383, 114]; a blue square block on a black background: [132, 0, 118, 85]; a blue block with a square shape: [228, 59, 95, 88]; a blue block with a blue background: [143, 59, 180, 88]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a red, blue and yellow block in minecraft\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the chair is blue: [48, 12, 257, 211]; white bedspread on the bed: [0, 65, 381, 211]; the square is yellow and red: [0, 36, 70, 165]; red square on the sign: [83, 120, 189, 212]; yellow section of the object: [0, 38, 61, 104]; back of the chair is blue: [58, 14, 189, 135]; a dark colored basket: [251, 64, 316, 82]; a blue section of the suitcase: [184, 94, 253, 190]; a white wall: [51, 1, 294, 82]; white tablecloth on the table: [266, 93, 375, 206]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 79, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[134, 80, 249, 132]\n",
      "process_ann took 0.00 seconds\n",
      "[59, 15, 126, 122]\n",
      "process_ann took 0.00 seconds\n",
      "[58, 15, 182, 157]\n",
      "process_ann took 0.00 seconds\n",
      "[1, 0, 286, 80]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a snowy mountain: [0, 79, 383, 133]; a white and black image of a skateboard: [134, 80, 249, 132]; a blue and white square with a white border: [59, 15, 126, 122]; blue squares in minecraft: [58, 15, 182, 157]; a black and white image of a psd file: [1, 0, 286, 80]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a red, blue and yellow block in minecraft; Dense Caption: the chair is blue: [48, 12, 257, 211]; white bedspread on the bed: [0, 65, 381, 211]; the square is yellow and red: [0, 36, 70, 165]; red square on the sign: [83, 120, 189, 212]; yellow section of the object: [0, 38, 61, 104]; back of the chair is blue: [58, 14, 189, 135]; a dark colored basket: [251, 64, 316, 82]; a blue section of the suitcase: [184, 94, 253, 190]; a white wall: [51, 1, 294, 82]; white tablecloth on the table: [266, 93, 375, 206]; ; Region Captions: a black and white image of a snowy mountain: [0, 79, 383, 133]; a white and black image of a skateboard: [134, 80, 249, 132]; a blue and white square with a white border: [59, 15, 126, 122]; blue squares in minecraft: [58, 15, 182, 157]; a black and white image of a psd file: [1, 0, 286, 80]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in front of a square block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the stack of blue and yellow boxes: [2, 1, 225, 212]; lego person is holding a snowboard: [223, 27, 275, 122]; the paper is white: [252, 172, 352, 212]; red part of the object: [226, 55, 267, 91]; shadow of the object: [222, 103, 264, 123]; flat white desk top: [5, 58, 369, 212]; yellow square on the side of a blue and white striped box: [163, 93, 217, 179]; a toy on the ground: [208, 16, 294, 147]; blue and red stripes: [231, 87, 257, 116]; the line is yellow: [102, 38, 178, 154]; yellow stripe on the flag: [2, 1, 159, 146]; the post is blue and yellow: [117, 56, 193, 175]; blue and yellow box: [155, 3, 221, 181]; the base of the hydrant is blue: [229, 59, 266, 119]; yellow stripe on the flag: [52, 47, 151, 136]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 64, 383, 148]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 64, 248, 148]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 162, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[158, 0, 225, 70]\n",
      "process_ann took 0.00 seconds\n",
      "[35, 114, 132, 99]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.68 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a door: [0, 64, 383, 148]; a black and white image of a person standing in a room: [135, 64, 248, 148]; a yellow square with a pixelated pattern: [0, 0, 162, 160]; a black and white image of a building with a sign: [158, 0, 225, 70]; a blue square with a black background: [35, 114, 132, 99]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a person standing in front of a square block; Dense Caption: the stack of blue and yellow boxes: [2, 1, 225, 212]; lego person is holding a snowboard: [223, 27, 275, 122]; the paper is white: [252, 172, 352, 212]; red part of the object: [226, 55, 267, 91]; shadow of the object: [222, 103, 264, 123]; flat white desk top: [5, 58, 369, 212]; yellow square on the side of a blue and white striped box: [163, 93, 217, 179]; a toy on the ground: [208, 16, 294, 147]; blue and red stripes: [231, 87, 257, 116]; the line is yellow: [102, 38, 178, 154]; yellow stripe on the flag: [2, 1, 159, 146]; the post is blue and yellow: [117, 56, 193, 175]; blue and yellow box: [155, 3, 221, 181]; the base of the hydrant is blue: [229, 59, 266, 119]; yellow stripe on the flag: [52, 47, 151, 136]; ; Region Captions: a black and white image of a door: [0, 64, 383, 148]; a black and white image of a person standing in a room: [135, 64, 248, 148]; a yellow square with a pixelated pattern: [0, 0, 162, 160]; a black and white image of a building with a sign: [158, 0, 225, 70]; a blue square with a black background: [35, 114, 132, 99]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a blue and yellow square in a minecraft game\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "the stack of blue and yellow boxes: [2, 1, 226, 212]; the corner of a piece of paper: [252, 172, 352, 212]; flat white desk top: [29, 63, 358, 213]; yellow stripe on the flag: [1, 1, 160, 150]; yellow square on the side of a blue and white striped box: [163, 93, 217, 179]; a small basket on the floor: [215, 46, 251, 67]; the line is yellow: [104, 40, 177, 151]; white wall in the background: [224, 0, 380, 69]; the ground is white: [196, 62, 373, 212]; a drain in the middle of the floor: [234, 70, 256, 82]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 63, 383, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[135, 63, 248, 149]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 162, 160]\n",
      "process_ann took 0.00 seconds\n",
      "[219, 0, 164, 69]\n",
      "process_ann took 0.00 seconds\n",
      "[35, 114, 132, 99]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.67 seconds\n",
      "finished...\n",
      "\n",
      "a white wall with a white door: [0, 63, 383, 149]; a white plate with a black background: [135, 63, 248, 149]; a yellow square on a black background: [0, 0, 162, 160]; a gray t shirt with the word arizona on it: [219, 0, 164, 69]; a blue square on a black background: [35, 114, 132, 99]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a blue and yellow square in a minecraft game; Dense Caption: the stack of blue and yellow boxes: [2, 1, 226, 212]; the corner of a piece of paper: [252, 172, 352, 212]; flat white desk top: [29, 63, 358, 213]; yellow stripe on the flag: [1, 1, 160, 150]; yellow square on the side of a blue and white striped box: [163, 93, 217, 179]; a small basket on the floor: [215, 46, 251, 67]; the line is yellow: [104, 40, 177, 151]; white wall in the background: [224, 0, 380, 69]; the ground is white: [196, 62, 373, 212]; a drain in the middle of the floor: [234, 70, 256, 82]; ; Region Captions: a white wall with a white door: [0, 63, 383, 149]; a white plate with a black background: [135, 63, 248, 149]; a yellow square on a black background: [0, 0, 162, 160]; a gray t shirt with the word arizona on it: [219, 0, 164, 69]; a blue square on a black background: [35, 114, 132, 99]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with red, blue and yellow blocks\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a stack of books: [0, 107, 100, 211]; red section of a snowboard: [155, 67, 209, 117]; a red and blue wall: [261, 0, 383, 211]; red and yellow box: [149, 7, 215, 119]; a black metal basket: [209, 40, 255, 67]; the ground is white: [3, 2, 381, 210]; the white table: [76, 65, 318, 213]; the boxes are yellow: [148, 5, 308, 122]; white table cloth: [106, 110, 252, 211]; yellow square on the wall: [250, 6, 304, 75]; two yellow square boxes: [154, 9, 299, 71]; the corner of a mattress: [242, 3, 306, 127]; the boxes are made of cardboard: [139, 5, 353, 183]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[80, 6, 215, 206]\n",
      "process_ann took 0.00 seconds\n",
      "[80, 67, 205, 145]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 303, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 189, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[282, 0, 101, 211]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a white floor with a black background: [80, 6, 215, 206]; a white floor with a white floor: [80, 67, 205, 145]; a black and gray png image of a door: [0, 0, 303, 140]; a gray png image of a png file: [0, 0, 189, 140]; a blue pixelated block with a red and blue border: [282, 0, 101, 211]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with red, blue and yellow blocks; Dense Caption: a stack of books: [0, 107, 100, 211]; red section of a snowboard: [155, 67, 209, 117]; a red and blue wall: [261, 0, 383, 211]; red and yellow box: [149, 7, 215, 119]; a black metal basket: [209, 40, 255, 67]; the ground is white: [3, 2, 381, 210]; the white table: [76, 65, 318, 213]; the boxes are yellow: [148, 5, 308, 122]; white table cloth: [106, 110, 252, 211]; yellow square on the wall: [250, 6, 304, 75]; two yellow square boxes: [154, 9, 299, 71]; the corner of a mattress: [242, 3, 306, 127]; the boxes are made of cardboard: [139, 5, 353, 183]; ; Region Captions: a white floor with a black background: [80, 6, 215, 206]; a white floor with a white floor: [80, 67, 205, 145]; a black and gray png image of a door: [0, 0, 303, 140]; a gray png image of a png file: [0, 0, 189, 140]; a blue pixelated block with a red and blue border: [282, 0, 101, 211]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character standing in a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red and blue object: [0, 0, 139, 210]; a red and yellow fire hydrant: [201, 35, 265, 144]; a fire hydrant: [181, 27, 283, 165]; a scene outside: [1, 0, 382, 210]; shadow of the hydrant: [203, 125, 254, 151]; the red part of the hydrant: [204, 65, 263, 110]; a white snowy ground: [121, 66, 375, 211]; blue and red painted post: [214, 107, 246, 142]; yellow wheel on a skateboard: [211, 90, 224, 121]; square blue stripe on the hydrant: [218, 54, 253, 81]; red section of a large object: [105, 20, 137, 110]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[126, 73, 257, 140]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 139, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[81, 0, 302, 100]\n",
      "process_ann took 0.00 seconds\n",
      "[233, 0, 150, 76]\n",
      "process_ann took 0.00 seconds\n",
      "[80, 0, 153, 71]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a person is standing on a snowy path: [126, 73, 257, 140]; a blue and red square block in minecraft: [0, 0, 139, 212]; a black and white image of a room with a door: [81, 0, 302, 100]; a gray cat standing on a black background: [233, 0, 150, 76]; a grey t shirt with a black background: [80, 0, 153, 71]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character standing in a room; Dense Caption: a red and blue object: [0, 0, 139, 210]; a red and yellow fire hydrant: [201, 35, 265, 144]; a fire hydrant: [181, 27, 283, 165]; a scene outside: [1, 0, 382, 210]; shadow of the hydrant: [203, 125, 254, 151]; the red part of the hydrant: [204, 65, 263, 110]; a white snowy ground: [121, 66, 375, 211]; blue and red painted post: [214, 107, 246, 142]; yellow wheel on a skateboard: [211, 90, 224, 121]; square blue stripe on the hydrant: [218, 54, 253, 81]; red section of a large object: [105, 20, 137, 110]; ; Region Captions: a person is standing on a snowy path: [126, 73, 257, 140]; a blue and red square block in minecraft: [0, 0, 139, 212]; a black and white image of a room with a door: [81, 0, 302, 100]; a gray cat standing on a black background: [233, 0, 150, 76]; a grey t shirt with a black background: [80, 0, 153, 71]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft character is standing in front of a room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a red blue and orange striped object: [199, 1, 381, 211]; the wood is brown: [1, 22, 183, 90]; snow covering the ground: [0, 2, 382, 210]; the sign is in the snow: [0, 72, 86, 212]; yellow and black pattern on a piece of cardboard: [1, 76, 83, 128]; snow on the ground: [46, 56, 280, 213]; a blue and white circle: [0, 150, 64, 212]; the snowboard is red and blue: [158, 2, 317, 181]; yellow and black square: [39, 77, 82, 120]; dark blue and orange stripes on the right side of the umbrella: [200, 1, 254, 138]; the snowboarders are on a slope: [0, 21, 182, 209]; white snow on the ground: [74, 83, 210, 211]; three squares on a kite: [199, 55, 241, 136]; red section of the object: [240, 3, 381, 135]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[204, 0, 179, 212]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 57, 329, 155]\n",
      "process_ann took 0.00 seconds\n",
      "[241, 0, 142, 142]\n",
      "process_ann took 0.00 seconds\n",
      "[228, 78, 155, 135]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 28, 179, 58]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.49 seconds\n",
      "finished...\n",
      "\n",
      "a red and blue square block in minecraft: [204, 0, 179, 212]; a white map with a star on it: [0, 57, 329, 155]; red pixelated bag in minecraft: [241, 0, 142, 142]; blue block png: [228, 78, 155, 135]; a stack of wooden blocks in minecraft: [0, 28, 179, 58]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft character is standing in front of a room; Dense Caption: a red blue and orange striped object: [199, 1, 381, 211]; the wood is brown: [1, 22, 183, 90]; snow covering the ground: [0, 2, 382, 210]; the sign is in the snow: [0, 72, 86, 212]; yellow and black pattern on a piece of cardboard: [1, 76, 83, 128]; snow on the ground: [46, 56, 280, 213]; a blue and white circle: [0, 150, 64, 212]; the snowboard is red and blue: [158, 2, 317, 181]; yellow and black square: [39, 77, 82, 120]; dark blue and orange stripes on the right side of the umbrella: [200, 1, 254, 138]; the snowboarders are on a slope: [0, 21, 182, 209]; white snow on the ground: [74, 83, 210, 211]; three squares on a kite: [199, 55, 241, 136]; red section of the object: [240, 3, 381, 135]; ; Region Captions: a red and blue square block in minecraft: [204, 0, 179, 212]; a white map with a star on it: [0, 57, 329, 155]; red pixelated bag in minecraft: [241, 0, 142, 142]; blue block png: [228, 78, 155, 135]; a stack of wooden blocks in minecraft: [0, 28, 179, 58]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a minecraft room with a red and yellow block\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a multi colored box: [0, 89, 241, 190]; red and yellow object: [330, 40, 383, 187]; snow on the ground: [0, 123, 381, 212]; a brown and yellow box: [3, 19, 285, 208]; yellow and black pattern on umbrella: [0, 141, 64, 199]; red section of a snowboard: [334, 104, 383, 180]; dark grey sky: [0, 2, 371, 140]; yellow section of the object: [347, 42, 383, 109]; line of squares on board: [136, 95, 184, 158]; the sky is dark: [86, 49, 217, 94]; a brown and tan suitcase: [118, 94, 240, 163]; the sky is dark: [18, 34, 264, 107]; red brick wall: [51, 97, 131, 166]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 133]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 133, 383, 79]\n",
      "process_ann took 0.00 seconds\n",
      "[336, 44, 47, 136]\n",
      "process_ann took 0.00 seconds\n",
      "[52, 99, 79, 66]\n",
      "process_ann took 0.00 seconds\n",
      "[336, 106, 47, 74]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.57 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a puddle: [0, 1, 383, 133]; a white and black image of a mountain: [0, 133, 383, 79]; a red and yellow pixelated block: [336, 44, 47, 136]; a wooden bench with a wooden top: [52, 99, 79, 66]; a red square on a black background: [336, 106, 47, 74]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a minecraft room with a red and yellow block; Dense Caption: a multi colored box: [0, 89, 241, 190]; red and yellow object: [330, 40, 383, 187]; snow on the ground: [0, 123, 381, 212]; a brown and yellow box: [3, 19, 285, 208]; yellow and black pattern on umbrella: [0, 141, 64, 199]; red section of a snowboard: [334, 104, 383, 180]; dark grey sky: [0, 2, 371, 140]; yellow section of the object: [347, 42, 383, 109]; line of squares on board: [136, 95, 184, 158]; the sky is dark: [86, 49, 217, 94]; a brown and tan suitcase: [118, 94, 240, 163]; the sky is dark: [18, 34, 264, 107]; red brick wall: [51, 97, 131, 166]; ; Region Captions: a black and white image of a puddle: [0, 1, 383, 133]; a white and black image of a mountain: [0, 133, 383, 79]; a red and yellow pixelated block: [336, 44, 47, 136]; a wooden bench with a wooden top: [52, 99, 79, 66]; a red square on a black background: [336, 106, 47, 74]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a bed with a bedside table and a bed\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Step2, Dense Caption:\n",
      "\n",
      "a building with a white and blue stripe: [0, 150, 87, 212]; a brown wooden building: [139, 141, 382, 211]; the sky is dark: [37, 13, 350, 178]; yellow and black sign: [337, 122, 383, 175]; a brown section of a roof: [142, 151, 282, 211]; the sky is dark: [165, 82, 282, 141]; the sky is dark: [130, 59, 372, 211]; the sky is dark: [22, 72, 286, 203]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step3, Semantic Prompt:\n",
      "extract region segmentation with SAM model....\n",
      "\n",
      "finished...\n",
      "\n",
      "generate region supervision with edit anything model....\n",
      "\n",
      "[0, 1, 383, 211]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 0, 383, 83]\n",
      "process_ann took 0.00 seconds\n",
      "[0, 82, 383, 130]\n",
      "process_ann took 0.00 seconds\n",
      "[141, 154, 142, 59]\n",
      "process_ann took 0.00 seconds\n",
      "[238, 153, 145, 60]\n",
      "process_ann took 0.00 seconds\n",
      "region_level_semantic_api took 0.64 seconds\n",
      "finished...\n",
      "\n",
      "a black and white image of a building with a clock: [0, 1, 383, 211]; a black and white image of a person: [0, 0, 383, 83]; a black and white image of a black and white image: [0, 82, 383, 130]; a wooden table with a wooden top: [141, 154, 142, 59]; a wooden plank on a black background: [238, 153, 145, 60]; \n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "Generated Text:\n",
      "Caption: a bed with a bedside table and a bed; Dense Caption: a building with a white and blue stripe: [0, 150, 87, 212]; a brown wooden building: [139, 141, 382, 211]; the sky is dark: [37, 13, 350, 178]; yellow and black sign: [337, 122, 383, 175]; a brown section of a roof: [142, 151, 282, 211]; the sky is dark: [165, 82, 282, 141]; the sky is dark: [130, 59, 372, 211]; the sky is dark: [22, 72, 286, 203]; ; Region Captions: a black and white image of a building with a clock: [0, 1, 383, 211]; a black and white image of a person: [0, 0, 383, 83]; a black and white image of a black and white image: [0, 82, 383, 130]; a wooden table with a wooden top: [141, 154, 142, 59]; a wooden plank on a black background: [238, 153, 145, 60]; \n",
      "Namespace(image_src='/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png', gpt_version='gpt-3.5-turbo', image_caption=True, dense_caption=True, semantic_segment=True, sam_arch='vit_b', captioner_base_model='blip2', region_classify_model='edit_anything', image_caption_device='cuda', dense_caption_device='cuda', semantic_segment_device='cuda', contolnet_device='cpu')\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n",
      "\n",
      "Step1, BLIP2 caption:\n",
      "a person standing in a minecraft room\n",
      "\u001b[1;35m****************************************************************************************************\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py --semantic_segment --captioner_base_model blip2 --image_src \"/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png\" --image_caption_device cuda --semantic_segment_device cuda --dense_caption_device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "YZPnoglpua40",
    "outputId": "5f28b70d-9c24-4034-a7a5-aeeb5d43810d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=852x477>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "pil_im = Image.open('/home/anrao/MindCraft/experiments/Frames_60/main_logs/141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618/play1_141_212_108_99_20210325_121618_0008.png')\n",
    "display(pil_im)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
